% This file was created with JabRef 2.10.
% Encoding: UTF-8


@InProceedings{Abal:2014:VBL:2642937.2642990,
  Title                    = {42 Variability Bugs in the Linux Kernel: A Qualitative Analysis},
  Author                   = {Abal, Iago and Brabrand, Claus and Wasowski, Andrzej},
  Booktitle                = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
  Year                     = {2014},

  Address                  = {New York, NY, USA},
  Pages                    = {421--432},
  Publisher                = {ACM},
  Series                   = {ASE '14},

  Acmid                    = {2642990},
  Doi                      = {10.1145/2642937.2642990},
  ISBN                     = {978-1-4503-3013-8},
  Keywords                 = {bugs, feature interactions, linux, software variability},
  Location                 = {Vasteras, Sweden},
  Numpages                 = {12},
  Url                      = {http://doi.acm.org/10.1145/2642937.2642990}
}

@InProceedings{Abbasi2014,
  Title                    = {Reverse engineering web configurators},
  Author                   = {Abbasi, Ebrahim Khalil and Acher, Mathieu and Heymans, Patrick and Cleve, Anthony},
  Booktitle                = {17th European Conference on Software Maintenance and Reengineering (CSMR), Feb 2014, Antwerp, Belgium. IEEE, 2014},
  Year                     = {2014},
  Pages                    = {264--273},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {A Web configurator offers a highly interactive environment to assist users in customising sales products through the selection of configuration options. Our previous empirical study revealed that a significant number of configurators are suboptimal in reliability, efficiency, and maintainability, opening avenues for re-engineering support and methodologies. This paper presents a tool-supported reverse-engineering process to semi-automatically extract configuration-specific data from a legacy Web configurator. The extracted and structured data is stored in formal models (e.g., variability models) and can be used in a forward-engineering process to generate a customized interface with an underlying reliable reasoning engine. Two major components are presented: (1) a Web Wrapper that extracts structured configuration-specific data from unstructured or semistructured Web pages of a configurator, and (2) a Web Crawler that explores the 'configuration space' (i.e., all objects representing configuration-specific data) and simulates users' configuration actions. We describe variability data extraction patterns, used on top of the Wrapper and the Crawler to extract configuration data. Experimental results on five existing Web configurators show that the specification of a few variability patterns enable the identification of hundreds of options. {\textcopyright} 2014 IEEE.},
  Doi                      = {10.1109/CSMR-WCRE.2014.6747178}
}

@InProceedings{Abele2010,
  Title                    = {The CVM Framework-A Prototype Tool for Compositional Variability Management.},
  Author                   = {Abele, A and Papadopoulos, Y and Servat, D and T{\"{o}}rngren, M},
  Booktitle                = {Vamos},
  Year                     = {2010},

  Journal                  = {VaMoS},
  Url                      = {https://pdfs.semanticscholar.org/512b/682a9a6c500f5965f2ffc7b7029ff9464913.pdf}
}

@InProceedings{Acher2014,
  Title                    = {Customization and 3D printing: A challenging playground for software product lines},
  Author                   = {Acher, Mathieu and Baudry, Benoit and Barais, Olivier and J{\'{e}}z{\'{e}}quel, Jean Marc},
  Booktitle                = {SPLC},
  Year                     = {2014},
  Month                    = {sep},
  Pages                    = {142--146},
  Publisher                = {Association for Computing Machinery},
  Volume                   = {1},

  Abstract                 = {3D printing is gaining more and more momentum to build customized product in a wide variety of fields. We conduct an exploratory study of Thingiverse, the most popular Website for sharing user-created 3D design files, in order to establish a possible connection with software product line (SPL) engineering. We report on the socio-technical aspects and current practices for modeling variability, implementing variability, configuring and deriving products, and reusing artefacts. We provide hints that SPL-alike techniques are practically used in 3D printing and thus relevant. Finally, we discuss why the customization in the 3D printing field represents a challenging playground for SPL engineering. Copyright 2014 ACM.},
  Doi                      = {10.1145/2648511.2648526},
  ISBN                     = {9781450327404}
}

@InProceedings{Acher2013,
  Title                    = {Support for reverse engineering and maintaining feature models},
  Author                   = {Acher, M and Baudry, B and Heymans, P and Cleve, A},
  Year                     = {2013},

  Journal                  = {Proc.},
  Url                      = {http://dl.acm.org/citation.cfm?id=2430530}
}

@InProceedings{Acher2011a,
  Title                    = {Reverse engineering architectural feature models},
  Author                   = {Acher, M and Cleve, A and Collet, P and Merle, P and Duchien, L},
  Booktitle                = {European Conference of Software Architecture (ECSA)},
  Year                     = {2011},

  Journal                  = {Conf. Softw. {\ldots}},
  Url                      = {http://link.springer.com/10.1007{\%}2F978-3-642-23798-0{\_}25}
}

@Article{Acher2014a,
  Title                    = {Extraction and evolution of architectural variability models in plugin-based systems},
  Author                   = {Acher, Mathieu and Cleve, Anthony and Collet, Philippe and Merle, Philippe and Duchien, Laurence and Lahire, Philippe},
  Journal                  = {Software \& Systems Modeling (SoSyM),},
  Year                     = {2014},

  Month                    = {sep},
  Number                   = {4},
  Pages                    = {1367--1394},
  Volume                   = {13},

  Abstract                 = {Variability management is a key issue when building and evolving software-intensive systems, making it possible to extend, configure, customize and adapt such systems to customers' needs and specific deployment contexts. A wide form of variability can be found in extensible software systems, typically built on top of plugin-based architectures that offer a (large) number of configuration options through plugins. In an ideal world, a software architect should be able to generate a system variant on-demand, corresponding to a particular assembly of plugins. To this end, the variation points and constraints between architectural elements should be properly modeled and maintained over time (i.e., for each version of an architecture). A crucial, yet error-prone and time-consuming, task for a software architect is to build an accurate representation of the variability of an architecture, in order to prevent unsafe architectural variants and reach the highest possible level of flexibility. In this article, we propose a reverse engineering process for producing a variability model (i.e., a feature model) of a plugin-based architecture. We develop automated techniques to extract and combine different variability descriptions, including a hierarchical software architecture model, a plugin dependency model and the software architect knowledge. By computing and reasoning about differences between versions of architectural feature models, software architect can control both the variability extraction and evolution processes. The proposed approach has been applied to a representative, large-scale plugin-based system (FraSCAti), considering different versions of its architecture. We report on our experience in this context.},
  Doi                      = {10.1007/s10270-013-0364-2},
  ISSN                     = {16191374},
  Publisher                = {Springer Verlag}
}

@InProceedings{Acher2012,
  Title                    = {On extracting feature models from product descriptions},
  Author                   = {Acher, Mathieu and Cleve, Anthony and Perrouin, Gilles and Heymans, Patrick and Vanbeneden, Charles and Collet, Philippe and Lahire, Philippe},
  Booktitle                = {Vamos},
  Year                     = {2012},
  Pages                    = {45--54},

  Abstract                 = {In product line engineering, domain analysis is the process of analyzing related products to identify their common and variable features. This process is generally carried out by experts on the basis of existing product descriptions, which are expressed in a more or less structured way. Modeling and reasoning about product descriptions are error-prone and time consuming tasks. Feature models (FMs) constitute popular means to specify product commonalities and variabilities in a compact way, and to provide automated support to the domain analysis process. This paper aims at easing the transition from product descriptions expressed in a tabular format to FMs accurately representing them. This process is parameterized through a dedicated language and high-level directives (e.g., products/features scoping). We guarantee that the resulting FM represents the set of legal feature combinations supported by the considered products and has a readable tree hierarchy together with variability information. We report on our experiments based on public data and characterize the properties of the derived FMs. Copyright 2012 ACM.},
  Doi                      = {10.1145/2110147.2110153},
  ISBN                     = {9781450310581}
}

@Article{Acher2012a,
  Title                    = {Composing multiple variability artifacts to assemble coherent workflows},
  Author                   = {Acher, Mathieu and Collet, Philippe and Gaignard, Alban and Lahire, Philippe and Montagnat, Johan and France, Robert B.},
  Journal                  = {Software Quality Journal},
  Year                     = {2012},

  Month                    = {sep},
  Number                   = {3-4},
  Pages                    = {689--734},
  Volume                   = {20},

  Abstract                 = {The development of scientific workflows is evolving toward the systematic use of service-oriented architectures, enabling the composition of dedicated and highly parameterized software services into processing pipelines. Building consistent workflows then becomes a cumbersome and error-prone activity as users cannot manage such large-scale variability. This paper presents a rigorous and tooled approach in which techniques from Software Product Line (SPL) engineering are reused and extended to manage variability in service and workflow descriptions. Composition can be facilitated while ensuring consistency. Services are organized in a rich catalog which is organized as a SPL and structured according to the common and variable concerns captured for all services. By relying on sound merging techniques on the feature models that make up the catalog, reasoning about the compatibility between connected services is made possible. Moreover, an entire workflow is then seen as a multiple SPL (i. e., a composition of several SPLs). When services are configured within, the propagation of variability choices is then automated with appropriate techniques and the user is assisted in obtaining a consistent workflow. The approach proposed is completely supported by a combination of dedicated tools and languages. Illustrations and experimental validations are provided using medical imaging pipelines, which are representative of current scientific workflows in many domains. {\textcopyright} 2011 Springer Science+Business Media, LLC.},
  Doi                      = {10.1007/s11219-011-9170-7},
  ISSN                     = {09639314}
}

@Article{Acher2010,
  Title                    = {Managing multiple software product lines using merging techniques},
  Author                   = {Acher, M and Collet, P and Lahire, P},
  Journal                  = {Tech. ISRN I3S {\ldots}},
  Year                     = {2010},

  Url                      = {https://www.researchgate.net/profile/Philippe{\_}Collet/publication/266032953{\_}MANAGING{\_}MULTIPLE{\_}SOFTWARE{\_}PRODUCT{\_}LINES{\_}USING{\_}MERGING{\_}TECHNIQUES/links/5603cf2408ae460e2704fb69.pdf}
}

@Article{Acher2011b,
  Title                    = {Managing feature models with familiar: a demonstration of the language and its tool support},
  Author                   = {Acher, M and Collet, P and Lahire, P and France, RB},
  Journal                  = {Proc. 5th},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=1944903}
}

@InProceedings{Acher2011e,
  Title                    = {A domain-specific language for managing feature models},
  Author                   = {Acher, M and Collet, P and Lahire, P and France, RB},
  Booktitle                = {SAC '11 Proceedings of the 2011 ACM Symposium on Applied Computing},
  Year                     = {2011},

  Journal                  = {SAC '11 Proceedings of the 2011 ACM Symposium on Applied Computing},
  Url                      = {http://dl.acm.org/citation.cfm?id=1982473}
}

@Article{Acher2010a,
  Title                    = {Comparing approaches to implement feature model composition},
  Author                   = {Acher, M and Collet, P and Lahire, P and France, R},
  Journal                  = {Eur. Conf.},
  Year                     = {2010},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-13595-8{\_}3}
}

@InProceedings{Acher2010b,
  Title                    = {Managing variability in workflow with feature model composition operators},
  Author                   = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert},
  Year                     = {2010},
  Pages                    = {17--33},
  Volume                   = {6144 LNCS},

  Abstract                 = {In grid-based scientific applications, building a workflow essentially involves composing parameterized services describing families of services and then configuring the resulting workflow product line. In domains (e.g., medical imaging) in which many different kinds of highly parameterized services exist, there is a strong need to manage variabilities so that scientists can more easily configure and compose services with consistency guarantees. In this paper, we propose an approach in which variable points in services are described with several separate feature models, so that families of workflow can be defined as compositions of feature models. A compositional technique then allows reasoning about the compatibility between connected services to ensure consistency of an entire workflow, while supporting automatic propagation of variability choices when configuring services. {\textcopyright} 2010 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-14046-4_2},
  ISBN                     = {3642140459},
  ISSN                     = {03029743}
}

@InProceedings{Acher2013c,
  Title                    = {FAMILIAR: A domain-specific language for large scale management of feature models},
  Author                   = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert B.},
  Year                     = {2013},
  Month                    = {jun},
  Number                   = {6},
  Pages                    = {657--681},
  Volume                   = {78},

  Abstract                 = {The feature model formalism has become the de facto standard for managing variability in software product lines (SPLs). In practice, developing an SPL can involve modeling a large number of features representing different viewpoints, sub-systems or concerns of the software system. This activity is generally tedious and error-prone. In this article, we present FAMILIAR a Domain-Specific Language (DSL) that is dedicated to the large scale management of feature models and that complements existing tool support. The language provides a powerful support for separating concerns in feature modeling, through the provision of composition and decomposition operators, reasoning facilities and scripting capabilities with modularization mechanisms. We illustrate how an SPL consisting of medical imaging services can be practically managed using reusable FAMILIAR scripts that implement reasoning mechanisms. We also report on various usages and applications of FAMILIAR and its operators, to demonstrate their applicability to different domains and use for different purposes. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.scico.2012.12.004},
  ISSN                     = {01676423}
}

@InProceedings{Acher2012b,
  Title                    = {Separation of concerns in feature modeling: Support and applications},
  Author                   = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert B.},
  Year                     = {2012},
  Pages                    = {1--12},

  Abstract                 = {Feature models (FMs) are a popular formalism for describing the commonality and variability of software product lines (SPLs) in terms of features. SPL development increasingly involves manipulating many large FMs, and thus scalable modular techniques that support compositional development of complex SPLs are required. In this paper, we describe how a set of complementary operators (aggregate, merge, slice) provides practical support for separation of concerns in feature modeling. We show how the combination of these operators can assist in tedious and error prone tasks such as automated correction of FM anomalies, update and extraction of FM views, reconciliation of FMs and reasoning about properties of FMs. For each task, we report on practical applications in different domains. We also present a technique that can efficiently decompose FMs with thousands of features and report our experimental results. {\textcopyright} 2012 ACM.},
  Doi                      = {10.1145/2162049.2162051},
  ISBN                     = {9781450310925}
}

@InProceedings{Acher2011d,
  Title                    = {Decomposing feature models: Language, environment, and applications},
  Author                   = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert B.},
  Year                     = {2011},
  Pages                    = {600--603},

  Abstract                 = {Variability in software product lines is often expressed through feature models (FMs). To handle the complexity of increasingly larger FMs, we propose semantically meaningful decomposition support through a slicing operator. We describe how the slicing operator is integrated into the FAMILIAR environment and how it can be combined with other operators to support complex tasks over FMs in different case studies. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/ASE.2011.6100135},
  ISBN                     = {9781457716393}
}

@InProceedings{Acher2011f,
  Title                    = {Slicing feature models},
  Author                   = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert B.},
  Year                     = {2011},
  Pages                    = {424--427},

  Abstract                 = {Feature models (FMs) are a popular formalism for describing the commonality and variability of software product lines (SPLs) in terms of features. As SPL development increasingly involves numerous large FMs, scalable modular techniques are required to manage their complexity. In this paper, we present a novel slicing technique that produces a projection of an FM, including constraints. The slicing allows SPL practitioners to find semantically meaningful decompositions of FMs and has been integrated into the FAMILIAR language. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/ASE.2011.6100089},
  ISBN                     = {9781457716393}
}

@InProceedings{Acher2011c,
  Title                    = {Modeling variability from requirements to runtime},
  Author                   = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and Moisan, Sabine and Rigault, Jean Paul},
  Year                     = {2011},
  Pages                    = {77--86},

  Abstract                 = {In software product line (SPL) engineering, a software configuration can be obtained through a valid selection of features represented in a feature model (FM). With a strong separation between requirements and reusable components and a deep impact of high level choices on technical parts, determining and configuring an well-adapted software configuration is a long, cumbersome and error-prone activity. This paper presents a modeling process in which variability sources are separated in different FMs and inter-related by propositional constraints while consistency checking and propagation of variability choices are automated. We show how the variability requirements can be expressed and then refined at design time so that the set of valid software configurations to be considered at runtime may be highly reduced. Software tools support the approach and some experimentations on a video surveillance SPL are also reported. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/ICECCS.2011.15},
  ISBN                     = {9780769543819}
}

@InProceedings{Acher2013a,
  Title                    = {Composing your compositions of variability models},
  Author                   = {Acher, Mathieu and Combemale, Benoit and Collet, Philippe and Barais, Olivier and Lahire, Philippe and France, Robert B.},
  Year                     = {2013},
  Pages                    = {352--369},
  Volume                   = {8107 LNCS},

  Abstract                 = {Modeling and managing variability is a key activity in a growing number of software engineering contexts. Support for composing variability models is arising in many engineering scenarios, for instance, when several subsystems or modeling artifacts, each coming with their own variability and possibly developed by different stakeholders, should be combined together. In this paper, we consider the problem of composing feature models (FMs), a widely used formalism for representing and reasoning about a set of variability choices. We show that several composition operators can actually be defined, depending on both matching/ merging strategies and semantic properties expected in the composed FM. We present four alternative forms and their implementations. We discuss their relative trade-offs w.r.t. reasoning, customizability, traceability, composability and quality of the resulting feature diagram. We summarize these findings in a reading grid which is validated by revisiting some relevant existing works. Our contribution should assist developers in choosing and implementing the right composition operators. {\textcopyright} 2013 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-41533-3_22},
  ISBN                     = {9783642415326},
  ISSN                     = {03029743}
}

@InProceedings{Acher2012c,
  Title                    = {Feature model differences},
  Author                   = {Acher, Mathieu and Heymans, Patrick and Collet, Philippe and Quinton, Cl{\'{e}}ment and Lahire, Philippe and Merle, Philippe},
  Year                     = {2012},
  Pages                    = {629--645},
  Volume                   = {7328 LNCS},

  Abstract                 = {Feature models are a widespread means to represent commonality and variability in software product lines. As is the case for other kinds of models, computing and managing feature model differences is useful in various real-world situations. In this paper, we propose a set of novel differencing techniques that combine syntactic and semantic mechanisms, and automatically produce meaningful differences. Practitioners can exploit our results in various ways: to understand, manipulate, visualize and reason about differences. They can also combine them with existing feature model composition and decomposition operators. The proposed automations rely on satisfiability algorithms. They come with a dedicated language and a comprehensive environment. We illustrate and evaluate the practical usage of our techniques through a case study dealing with a configurable component framework. {\textcopyright} 2012 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-31095-9_41},
  ISBN                     = {9783642310942},
  ISSN                     = {03029743}
}

@InProceedings{Al-Bashayreh2012,
  Title                    = {Feature model to design application framework for context-aware mobile patient monitoring systems},
  Author                   = {Al-Bashayreh, Mahmood Ghaleb and Hashim, Nor Laily and Khorma, Ola Taiseer},
  Year                     = {2012},
  Pages                    = {72--77},

  Abstract                 = {The objective of this paper is to present a feature model as a main deliverable of a domain analysis for context-aware Mobile Patient Monitoring Systems (MPMS). This model is a part of ongoing work to design an application framework to develop context-aware MPMS. These systems will enable elderly populations and patients with chronic diseases to undertake monitoring of themselves during their daily life. Unfortunately, developing these systems is very complex. An application framework, as an ideal reuse technique, is one of the most suitable solutions to simplify the development of such systems and overcome their development complexity. The scope of this paper is limited to construction process for context-aware MPMS feature model. The expected benefits of the resulted model are twofold. First, it enhances the understanding of the domain of context-aware MPMS. Second, it supports designing frameworks that satisfy the main characteristics of application frameworks, which are framework extensibility and reusability. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/IECBES.2012.6498052},
  ISBN                     = {9781467316668}
}

@InProceedings{Alferez2011,
  Title                    = {Supporting consistency checking between features and software product line use scenarios},
  Author                   = {Alf{\'{e}}rez, Mauricio and Lopez-Herrejon, Roberto E. and Moreira, Ana and Amaral, Vasco and Egyed, Alexander},
  Year                     = {2011},
  Pages                    = {20--35},
  Volume                   = {6727 LNCS},

  Abstract                 = {A key aspect for effective variability modeling of Software Product Lines (SPL) is to harmonize the need to achieve separation of concerns with the need to satisfy consistency of requirements and constraints. Techniques for variability modeling such as feature models used together with use scenarios help to achieve separation of stakeholders' concerns but ensuring their joint consistency is largely unsupported. Therefore, inconsistent assumptions about system's expected use scenarios and the way in which they vary according to the presence or absence of features reduce the models usefulness and possibly renders invalid SPL systems. In this paper we propose an approach to check consistency - the verification of semantic relationships among the models - between features and use scenarios that realize them. The novelty of this approach is that it is specially tailored for the SPL domain and considers complex composition situations where the customization of use scenarios for specific products depends on the presence or absence of sets of features. We illustrate our approach and supporting tools using variant constructs that specify how the inclusion of sets of variable features (that refer to uncommon requirements between products of a SPL) adapt use scenarios related to other features. {\textcopyright} 2011 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-21347-2_3},
  ISBN                     = {9783642213465},
  ISSN                     = {03029743}
}

@Article{Al-Hajjaji2016,
  Title                    = {IncLing: Efficient Product-Line Testing Using Incremental Pairwise Sampling},
  Author                   = {Al-Hajjaji, M and Krieter, S and Th{\"{u}}m, T and Lochau, M and Saake, G},
  Year                     = {2016},

  Url                      = {https://www.isf.cs.tu-bs.de/cms/team/thuem/papers/2016-GPCE-AlHajjaji.pdf}
}

@Article{Al-Hajjaji2016a,
  Title                    = {Tool Demo: Testing Configurable Systems with FeatureIDE},
  Author                   = {Al-Hajjaji, M and Meinicke, J and Krieter, S and Schr{\"{o}}ter, R},
  Journal                  = {Proc. Int'l Conf.},
  Year                     = {2016},

  Url                      = {https://www.isf.cs.tu-bs.de/cms/team/thuem/papers/2016-GPCE-AlHajjaji-demo.pdf}
}

@InProceedings{Al-Hajjaji2014,
  Title                    = {Similarity-based prioritization in software product-line testing},
  Author                   = {Al-Hajjaji, Mustafa and Th{\"{u}}m, Thomas and Meinicke, Jens and Lochau, Malte and Saake, Gunter},
  Year                     = {2014},
  Month                    = {sep},
  Pages                    = {197--206},
  Publisher                = {Association for Computing Machinery},
  Volume                   = {1},

  Abstract                 = {Exhaustively testing every product of a software product line (SPL) is a difficult task due to the combinatorial explosion of the number of products. Combinatorial interaction testing is a technique to reduce the number of products under test. However, it is typically up-to the tester in which order these products are tested. We propose a similarity-based prioritization to be applied on these products before they are generated. The proposed approach does not guarantee to find more errors than sampling approaches, but it aims at increasing interaction coverage of an SPL under test as fast as possible over time. This is especially beneficial since usually the time budget for testing is limited. We implemented similarity-based prioritization in FeatureIDE and evaluated it by comparing its outcome to the default outcome of three sampling algorithms as well as to random orders. The experiment results indicate that the order with similarity-based prioritization is better than random orders and often better than the default order of existing sampling algorithms. Copyright 2014 ACM.},
  Doi                      = {10.1145/2648511.2648532},
  ISBN                     = {9781450327404}
}

@Article{Al-MsieDeen2014,
  Title                    = {Automatic documentation of [Mined] feature implementations from source code elements and use-case diagrams with the REVPLINE approach},
  Author                   = {Al-Msie'Deen, R. and Huchard, M. and Seriai, A. D. and Urtado, C. and Vauttier, S.},
  Year                     = {2014},

  Month                    = {dec},
  Number                   = {10},
  Pages                    = {1413--1438},
  Volume                   = {24},

  Abstract                 = {Companies often develop a set of software variants that share some features and differ in others to meet specific requirements. To exploit the existing software variants as a Software Product Line (SPL), a Feature Model of this SPL must be built as a first step. To do so, it is necessary to define and document the optional and mandatory features that compose the variants. In our previous work, we mined a set of feature implementations as identified sets of source code elements. In this paper, we propose a complementary approach, which aims to document the mined feature implementations by giving them names and descriptions, based on the source code elements that form feature implementations and the use-case diagrams that specify software variants. The novelty of our approach is its use of commonality and variability across software variants, at feature implementation and use-case levels, to run Information Retrieval methods in an efficient way. Experiments on several real case studies (Mobile media and ArgoUML-SPL) validate our approach and show promising results.},
  Doi                      = {10.1142/S0218194014400142},
  ISSN                     = {02181940},
  Publisher                = {World Scientific Publishing Co. Pte Ltd}
}

@InProceedings{Al-MsieDeen2013,
  Title                    = {Mining features from the object-oriented source code of software variants by combining lexical and structural similarity},
  Author                   = {Al-Msie'Deen, R. and Seriai, A. D. and Huchard, M. and Urtado, C. and Vauttier, S.},
  Year                     = {2013},
  Pages                    = {586--593},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {Migrating software product variants which are deemed similar into a product line is a challenging task with main impact in software reengineering. To exploit existing software variants to build a software product line (SPL), the first step is to mine the feature model of this SPL which involves extracting common and optional features. Thus, we propose, in this paper, a new approach to mine features from the object-oriented source code of software variants by using lexical and structural similarity. To validate our approach, we applied it on ArgoUML, Health Watcher and Mobile Media software. The results of this evaluation showed that most of the features were identified1. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/IRI.2013.6642522},
  ISBN                     = {9781479910502}
}

@InProceedings{AL-Msiedeen2013,
  Title                    = {Mining features from the object-oriented source code of a collection of software variants using formal concept analysis and latent semantic indexing},
  Author                   = {AL-Msie'deen, R. and Seriai, A. D. and Huchard, M. and Urtado, C. and Vauttier, S. and Salman, H. Eyal},
  Year                     = {2013},
  Number                   = {January},
  Pages                    = {244--249},
  Publisher                = {Knowledge Systems Institute Graduate School},

  Abstract                 = {Companies often develop a set of software variants that share some features and differ in other ones to meet specific requirements. To exploit existing software variants and build a software product line (SPL), a feature model of this SPL must be built as a first step. To do so, it is necessary to mine optional and mandatory features from the source code of the software variants. Thus, we propose, in this paper, a new approach to mine features from the object-oriented source code of a set of software variants based on Formal Concept Analysis and Latent Semantic Indexing. To validate our approach, we applied it on ArgoUML and Mobile Media case studies. The results of this evaluation validate the relevance and the performance of our proposal as most of the features were correctly identified.},
  ISSN                     = {23259086}
}

@Article{Andres2013,
  Title                    = {A formal framework for software product lines},
  Author                   = {Andr{\'{e}}s, C{\'{e}}sar and Camacho, Carlos and Llana, Luis},
  Year                     = {2013},

  Month                    = {nov},
  Number                   = {11},
  Pages                    = {1925--1947},
  Volume                   = {55},

  Abstract                 = {Context A Software Product Line is a set of software systems that are built from a common set of features. These systems are developed in a prescribed way and they can be adapted to fit the needs of customers. Feature models specify the properties of the systems that are meaningful to customers. A semantics that models the feature level has the potential to support the automatic analysis of entire software product lines. Objective The objective of this paper is to define a formal framework for Software Product Lines. This framework needs to be general enough to provide a formal semantics for existing frameworks like FODA (Feature Oriented Domain Analysis), but also to be easily adaptable to new problems. Method We define an algebraic language, called SPLA, to describe Software Product Lines. We provide the semantics for the algebra in three different ways. The approach followed to give the semantics is inspired by the semantics of process algebras. First we define an operational semantics, next a denotational semantics, and finally an axiomatic semantics. We also have defined a representation of the algebra into propositional logic. Results We prove that the three semantics are equivalent. We also show how FODA diagrams can be automatically translated into SPLA. Furthermore, we have developed our tool, called AT, that implements the formal framework presented in this paper. This tool uses a SAT-solver to check the satisfiability of an SPL. Conclusion This paper defines a general formal framework for software product lines. We have defined three different semantics that are equivalent; this means that depending on the context we can choose the most convenient approach: operational, denotational or axiomatic. The framework is flexible enough because it is closely related to process algebras. Process algebras are a well-known paradigm for which many extensions have been defined. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.infsof.2013.05.005},
  ISSN                     = {09505849}
}

@Article{Antkiewicz2013,
  Title                    = {Clafer tools for product line engineering},
  Author                   = {Antkiewicz, M and B{\c{a}}k, K and Murashkin, A and Olaechea, R},
  Journal                  = {Proc. 17th},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2499779}
}

@Book{Apel2013,
  Title                    = {Feature-Oriented Software Product Lines},
  Author                   = {Apel, S and Batory, D and K{\"{a}}stner, C and Saake, G},
  Year                     = {2013},

  Url                      = {http://link.springer.com/content/pdf/10.1007/978-3-642-37521-7.pdf}
}

@Article{Apel2010,
  Title                    = {Detecting dependences and interactions in feature-oriented design},
  Author                   = {Apel, S and Scholz, W and Lengauer, C},
  Journal                  = {2010 IEEE 21st},
  Year                     = {2010},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5635137}
}

@InProceedings{Apel2010a,
  Title                    = {Language-independent reference checking in software product lines},
  Author                   = {Apel, Sven and Scholz, Wolfgang and Lengauer, Christian and K{\"{a}}stner, Christian},
  Year                     = {2010},
  Pages                    = {65--71},

  Abstract                 = {Feature-Oriented Software Development (FOSD) is a paradigm for the development of software product lines. A challenge in FOSD is to guarantee that all software systems of a software product line are correct. Recent work on type checking product lines can provide a guarantee of type correctness without generating all possible systems. We generalize previous results by abstracting from the specifics of particular programming languages. In a first attempt, we present a reference-checking algorithm that performs key tasks of product-line type checking independently of the target programming language. Experiments with two sample product lines written in Java and C are encouraging and give us confidence that this approach is promising. {\textcopyright} 2010 ACM.},
  Doi                      = {10.1145/1868688.1868698},
  ISBN                     = {9781450302081}
}

@Article{Apel2011,
  Title                    = {Detection of feature interactions using feature-aware verification},
  Author                   = {Apel, S and Speidel, H and Wendler, P and von Rhein, A},
  Journal                  = {Autom. Softw. {\ldots}},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=2190192}
}

@Article{Araar2016,
  Title                    = {Software features extraction from object-oriented source code using an overlapping clustering approach},
  Author                   = {Araar, Imad Eddine and Seridi, Hassina},
  Year                     = {2016},

  Month                    = {jun},
  Number                   = {2},
  Pages                    = {245--255},
  Volume                   = {40},

  Abstract                 = {For many decades, numerous organizations have launched software reuse initiatives to improve their productivity. Software product lines (SPL) addressed this problem by organizing software development around a set of features that are shared by a set of products. In order to exploit existing software products for building a new SPL, features composing each of the used products must be specified in the first place. In this paper we analyze the effectiveness of overlapping clustering based technique to mine functional features from object-oriented (OO) source code of existing systems. The evaluation of the proposed approach using two different Java open-source applications, i.e. "Mobile media" and "Drawing Shapes", has revealed encouraging results.},
  ISSN                     = {03505596},
  Publisher                = {Slovene Society Informatika}
}

@InProceedings{Aranega2012,
  Title                    = {Using feature model to build model transformation chains},
  Author                   = {Aranega, Vincent and Etien, Anne and Mosser, Sebastien},
  Year                     = {2012},
  Pages                    = {562--578},
  Volume                   = {7590 LNCS},

  Abstract                 = {Model transformations are intrinsically related to model-driven engineering. According to the increasing size of standardised meta-model, large transformations need to be developed to cover them. Several approaches promote separation of concerns in this context, that is, the definition of small transformations in order to master the overall complexity. Unfortunately, the decomposition of transformations into smaller ones raises new issues: organising the increasing number of transformations and ensuring their composition (i.e. the chaining). In this paper, we propose to use feature models to classify model transformations dedicated to a given business domain. Based on this feature models, automated techniques are used to support the designer, according to two axis: (i)the definition of a valid set of model transformations and (ii) the generation of an executable chain of model transformation that accurately implement designer's intention. This approach is validated on Gaspard2, a tool dedicated to the design of embedded system. {\textcopyright} 2012 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-33666-9_36},
  ISBN                     = {9783642336652},
  ISSN                     = {03029743}
}

@InProceedings{Arcaini2016,
  Title                    = {Automatic Detection and Removal of Conformance Faults in Feature Models},
  Author                   = {Arcaini, Paolo and Gargantini, Angelo and Vavassori, Paolo},
  Year                     = {2016},
  Month                    = {jul},
  Pages                    = {102--112},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {Building a feature model for an existing SPL can improve the automatic analysis of the SPL and reduce the effort in maintenance. However, developing a feature model can be error prone, and checking that it correctly identifies each actual product of the SPL may be unfeasible due to the huge number of possible configurations. We apply mutation analysis and propose a method to detect and remove conformance faults by selecting special configurations that distinguish a feature model from its mutants. We propose a technique that, by iterating this process, is able to repair a faulty model. We devise several variations of a simple hill climbing algorithm for automatic fault removal and we compare them by a series of experiments on three different sets of feature models. We find that our technique is able to improve the conformance of around 90{\%} of the models and find the correct model in around 40{\%} of the cases.},
  Doi                      = {10.1109/ICST.2016.10},
  ISBN                     = {9781509018260}
}

@InProceedings{Arcaini2015,
  Title                    = {Generating tests for detecting faults in feature models},
  Author                   = {Arcaini, Paolo and Gargantini, Angelo and Vavassori, Paolo},
  Year                     = {2015},
  Month                    = {may},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {We present a novel fault-based approach for testing feature models (FMs). We identify several fault classes that represent possible mistakes one can make during feature modeling. We introduce the concept of distinguishing configuration, i.e., a configuration that is able to detect a given fault. Starting from this definition, we devise a technique, based on the use of a logic solver, able either to find distinguishing configurations to be used as tests or to prove that a mutation produces an equivalent feature model. Compact test suites can be produced by exploiting an SMT solver. The experiments show that our methodology is viable and produces reasonable sized test suites in a short time. W.r.t. the approaches that use only the products, our approach has a better fault detection capability and requires fewer tests.},
  Doi                      = {10.1109/ICST.2015.7102591},
  ISBN                     = {9781479971251}
}

@InProceedings{Ardagna2016,
  Title                    = {A certification technique for cloud security adaptation},
  Author                   = {Ardagna, Claudio A. and Asal, Rasool and Damiani, Ernesto and {El Ioini}, Nabil and Pahl, Claus and Dimitrakos, Theo},
  Booktitle                = {IEEE 13th International Conference on Services Computing (SCC)},
  Year                     = {2016},
  Month                    = {aug},
  Pages                    = {324--331},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {Unpredictability of cloud computing due to segregation of visibility and control between applications, data owners, and cloud providers increases tenants' uncertainty when using cloud services. Adaptation techniques become fundamental to provide a reliable cloud-based infrastructure with definite behavior, which preserves a stable quality of service for tenants. Existing adaptation techniques mostly focus on performance properties and are based on unverifiable evidence, which is collected in an untrusted way. In this paper, we propose a security-oriented adaptation technique for the cloud, based on evidence collected by means of a reliable certification process. Our approach adapts the cloud to maintain stable security properties over time, by continuously verifying certificate validity. It uses the output of verification activities to index a feature model, where equivalent configurations are used as the basis for adaptation. We also provide an analysis of the approach on British Telecommunications (BT) premises.},
  Doi                      = {10.1109/SCC.2016.49},
  ISBN                     = {9781509026289}
}

@Article{Asadi2012,
  Title                    = {Requirements engineering in feature oriented software product lines: an initial analytical study},
  Author                   = {Asadi, M and Bagheri, E and Mohabbati, B},
  Journal                  = {Proc. 16th},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2364419}
}

@Article{Asadi2016,
  Title                    = {The effects of visualization and interaction techniques on feature model configuration},
  Author                   = {Asadi, Mohsen and Soltani, Samaneh and Ga{\v{s}}evi{\'{c}}, Dragan and Hatala, Marek},
  Year                     = {2016},

  Month                    = {aug},
  Number                   = {4},
  Pages                    = {1706--1743},
  Volume                   = {21},

  Abstract                 = {A Software Product Line is a set of software systems of a domain, which share some common features but also have significant variability. A feature model is a variability modeling artifact which represents differences among software products with respect to variability relationships among their features. Having a feature model along with a reference model developed in the domain engineering lifecycle, a concrete product of the family is derived by selecting features in the feature model (referred to as the configuration process) and by instantiating the reference model. However, feature model configuration can be a cumbersome task because: 1) feature models may consist of a large number of features, which are hard to comprehend and maintain; and 2) many factors including technical limitations, implementation costs, stakeholders' requirements and expectations must be considered in the configuration process. Recognizing these issues, a significant amount of research efforts has been dedicated to different aspects of feature model configuration such as automating the configuration process. Several approaches have been proposed to alleviate the feature model configuration challenges through applying visualization and interaction techniques. However, there have been limited empirical insights available into the impact of visualization and interaction techniques on the feature model configuration process. In this paper, we present a set of visualization and interaction interventions for representing and configuring feature models, which are then empirically validated to measure the impact of the proposed interventions. An empirical study was conducted by following the principles of control experiments in software engineering and by applying the well-known software quality standard ISO 9126 to operationalize the variables investigated in the experiment. The results of the empirical study revealed that the employed visualization and interaction interventions significantly improved completion time of comprehension and changing of the feature model configuration. Additionally, according to results, the proposed interventions are easy-to-use and easy-to-learn for the participants.},
  Doi                      = {10.1007/s10664-014-9353-5},
  ISSN                     = {15737616},
  Publisher                = {Springer New York LLC}
}

@Article{Asadi2014,
  Title                    = {Toward automated feature model configuration with optimizing non-functional requirements},
  Author                   = {Asadi, Mohsen and Soltani, Samaneh and Gasevic, Dragan and Hatala, Marek and Bagheri, Ebrahim},
  Year                     = {2014},
  Number                   = {9},
  Pages                    = {1144--1165},
  Volume                   = {56},

  Abstract                 = {Context A software product line is a family of software systems that share some common features but also have significant variabilities. A feature model is a variability modeling artifact, which represents differences among software products with respect to the variability relationships among their features. Having a feature model along with a reference model developed in the domain engineering lifecycle, a concrete product of the family is derived by binding the variation points in the feature model (called configuration process) and by instantiating the reference model. Objective In this work we address the feature model configuration problem and propose a framework to automatically select suitable features that satisfy both the functional and non-functional preferences and constraints of stakeholders. Additionally, interdependencies between various non-functional properties are taken into account in the framework. Method The proposed framework combines Analytical Hierarchy Process (AHP) and Fuzzy Cognitive Maps (FCM) to compute the non-functional properties weights based on stakeholders' preferences and interdependencies between non-functional properties. Afterwards, Hierarchical Task Network (HTN) planning is applied to find the optimal feature model configuration. Result Our approach improves state-of-art of feature model configuration by considering positive or negative impacts of the features on non-functional properties, the stakeholders' preferences, and non-functional interdependencies. The approach presented in this paper extends earlier work presented in [1] from several distinct perspectives including mechanisms handling interdependencies between non-functional properties, proposing a novel tooling architecture, and offering visualization and interaction techniques for representing functional and non-functional aspects of feature models. Conclusion our experiments show the scalability of our configuration approach when considering both functional and non-functional requirements of stakeholders. {\textcopyright} 2014 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.infsof.2014.03.005},
  ISSN                     = {09505849},
  Publisher                = {Elsevier}
}

@Article{Becan2016,
  Title                    = {Breathing ontological knowledge into feature model synthesis: an empirical study},
  Author                   = {B{\'{e}}can, Guillaume and Acher, Mathieu and Baudry, Benoit and Nasr, Sana Ben},
  Year                     = {2016},

  Month                    = {aug},
  Number                   = {4},
  Pages                    = {1794--1841},
  Volume                   = {21},

  Abstract                 = {Feature Models (FMs) are a popular formalism for modeling and reasoning about the configurations of a software product line. As the manual construction of an FM is time-consuming and error-prone, management operations have been developed for reverse engineering, merging, slicing, or refactoring FMs from a set of configurations/dependencies. Yet the synthesis of meaningless ontological relations in the FM – as defined by its feature hierarchy and feature groups – may arise and cause severe difficulties when reading, maintaining or exploiting it. Numerous synthesis techniques and tools have been proposed, but only a few consider both configuration and ontological semantics of an FM. There are also few empirical studies investigating ontological aspects when synthesizing FMs. In this article, we define a generic, ontologic-aware synthesis procedure that computes the likely siblings or parent candidates for a given feature. We develop six heuristics for clustering and weighting the logical, syntactical and semantical relationships between feature names. We then perform an empirical evaluation on hundreds of FMs, coming from the SPLOT repository and Wikipedia. We provide evidence that a fully automated synthesis (i.e., without any user intervention) is likely to produce FMs far from the ground truths. As the role of the user is crucial, we empirically analyze the strengths and weaknesses of heuristics for computing ranking lists and different kinds of clusters. We show that a hybrid approach mixing logical and ontological techniques outperforms state-of-the-art solutions. We believe our approach, environment, and empirical results support researchers and practitioners working on reverse engineering and management of FMs.},
  Doi                      = {10.1007/s10664-014-9357-1},
  ISSN                     = {15737616},
  Publisher                = {Springer New York LLC}
}

@InProceedings{Bottcher2014,
  Title                    = {From formal requirements on technical systems to complete designs-a holistic approach},
  Author                   = {B{\"{o}}ttcher, Bj{\"{o}}rn and Moriz, Natalia and Niggemann, Oliver},
  Year                     = {2014},
  Pages                    = {977--978},
  Publisher                = {IOS Press},
  Volume                   = {263},

  Abstract                 = {The design processes of todays more and more complex automation systems require computer-based support to maintain their manageability. As a base for that, the authors introduce a holistic design approach for these systems. Requirements on the system to be designed are represented by an extended feature model which serves as consistent requirements model during the entire design process. A grammar-based synthesis applies formalised expert knowledge to generate solutions to these requirements. The paper's main contribution is to combine formalisms from overlapping areas of artificial intelligence and software engineering to obtain a holistic design process for industrial automation systems.},
  Doi                      = {10.3233/978-1-61499-419-0-977},
  ISBN                     = {9781614994183},
  ISSN                     = {09226389}
}

@Article{Burdek2016,
  Title                    = {Reasoning about product-line evolution using complex feature model differences},
  Author                   = {B{\"{u}}rdek, Johannes and Kehrer, Timo and Lochau, Malte and Reuling, Dennis and Kelter, Udo and Sch{\"{u}}rr, Andy},
  Year                     = {2016},

  Month                    = {dec},
  Number                   = {4},
  Pages                    = {687--733},
  Volume                   = {23},

  Abstract                 = {Features define common and variable parts of the members of a (software) product line. Feature models are used to specify the set of all valid feature combinations. Feature models not only enjoy an intuitive tree-like graphical syntax, but also a precise formal semantics, which can be denoted as propositional formulae over Boolean feature variables. A product line usually constitutes a long-term investment and, therefore, has to undergo continuous evolution to meet ever-changing requirements. First of all, product-line evolution leads to changes of the feature model due to its central role in the product-line paradigm. As a result, product-line engineers are often faced with the problems that (1) feature models are changed in an ad-hoc manner without proper documentation, and (2) the semantic impact of feature diagram changes is unclear. In this article, we propose a comprehensive approach to tackle both challenges. For (1), our approach compares the old and new version of the diagram representation of a feature model and specifies the changes using complex edit operations on feature diagrams. In this way, feature model changes are automatically detected and formally documented. For (2), we propose an approach for reasoning about the semantic impact of diagram changes. We present a set of edit operations on feature diagrams, where complex operations are primarily derived from evolution scenarios observed in a real-world case study, i.e., a product line from the automation engineering domain. We evaluated our approach to demonstrate its applicability with respect to the case study, as well as its scalability concerning experimental data sets.},
  Doi                      = {10.1007/s10515-015-0185-3},
  ISSN                     = {15737535},
  Publisher                = {Springer New York LLC}
}

@InProceedings{Bagheri2010,
  Title                    = {Stratified analytic hierarchy process: Prioritization and selection of software features},
  Author                   = {Bagheri, Ebrahim and Asadi, Mohsen and Gasevic, Dragan and Soltani, Samaneh},
  Year                     = {2010},
  Pages                    = {300--315},
  Volume                   = {6287 LNCS},

  Abstract                 = {Product line engineering allows for the rapid development of variants of a domain specific application by using a common set of reusable assets often known as core assets. Variability modeling is a critical issue in product line engineering, where the use of feature modeling is one of most commonly used formalisms. To support an effective and automated derivation of concrete products for a product family, staged configuration has been proposed in the research literature. In this paper, we propose the integration of well-known requirements engineering principles into stage configuration. Being inspired by the well-established Preview requirements engineering framework, we initially propose an extension of feature models with capabilities for capturing business oriented requirements. This representation enables a more effective capturing of stakeholders' preferences over the business requirements and objectives (e.g.,. implementation costs or security) in the form of fuzzy linguistic variables (e.g., high, medium, and low). On top of this extension, we propose a novel method, the Stratified Analytic Hierarchy process, which first helps to rank and select the most relevant high level business objectives for the target stakeholders (e.g., security over implementation costs), and then helps to rank and select the most relevant features from the feature model to be used as the starting point in the staged configuration process. Besides a complete formalization of the process, we define the place of our proposal in existing software product line lifecycles as well as demonstrate the use of our proposal on the widely-used e-Shop case study. Finally, we report on the results of our user study, which indicates a high appreciation of the proposed method by the participating industrial software developers. The tool support for S-AHP is also introduced. {\textcopyright} 2010 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-15579-6_21},
  ISBN                     = {3642155782},
  ISSN                     = {03029743}
}

@InProceedings{Bagheri2010a,
  Title                    = {Configuring software product line feature models based on stakeholders' soft and hard requirements},
  Author                   = {Bagheri, Ebrahim and {Di Noia}, Tommaso and Ragone, Azzurra and Gasevic, Dragan},
  Year                     = {2010},
  Pages                    = {16--31},
  Volume                   = {6287 LNCS},

  Abstract                 = {Feature modeling is a technique for capturing commonality and variability. Feature models symbolize a representation of the possible application configuration space, and can be customized based on specific domain requirements and stakeholder goals. Most feature model configuration processes neglect the need to have a holistic approach towards the integration and satisfaction of the stakeholder's soft and hard constraints, and the application-domain integrity constraints. In this paper, we will show how the structure and constraints of a feature model can be modeled uniformly through Propositional Logic extended with concrete domains, called . Furthermore, we formalize the representation of soft constraints in fuzzy and explain how semi-automated feature model configuration is performed. The model configuration derivation process that we propose respects the soundness and completeness properties. {\textcopyright} 2010 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-15579-6_2},
  ISBN                     = {3642155782},
  ISSN                     = {03029743}
}

@Article{Bagheri2011,
  Title                    = {Assessing the maintainability of software product line feature models using structural metrics},
  Author                   = {Bagheri, Ebrahim and Gasevic, Dragan},
  Year                     = {2011},

  Month                    = {sep},
  Number                   = {3},
  Pages                    = {579--612},
  Volume                   = {19},

  Abstract                 = {A software product line is a unified representation of a set of conceptually similar software systems that share many common features and satisfy the requirements of a particular domain. Within the context of software product lines, feature models are tree-like structures that are widely used for modeling and representing the inherent commonality and variability of software product lines. Given the fact that many different software systems can be spawned from a single software product line, it can be anticipated that a low-quality design can ripple through to many spawned software systems. Therefore, the need for early indicators of external quality attributes is recognized in order to avoid the implications of defective and low-quality design during the late stages of production. In this paper, we propose a set of structural metrics for software product line feature models and theoretically validate them using valid measurement-theoretic principles. Further, we investigate through controlled experimentation whether these structural metrics can be good predictors (early indicators) of the three main subcharacteristics of maintainability: analyzability, changeability, and understandability. More specifically, a four-step analysis is conducted: (1) investigating whether feature model structural metrics are correlated with feature model maintainability through the employment of classical statistical correlation techniques; (2) understanding how well each of the structural metrics can serve as discriminatory references for maintainability; (3) identifying the sufficient set of structural metrics for evaluating each of the subcharacteristics of maintainability; and (4) evaluating how well different prediction models based on the proposed structural metrics can perform in indicating the maintainability of a feature model. Results obtained from the controlled experiment support the idea that useful prediction models can be built for the purpose of evaluating feature model maintainability using early structural metrics. Some of the structural metrics show significant correlation with the subjective perception of the subjects about the maintainability of the feature models. {\textcopyright} 2010 Springer Science+Business Media, LLC.},
  Doi                      = {10.1007/s11219-010-9127-2},
  ISSN                     = {09639314}
}

@Article{Bagheri2012,
  Title                    = {Formalizing interactive staged feature model configuration},
  Author                   = {Bagheri, E and Noia, TD and Gasevic, D},
  Journal                  = {J. Softw.},
  Year                     = {2012},

  Url                      = {http://onlinelibrary.wiley.com/doi/10.1002/smr.534/full}
}

@Article{Bak2013,
  Title                    = {Modeling and analysis of software product line variability in Clafer},
  Author                   = {Bak, K},
  Year                     = {2013},

  Url                      = {https://uwspace.uwaterloo.ca/handle/10012/8039}
}

@InProceedings{Bak2011,
  Title                    = {Feature and meta-models in clafer: Mixed, specialized, and coupled},
  Author                   = {Ba̧k, Kacper and Czarnecki, Krzysztof and Wa̧sowski, Andrzej},
  Year                     = {2011},
  Pages                    = {102--122},
  Volume                   = {6563 LNCS},

  Abstract                 = {We present Clafer, a meta-modeling language with first-class support for feature modeling. We designed Clafer as a concise notation for meta-models, feature models, mixtures of meta- and feature models (such as components with options), and models that couple feature models and meta-models via constraints (such as mapping feature configurations to component configurations or model templates). Clafer also allows arranging models into multiple specialization and extension layers via constraints and inheritance. We identify four key mechanisms allowing a meta-modeling language to express feature models concisely and show that Clafer meets its design objectives using a sample product line. We evaluated Clafer and how it lends itself to analysis on sample feature models, meta-models, and model templates of an E-Commerce platform. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-19440-5_7},
  ISBN                     = {9783642194399},
  ISSN                     = {03029743}
}

@Article{Bakar2015,
  Title                    = {Feature extraction approaches from natural language requirements for reuse in software product lines: A systematic literature review},
  Author                   = {Bakar, Noor Hasrina and Kasirun, Zarinah M. and Salleh, Norsaremah},
  Year                     = {2015},

  Month                    = {aug},
  Pages                    = {132--149},
  Volume                   = {106},

  Abstract                 = {Abstract Requirements for implemented system can be extracted and reused for a production of a new similar system. Extraction of common and variable features from requirements leverages the benefits of the software product lines engineering (SPLE). Although various approaches have been proposed in feature extractions from natural language (NL) requirements, no related literature review has been published to date for this topic. This paper provides a systematic literature review (SLR) of the state-of-the-art approaches in feature extractions from NL requirements for reuse in SPLE. We have included 13 studies in our synthesis of evidence and the results showed that hybrid natural language processing approaches were found to be in common for overall feature extraction process. A mixture of automated and semi-automated feature clustering approaches from data mining and information retrieval were also used to group common features, with only some approaches coming with support tools. However, most of the support tools proposed in the selected studies were not made available publicly and thus making it hard for practitioners' adoption. As for the evaluation, this SLR reveals that not all studies employed software metrics as ways to validate experiments and case studies. Finally, the quality assessment conducted confirms that practitioners' guidelines were absent in the selected studies.},
  Doi                      = {10.1016/j.jss.2015.05.006},
  ISSN                     = {01641212},
  Publisher                = {Elsevier Inc.}
}

@Article{Baresi2012,
  Title                    = {Service-oriented dynamic software product lines},
  Author                   = {Baresi, Luciano and Guinea, Sam and Pasquale, Liliana},
  Year                     = {2012},
  Number                   = {10},
  Pages                    = {42--48},
  Volume                   = {45},

  Abstract                 = {An operational example of controls in a smart home demonstrates the potential of a solution that combines the Common Variability Language and a dynamic extension of the Business Process Execution Language to address the need to manage software system variability at runtime. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/MC.2012.289},
  ISSN                     = {00189162}
}

@InProceedings{Baresi2015,
  Title                    = {Dynamically Evolving the Structural Variability of Dynamic Software Product Lines},
  Author                   = {Baresi, Luciano and Quinton, Clement},
  Year                     = {2015},
  Month                    = {aug},
  Pages                    = {57--63},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {A Dynamic Software Product Line (DSPL) is a widely used approach to handle variability at runtime, e.g., By activating or deactivating features to adapt the running configuration. With the emergence of highly configurable and evolvable systems, DSPLs have to cope with the evolution of their structural variability, i.e., The Feature Model (FM) used to derive the configuration. So far, little is known about the evolution of the FM while a configuration derived from this FM is running. In particular, such a dynamic evolution changes the DSPL configuration space, which is thus unsynchronized with the running configuration and its adaptation capabilities. In this position paper, we propose and describe an initial architecture to manage the dynamic evolution of DSPLs and their synchronization. In particular, we explain how this architecture supports the evolution of DSPLs based on FMs extended with cardinality and attributes, which, to the best of our knowledge, has never been addressed yet.},
  Doi                      = {10.1109/SEAMS.2015.24},
  ISBN                     = {9781479919345}
}

@InProceedings{Bashari2016,
  Title                    = {Automated composition of service mashups through software product line engineering},
  Author                   = {Bashari, Mahdi and Bagheri, Ebrahim and Du, Weichang},
  Year                     = {2016},
  Pages                    = {20--38},
  Publisher                = {Springer Verlag},
  Volume                   = {9679},

  Abstract                 = {The growing number of online resources, including data and services, has motivated both researchers and practitioners to provide methods and tools for non-expert end-users to create desirable applications by putting these resources together leading to the so called mashups. In this paper, we focus on a class of mashups referred to as service mashups. A service mashup is built from existing services such that the developed service mashup offers added-value through new functionalities. We propose an approach which adopts concepts from software product line engineering and automated AI planning to support the automated composition of service mashups. One of the advantages of our work is that it allows non-experts to build and optimize desired mashups with little knowledge of service composition. We report on the results of the experimentation that we have performed which support the practicality and scalability of our proposed work.},
  Doi                      = {10.1007/978-3-319-35122-3_2},
  ISBN                     = {9783319351216},
  ISSN                     = {16113349}
}

@Article{Beek2016,
  Title                    = {Statistical model checking for product lines},
  Author                   = {ter Beek, MH and Legay, A and Lafuente, AL},
  Journal                  = {Symp. Leveraging {\ldots}},
  Year                     = {2016},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-319-47166-2{\_}8}
}

@InProceedings{TerBeek2014c,
  Title                    = {Challenges in modelling and analyzing quantitative aspects of bike-sharing systems},
  Author                   = {ter Beek, Maurice H. and Fantechi, Alessandro and Gnesi, Stefania},
  Year                     = {2014},
  Pages                    = {351--367},
  Publisher                = {Springer Verlag},
  Volume                   = {8802},

  Abstract                 = {Bike-sharing systems are becoming popular not only as a sustainable means of transportation in the urban environment, but also as a challenging case study that presents interesting run-time optimization problems. As a side-study within a research project aimed at quantitative analysis that used such a case study, we have observed how the deployed systems enjoy a wide variety of different features. We have therefore applied variability analysis to define a family of bike-sharing systems, and we have sought support in available tools. We have so established a tool chain that includes (academic) tools that provide different functionalities regarding the analysis of software product lines, from feature modelling to product derivation and from quantitative evaluation of the attributes of products to model checking value-passing modal specifications. The tool chain is currently experimented inside the mentioned project as a complement to more sophisticated product-based analysis techniques.},
  ISBN                     = {9783662452332},
  ISSN                     = {16113349}
}

@InProceedings{TerBeek2015,
  Title                    = {Towards automatic decision support for bike-sharing system design},
  Author                   = {ter Beek, Maurice H. and Gnesi, Stefania and Latella, Diego and Massink, Mieke},
  Year                     = {2015},
  Pages                    = {266--280},
  Publisher                = {Springer Verlag},
  Volume                   = {9509},

  Abstract                 = {Public bike-sharing systems are a popular means of sustainable urban mobility, but their successful introduction in a city stands or falls with their specific designs. What kind of bikes and docking stations are needed, how many and where to install them? How to avoid as much as possible that stations are completely empty or full for some period? Hence, a bike-sharing system can be seen both as a highly (re)configurable system and as a collective adaptive system. In this paper, we present two complementary strategies for the evaluation of bike-sharing system designs by means of automated tool support. We use the Clafer toolset to perform multi-objective optimisation of attributed feature models known from software product line engineering and the recently developed mean field model checker FlyFast to assess performance and user satisfaction aspects of variants of large-scale bike-sharing systems. The combined use of these analysis approaches is a preliminary step in the direction of automatic decision support for the initial design of a bike-sharing system as well as its successive adaptations and reconfigurations that considers both qualitative and performance aspects.},
  Doi                      = {10.1007/978-3-662-49224-6_22},
  ISBN                     = {9783662492239},
  ISSN                     = {16113349}
}

@InProceedings{TerBeek2014b,
  Title                    = {Towards modular verification of software product lines with mCRL2},
  Author                   = {ter Beek, Maurice H. and de Vink, Erik P.},
  Year                     = {2014},
  Pages                    = {368--385},
  Publisher                = {Springer Verlag},
  Volume                   = {8802},

  Abstract                 = {We introduce by means of an example a modular verification technique for analyzing the behavior of software product lines using the mCRL2 toolset. Based on feature-driven borders, we divide a behavioral model of a product line into a set of separate components with interfaces and a driver process to coordinate them. Abstracting from irrelevant components, we verify properties over a smaller behavioral model, which not only simplifies the model checking task but also makes the result amenable for reuse. This is a fundamental step forward for the approach to scale up to industrial-size product lines.},
  ISBN                     = {9783662452332},
  ISSN                     = {16113349}
}

@Article{Belategi2011,
  Title                    = {Model based analysis process for embedded software product lines},
  Author                   = {Belategi, L and Sagardui, G and Etxeberria, L},
  Journal                  = {Proc. 2011},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=1987886}
}

@InProceedings{Benavides2013,
  Title                    = {Automated analysis in feature modelling and product configuration},
  Author                   = {Benavides, David and Felfernig, Alexander and Galindo, Jos{\'{e}} A. and Reinfrank, Florian},
  Year                     = {2013},
  Pages                    = {160--175},
  Volume                   = {7925 LNCS},

  Abstract                 = {The automated analysis of feature models is one of the thriving topics of research in the software product line and variability management communities that has attracted more attention in the last years. A recent literature review reported that more than 30 analysis operations have been identified and different analysis mechanisms have been proposed. Product configuration is a well established research field with more than 30 years of successful applications in different industrial domains. Our hypothesis, that is not really new, is that these two independent areas of research have interesting synergies that have not been fully explored. To try to explore the potential synergies systematically, in this paper we provide a rapid review to bring together these previously disparate streams of work. We define a set of research questions and give a preliminary answer to some of them. We conclude that there are many research opportunities in the synergy of these independent areas. {\textcopyright} 2013 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-38977-1_11},
  ISBN                     = {9783642389764},
  ISSN                     = {03029743}
}

@Article{Berger2010,
  Title                    = {Feature-to-Code Mapping in Two Large Product Lines.},
  Author                   = {Berger, T and She, S and Lotufo, R and Czarnecki, K and Wasowski, A},
  Journal                  = {SPLC},
  Year                     = {2010},

  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.387.7133{\&}rep=rep1{\&}type=pdf}
}

@Article{Berger2012,
  Title                    = {Variability modeling in the systems software domain},
  Author                   = {Berger, T and She, S and Lotufo, R and Wasowski, A},
  Journal                  = {Lab. Univ. {\ldots}},
  Year                     = {2012},

  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.386.6515{\&}rep=rep1{\&}type=pdf}
}

@Article{Berger2013,
  Title                    = {A study of variability models and languages in the systems software domain},
  Author                   = {Berger, Thorsten and She, Steven and Lotufo, Rafael and Wasowski, Andrzej and Czarnecki, Krzysztof},
  Year                     = {2013},

  Month                    = {dec},
  Number                   = {12},
  Pages                    = {1611--1640},
  Volume                   = {39},

  Abstract                 = {Variability models represent the common and variable features of products in a product line. Since the introduction of FODA in 1990, several variability modeling languages have been proposed in academia and industry, followed by hundreds of research papers on variability models and modeling. However, little is known about the practical use of such languages. We study the constructs, semantics, usage, and associated tools of two variability modeling languages, Kconfig and CDL, which are independently developed outside academia and used in large and significant software projects. We analyze 128 variability models found in 12 open - source projects using these languages. Our study 1) supports variability modeling research with empirical data on the real-world use of its flagship concepts. However, we 2) also provide requirements for concepts and mechanisms that are not commonly considered in academic techniques, and 3) challenge assumptions about size and complexity of variability models made in academic papers. These results are of interest to researchers working on variability modeling and analysis techniques and to designers of tools, such as feature dependency checkers and interactive product configurators. {\textcopyright} 1976-2012 IEEE.},
  Doi                      = {10.1109/TSE.2013.34},
  ISSN                     = {00985589}
}

@InProceedings{Berger2010a,
  Title                    = {Variability modeling in the real: A perspective from the operating systems domain},
  Author                   = {Berger, Thorsten and She, Steven and Lotufo, Rafael and Wa̧sowski, Andrzej and Czarnecki, Krzysztof},
  Year                     = {2010},
  Pages                    = {73--82},

  Abstract                 = {Variability models represent the common and variable features of products in a product line. Several variability modeling languages have been proposed in academia and industry; however, little is known about the practical use of such languages. We study and compare the constructs, semantics, usage and tools of two variability modeling languages, Kconfig and CDL. We provide empirical evidence for the real-world use of the concepts known from variability modeling research. Since variability models provide basis for automated tools (feature dependency checkers and product configurators), we believe that our findings will be of interest to variability modeling language and tool designers. {\textcopyright} 2010 ACM.},
  Doi                      = {10.1145/1858996.1859010},
  ISBN                     = {9781450301169}
}

@Article{Bezerra2016,
  Title                    = {Exploring quality measures for the evaluation of feature models: a case study},
  Author                   = {Bezerra, CIM and Andrade, RMC and Monteiro, JM},
  Journal                  = {J. Syst.},
  Year                     = {2016},

  Url                      = {http://www.sciencedirect.com/science/article/pii/S0164121216301340}
}

@InProceedings{Bezerra2014,
  Title                    = {Measures for quality evaluation of feature models},
  Author                   = {Bezerra, Carla I M and Andrade, Rossana M C and Monteiro, Jos{\'{e}} Maria S},
  Year                     = {2014},
  Pages                    = {282--297},
  Publisher                = {Springer Verlag},
  Volume                   = {8919},

  Abstract                 = {In Software Product Lines (SPL), quality evaluation is a critical factor, because an error in a SPL can spread to various end products. However, it is often proved impractical to ensure the quality of all products of a given SPL both for economic reasons and the effort needed due to their large number. In this context, a strategy that can be used is to make quality assessments on the initial phases of the SPL development. This approach avoids having errors that could be propagated to the next SPL phases. So, taking into account the feature model, which is one of the most important artifacts in a SPL since its quality directly affects the quality of the SPL end products, to assure the quality of the feature model is one of the current strategies to assess the quality of a SPL. In this sense, one way to evaluate the feature model is to use measures, which could be associated with the feature model quality characteristics and their quality attributes. This paper presents a measures catalog, which can be used to support the quality evaluation of the feature model. In order to identify these measures, a systematic mapping is conducted and to validate the measures catalog, we perform a peer review with experts in software quality and SPL. Besides that, to evaluate the use of the proposed catalog, we apply the measures in three feature models in the domain of mobile applications. The results show that the proposed measures catalog can be effectively deployed to support the quality evaluation of the feature models.},
  ISBN                     = {9783319141299},
  ISSN                     = {16113349}
}

@InProceedings{Bezerra2016a,
  Title                    = {Analyzing the feature models maintainability over their evolution process: An exploratory study},
  Author                   = {Bezerra, Carla I M and Monteiro, Jos{\'{e}} Maria and Andrade, Rossana M C and Rocha, Lincoln S.},
  Year                     = {2016},
  Month                    = {jan},
  Pages                    = {17--24},
  Publisher                = {Association for Computing Machinery},

  Abstract                 = {The feature model is one of the most important artifact of a Software Product Line (SPL). It is built in the early stages of SPL development and describes the main features and relationships. The feature model evolves according to the evolution of the SPL. Thus, it is important to build maintainable feature models. In this scenario, measures have been proven useful in the maintainability evaluation of the feature models. This paper presents an exploratory study on the impact of feature models maintainability over the SPL evolution process. In order to support this analysis, we built a dataset containing a compiled set of 21 maintainability structural measures extracted from 16 feature models and respective versions. Although not conclusive, our findings indicate that the feature models maintainability tends to decrease as it evolves. We also identified the most common changes performed in a feature model during its evolution process.},
  Doi                      = {10.1145/2866614.2866617},
  ISBN                     = {9781450340199}
}

@Article{Boskovi2010,
  Title                    = {Automated staged configuration with semantic web technologies},
  Author                   = {Bo{\v{s}}kovi, Marko and Bagheri, Ebrahim and Ga{\v{S}}evi, Dragan and Mohabbati, Bardia and Kaviani, Nima and Hatala, Marek},
  Year                     = {2010},

  Month                    = {jun},
  Number                   = {4},
  Pages                    = {459--484},
  Volume                   = {20},

  Abstract                 = {Since the introduction in the early nineties, feature models receive a great deal of attention in industry and academia. Industrial success stories in applying feature models for modeling software product lines, and using them for configuring software-intensive systems motivate academia to discover ways to integrate different feature dependencies into the feature model, and automate verified feature configuration. In this paper we demonstrate how ontologies and Semantic Web technologies facilitate seamless integration of required external services and deployment platform capabilities into the feature model. Furthermore, we also contribute with an algorithm for automating staged configuration using Semantic Web reasoners to discover unfeasible features of the feature model. {\textcopyright} 2010 World Scientific Publishing Company.},
  Doi                      = {10.1142/S0218194010004827},
  ISSN                     = {02181940}
}

@InProceedings{Boskovic2011,
  Title                    = {Aspect-oriented feature models},
  Author                   = {Bo{\v{s}}kovi{\'{c}}, Marko and Mussbacher, Gunter and Bagheri, Ebrahim and Amyot, Daniel and Ga{\v{s}}evi{\'{c}}, Dragan and Hatala, Marek},
  Year                     = {2011},
  Pages                    = {110--124},
  Volume                   = {6627 LNCS},

  Abstract                 = {Software Product Lines (SPLs) have emerged as a prominent approach for software reuse. SPLs are sets of software systems called families that are usually developed as a whole and share many common features. Feature models are most typically used as a means for capturing commonality and managing variability of the family. A particular product from the family is configured by selecting the desired features of that product. Typically, feature models are considered monolithic entities that do not support modularization well. As industrial feature models tend to be large, their modularization has become an important research topic lately. However, existing modularization approaches do not support modularization of crosscutting concerns. In this paper, we introduce Aspect-oriented Feature Models (AoFM) and argue that using aspect-oriented techniques improves the manageability and reduces the maintainability effort of feature models. Particularly, we advocate an asymmetric approach that allows for the modularization of basic and crosscutting concerns in feature models. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-21210-9_11},
  ISBN                     = {9783642212093},
  ISSN                     = {03029743}
}

@Article{Bodden2013,
  Title                    = {Spl lift: statically analyzing software product lines in minutes instead of years},
  Author                   = {Bodden, E and Tol{\^{e}}do, T and Ribeiro, M and Brabrand, C},
  Journal                  = {ACM SIGPLAN},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2491976}
}

@Article{Botterweck2010,
  Title                    = {EvoFM: feature-driven planning of product-line evolution},
  Author                   = {Botterweck, G and Pleuss, A and Dhungana, D and Polzer, A},
  Journal                  = {Proc.},
  Year                     = {2010},

  Url                      = {http://dl.acm.org/citation.cfm?id=1808941}
}

@InProceedings{Boucher2012a,
  Title                    = {Towards more reliable configurators: A re-engineering perspective},
  Author                   = {Boucher, Quentin and Abbasi, Ebrahim Khalil and Hubaux, Arnaud and Perrouin, Gilles and Acher, Mathieu and Heymans, Patrick},
  Year                     = {2012},
  Pages                    = {29--32},

  Abstract                 = {Delivering configurable solutions, that is products tailored to the requirements of a particular customer, is a priority of most B2B and B2C markets. These markets now heavily rely on interactive configurators that help customers build complete and correct products. Reliability is thus a critical requirement for configurators. Yet, our experience in industry reveals that many configurators are developed in an ad hoc manner, raising correctness and maintenance issues. In this paper, we present a vision to re-engineering more reliable configurators and the challenges it poses. The first challenge is to reverse engineer from an existing configurator the variability information, including complex rules, and to consolidate it in a variability model, namely a feature model. The second challenge is to forward engineer a new configurator that uses the feature model to generate a customized graphical user interface and the underlying reasoning engine. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/PLEASE.2012.6229766},
  ISBN                     = {9781467317511}
}

@Article{Boucher2012,
  Title                    = {Deriving configuration interfaces from feature models: A vision paper},
  Author                   = {Boucher, Q and Perrouin, G and Heymans, P},
  Journal                  = {Proc. Sixth},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2110152}
}

@Article{Brabrand2012,
  Title                    = {Intraprocedural dataflow analysis for software product lines},
  Author                   = {Brabrand, C and Ribeiro, M and Tol{\^{e}}do, T and Borba, P},
  Journal                  = {Proc. 11th},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2162052}
}

@Article{Broek2010,
  Title                    = {Merging feature models},
  Author                   = {van den Broek, PM and da Silva, I Galvao Lourenco},
  Year                     = {2010},

  Url                      = {http://eprints.eemcs.utwente.nl/18520/}
}

@Article{Bruno2013,
  Title                    = {Analysis of human behavior recognition algorithms based on acceleration data},
  Author                   = {Bruno, B and Mastrogiovanni, F and Sgorbissa, A},
  Journal                  = {(ICRA), 2013 IEEE {\ldots}},
  Year                     = {2013},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6630784}
}

@InProceedings{Buchmann2013,
  Title                    = {MOD2-SCM: A model-driven product line for software configuration management systems},
  Author                   = {Buchmann, Thomas and Dotor, Alexander and Westfechtel, Bernhard},
  Year                     = {2013},
  Month                    = {mar},
  Number                   = {3},
  Pages                    = {630--650},
  Volume                   = {55},

  Abstract                 = {Context: Software Configuration Management (SCM) is the discipline of controlling the evolution of large and complex software systems. Over the years many different SCM systems sharing similar concepts have been implemented from scratch. Since these concepts usually are hard-wired into the respective program code, reuse is hardly possible. Objective: Our objective is to create a model-driven product line for SCM systems. By explicitly describing the different concepts using models, reuse can be performed on the modeling level. Since models are executable, the need for manual programming is eliminated. Furthermore, by providing a library of loosely coupled modules, we intend to support flexible composition of SCM systems. Method: We developed a method and a tool set for model-driven software product line engineering which we applied to the SCM domain. For domain analysis, we applied the FORM method, resulting in a layered feature model for SCM systems. Furthermore, we developed an executable object-oriented domain model which was annotated with features from the feature model. A specific SCM system is configured by selecting features from the feature model and elements of the domain model realizing these features. Results: Due to the orthogonality of both feature model and domain model, a very large number of SCM systems may be configured. We tested our approach by creating instances of the product line which mimic wide-spread systems such as CVS, GIT, Mercurial, and Subversion. Conclusion: The experiences gained from this project demonstrate the feasibility of our approach to model-driven software product line engineering. Furthermore, our work advances the state of the art in the domain of SCM systems since it support the modular composition of SCM systems at the model rather than the code level. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.infsof.2012.07.010},
  ISSN                     = {09505849}
}

@InProceedings{Calvagna2013,
  Title                    = {Combinatorial testing for feature models using CitLab},
  Author                   = {Calvagna, Andrea and Gargantini, Angelo and Vavassori, Paolo},
  Year                     = {2013},
  Pages                    = {338--347},

  Abstract                 = {Feature models are commonly used to represent product lines and systems with a set of features interrelated each others. Test generation from feature models, i.e. generating a valid and representative subset of all the possible product configurations, is still an open challenge. A common approach is to build combinatorial interaction test suites, for instance achieving pair wise coverage among the features. In this paper we show how standard feature models can be translated to combinatorial interaction models in our framework CitLab, with all the advantages of having a combinatorial testing environment (in terms of a clear semantics, editing facilities, language for seeds and test goals, and generation algorithms). We present our translation which gives a precise semantics to feature models and it tries to minimize the number of parameter and constraints while preserving the original semantics of the feature model. Experiments show the advantages of our approach. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/ICSTW.2013.45}
}

@Article{Camacho2016,
  Title                    = {Cost-related interface for software product lines},
  Author                   = {Camacho, Carlos and Llana, Luis and N{\'{u}}{\~{n}}ez, Alberto},
  Year                     = {2016},

  Month                    = {jan},
  Number                   = {1},
  Pages                    = {227--244},
  Volume                   = {85},

  Abstract                 = {Software Product Lines modeling improves software development processes by automating system debugging and analysis. The objective of this paper focuses on extending the formal framework SPLA to represent features such as cost objects and comparisons between products in terms of production costs. We illustrate this extension with a practical example by modeling the creation of valid run-lists for Chef, a widely used configuration management tool. Also, we execute our formal specification in a distributed system using SCOOP and we provide strategies to optimize the effort required to compute a SPLA term.},
  Doi                      = {10.1016/j.jlamp.2015.09.009},
  ISSN                     = {23522216},
  Publisher                = {Elsevier Inc.}
}

@Article{Cao2012,
  Title                    = {An approach to automated conversion from design feature model to analysis feature model},
  Author                   = {Cao, Weijuan and Chen, Xiaoshen and Gao, Shuming},
  Year                     = {2012},

  Month                    = {aug},
  Number                   = {8},
  Pages                    = {1090--1098},
  Volume                   = {24},

  Abstract                 = {An approach to automatically converting a design feature model to an analysis feature model for downstream finite element analysis is proposed. In the approach, the design feature model is first decomposed into a set of remnants of additive features, each of which represents part of an additive feature's volume that remain in the final volume of the design model. The remnant of each additive feature is then decomposed into swept bodies and non-swept bodies. After that, the candidate analysis regions of each swept body are effectively determined based on its contour information. These detected candidate regions may be wrongly recognized, so, together with potentially missing ones, they are thus detected and corrected by a synthesis process. Finally, the analysis features and their relative interfaces are generated, which ultimately gives the corresponding analysis feature model to the input design feature model. Experimental results are also shown to demonstrate the proposed method's effectiveness.},
  ISSN                     = {10039775}
}

@Article{Capilla2014a,
  Title                    = {An overview of Dynamic Software Product Line architectures and techniques: Observations from research and industry},
  Author                   = {Capilla, Rafael and Bosch, Jan and Trinidad, Pablo and Ruiz-Cort{\'{e}}s, Antonio and Hinchey, Mike},
  Year                     = {2014},

  Month                    = {may},
  Number                   = {1},
  Pages                    = {3--23},
  Volume                   = {91},

  Abstract                 = {Over the last two decades, software product lines have been used successfully in industry for building families of systems of related products, maximizing reuse, and exploiting their variable and configurable options. In a changing world, modern software demands more and more adaptive features, many of them performed dynamically, and the requirements on the software architecture to support adaptation capabilities of systems are increasing in importance. Today, many embedded system families and application domains such as ecosystems, service-based applications, and self-adaptive systems demand runtime capabilities for flexible adaptation, reconfiguration, and post-deployment activities. However, as traditional software product line architectures fail to provide mechanisms for runtime adaptation and behavior of products, there is a shift toward designing more dynamic software architectures and building more adaptable software able to handle autonomous decision-making, according to varying conditions. Recent development approaches such as Dynamic Software Product Lines (DSPLs) attempt to face the challenges of the dynamic conditions of such systems but the state of these solution architectures is still immature. In order to provide a more comprehensive treatment of DSPL models and their solution architectures, in this research work we provide an overview of the state of the art and current techniques that, partially, attempt to face the many challenges of runtime variability mechanisms in the context of Dynamic Software Product Lines. We also provide an integrated view of the challenges and solutions that are necessary to support runtime variability mechanisms in DSPL models and software architectures. {\textcopyright} 2014 Elsevier Inc.},
  Doi                      = {10.1016/j.jss.2013.12.038},
  ISSN                     = {01641212}
}

@Article{Capilla2014,
  Title                    = {Context variability for context-aware systems},
  Author                   = {Capilla, R and Ortiz, {\'{O}} and Hinchey, M},
  Journal                  = {Computer (Long. Beach. Calif).},
  Year                     = {2014},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6756724}
}

@InProceedings{Carbonnel2016,
  Title                    = {FCA for software product lines representation: Mixing configuration and feature relationships in a unique canonical representation},
  Author                   = {Carbonnel, Jessie and Bertet, Karell and Huchard, Marianne and Nebut, Cl{\'{e}}mentine},
  Year                     = {2016},
  Pages                    = {109--122},
  Publisher                = {CEUR-WS},
  Volume                   = {1624},

  Abstract                 = {Software Product Line Engineering (SPLE) is a software engineering domain in which families of similar softwares (called products) are built reusing common artifacts. This requires to analyze commonalities and variabilities, for example to detect which parts are common to several products and which parts differ from one product to another. Such software characteristics that may be present or not in a product are called features. Several approaches in the literature exist to organize features and product configurations in terms of features. In this paper we review those approaches and show that concept lattices are a relevant structure to organize features and product configurations. We also address scaling issues related to formal context computation in the domain of SPLE.},
  ISSN                     = {16130073}
}

@InProceedings{Chen2011,
  Title                    = {Optimizing the product derivation process},
  Author                   = {Chen, Sheng and Erwig, Martin},
  Year                     = {2011},
  Pages                    = {35--44},

  Abstract                 = {Feature modeling is widely used in software product-line engineering to capture the commonalities and variabilities within an application domain. As feature models evolve, they can become very complex with respect to the number of features and the dependencies among them, which can cause the product derivation based on feature selection to become quite time consuming and error prone. We address this problem by presenting techniques to find good feature selection sequences that are based on the number of products that contain a particular feature and the impact of a selected feature on the selection of other features. Specifically, we identify a feature selection strategy, which brings up highly selective features early for selection. By prioritizing feature selection based on the selectivity of features our technique makes the feature selection process more efficient. Moreover, our approach helps with the problem of unexpected side effects of feature selection in later stages of the selection process, which is commonly considered a difficult problem. We have run our algorithm on the e-Shop and Berkeley DB feature models and also on some automatically generated feature models. The evaluation results demonstrate that our techniques can shorten the product derivation processes significantly. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/SPLC.2011.47},
  ISBN                     = {9780769544878}
}

@Article{Chen2016,
  Title                    = {FEMOSAA: Feature Guided and Knee Driven Multi-Objective Optimization for Self-Adaptive Software at Runtime},
  Author                   = {Chen, T and Li, K and Bahsoon, R and Yao, X},
  Journal                  = {arXiv Prepr. arXiv1608.08933},
  Year                     = {2016},

  Url                      = {https://arxiv.org/abs/1608.08933}
}

@Article{Chimiak-Opoka2011,
  Title                    = {OCL tools report based on the ide4OCL feature model},
  Author                   = {Chimiak-Opoka, JD and Demuth, B},
  Journal                  = {of the EASST},
  Year                     = {2011},

  Url                      = {http://journal.ub.tu-berlin.de/eceasst/article/view/665/0}
}

@InProceedings{Chrszon2016,
  Title                    = {Family-based modeling and analysis for probabilistic systems – featuring PROFEAT},
  Author                   = {Chrszon, Philipp and Dubslaff, Clemens and Kl{\"{u}}ppelholz, Sascha and Baier, Christel},
  Year                     = {2016},
  Pages                    = {287--304},
  Publisher                = {Springer Verlag},
  Volume                   = {9633},

  Abstract                 = {Feature-based formalisms provide an elegant way to specify families of systems that share a base functionality and differ in certain features. They can also facilitate an all-in-one analysis, where all systems of the family are analyzed at once on a single family model instead of one-by-one. This paper presents the basic concepts of the tool ProFeat, which provides a guarded-command language for modeling families of probabilistic systems and an automatic translation of family models to the input language of the probabilistic model checker Prism. This translational approach enables a family-based quantitative analysis with Prism. Besides modeling families of systems that differ in system parameters such as the number of identical processes or channel sizes, ProFeat also provides special support for the modeling and analysis of (probabilistic) product lines with dynamic feature switches, multifeatures and feature attributes. By means of several case studies we show how ProFeat eases family-based modeling and compare the one-by-one and all-in-one analysis approach.},
  Doi                      = {10.1007/978-3-662-49665-7_17},
  ISBN                     = {9783662496640},
  ISSN                     = {16113349}
}

@Article{Chuang2012,
  Title                    = {Epistatic interaction in software evolution and the solution},
  Author                   = {Chuang, Wang and Xiangwu, Meng},
  Year                     = {2012},

  Month                    = {apr},
  Number                   = {7},
  Pages                    = {234--241},
  Volume                   = {6},

  Abstract                 = {An algorithm is designed to solve the epistatic interaction problem in software evolution process of multi-version software. The interactions among software components complicate the decision problem of version chosen in the software evolution process. The software NK model is built based on the NK model and characteristics of software system. The theoretical analysis of the formal model is discussed. It is proved that some choices have no contribution to the optimal result, and these choices can be deleted to reduce the scale of the problem. The solving algorithms are provided based on these conclusions. The experiments verified the effectiveness of the proposed algorithm.},
  Doi                      = {10.4156/jdcta.vol6.issue7.29},
  ISSN                     = {19759339}
}

@InProceedings{Clarke2011,
  Title                    = {Variability modelling in the ABS language},
  Author                   = {Clarke, Dave and Muschevici, Radu and Proen{\c{c}}a, Jos{\'{e}} and Schaefer, Ina and Schlatte, Rudolf},
  Year                     = {2011},
  Pages                    = {204--224},
  Volume                   = {6957 LNCS},

  Abstract                 = {The HATS project aims at developing a model-centric methodology for the design, implementation and verification of highly configurable systems, such as software product lines, centred around the Abstract Behavioural Specification (ABS) modelling Language. This article describes the variability modelling features of the ABS Modelling framework. It consists of four languages, namely, $\mu$TVL for describing feature models at a high level of abstraction, the Delta Modelling Language DML for describing variability of the 'code' base in terms of delta modules, the Product Line Configuration Language CL for linking feature models and delta modules together and the Product Selection Language PSL for describing a specific product to extract from a product line. Both formal semantics and examples of each language are presented. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-25271-6_11},
  ISBN                     = {9783642252709},
  ISSN                     = {03029743}
}

@Article{Clarke2010a,
  Title                    = {Towards a theory of views for feature models},
  Author                   = {Clarke, D and Proen{\c{c}}a, J},
  Journal                  = {Proc. First Intl. Work.},
  Year                     = {2010},

  Url                      = {https://lirias.kuleuven.be/handle/123456789/288827}
}

@Article{Classen2011,
  Title                    = {Modelling and model checking variability-intensive systems},
  Author                   = {Classen, A},
  Year                     = {2011},

  Url                      = {http://dial.uclouvain.be/handle/boreal:90863}
}

@Article{Classen2011b,
  Title                    = {A text-based approach to feature modelling: Syntax and semantics of TVL},
  Author                   = {Classen, Andreas and Boucher, Quentin and Heymans, Patrick},
  Year                     = {2011},

  Month                    = {dec},
  Number                   = {12},
  Pages                    = {1130--1143},
  Volume                   = {76},

  Abstract                 = {In the scientific community, feature models are the de-facto standard for representing variability in software product line engineering. This is different from industrial settings where they appear to be used much less frequently. We and other authors found that in a number of cases, they lack concision, naturalness and expressiveness. This is confirmed by industrial experience. When modelling variability, an efficient tool for making models intuitive and concise are feature attributes. Yet, the semantics of feature models with attributes is not well understood and most existing notations do not support them at all. Furthermore, the graphical nature of feature models' syntax also appears to be a barrier to industrial adoption, both psychological and rational. Existing tool support for graphical feature models is lacking or inadequate, and inferior in many regards to tool support for text-based formats. To overcome these shortcomings, we designed TVL, a text-based feature modelling language. In terms of expressiveness, TVL subsumes most existing dialects. The main goal of designing TVL was to provide engineers with a human-readable language with a rich syntax to make modelling easy and models natural, but also with a formal semantics to avoid ambiguity and allow powerful automation. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.scico.2010.10.005},
  ISSN                     = {01676423}
}

@Article{Classen2011a,
  Title                    = {Symbolic model checking of software product lines},
  Author                   = {Classen, A and Heymans, P and Schobbens, PY},
  Journal                  = {Proc. 33rd},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=1985838}
}

@Article{Combemale2012,
  Title                    = {Using CVL to operationalize product line development with reusable aspect models},
  Author                   = {Combemale, B and Barais, O and Alam, O},
  Journal                  = {Proc.},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2425418}
}

@InProceedings{Constantino2016,
  Title                    = {An empirical study of two software product line tools},
  Author                   = {Constantino, Kattiana and Pereira, Juliana Alves and Padilha, Juliana and Vasconcelos, Priscilla and Figueiredo, Eduardo},
  Year                     = {2016},
  Pages                    = {164--171},
  Publisher                = {SciTePress},

  Abstract                 = {In the last decades, software product lines (SPL) have proven to be an efficient software development technique in industries due its capability to increase quality and productivity and decrease cost and time-tomarket through extensive reuse of software artifacts. To achieve these benefits, tool support is fundamental to guide industries during the SPL development life-cycle. However, many different SPL tools are available nowadays and the adoption of the appropriate tool is a big challenge in industries. In order to support engineers choosing a tool that best fits their needs, this paper presents the results of a controlled empirical study to assess two Eclipse-based tools, namely FeatureIDE and pure::variants. This empirical study involved 84 students who used and evaluated both tools. The main weakness we observe in both tools are the lack adequate mechanisms for managing the variability, such as for product configuration. As a strength, we observe the automated analysis and the feature model editor.},
  ISBN                     = {9789897581892}
}

@Article{Cordy2012,
  Title                    = {Managing evolution in software product lines: A model-checking perspective},
  Author                   = {Cordy, M and Classen, A and Schobbens, PY},
  Journal                  = {Proc.},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2110168}
}

@Article{Cordy2013,
  Title                    = {Beyond boolean product-line model checking: dealing with feature attributes and multi-features},
  Author                   = {Cordy, M and Schobbens, PY and Heymans, P},
  Journal                  = {Proc. 2013},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2486851}
}

@Article{Costa2015,
  Title                    = {A Scientific Software Product Line for the Bioinformatics domain},
  Author                   = {Costa, Gabriella Castro B and Braga, Regina and David, Jos{\'{e}} Maria N and Campos, Fernanda},
  Year                     = {2015},

  Month                    = {aug},
  Pages                    = {239--264},
  Volume                   = {56},

  Abstract                 = {Context: Most specialized users (scientists) that use bioinformatics applications do not have suitable training on software development. Software Product Line (SPL) employs the concept of reuse considering that it is defined as a set of systems that are developed from a common set of base artifacts. In some contexts, such as in bioinformatics applications, it is advantageous to develop a collection of related software products, using SPL approach. If software products are similar enough, there is the possibility of predicting their commonalities, differences and then reuse these common features to support the development of new applications in the bioinformatics area. Objectives: This paper presents the PL-Science approach which considers the context of SPL and ontology in order to assist scientists to define a scientific experiment, and to specify a workflow that encompasses bioinformatics applications of a given experiment. This paper also focuses on the use of ontologies to enable the use of Software Product Line in biological domains. Method: In the context of this paper, Scientific Software Product Line (SSPL) differs from the Software Product Line due to the fact that SSPL uses an abstract scientific workflow model. This workflow is defined according to a scientific domain and using this abstract workflow model the products (scientific applications/algorithms) are instantiated. Results: Through the use of ontology as a knowledge representation model, we can provide domain restrictions as well as add semantic aspects in order to facilitate the selection and organization of bioinformatics workflows in a Scientific Software Product Line. The use of ontologies enables not only the expression of formal restrictions but also the inferences on these restrictions, considering that a scientific domain needs a formal specification. Conclusions: This paper presents the development of the PL-Science approach, encompassing a methodology and an infrastructure, and also presents an approach evaluation. This evaluation presents case studies in bioinformatics, which were conducted in two renowned research institutions in Brazil.},
  Doi                      = {10.1016/j.jbi.2015.05.014},
  ISSN                     = {15320464},
  Publisher                = {Academic Press Inc.}
}

@InProceedings{Czarnecki2012,
  Title                    = {Cool features and tough decisions: A comparison of variability modeling approaches},
  Author                   = {Czarnecki, Krzysztof and Gr{\"{u}}nbacher, Paul and Rabiser, Rick and Schmid, Klaus and Wa̧sowski, Andrzej},
  Year                     = {2012},
  Pages                    = {173--182},

  Abstract                 = {Variability modeling is essential for defining and managing the commonalities and variabilities in software product lines. Numerous variability modeling approaches exist today to support domain and application engineering activities. Most are based on feature modeling (FM) or decision modeling (DM), but so far no systematic comparison exists between these two classes of approaches. Over the last two decades many new features have been added to both FM and DM and it is tough to decide which approach to use for what purpose. This paper clarifies the relation between FM and DM. We aim to systematize the research field of variability modeling and to explore potential synergies. We compare multiple aspects of FM and DM ranging from historical origins and rationale, through syntactic and semantic richness, to tool support, identifying commonalities and differences. We hope that this effort will improve the understanding of the range of approaches to variability modeling by discussing the possible variations. This will provide insights to users considering adopting variability modeling in practice and to designers of new languages, such as the new OMG Common Variability Language. Copyright 2012 ACM.},
  Doi                      = {10.1145/2110147.2110167},
  ISBN                     = {9781450310581}
}

@Article{Diaz2011,
  Title                    = {Change impact analysis in product-line architectures},
  Author                   = {D{\'{i}}az, J and P{\'{e}}rez, J and Garbajosa, J and Wolf, AL},
  Journal                  = {Eur. Conf. Softw.},
  Year                     = {2011},

  Url                      = {http://link.springer.com/10.1007{\%}2F978-3-642-23798-0{\_}12}
}

@InProceedings{Davril2013,
  Title                    = {Feature model extraction from large collections of informal product descriptions},
  Author                   = {Davril, Jean Marc and Delfosse, Edouard and Hariri, Negar and Acher, Mathieu and Cleland-Huang, Jane and Heymans, Patrick},
  Year                     = {2013},
  Pages                    = {290--300},

  Abstract                 = {Feature Models (FMs) are used extensively in software product line engineering to help generate and validate individual product configurations and to provide support for domain analysis. As FM construction can be tedious and time-consuming, researchers have previously developed techniques for extracting FMs from sets of formally specified individual configurations, or from software requirements specifications for families of existing products. However, such artifacts are often not available. In this paper we present a novel, automated approach for constructing FMs from publicly available product descriptions found in online product repositories and marketing websites such as SoftPedia and CNET. While each individual product description provides only a partial view of features in the domain, a large set of descriptions can provide fairly comprehensive coverage. Our approach utilizes hundreds of partial product descriptions to construct an FM and is described and evaluated against antivirus product descriptions mined from SoftPedia.},
  Doi                      = {10.1145/2491411.2491455},
  ISBN                     = {9781450322379}
}

@InProceedings{DeMello2012,
  Title                    = {Checklist-based inspection technique for feature models review},
  Author                   = {{De Mello}, Rafael M. and Teixeira, Eldanae N. and Schots, Marcelo and Werner, Cl{\'{a}}udia M L and Travassos, Guilherme Horta},
  Year                     = {2012},
  Pages                    = {140--149},

  Abstract                 = {Software Product Line Engineering aims to ensure the correctness, completeness and consistency among its artifacts and the specified domain, in order to prevent the spread of defects for the products derived from this domam. Among initial artifacts of a software product line, feature models are artifacts generated in various domain engineering approaches. Although software inspection is highlighted as an effective review activity for detection of defects in software artifacts, mainly in the early models of software projects, a recent quasi-systematic review of literature indicated a lack of techniques to support the inspection of software product line artifacts, which include features models. Thus, this paper presents FMCheck, a checklist-based inspection technique to support the detection of defects on feature models. This technique was developed to be configurable and to be applied on several extensions of the original feature model notation presented by FODA approach, including the Odyssey-FEX notation, in particular. FMCheck was submitted to a proof of concept and to a further in vitro feasibility study, in which it could be seen the feasibility of FMCheck application and also that inspections applying FMCheck are more effective than ad-hoc inspections, when applied on four distinct domains. {\textcopyright}2012 IEEE.},
  Doi                      = {10.1109/SBCARS.2012.25},
  ISBN                     = {9780769549170}
}

@Article{Deckwerth2016,
  Title                    = {Conflict Detection for Edits on Extended Feature Models using Symbolic Graph Transformation},
  Author                   = {Deckwerth, F and Kulcs{\'{a}}r, G and Lochau, M and Varr{\'{o}}, G},
  Journal                  = {arXiv Prepr. arXiv},
  Year                     = {2016},

  Url                      = {http://arxiv.org/abs/1604.00347}
}

@Article{Del-Rio-Ortega2013,
  Title                    = {On the definition and design-time analysis of process performance indicators},
  Author                   = {Del-R{\'{i}}o-Ortega, Adela and Resinas, Manuel and Cabanillas, Cristina and Ruiz-Cort{\'{e}}s, Antonio},
  Year                     = {2013},
  Number                   = {4},
  Pages                    = {470--490},
  Volume                   = {38},

  Abstract                 = {A key aspect in any process-oriented organisation is the evaluation of process performance for the achievement of its strategic and operational goals. Process Performance Indicators (PPIs) are a key asset to carry out this evaluation, and, therefore, having an appropriate definition of these PPIs is crucial. After a careful review of the literature related and a study of the current picture in different real organisations, we conclude that there not exists any proposal that allows to define PPIs in a way that is unambiguous and highly expressive, understandable by technical and non-technical users and traceable with the Business Process (BP). In addition, like other activities carried out during the BP lifecycle, the management of PPIs is considered time-consuming and error-prone. Therefore, providing an automated support for them is very appealing from a practical point of view. In this paper, we propose the PPINOT metamodel, which allows such an advanced definition of PPIs and is independent of the language used to model the business process. Furthermore, we provide an automatic semantic mapping from the metamodel to Description Logics (DL) that allows the implementation of design-time analysis operations in such a way that DL reasoners' facilities can be leveraged. These operations provide information that can assist process analysts in the definition and instrumentation of PPIs. Finally, to validate the usefulness of our proposal, we have used the PPINOT metamodel at the core of a software tool called the PPINOT Tool Suite and we have applied it in several real scenarios. {\textcopyright} 2012 Elsevier Ltd.},
  Doi                      = {10.1016/j.is.2012.11.004},
  ISSN                     = {03064379}
}

@Article{Dermeval2015,
  Title                    = {Ontology-based feature modeling: An empirical study in changing scenarios},
  Author                   = {Dermeval, Diego and Ten{\'{o}}rio, Thyago and Bittencourt, Ig Ibert and Silva, Alan and Isotani, Seiji and Ribeiro, M{\'{a}}rcio},
  Year                     = {2015},

  Month                    = {jul},
  Number                   = {11},
  Pages                    = {4950--4964},
  Volume                   = {42},

  Abstract                 = {A software product line (SPL) is a set of software systems that have a particular set of common features and that satisfy the needs of a particular market segment or mission. Feature modeling is one of the key activities involved in the design of SPLs. The feature diagram produced in this activity captures the commonalities and variabilities of SPLs. In some complex domains (e.g.; ubiquitous computing, autonomic systems and context-aware computing), it is difficult to foresee all functionalities and variabilities a specific SPL may require. Thus, Dynamic Software Product Lines (DSPLs) bind variation points at runtime to adapt to fluctuations in user needs as well as to adapt to changes in the environment. In this context, relying on formal representations of feature models is important to allow them to be automatically analyzed during system execution. Among the mechanisms used for representing and analyzing feature models, description logic (DL) based approaches demand to be better investigated in DSPLs since it provides capabilities, such as automated inconsistency detection, reasoning efficiency, scalability and expressivity. Ontology is the most common way to represent feature models knowledge based on DL reasoners. Previous works conceived ontologies for feature modeling either based on OWL classes and properties or based on OWL individuals. However, considering change or evolution scenarios of feature models, we need to compare whether a class-based or an individual-based feature modeling style is recommended to describe feature models to support SPLs, and especially its capabilities to deal with changes in feature models, as required by DSPLs. In this paper, we conduct a controlled experiment to empirically compare two approaches based on each one of these modeling styles in several changing scenarios (e.g.; add/remove mandatory feature, add/remove optional feature and so on). We measure time to perform changes, structural impact of changes (flexibility) and correctness for performing changes in our experiment. Our results indicate that using OWL individuals requires less time to change and is more flexible than using OWL classes and properties. These results provide insightful assumptions towards the definition of an approach relying on reasoning capabilities of ontologies that can effectively support products reconfiguration in the context of DSPL.},
  Doi                      = {10.1016/j.eswa.2015.02.020},
  ISSN                     = {09574174},
  Publisher                = {Elsevier Ltd}
}

@Article{Dhungana2013,
  Title                    = {Integrating heterogeneous variability modeling approaches with invar},
  Author                   = {Dhungana, D and Seichter, D and Botterweck, G},
  Journal                  = {Proc.},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2430514}
}

@InProceedings{Dhungana2011,
  Title                    = {Configuration of multi product lines by bridging heterogeneous variability modeling approaches},
  Author                   = {Dhungana, Deepak and Seichter, Dominik and Botterweck, Goetz and Rabiser, Rick and Gr{\"{u}}nbacher, Paul and Benavides, David and Galindo, Jos{\'{e}} A.},
  Year                     = {2011},
  Pages                    = {120--129},

  Abstract                 = {In industrial settings, products are rarely developed by one organization alone. Software vendors and suppliers typically maintain their own product lines, which can contribute to a larger (multi) product line. The teams involved often use different approaches and tools to manage the variability of their systems. It is unrealistic to assume that all participating units can use a standardized and prescribed variability modeling technique. The configuration of products based on several models in different notations and with different semantics is not well supported by existing approaches. In this paper we present an integrative approach that provides a unified perspective to users configuring products in multi product line environments, regardless of the different modeling methods and tools used internally. We also present a technical infrastructure and a prototypic implementation based on Web Services. We show the feasibility of the approach and its implementation by using it with two different variability modeling approaches (one feature-based and one decision-oriented approach) on an example derived from industrial experience. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/SPLC.2011.22},
  ISBN                     = {9780769544878}
}

@InProceedings{Dhungana2013a,
  Title                    = {Automated verification of interactive rule-based configuration systems},
  Author                   = {Dhungana, Deepak and Tang, Ching Hoo and Weidenbach, Christoph and Wischnewski, Patrick},
  Year                     = {2013},
  Pages                    = {551--561},

  Abstract                 = {Rule-based specifications of systems have again become common in the context of product line variability modeling and configuration systems. In this paper, we define a logical foundation for rule-based specifications that has enough expressivity and operational behavior to be practically useful and at the same time enables decidability of important overall properties such as consistency or cycle-freeness. Our logic supports rule-based interactive user transitions as well as the definition of a domain theory via rule transitions. As a running example, we model DOPLER, a rule-based configuration system currently in use at Siemens. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/ASE.2013.6693112},
  ISBN                     = {9781479902156}
}

@Article{Dintzner2014,
  Title                    = {Extracting feature model changes from the Linux kernel using FMDiff},
  Author                   = {Dintzner, N and Deursen, A Van and Pinzger, M},
  Journal                  = {Proc. Eighth},
  Year                     = {2014},

  Url                      = {http://dl.acm.org/citation.cfm?id=2556631}
}

@Article{Dougherty2012,
  Title                    = {Model-driven auto-scaling of green cloud computing infrastructure},
  Author                   = {Dougherty, B and White, J and Schmidt, DC},
  Journal                  = {Futur. Gener. Comput. Syst.},
  Year                     = {2012},

  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167739X11000902}
}

@InProceedings{Dubslaff2015,
  Title                    = {Probabilistic model checking for feature-oriented systems},
  Author                   = {Dubslaff, Clemens and Baier, Christel and Kl{\"{u}}ppelholz, Sascha},
  Year                     = {2015},
  Pages                    = {180--220},
  Publisher                = {Springer Verlag},
  Volume                   = {8989},

  Abstract                 = {Within product lines, collections of several related products are defined through their commonalities in terms of features rather than specifying them individually one-by-one. In this paper we present a compositional framework for modeling dynamic product lines by a statebased formalism with both probabilistic and nondeterministic behaviors. Rules for feature changes in products made during runtime are formalized by a coordination component imposing constraints on possible feature activations and deactivations. Our framework supports large-scaled product lines described through multi-features, i.e., where products may involve multiple instances of a feature. To establish temporal properties for products in a product line, verification techniques have to face a combinatorial blow-up that arises when reasoning about several feature combinations. This blow-up can be avoided by family-based approaches exploiting common feature behaviors. We adapt such approaches to our framework, allowing for a quantitative analysis in terms of probabilistic model checking to reason, e.g., about energy and memory consumption, monetary costs, or the reliability of products. Our framework can also be used to compute strategies how to trigger feature changes for optimizing quantitative objectives using probabilistic model-checking techniques. We present a natural and conceptually simple translation of product lines into the input language of the prominent probabilistic model checker Prism and show feasibility of this translation within a case study on an energy-aware server platform product line comprising thousands of products. To cope with the arising complexity, we follow the family-based analysis scheme and apply symbolic methods for a compact state-space representation.},
  Doi                      = {10.1007/978-3-662-46734-3_5},
  ISBN                     = {9783662467336},
  ISSN                     = {16113349}
}

@InProceedings{Dubslaff2014,
  Title                    = {Probabilistic model checking for energy analysis in software product lines},
  Author                   = {Dubslaff, Clemens and Kl{\"{u}}ppelholz, Sascha and Baier, Christel},
  Year                     = {2014},
  Pages                    = {169--180},
  Publisher                = {Association for Computing Machinery},

  Abstract                 = {In a software product line (SPL), a collection of software products is defined by their commonalities in terms of features rather than explicitly specifying all products one-by-one. Several verification techniques were adapted to establish temporal properties of SPLs. Symbolic and family-based model checking have been proven to be successful for tackling the combinatorial blow-up arising when reasoning about several feature combinations. However, most formal verification approaches for SPLs presented in the literature focus on the static SPLs, where the features of a product are fixed and cannot be changed during runtime. This is in contrast to dynamic SPLs, allowing to adapt feature combinations of a product dynamically after deployment. The main contribution of the paper is a compositional modeling framework for dynamic SPLs, which supports probabilistic and nondeterministic choices and allows for quantitative analysis. We specify the feature changes during runtime within an automata-based coordination component, enabling to reason over strategies how to trigger dynamic feature changes for optimizing various quantitative objectives, e.g., energy or monetary costs and reliability. For our framework there is a natural and conceptually simple translation into the input language of the prominent probabilistic model checker PRISM. This facilitates the application of PRISM's powerful symbolic engine to the operational behavior of dynamic SPLs and their family-based analysis against various quantitative queries. We demonstrate feasibility of our approach by a case study issuing an energy-aware bonding network device. Copyright {\textcopyright} 2014 ACM. Copyright {\textcopyright} 2014 ACM.},
  Doi                      = {10.1145/2577080.2577095}
}

@Article{Dumitrescu2013,
  Title                    = {Bridging the gap between product lines and systems engineering: an experience in variability management for automotive model based systems engineering},
  Author                   = {Dumitrescu, C and Mazo, R and Salinesi, C},
  Journal                  = {Proc. 17th},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2491655}
}

@InProceedings{Dumitru2011,
  Title                    = {On-demand feature recommendations derived from mining public product descriptions},
  Author                   = {Dumitru, Horatiu and Gibiec, Marek and Hariri, Negar and Cleland-Huang, Jane and Mobasher, Bamshad and Castro-Herrera, Carlos and Mirakhorli, Mehdi},
  Year                     = {2011},
  Pages                    = {181--190},

  Abstract                 = {We present a recommender system that models and recommends product features for a given domain. Our approach mines product descriptions from publicly available online specifications, utilizes text mining and a novel incremental diffusive clustering algorithm to discover domain-specific features, generates a probabilistic feature model that represents commonalities, variants, and cross-category features, and then uses association rule mining and the k-Nearest-Neighbor machine learning strategy to generate product specific feature recommendations. Our recommender system supports the relatively labor-intensive task of domain analysis, potentially increasing opportunities for re-use, reducing time-to-market, and delivering more competitive software products. The approach is empirically validated against 20 different product categories using thousands of product descriptions mined from a repository of free software applications. {\textcopyright} 2011 ACM.},
  Doi                      = {10.1145/1985793.1985819},
  ISBN                     = {9781450304450},
  ISSN                     = {02705257}
}

@InCollection{Dunlap2013,
  Title                    = {A feature model of coupling technologies for Earth System Models},
  Author                   = {Dunlap, Rocky and Rugaber, Spencer and Mark, Leo},
  Booktitle                = {Computers \& Geosciences},
  Year                     = {2013},
  Month                    = {apr},
  Pages                    = {13--20},
  Volume                   = {53},

  Abstract                 = {Couplers that link together two or more numerical simulations are well-known abstractions in the Earth System Modeling (ESM) community. In the past decade, reusable software assets have emerged to facilitate scientists in implementing couplers. While there is a large amount of overlap in the features supported by software coupling technologies, their implementations differ significantly in terms of both functional and non-functional properties. Using a domain analysis method called feature analysis, we explore the spectrum of features supported by coupling technologies used to build today's production ESMs. {\textcopyright} 2011 Elsevier Ltd.},
  Doi                      = {10.1016/j.cageo.2011.10.002},
  ISSN                     = {00983004}
}

@Article{Eichelberger2014,
  Title                    = {Mapping the design-space of textual variability modeling languages: a refined analysis},
  Author                   = {Eichelberger, Holger and Schmid, Klaus},
  Year                     = {2014},

  Month                    = {dec},
  Number                   = {5},
  Pages                    = {559--584},
  Volume                   = {17},

  Abstract                 = {Variability modeling is a major part of modern product line engineering. Graphical or table-based approaches to variability modeling are focused around abstract models and specialized tools to interact with these models. However, more recently textual variability modeling languages, comparable to some extent to programming languages, were introduced. We consider the recent trend in product line engineering towards textual variability modeling languages as a phenomenon, which deserves deeper analysis. In this article, we report on the results and approach of a literature survey combined with an expert study. In the literature survey, we identified 11 languages, which enable the textual specification of product line variability and which are sufficiently described for an in-depth analysis. We provide a classification scheme, useful to describe the range of capabilities of such languages. Initially, we identified the relevant capabilities of these languages from a literature survey. The result of this has been refined, validated and partially improved by the expert survey. A second recent phenomenon in product line variability modeling is the increasing scale of variability models. Some authors of textual variability modeling languages argue that these languages are more appropriate for large-scale models. As a consequence, we would expect specific capabilities addressing scalability in the languages. Thus, we compare the capabilities of textual variability modeling techniques, if compared to graphical variability modeling approaches and in particular to analyze their specialized capabilities for large-scale models.},
  Doi                      = {10.1007/s10009-014-0362-x},
  ISSN                     = {14332787},
  Publisher                = {Springer Verlag}
}

@Article{Eichelberger2013,
  Title                    = {A systematic analysis of textual variability modeling languages},
  Author                   = {Eichelberger, H and Schmid, K},
  Journal                  = {17th Int. Softw. Prod. {\ldots}},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2491652}
}

@InProceedings{ElDammagh2011,
  Title                    = {Feature modeling tools: Evaluation and lessons learned},
  Author                   = {{El Dammagh}, Mohammed and {De Troyer}, Olga},
  Year                     = {2011},
  Pages                    = {120--129},
  Volume                   = {6999 LNCS},

  Abstract                 = {This paper presents an evaluation of feature modeling tools. The purpose of the evaluation was to gain insight in the aspects that influence the quality and more in the particular usability. The evaluation focused on the quality criteria: usability, safety, and the support for functional usability requirements. The study involved 9 feature-modeling tools and was done using an experimental evaluation and an investigation by the authors of the paper. From the results, recommendations are formulated that can be taken into consideration in future tool design for these kind of modeling tools. {\textcopyright} 2011 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-24574-9_17},
  ISBN                     = {9783642245732},
  ISSN                     = {03029743}
}

@Article{El-Sharkawy2012,
  Title                    = {From feature models to decision models and back again an analysis based on formal transformations},
  Author                   = {El-Sharkawy, S and Dederichs, S and Schmid, K},
  Journal                  = {Proc. 16th},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2362555}
}

@Article{Ensan2012,
  Title                    = {Evolutionary search-based test generation for software product line feature models},
  Author                   = {Ensan, F and Bagheri, E and Ga{\v{s}}evi{\'{c}}, D},
  Journal                  = {Int. Conf. Adv.},
  Year                     = {2012},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-31095-9{\_}40}
}

@InProceedings{Ernst2011,
  Title                    = {Finding incremental solutions for evolving requirements},
  Author                   = {Ernst, Neil A. and Borgida, Alexander and Jureta, Ivan},
  Year                     = {2011},
  Pages                    = {15--24},

  Abstract                 = {This paper investigates aspects of the problem of software evolution resulting from top-level requirements change. In particular, while most research on design for software focuses on finding some correct solution, this ignores that such a solution is often only correct in a particular, and often short-lived, context. Using a logic-based goal-oriented requirements modeling language, the paper poses the problem of finding desirable solutions as the requirements change. Among other possible criteria of desirability, we consider minimizing the effort required to implement the new solution, which involves reusing parts of the old solution. In general, the solution of requirements problems is viewed as an exploration using a "requirements engineering knowledge base" (REKB), whose specification is formalized. The paper reports on experience implementing the REKB on top of a so-called "reason-maintenance system", and provides evidence that incremental solution finding is indeed more efficient. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/RE.2011.6051656},
  ISBN                     = {9781457709234}
}

@InProceedings{Eyal-Salman2016,
  Title                    = {Toward recovering component-based software product line architecture from object-oriented product variants},
  Author                   = {Eyal-Salman, Hamzeh and Seriai, Abdelhak Djamel},
  Year                     = {2016},
  Pages                    = {1--7},
  Publisher                = {Knowledge Systems Institute Graduate School},

  Abstract                 = {Usually, companies meet different customer needs in a particular domain by developing variants of a software product. This is often performed by ad-hoc copying and modifying of various existing variants to fit purposes of new one. As the number of product variants grows, such an adhoc development causes severe problems to maintain these variants. Software Product Line Engineering (SPLE) can be helpful here by supporting a large-scale reuse systematically. SPL architecture (SPLA) is a key asset as it is used to derive architecture for each product in SPL. Unfortunately, developing SPLA from scratch is a costly task. In this paper, we propose an approach to contribute for recovering SPLA from existing product variants. This contribution is two-fold. Firstly, identifying common features and variation points of features of a given collection of product variants. Secondly, exploiting commonality and variability in terms of features to identify mandatory components and variation points of components as an important step in this recovering process. To evaluate the proposed approach, we applied it to two case studies. The experimental results bring evidence the effectiveness of our approach.},
  ISBN                     = {189170639X},
  ISSN                     = {23259086}
}

@Article{Famelis2012,
  Title                    = {Partial models: Towards modeling and reasoning with uncertainty},
  Author                   = {Famelis, M and Salay, R and Chechik, M},
  Journal                  = {2012 34th Int.},
  Year                     = {2012},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6227159}
}

@Article{Felfernig2013,
  Title                    = {Towards anomaly explanation in feature models},
  Author                   = {Felfernig, A and Benavides, D and Galindo, J},
  Journal                  = {Config. Vienna, {\ldots}},
  Year                     = {2013},

  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.664.5138{\&}rep=rep1{\&}type=pdf{\#}page=117}
}

@Book{Felfernig2014,
  Title                    = {Knowledge-based configuration: From research to business cases},
  Author                   = {Felfernig, A and Hotz, L and Bagley, C and Tiihonen, J},
  Year                     = {2014},

  Url                      = {https://books.google.es/books?hl=en{\&}lr={\&}id=fSqSAgAAQBAJ{\&}oi=fnd{\&}pg=PR1{\&}ots={\_}1sX0zoUpe{\&}sig=UrUby5Ja3kMJlIURRJQ28hctv6k}
}

@InCollection{Felfernig2014a,
  Title                    = {Configuration-Related Research Challenges},
  Author                   = {Felfernig, Alexander and Hotz, Lothar and Bagley, Claire and Tiihonen, Juha},
  Publisher                = {Elsevier Inc.},
  Year                     = {2014},
  Month                    = {apr},
  Pages                    = {191--195},

  Abstract                 = {In this part on advanced topics in configuration, we took a look at the issues of configuration knowledge engineering (testing and debugging and redundancy detection) and intelligent configurator user interfaces (personalized configuration and consumer decision-making). To stimulate further configuration-related research, we conclude this part with a discussion of issues for future research. {\textcopyright} 2014 Elsevier Inc. All rights reserved.},
  Doi                      = {10.1016/B978-0-12-415817-7.00015-3},
  ISBN                     = {9780124158177}
}

@Article{Fernandes2011,
  Title                    = {An approach for feature modeling of context-aware software product line},
  Author                   = {Fernandes, Paula and Werner, Cl{\'{a}}udia and Teixeira, Eld{\^{a}}nae},
  Year                     = {2011},
  Number                   = {5},
  Pages                    = {807--829},
  Volume                   = {17},

  Abstract                 = {Feature modeling is an approach to represent commonalities and variabilities among products of a product line. Context-aware applications use context information to provide relevant services and information for their users. One of the challenges to build a context-aware product line is to develop mechanisms to incorporate context information and adaptation knowledge in a feature model. This paper presents UbiFEX, an approach to support feature analysis for context-aware software product lines, which incorporates a modeling notation and a mechanism to verify the consistency of product configuration regarding context variations. Moreover, an experimental study was performed as a preliminary evaluation, and a prototype was developed to enable the application of the proposed approach. {\textcopyright} J.UCS.},
  ISSN                     = {0958695X}
}

@Article{Fernandez-Amoros2014,
  Title                    = {A Scalable Approach to Exact Model and Commonality Counting for Extended Feature Models},
  Author                   = {Fernandez-Amoros, David and Heradio, Ruben and Cerrada, Jose A. and Cerrada, Carlos},
  Year                     = {2014},

  Month                    = {sep},
  Number                   = {9},
  Pages                    = {895--910},
  Volume                   = {40},

  Abstract                 = {A software product line is an engineering approach to efficient development of software product portfolios. Key to the success of the approach is to identify the common and variable features of the products and the interdependencies between them, which are usually modeled using feature models. Implicitly, such models also include valuable information that can be used by economic models to estimate the payoffs of a product line. Unfortunately, as product lines grow, analyzing large feature models manually becomes impracticable. This paper proposes an algorithm to compute the total number of products that a feature model represents and, for each feature, the number of products that implement it. The inference of both parameters is helpful to describe the standardization/parameterization balance of a product line, detect scope flaws, assess the product line incremental development, and improve the accuracy of economic models. The paper reports experimental evidence that our algorithm has better runtime performance than existing alternative approaches.},
  Doi                      = {10.1109/TSE.2014.2331073},
  ISSN                     = {00985589},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.}
}

@Article{Filho2014,
  Title                    = {Generating counterexamples of model-based software product lines},
  Author                   = {Filho, Jo{\~{a}}o Bosco Ferreira and Barais, Olivier and Acher, Mathieu and {Le Noir}, J{\'{e}}r{\^{o}}me and Legay, Axel and Baudry, Benoit},
  Year                     = {2014},

  Month                    = {aug},
  Number                   = {5},
  Pages                    = {585--600},
  Volume                   = {17},

  Abstract                 = {In a model-based software product line (MSPL), the variability of the domain is characterized in a variability model and the core artifacts are base models conforming to a modeling language (also called metamodel). A realization model connects the features of the variability model to the base model elements, triggering operations over these elements based on a configuration. The design space of an MSPL is extremely complex to manage for the engineer, since the number of variants may be exponential and the derived product models have to be conforming to numerous well-formedness and business rules. In this paper, the objective is to provide a way to generate MSPLs, called counterexamples (also called antipatterns), that can produce invalid product models despite a valid configuration in the variability model. We describe the foundations and motivate the usefulness of counterexamples (e.g., inference of guidelines or domain-specific rules to avoid earlier the specification of incorrect mappings; testing oracles for increasing the robustness of derivation engines given a modeling language). We provide a generic process, based on the common variability language (CVL) to randomly search the space of MSPLs for a specific modeling language. We develop LineGen a tool on top of CVL and modeling technologies to support the methodology and the process. LineGen targets different scenarios and is flexible to work either with just a domain metamodel as input or also with pre-defined variability models and base models. We validate the effectiveness of this process for three formalisms at different scales (up to 247 metaclasses and 684 rules). We also apply the approach in the context of a real industrial scenario involving a large-scale metamodel.},
  Doi                      = {10.1007/s10009-014-0341-2},
  ISSN                     = {14332787},
  Publisher                = {Springer Verlag}
}

@InProceedings{Fischer2016,
  Title                    = {A preliminary empirical assessment of similarity for combinatorial interaction testing of software product lines},
  Author                   = {Fischer, Stefan and Lopez-Herrejon, Roberto E. and Ramler, Rudolf and Egyed, Alexander},
  Year                     = {2016},
  Month                    = {may},
  Pages                    = {15--18},
  Publisher                = {Association for Computing Machinery, Inc},

  Abstract                 = {Extensive work on Search-Based Software Testing for Software Product Lines has been published in the last few years. Salient among them is the use of similarity as a surrogate metric for t-wise coverage whenever higher strengths are needed or whenever the size of the test suites is infeasible because of technological or budget limitations. Though promising, this metric has not been assessed with real fault data. In this paper, we address this limitation by using Drupal, a widely used open source web content management system, as an industry-strength case study for which both variability information and fault data have been recently made available. Our preliminary assessment corroborates some of the previous findings but also raises issues on some assumptions and claims made. We hope our work encourages further empirical evaluations of Combinatorial Interaction Testing approaches for Software Product Lines.},
  Doi                      = {10.1145/2897010.2897011},
  ISBN                     = {9781450341660}
}

@InProceedings{Font2015,
  Title                    = {Addressing metamodel revisions in model-based Software Product Lines},
  Author                   = {Font, Jaime and Arcega, Lorena and Haugen, {\O}ystein and Cetina, Carlos},
  Year                     = {2015},
  Month                    = {oct},
  Pages                    = {161--170},
  Publisher                = {Association for Computing Machinery, Inc},

  Abstract                 = {Metamodels evolve over time, which can break the conformance between the models and the metamodel. Model migration strategies aim to co-evolve models and metamodels together, but their application is not fully automatizable and is thus cumbersome and error prone. We introduce the Variable MetaModel (VMM) strategy to address the evolution of the reusable model assets of a model-based Software Product Line. TheVMMstrategy applies variability modeling ideas to express the evolution of the metamodel in terms of commonalities and variabilities. When the metamodel evolves, the models continue to conform to the VMM, avoiding the need for migration. We have applied both the traditional migration strategy and the VMM strategy to a retrospective case study that includes 13 years of evolution of our industrial partner, an induction hobs manufacturer. The comparison between the two strategies shows better results for the VMM strategy in terms of model indirection, automation, and trust leak.},
  Doi                      = {10.1145/2814204.2814214},
  ISBN                     = {9781450336871}
}

@Article{Gomez2014,
  Title                    = {A framework for variable content document generation with multiple actors},
  Author                   = {G{\'{o}}mez, Abel and Penad{\'{e}}s, M. Carmen and Can{\'{o}}s, Jos{\'{e}} H. and Borges, Marcos R S and Llavador, Manuel},
  Year                     = {2014},
  Number                   = {9},
  Pages                    = {1101--1121},
  Volume                   = {56},

  Abstract                 = {Context Advances in customization have highlighted the need for tools supporting variable content document management and generation in many domains. Current tools allow the generation of highly customized documents that are variable in both content and layout. However, most frameworks are technology-oriented, and their use requires advanced skills in implementation-related tools, which means their use by end users (i.e. document designers) is severely limited. Objective Starting from past and current trends for customized document authoring, our goal is to provide a document generation alternative in which variants are specified at a high level of abstraction and content reuse can be maximized in high variability scenarios. Method Based on our experience in Document Engineering, we identified areas in the variable content document management and generation field open to further improvement. We first classified the primary sources of variability in document composition processes and then developed a methodology, which we called DPL - based on Software Product Lines principles - to support document generation in high variability scenarios. Results In order to validate the applicability of our methodology we implemented a tool - DPLfw - to carry out DPL processes. After using this in different scenarios, we compared our proposal with other state-of-the-art tools for variable content document management and generation. Conclusion The DPLfw showed a good capacity for the automatic generation of variable content documents equal to or in some cases surpassing other currently available approaches. To the best of our knowledge, DPLfw is the only framework that combines variable content and document workflow facilities, easing the generation of variable content documents in which multiple actors play different roles. {\textcopyright} 2014 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.infsof.2013.12.006},
  ISSN                     = {09505849},
  Publisher                = {Elsevier}
}

@Article{Gomez2010,
  Title                    = {Cardinality-Based Feature Modeling and Model-Driven Engineering: Fitting them Together.},
  Author                   = {G{\'{o}}mez, A and Ramos, I},
  Journal                  = {VaMoS},
  Year                     = {2010},

  Url                      = {http://issi.dsic.upv.es/publications/archives/f-1263570538890/document.pdf}
}

@InProceedings{Gunther2012,
  Title                    = {RbFeatures: Feature-oriented programming with Ruby},
  Author                   = {G{\"{u}}nther, Sebastian and Sunkle, Sagar},
  Year                     = {2012},
  Month                    = {mar},
  Number                   = {3},
  Pages                    = {152--173},
  Volume                   = {77},

  Abstract                 = {Features are pieces of core functionality of a program that is relevant to particular stakeholders. Features pose dependencies and constraints among each other. These dependencies and constraints describe the possible number of variants of the program: A valid feature configuration generates a specific variant with unique behavior. Feature-Oriented Programming is used to implement features as program units. This paper introduces rbFeatures, a feature-oriented programming language implemented on top of the dynamic programming language Ruby. With rbFeatures, programmers use software product lines, variants, and features as first-class entities. This allows several runtime reflection and modification capabilities, including the extension of the product line with new features and the provision of multiple variants. The paper gives a broad overview to the implementation and application of rbFeatures. We explain how features as first-class entities are designed and implemented, and discuss how the semantics of features are carefully added to Ruby programs. We show two case studies: The expression product line, a common example in feature-oriented programming, and a web application. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.scico.2010.12.007},
  ISSN                     = {01676423}
}

@InProceedings{Galindo2014,
  Title                    = {A variability-based testing approach for synthesizing video sequences},
  Author                   = {Galindo, Jos{\'{e}} A. and Alf{\'{e}}rez, Mauricio and Acher, Mathieu and Baudry, Benoit and Benavides, David},
  Year                     = {2014},
  Month                    = {jul},
  Pages                    = {293--303},
  Publisher                = {Association for Computing Machinery, Inc},

  Abstract                 = {A key problem when developing video processing software is the difficulty to test different input combinations. In this paper, we present VANE, a variability-based testing approach to derive video sequence variants. The ideas of VANE are i) to encode in a variability model what can vary within a video sequence; ii) to exploit the variability model to generate testable configurations; iii) to synthesize variants of video sequences corresponding to configurations. VANE computes T-wise covering sets while optimizing a function over attributes. Also, we present a preliminary validation of the scalability and practicality of VANE in the context of an industrial project involving the test of video processing algorithms.},
  ISBN                     = {9781450326452}
}

@InProceedings{Galindo2010,
  Title                    = {Debian packages repositories as software product line models. Towards automated analysis},
  Author                   = {Galindo, Jos{\'{e}} A. and Benavides, David and Segura, Sergio},
  Year                     = {2010},
  Pages                    = {29--34},
  Volume                   = {688},

  Abstract                 = {The automated analysis of variability models in general and feature models in particular is a thriving research topic. There have been numerous contributions along the last twenty years in this area including both, research papers and tools. However, the lack of realistic variability models to evaluate those techniques and tools is recognized as a major problem by the community. To address this issue, we looked for large-scale variability models in the open source community. We found that the Debian package dependency language can be interpreted as software product line variability model. Moreover, we found that those models can be automatically analysed in a software product line variability model-like style. In this paper, we take a first step towards the automated analysis of Debian package dependency language. We provide a mapping from these models to propositional formulas. We also show how this could allow us to perform analysis operations on the repositories like the detection of anomalies (e.g. packages that cannot be installed).},
  ISSN                     = {16130073}
}

@Article{Galindo2015,
  Title                    = {Supporting distributed product configuration by integrating heterogeneous variability modeling approaches},
  Author                   = {Galindo, Jos{\'{e}} A. and Dhungana, Deepak and Rabiser, Rick and Benavides, David and Botterweck, Goetz and Gr{\"{u}}nbacher, Paul},
  Year                     = {2015},
  Number                   = {1},
  Pages                    = {78--100},
  Volume                   = {62},

  Abstract                 = {Context: In industrial settings products are developed by more than one organization. Software vendors and suppliers commonly typically maintain their own product lines, which contribute to a larger (multi) product line or software ecosystem. It is unrealistic to assume that the participating organizations will agree on using a specific variability modeling technique - they will rather use different approaches and tools to manage the variability of their systems. Objective: We aim to support product configuration in software ecosystems based on several variability models with different semantics that have been created using different notations. Method: We present an integrative approach that provides a unified perspective to users configuring products in multi product line environments, regardless of the different modeling methods and tools used internally. We also present a technical infrastructure and a prototype implementation based on web services. Results: We show the feasibility of the approach and its implementation by using it with the three most widespread types of variability modeling approaches in the product line community, i.e., feature-based, OVM-style, and decision-oriented modeling. To demonstrate the feasibility and flexibility of our approach, we present an example derived from industrial experience in enterprise resource planning. We further applied the approach to support the configuration of privacy settings in the Android ecosystem based on multiple variability models. We also evaluated the performance of different model enactment strategies used in our approach. Conclusions: Tools and techniques allowing stakeholders to handle variability in a uniform manner can considerably foster the initiation and growth of software ecosystems from the perspective of software reuse and configuration.},
  Doi                      = {10.1016/j.infsof.2015.02.002},
  ISSN                     = {09505849},
  Publisher                = {Elsevier}
}

@Article{Galindo2016,
  Title                    = {Testing variability-intensive systems using automated analysis: an application to Android},
  Author                   = {Galindo, Jos{\'{e}} A. and Turner, Hamilton and Benavides, David and White, Jules},
  Year                     = {2016},

  Month                    = {jun},
  Number                   = {2},
  Pages                    = {365--405},
  Volume                   = {24},

  Abstract                 = {Software product lines are used to develop a set of software products that, while being different, share a common set of features. Feature models are used as a compact representation of all the products (e.g., possible configurations) of the product line. The number of products that a feature model encodes may grow exponentially with the number of features. This increases the cost of testing the products within a product line. Some proposals deal with this problem by reducing the testing space using different techniques. However, a daunting challenge is to explore how the cost and value of test cases can be modeled and optimized in order to have lower-cost testing processes. In this paper, we present TESting vAriAbiLity Intensive Systems (TESALIA), an approach that uses automated analysis of feature models to optimize the testing of variability-intensive systems. We model test value and cost as feature attributes, and then we use a constraint satisfaction solver to prune, prioritize and package product line tests complementing prior work in the software product line testing literature. A prototype implementation of TESALIA is used for validation in an Android example showing the benefits of maximizing the mobile market share (the value function) while meeting a budgetary constraint.},
  Doi                      = {10.1007/s11219-014-9258-y},
  ISSN                     = {15731367},
  Publisher                = {Springer New York LLC}
}

@Article{Galindo2016a,
  Title                    = {Exploiting the enumeration of all feature model configurations: a new perspective with distributed computing},
  Author                   = {Galindo, JA and Acher, M and Tirado, JM and Vidal, C},
  Journal                  = {Proc. 20th},
  Year                     = {2016},

  Url                      = {http://dl.acm.org/citation.cfm?id=2934478}
}

@Article{Galster2014,
  Title                    = {Variability in software systems-A systematic literature review},
  Author                   = {Galster, Matthias and Weyns, Danny and Tofan, Dan and Michalik, Bartosz and Avgeriou, Paris},
  Year                     = {2014},
  Number                   = {3},
  Pages                    = {282--306},
  Volume                   = {40},

  Abstract                 = {Context: Variability (i.e., the ability of software systems or artifacts to be adjusted for different contexts) became a key property of many systems. Objective: We analyze existing research on variability in software systems. We investigate variability handling in major software engineering phases (e.g., requirements engineering, architecting). Method: We performed a systematic literature review. A manual search covered 13 premium software engineering journals and 18 premium conferences, resulting in 15,430 papers searched and 196 papers considered for analysis. To improve reliability and to increase reproducibility, we complemented the manual search with a targeted automated search. Results: Software quality attributes have not received much attention in the context of variability. Variability is studied in all software engineering phases, but testing is underrepresented. Data to motivate the applicability of current approaches are often insufficient; research designs are vaguely described. Conclusions: Based on our findings we propose dimensions of variability in software engineering. This empirically grounded classification provides a step towards a unifying, integrated perspective of variability in software systems, spanning across disparate or loosely coupled research themes in the software engineering community. Finally, we provide recommendations to bridge the gap between research and practice and point to opportunities for future research. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/TSE.2013.56},
  ISSN                     = {00985589},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.}
}

@InProceedings{Garba2016,
  Title                    = {MUSA: A scalable multi-touch and multi-perspective variability management tool},
  Author                   = {Garba, Muhammad and Noureddine, Adel and Bashroush, Rabih},
  Year                     = {2016},
  Month                    = {jul},
  Pages                    = {299--302},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {Variability management is one of the main activities in the Software Product Line Engineering process. Common and varied features of related products are modelled along with the dependencies and relationships among them. With the increase in size and complexity of product lines and the more holistic systems approach to the design process, managing the ever-growing variability models has become a challenge. In this paper, we present MUSA, a tool for managing variability and features in large-scale models. MUSA adopts the Separation of Concerns design principle by providing multiple perspectives to the model, each conveying different set of information. The demonstration is conducted using a real-life model (comprising of 1000+ features) particularly showing the Structural View, which is displayed using a mind-mapping visualisation technique (hyperbolic trees), and the Dependency View, which is displayed graphically using logic gates.},
  Doi                      = {10.1109/WICSA.2016.45},
  ISBN                     = {9781509021314}
}

@InProceedings{Garcia-Galan2016,
  Title                    = {User-centric adaptation analysis of multi-tenant services},
  Author                   = {Garc{\'{i}}a-Gal{\'{a}}n, Jes{\'{u}}s and Pasquale, Liliana and Trinidad, Pablo and Ruiz-Cort{\'{e}}s, Antonio},
  Year                     = {2016},
  Month                    = {feb},
  Number                   = {4},
  Publisher                = {Association for Computing Machinery},
  Volume                   = {10},

  Abstract                 = {Multi-tenancy is a key pillar of cloud services. It allows different users to share computing and virtual resources transparently, meanwhile guaranteeing substantial cost savings. Due to the tradeoff between scalability and customization, one of the major drawbacks of multi-tenancy is limited configurability. Since users may often have conflicting configuration preferences, offering the best user experience is an open challenge for service providers. In addition, the users, their preferences, and the operational environment may change during the service operation, thus jeopardizing the satisfaction of user preferences. In this article, we present an approach to support user-centric adaptation of multi-tenant services. We describe how to engineer the activities of the Monitoring, Analysis, Planning, Execution (MAPE) loop to support user-centric adaptation, and we focus on adaptation analysis. Our analysis computes a service configuration that optimizes user satisfaction, complies with infrastructural constraints, and minimizes reconfiguration obtrusiveness when user- or service-related changes take place. To support our analysis, we model multitenant services and user preferences by using feature and preference models, respectively. We illustrate our approach by utilizing different cases of virtual desktops. Our results demonstrate the effectiveness of the analysis in improving user preferences satisfaction in negligible time.},
  Doi                      = {10.1145/2790303},
  ISSN                     = {15564703}
}

@InProceedings{Garcia-Galan2013,
  Title                    = {Migrating to the Cloud: A software product line based analysis},
  Author                   = {Garc{\'{i}}a-Gal{\'{a}}n, Jes{\'{u}}s and Rana, Omer and Trinidad, Pablo and Ruiz-Cort{\'{e}}s, Antonio},
  Year                     = {2013},
  Pages                    = {416--426},

  Abstract                 = {Identifying which part of a local system should be migrated to a public Cloud environment is often a difficult and error prone process. With the significant (and increasing) number of commercial Cloud providers, choosing a provider whose capability best meets requirements is also often difficult. Most Cloud service providers offer large amounts of configurable resources, which can be combined in a number of different ways. In the case of small and medium companies, finding a suitable configuration with the minimum cost is often an essential requirement to migrate, or even to initiate the decision process for migration. We interpret this need as a problem associated with variability management and analysis. Variability techniques and models deal with large configuration spaces, and have been proposed previously to support configuration processes in industrial cases. Furthermore, this is a mature field which has a large catalog of analysis operations to extract valuable information in an automated way. Some of these operations can be used and tailored for Cloud environments. We focus in this work on Amazon Cloud services, primarily due to the large number of possible configurations available by this service provider and its popularity. Our approach can also be adapted to other providers offering similar capabilities.},
  ISBN                     = {9789898565525}
}

@Article{Garcia-Galan2016a,
  Title                    = {Automated configuration support for infrastructure migration to the cloud},
  Author                   = {Garc{\'{i}}a-Gal{\'{a}}n, Jes{\'{u}}s and Trinidad, Pablo and Rana, Omer F. and Ruiz-Cort{\'{e}}s, Antonio},
  Year                     = {2016},

  Month                    = {feb},
  Pages                    = {200--212},
  Volume                   = {55},

  Abstract                 = {With an increasing number of cloud computing offerings in the market, migrating an existing computational infrastructure to the cloud requires comparison of different offers in order to find the most suitable configuration. Cloud providers offer many configuration options, such as location, purchasing mode, redundancy, and extra storage. Often, the information about such options is not well organised. This leads to large and unstructured configuration spaces, and turns the comparison into a tedious, error-prone search problem for the customers. In this work we focus on supporting customer decision making for selecting the most suitable cloud configuration - in terms of infrastructural requirements and cost. We achieve this by means of variability modelling and analysis techniques. Firstly, we structure the configuration space of an IaaS using feature models, usually employed for the modelling of variability-intensive systems, and present the case study of the Amazon EC2. Secondly, we assist the configuration search process. Feature models enable the use of different analysis operations that, among others, automate the search of optimal configurations. Results of our analysis show how our approach, with a negligible analysis time, outperforms commercial approaches in terms of expressiveness and accuracy.},
  Doi                      = {10.1016/j.future.2015.03.006},
  ISSN                     = {0167739X},
  Publisher                = {Elsevier}
}

@InProceedings{Gey2014,
  Title                    = {Feature models at run time feature middleware for multi-tenant SaaS applications},
  Author                   = {Gey, Fatih and {Van Landuyt}, Dimitri and Walraven, Stefan and Joosen, Wouter},
  Year                     = {2014},
  Pages                    = {21--30},
  Publisher                = {CEUR-WS},
  Volume                   = {1270},

  Abstract                 = {Software product line engineering (SPLE) techniques revolve around a central variability model which in many cases is a feature model that documents the logical capabilities of the system as features and the variability relationships between them. In more traditional SPLE, this feature model is a result of domain analysis and requirement elicitation, while more recently this approach has been extended to represent also design-time variability, for example to document different ways to realize the same functionality. In many approaches, the feature model has run-time relevance as well. For example, in earlier work, we have used SPLE techniques to develop customizable multi-tenant SaaS applications, i.e. SaaS applications of which a single run-time instance is offered to many customer organizations (tenants), often with widely different requirements. In such systems, tenant customization is accomplished entirely at run time. In this paper, we present and explore the idea of promoting the feature model as a run-time artifact in the context of customizable multi-tenant SaaS applications, and we discuss the potential benefits in terms of the deployment, operation, maintenance, and evolution of these systems. In addition, we discuss the requirements this will impose on the development methods, the variability modeling languages, and the middleware.},
  ISSN                     = {16130073}
}

@Article{Gheyi2011,
  Title                    = {Automatically checking feature model refactorings},
  Author                   = {Gheyi, Rohit and Massoni, Tiago and Borba, Paulo},
  Year                     = {2011},
  Number                   = {5},
  Pages                    = {684--711},
  Volume                   = {17},

  Abstract                 = {A feature model (FM) defines the valid combinations of features, whose combinations correspond to a program in a Software Product Line (SPL). FMs may evolve, for instance, during refactoring activities. Developers may use a catalog of refactorings as support. However, the catalog is incomplete in principle. Additionally, it is non-trivial to propose correct refactorings. To our knowledge, no previous analysis technique for FMs is used for checking properties of general FM refactorings (a transformation that can be applied to a number of FMs) containing a representative number of features. We propose an efficient encoding of FMs in the Alloy formal specification language. Based on this encoding, we show how the Alloy Analyzer tool, which performs analysis on Alloy models, can be used to automatically check whether encoded general and specific FM refactorings are correct. Our approach can analyze general transformations automatically to a significant scale in a few seconds. In order to evaluate the analysis performance of our encoding, we evaluated in automatically generated FMs ranging from 500 to 2,000 features. Furthermore, we analyze the soundness of general transformations. {\textcopyright} J.UCS.},
  ISSN                     = {0958695X}
}

@Article{Ghezzi2011,
  Title                    = {Verifying non-functional properties of software product lines: Towards an efficient approach using parametric model checking},
  Author                   = {Ghezzi, C and Sharifloo, AM},
  Journal                  = {Softw. Prod. Line Conf. (},
  Year                     = {2011},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6030058}
}

@Article{Grebhahn2014,
  Title                    = {Optimizing performance of stencil code with SPL Conqueror},
  Author                   = {Grebhahn, A and Siegmund, N and Apel, S},
  Journal                  = {Proc.},
  Year                     = {2014},

  Url                      = {http://www.exastencils.org/histencils/2014/histencils2014.pdf{\#}page=17}
}

@Article{Guo2012,
  Title                    = {Consistency maintenance for evolving feature models},
  Author                   = {Guo, Jianmei and Wang, Yinglin and Trinidad, Pablo and Benavides, David},
  Year                     = {2012},

  Month                    = {apr},
  Number                   = {5},
  Pages                    = {4987--4998},
  Volume                   = {39},

  Abstract                 = {Software product line (SPL) techniques handle the construction of customized systems. One of the most common representations of the decisions a customer can make in SPLs is feature models (FMs). An FM represents the relationships among common and variable features in an SPL. Features are a representation of the characteristics in a system that are relevant to customers. FMs are subject to change since the set of features and their relationships can change along an SPL lifecycle. Due to this evolution, the consistency of FMs may be compromised. There exist some approaches to detect and explain inconsistencies in FMs, however this process can take a long time for large FMs. In this paper we present a complementary approach to dealing with inconsistencies in FM evolution scenarios that improves the performance for existing approaches reducing the impact of change to the smallest part of an FM that changes. To achieve our goal, we formalize FMs from an ontological perspective and define constraints that must be satisfied in FMs to be consistent. We define a set of primitive operations that modify FMs and which are responsible for the FM evolution, analyzing their impact on the FM consistency. We propose a set of predefined strategies to keep the consistency for error-prone operations. As a proof-of-concept we present the results of our experiments, where we check for the effectiveness and efficiency of our approach in FMs with thousands of features. Although our approach is limited by the kinds of consistency constraints and the primitive operations we define, the experiments present a significant improvement in performance results in those cases where they are applicable. {\textcopyright} 2011 Elsevier Ltd. All rights reserved.},
  Doi                      = {10.1016/j.eswa.2011.10.014},
  ISSN                     = {09574174}
}

@Article{Guo2011,
  Title                    = {A genetic algorithm for optimized feature selection with resource constraints in software product lines},
  Author                   = {Guo, Jianmei and White, Jules and Wang, Guangxin and Li, Jian and Wang, Yinglin},
  Year                     = {2011},

  Month                    = {dec},
  Number                   = {12},
  Pages                    = {2208--2221},
  Volume                   = {84},

  Abstract                 = {Software product line (SPL) engineering is a software engineering approach to building configurable software systems. SPLs commonly use a feature model to capture and document the commonalities and variabilities of the underlying software system. A key challenge when using a feature model to derive a new SPL configuration is determining how to find an optimized feature selection that minimizes or maximizes an objective function, such as total cost, subject to resource constraints. To help address the challenges of optimizing feature selection in the face of resource constraints, this paper presents an approach that uses G enetic A lgorithms for optimized FE ature S election (GAFES) in SPLs. Our empirical results show that GAFES can produce solutions with 86-97{\%} of the optimality of other automated feature selection algorithms and in 45-99{\%} less time than existing exact and heuristic feature selection techniques. {\textcopyright} 2011 Elsevier Inc. All rights reserved.},
  Doi                      = {10.1016/j.jss.2011.06.026},
  ISSN                     = {01641212}
}

@InProceedings{Guo2014,
  Title                    = {Scaling exact multi-objective combinatorial optimization by parallelization},
  Author                   = {Guo, Jianmei and Zulkoski, Edward and Olaechea, Rafael and Rayside, Derek and Czarnecki, Krzysztof and Apel, Sven and Atlee, Joanne M.},
  Year                     = {2014},
  Pages                    = {409--420},
  Publisher                = {Association for Computing Machinery, Inc},

  Abstract                 = {Multi-Objective Combinatorial Optimization (MOCO) is fundamental to the development and optimization of software systems. We propose five novel parallel algorithms for solving MOCO problems exactly and efficiently. Our algorithms rely on off-the-shelf solvers to search for exact Pareto-optimal solutions, and they parallelize the search via collaborative communication, divide-and-conquer, or both. We demonstrate the feasibility and performance of our algorithms by experiments on three case studies of software-system designs. A key finding is that one algorithm, which we call FS-GIA, achieves substantial (even super-linear) speedups that scale well up to 64 cores. Furthermore, we analyze the performance bottlenecks and opportunities of our parallel algorithms, which facilitates further research on exact, parallel MOCO.},
  Doi                      = {10.1145/2642937.2642971},
  ISBN                     = {9781450330138}
}

@Article{Hajri2016,
  Title                    = {Configuring use case models in product families},
  Author                   = {Hajri, I and Goknil, A and Briand, LC and Stephany, T},
  Journal                  = {Softw. Syst. Model.},
  Year                     = {2016},

  Url                      = {http://link.springer.com/article/10.1007/s10270-016-0539-8}
}

@InProceedings{Han2016,
  Title                    = {A feature-oriented mobile software development framework to resolve the device fragmentation phenomenon for application developers in the mobile software ecosystem},
  Author                   = {Han, Younghun and Go, Gyeongmin and Kang, Sungwon and Lee, Heuijin},
  Booktitle                = {International Conference on Cloud Computing (CloudComp 2015)},
  Year                     = {2016},
  Pages                    = {189--199},
  Publisher                = {Springer Verlag},
  Volume                   = {167},

  Abstract                 = {In the current mobile software environment, the device fragmentation phenomenon causes a serious problem to the mobile software ecosystem stakeholders. Since mobile manufacturers make various differentiated hardware components for product differentiation around strategically selected open platforms, a huge number of devices are produced each year. Since the application developers have to verify manually whether the developed application is compatible with specific devices, a tremendous burden is put on the application developers. To solve this problem, we propose a feature-oriented mobile software development framework and implement as part of it an automated tool for compatibility verification. To evaluate our framework, we conduct a case study with 10 devices and 21 features from the real world. The result of the case study indicates that a significant effort reduction can be achieved by using our framework.},
  Doi                      = {10.1007/978-3-319-38904-2_20},
  ISBN                     = {9783319389035},
  ISSN                     = {18678211}
}

@Article{Haslinger2013,
  Title                    = {Using feature model knowledge to speed up the generation of covering arrays},
  Author                   = {Haslinger, EN and Lopez-Herrejon, RE},
  Journal                  = {Proc. Seventh},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2430524}
}

@InProceedings{Haslinger2013a,
  Title                    = {On extracting feature models from sets of valid feature combinations},
  Author                   = {Haslinger, Evelyn Nicole and Lopez-Herrejon, Roberto Erick and Egyed, Alexander},
  Year                     = {2013},
  Pages                    = {53--67},
  Volume                   = {7793 LNCS},

  Abstract                 = {Rather than developing individual systems, Software Product Line Engineering develops families of systems. The members of the software family are distinguished by the features they implement and Feature Models (FMs) are the de facto standard for defining which feature combinations are considered valid members. This paper presents an algorithm to automatically extract a feature model from a set of valid feature combinations, an essential development step when companies, for instance, decide to convert their existing product variations portfolio into a Software Product Line. We performed an evaluation on 168 publicly available feature models, with 9 to 38 features and up to 147456 feature combinations. From the generated feature combinations of each of these examples, we reverse engineered an equivalent feature model with a median performance in the low milliseconds. {\textcopyright} 2013 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-37057-1_5},
  ISBN                     = {9783642370564},
  ISSN                     = {03029743}
}

@InProceedings{Haslinger2011,
  Title                    = {Reverse engineering feature models from programs' feature sets},
  Author                   = {Haslinger, Evelyn Nicole and Lopez-Herrejon, Roberto E. and Egyed, Alexander},
  Year                     = {2011},
  Pages                    = {308--312},

  Abstract                 = {Successful software is more and more rarely developed as a one-of-a-kind system. Instead, different system variants are built from a common set of assets and customized for catering to the different functionality or technology needs of the distinct clients and users. The Software Product Line Engineering (SPLE) paradigm has proven effective to cope with the variability described for this scenario. However, evolving a Software Product Line (SPL) from a family of systems is not a simple endeavor. A crucial requirement is accurately capturing the variability present in the family of systems and representing it with Feature Models (FMs), the de facto standard for variability modeling. Current research has focused on extracting FMs from configuration scripts, propositional logic expressions or natural language. In contrast, in this short paper we present an algorithm that reverse engineers a basic feature model from the feature sets which describe the features each system provides. We perform an evaluation of our approach using several case studies and outline the issues that still need to be addressed. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/WCRE.2011.45},
  ISBN                     = {9780769545820},
  ISSN                     = {10951350}
}

@Article{Heider2012,
  Title                    = {Facilitating the evolution of products in product line engineering by capturing and replaying configuration decisions},
  Author                   = {Heider, Wolfgang and Rabiser, Rick and Gr{\"{u}}nbacher, Paul},
  Year                     = {2012},
  Number                   = {5},
  Pages                    = {613--630},
  Volume                   = {14},

  Abstract                 = {Software product lines rely on developing reusable artifacts and defining their variability in models to support and accelerate the derivation of individual products. A major challenge in product lines is the continuous evolution of both the reusable artifacts and derived products. Products that have been derived from a product line have to be updated regularly, e. g., after bugfixes or the development of new features. Changes to reusable artifacts and variability models have to be propagated to derived products. The aim of our research is to provide automated support for the evolution of products derived from product lines by capturing and replaying configuration decisions. Our PUPLE (Product Updates in Product Line Engineering) approach supports updating derived products after changes to the product line they have been derived from. It exploits the structure of variability models and uses change-tracking data to minimize user intervention. The paper first explores how different types of product line changes influence the derived products. It then presents extensions to our decision-oriented product line approach DOPLER to support product line evolution. We evaluate the feasibility of the PUPLE approach with evolution tasks that were performed by engineers of an industry partner on a product line of an Eclipse-based tool suite with six derived products. We conclude with lessons learned and limitations of our approach. {\textcopyright} 2012 Springer-Verlag.},
  Doi                      = {10.1007/s10009-012-0229-y},
  ISSN                     = {14332779}
}

@InProceedings{Henard2015,
  Title                    = {Combining multi-objective search and constraint solving for configuring large software product lines},
  Author                   = {Henard, Christopher and Papadakis, Mike and Harman, Mark and {Le Traon}, Yves},
  Year                     = {2015},
  Month                    = {aug},
  Pages                    = {517--528},
  Publisher                = {IEEE Computer Society},
  Volume                   = {1},

  Abstract                 = {Software Product Line (SPL) feature selection involves the optimization of multiple objectives in a large and highly constrained search space. We introduce SATIBEA, that augments multi-objective search-based optimization with constraint solving to address this problem, evaluating it on five large real-world SPLs, ranging from 1,244 to 6,888 features with respect to three different solution quality indicators and two diversity metrics. The results indicate that SATIBEA statistically significantly outperforms the current state-of-the-art (p {\textless} 0.01) for all five SPLs on all three quality indicators and with maximal effect size ({\^{A}}12 = 1:0). We also present results that demonstrate the importance of combining constraint solving with searchbased optimization and the significant improvement SATIBEA produces over pure constraint solving. Finally, we demonstrate the scalability of SATIBEA: within less than half an hour, it finds thousands of constraint-satisfying optimized software products, even for the largest SPL considered in the literature to date.},
  Doi                      = {10.1109/ICSE.2015.69},
  ISBN                     = {9781479919345},
  ISSN                     = {02705257}
}

@InProceedings{Henard2014,
  Title                    = {Mutation-based generation of software product line test configurations},
  Author                   = {Henard, Christopher and Papadakis, Mike and {Le Traon}, Yves},
  Year                     = {2014},
  Pages                    = {92--106},
  Publisher                = {Springer Verlag},
  Volume                   = {8636 LNCS},

  Abstract                 = {Software Product Lines (SPLs) are families of software products that can be configured and managed through a combination of features. Such products are usually represented with a Feature Model (FM). Testing the entire SPL may not be conceivable due to economical or time constraints and, more simply, because of the large number of potential products. Thus, defining methods for generating test configurations is required, and is now a very active research topic for the testing community. In this context, mutation has recently being advertised as a promising technique. Mutation evaluates the ability of the test suite to detect defective versions of the FM, called mutants. In particular, it has been shown that existing test configurations achieving the mutation criterion correlate with fault detection. Despite the potential benefit of mutation, there is no approach which aims at generating test configurations for SPL with respect to the mutation criterion. In this direction, we introduce a search-based approach which explores the SPL product space to generate product test configurations with the aim of detecting mutants. {\textcopyright} 2014 Springer International Publishing Switzerland.},
  Doi                      = {10.1007/978-3-319-09940-8_7},
  ISBN                     = {9783319099392},
  ISSN                     = {16113349}
}

@Article{Henard2014a,
  Title                    = {Bypassing the combinatorial explosion: Using similarity to generate and prioritize t-wise test configurations for software product lines},
  Author                   = {Henard, Christopher and Papadakis, Mike and Perrouin, Gilles and Klein, Jacques and Heymans, Patrick and Traon, Yves Le},
  Year                     = {2014},

  Month                    = {jul},
  Number                   = {7},
  Pages                    = {650--670},
  Volume                   = {40},

  Abstract                 = {Large Software Product Lines (SPLs) are common in industry, thus introducing the need of practical solutions to test them. To this end, t-wise can help to drastically reduce the number of product configurations to test. Current t-wise approaches for SPLs are restricted to small values of t. In addition, these techniques fail at providing means to finely control the configuration process. In view of this, means for automatically generating and prioritizing product configurations for large SPLs are required. This paper proposes (a) a search-based approach capable of generating product configurations for large SPLs, forming a scalable and flexible alternative to current techniques and (b) prioritization algorithms for any set of product configurations. Both these techniques employ a similarity heuristic. The ability of the proposed techniques is assessed in an empirical study through a comparison with state of the art tools. The comparison focuses on both the product configuration generation and the prioritization aspects. The results demonstrate that existing t-wise tools and prioritization techniques fail to handle large SPLs. On the contrary, the proposed techniques are both effective and scalable. Additionally, the experiments show that the similarity heuristic can be used as a viable alternative to t-wise. {\textcopyright} 1976-2012 IEEE.},
  Doi                      = {10.1109/TSE.2014.2327020},
  ISSN                     = {00985589},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.}
}

@InProceedings{Henard2013,
  Title                    = {Multi-objective test generation for software product lines},
  Author                   = {Henard, Christopher and Papadakis, Mike and Perrouin, Gilles and Klein, Jacques and {Le Traon}, Yves},
  Year                     = {2013},
  Pages                    = {62--71},

  Abstract                 = {Software Products Lines (SPLs) are families of products sharing common assets representing code or functionalities of a software product. These assets are represented as features, usually organized into Feature Models (FMs) from which the user can configure software products. Generally, few features are sufficient to allow configuring millions of software products. As a result, selecting the products matching given testing objectives is a difficult problem. The testing process usually involves multiple and potentially conflicting testing objectives to fulfill, e.g. maximizing the number of optional features to test while at the same time both minimizing the number of products and minimizing the cost of testing them. However, most approaches for generating products usually target a single objective, like testing the maximum amount of feature interactions. While focusing on one objective may be sufficient in certain cases, this practice does not reflect real-life testing situations. The present paper proposes a genetic algorithm to handle multiple conflicting objectives in test generation for SPLs. Experiments conducted on FMs of different sizes demonstrate the effectiveness, feasibility and practicality of the introduced approach. {\textcopyright} 2013 ACM.},
  Doi                      = {10.1145/2491627.2491635},
  ISBN                     = {9781450319683}
}

@InProceedings{Henard2013a,
  Title                    = {Towards automated testing and fixing of re-engineered Feature Models},
  Author                   = {Henard, Christopher and Papadakis, Mike and Perrouin, Gilles and Klein, Jacques and {Le Traon}, Yves},
  Year                     = {2013},
  Pages                    = {1245--1248},

  Abstract                 = {Mass customization of software products requires their efficient tailoring performed through combination of features. Such features and the constraints linking them can be represented by Feature Models (FMs), allowing formal analysis, derivation of specific variants and interactive configuration. Since they are seldom present in existing systems, techniques to re-engineer FMs have been proposed. There are nevertheless error-prone and require human intervention. This paper introduces an automated search-based process to test and fix FMs so that they adequately represent actual products. Preliminary evaluation on the Linux kernel FM exhibit erroneous FM constraints and significant reduction of the inconsistencies. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/ICSE.2013.6606689},
  ISBN                     = {9781467330763},
  ISSN                     = {02705257}
}

@InProceedings{Henard2013b,
  Title                    = {Assessing software product line testing via model-based mutation: An application to similarity testing},
  Author                   = {Henard, Christopher and Papadakis, Mike and Perrouin, Gilles and Klein, Jacques and Traon, Yves Le},
  Year                     = {2013},
  Pages                    = {188--197},

  Abstract                 = {Needs for mass customization and economies of scale have pushed engineers to develop Software Product Lines (SPLs). SPLs are families of products sharing commonalities and exhibiting differences, built by reusing software assets abstractly represented by features. Feature models describe the constraints that link the features and allow the configuration of tailored software products. Common SPLs involve hundreds, even thousands of features, leading to billions of possible software products. As a result, testing a product line is challenging due to the enormous size of the possible products. Existing techniques focus on testing based on the product line's feature model by selecting a limited set of products to test. Being created manually or reverse-engineered, feature models are prone to errors impacting the generated test suites. In this paper, we examine ability of test suites to detect such errors. In particular, we propose two mutation operators to derive erroneous feature models (mutants) from an original feature model and assess the capability of the generated original test suite to kill the mutants. Experimentation on real feature models demonstrate that dissimilar tests suites have a higher mutant detection ability than similar ones, thus validating the relevance of similarity-driven product line testing. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/ICSTW.2013.30}
}

@Article{Heradio2013,
  Title                    = {A literature review on feature diagram product counting and its usage in software product line economic models},
  Author                   = {Heradio, Ruben and Fernandez-Amoros, David and Cerrada, Jose A. and Abad, Ismael},
  Year                     = {2013},

  Month                    = {oct},
  Number                   = {8},
  Pages                    = {1177--1204},
  Volume                   = {23},

  Abstract                 = {In software product line engineering, feature diagrams are a popular means to represent the similarities and differences within a family of related systems. In addition, feature diagrams implicitly model valuable information that can be used in economic models to estimate the cost savings of a product line. In particular, this paper reviews existing proposals on computing the total number of products modeled with a feature diagram and, given a feature, the number of products that implement it. This paper also reviews the economic information that can be estimated when such numbers are known. Thus, this paper contributes by bringing together previously-disparate streams of work: the automated analysis of feature diagrams and economic models for product lines. {\textcopyright} 2013 World Scientific Publishing Company.},
  Doi                      = {10.1142/S0218194013500368},
  ISSN                     = {02181940}
}

@Article{Heradio2012,
  Title                    = {Improving the accuracy of COPLIMO to estimate the payoff of a software product line},
  Author                   = {Heradio, Ruben and Fernandez-Amoros, David and Torre-Cubillo, Luis and {Perez Garcia-Plaza}, Alberto},
  Year                     = {2012},

  Month                    = {jul},
  Number                   = {9},
  Pages                    = {7919--7928},
  Volume                   = {39},

  Abstract                 = {Software product line engineering pursues the efficient development of families of similar products. COPLIMO is an economic model that relies on COCOMO II to estimate the benefits of adopting a product line approach compared to developing the products one by one. Although COPLIMO is an ideal economic model to support decision making on the incremental development of a product line, it makes some simplifying assumptions that may produce high distortions in the estimates (e.g.; COPLIMO takes for granted that all the products have the same size). This paper proposes a COPLIMO reformulation that avoids such assumptions and, consequently, improves the accuracy of the estimates. To support our proposal, we present an algorithm that infers the additional information that our COPLIMO reformulation requires from feature diagrams, which is a widespread notation to model the domain of a product line. {\textcopyright} 2012 Elsevier Ltd. All rights reserved.},
  Doi                      = {10.1016/j.eswa.2012.01.109},
  ISSN                     = {09574174}
}

@Article{Heradio2016,
  Title                    = {Augmenting measure sensitivity to detect essential, dispensable and highly incompatible features in mass customization},
  Author                   = {Heradio, Ruben and Perez-Morago, Hector and Alf{\'{e}}rez, Mauricio and Fernandez-Amoros, David and Alf{\'{e}}rez, Germ{\'{a}}n H.},
  Year                     = {2016},

  Month                    = {feb},
  Number                   = {3},
  Pages                    = {1066--1077},
  Volume                   = {248},

  Abstract                 = {Mass customization is the new frontier in business competition for both manufacturing and service industries. To improve customer satisfaction, reduce lead-times and shorten costs, families of similar products are built jointly by combining reusable parts that implement the features demanded by the customers. To guarantee the validity of the products derived from mass customization processes, feature dependencies and incompatibilities are usually specified with a variability model. As market demand grows and evolves, variability models become increasingly complex. In such entangled models it is hard to identify which features are essential, dispensable, highly required by other features, or highly incompatible with the remaining features. This paper exposes the limitations of existing approaches to gather such knowledge and provides efficient algorithms to retrieve that information from variability models.},
  Doi                      = {10.1016/j.ejor.2015.08.005},
  ISSN                     = {03772217},
  Publisher                = {Elsevier}
}

@Article{Heradio2016a,
  Title                    = {A bibliometric analysis of 20 years of research on software product lines},
  Author                   = {Heradio, Ruben and Perez-Morago, Hector and Fernandez-Amoros, David and {Javier Cabrerizo}, Francisco and Herrera-Viedma, Enrique},
  Journal                  = {Information and Software Technology},
  Year                     = {2016},

  Month                    = {apr},
  Pages                    = {1--15},
  Volume                   = {72},

  Abstract                 = {Context: Software product line engineering has proven to be an efficient paradigm to developing families of similar software systems at lower costs, in shorter time, and with higher quality. Objective: This paper analyzes the literature on product lines from 1995 to 2014, identifying the most influential publications, the most researched topics, and how the interest in those topics has evolved along the way. Method: Bibliographic data have been gathered from ISI Web of Science and Scopus. The data have been examined using two prominent bibliometric approaches: science mapping and performance analysis. Results: According to the study carried out, (i) software architecture was the initial motor of research in SPL; (ii) work on systematic software reuse has been essential for the development of the area; and (iii) feature modeling has been the most important topic for the last fifteen years, having the best evolution behavior in terms of number of published papers and received citations. Conclusion: Science mapping has been used to identify the main researched topics, the evolution of the interest in those topics and the relationships among topics. Performance analysis has been used to recognize the most influential papers, the journals and conferences that have published most papers, how numerous is the literature on product lines and what is its distribution over time.},
  Doi                      = {10.1016/j.infsof.2015.11.004},
  ISSN                     = {09505849},
  Publisher                = {Elsevier}
}

@Article{Heradio-Gil2011,
  Title                    = {Supporting commonality-based analysis of software product lines},
  Author                   = {Heradio-Gil, R. and Fernandez-Amoros, D. and Cerrada, J. A. and Cerrada, C.},
  Year                     = {2011},

  Month                    = {dec},
  Number                   = {6},
  Pages                    = {496--509},
  Volume                   = {5},

  Abstract                 = {Software product line (SPL) engineering is a cost-effective approach to developing families of similar products. Key to the success of this approach is to correctly scope the domain of the SPL, identifying the common and variable features of the products and the interdependencies between features. In this study, the authors show how the commonality of a feature (i.e. the reuse ratio of the feature among the products) can be used to detect scope flaws in the early stages of development. SPL domains are usually modelled by means of feature diagrams following the feature-oriented domain analysis (FODA) notation. The authors extend classical FODA trees with unrestricted cardinalities, and present an algorithm to compute the number of products modelled by a feature diagram and the commonality of the features. Finally, the authors compare the performance of their algorithm with two other approaches built on top of boolean logic satisfiability (SAT)-solver technology such as cachet and relsat. {\textcopyright} 2011 The Institution of Engineering and Technology.},
  Doi                      = {10.1049/iet-sen.2010.0022},
  ISSN                     = {17518806}
}

@InProceedings{Hervieu2011,
  Title                    = {PACOGEN: Automatic generation of pairwise test configurations from feature models},
  Author                   = {Hervieu, Aymeric and Baudry, Benoit and Gotlieb, Arnaud},
  Year                     = {2011},
  Pages                    = {120--129},

  Abstract                 = {Feature models are commonly used to specify variability in software product lines. Several tools support feature models for variability management at different steps in the development process. However, tool support for test configuration generation is currently limited. This test generation task consists in systematically selecting a set of configurations that represent a relevant sample of the variability space and that can be used to test the product line. In this paper we propose PACOGEN to analyze feature models and automatically generate a set of configurations that cover all pair wise interactions between features. PACOGEN relies on constraint programming to generate configurations that satisfy all constraints imposed by the feature model and to minimize the set of the tests configurations. This work also proposes an extensive experiment, based on the state-of-the art SPLOT feature models repository, showing that PACOGEN scales over variability spaces with millions of configurations and covers pair wise with less configurations than other available tools. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/ISSRE.2011.31},
  ISBN                     = {9780769545684},
  ISSN                     = {10719458}
}

@Article{Heymans2012,
  Title                    = {A code tagging approach to software product line development: An application to satellite communication libraries},
  Author                   = {Heymans, Patrick and Boucher, Quentin and Classen, Andreas and Bourdoux, Arnaud and Demonceau, Laurent},
  Journal                  = {International Journal on Software Tools for Technology Transfer},
  Year                     = {2012},
  Number                   = {5},
  Pages                    = {553--566},
  Volume                   = {14},

  Abstract                 = {Software product line engineering seeks to systematise reuse when developing families of similar software systems so as to minimise development time, cost and defects. To realise variability at the code level, product line methods classically advocate usage of inheritance, components, frameworks, aspects or generative techniques. However, these might require unaffordable paradigm shifts for developers if the software was not thought at the outset as a product line. Furthermore, these techniques can be conflicting with a company's coding practices or external regulations. These concerns were the motivation for the industry-university collaboration described in this paper in which we developed a minimally intrusive coding technique based on tags. The approach was complemented with traceability from code to feature diagrams which were exploited for automated configuration. It is supported by a toolchain and is now in use in the partner company for the development of flight-grade satellite communication software libraries. {\textcopyright} 2012 Springer-Verlag.},
  Doi                      = {10.1007/s10009-012-0242-1},
  ISSN                     = {14332779}
}

@Article{Hidaka2016,
  Title                    = {Feature-based classification of bidirectional transformation approaches},
  Author                   = {Hidaka, Soichiro and Tisi, Massimo and Cabot, Jordi and Hu, Zhenjiang},
  Year                     = {2016},

  Month                    = {jul},
  Number                   = {3},
  Pages                    = {907--928},
  Volume                   = {15},

  Abstract                 = {Bidirectional model transformation is a key technology in model-driven engineering (MDE), when two models that can change over time have to be kept constantly consistent with each other. While several model transformation tools include at least a partial support to bidirectionality, it is not clear how these bidirectional capabilities relate to each other and to similar classical problems in computer science, from the view update problem in databases to bidirectional graph transformations. This paper tries to clarify and visualize the space of design choices for bidirectional transformations from an MDE point of view, in the form of a feature model. The selected list of existing approaches are characterized by mapping them to the feature model. Then, the feature model is used to highlight some unexplored research lines in bidirectional transformations.},
  Doi                      = {10.1007/s10270-014-0450-0},
  ISSN                     = {16191374},
  Publisher                = {Springer Verlag}
}

@Article{Hierons2016,
  Title                    = {SIP: Optimal product selection from feature models using many-objective evolutionary optimization},
  Author                   = {Hierons, Robert M. and Li, Miqing and Liu, Xiaohui and Segura, Sergio and Zheng, Wei},
  Year                     = {2016},

  Month                    = {apr},
  Number                   = {2},
  Volume                   = {25},

  Abstract                 = {A feature model specifies the sets of features that define valid products in a software product line. Recent work has considered the problem of choosing optimal products from a feature model based on a set of user preferences, with this being represented as a many-objective optimization problem. This problem has been found to be difficult for a purely search-based approach, leading to classicalmany-objective optimization algorithms being enhanced either by adding in a valid product as a seed or by introducing additional mutation and replacement operators that use an SAT solver. In this article, we instead enhance the search in two ways: by providing a novel representation and by optimizing first on the number of constraints that hold and only then on the other objectives. In the evaluation, we also used feature models with realistic attributes, in contrast to previous work that used randomly generated attribute values. The results of experiments were promising, with the proposed (SIP) method returning valid products with six published feature models and a randomly generated feature model with 10,000 features. For the model with 10,000 features, the search took only a few minutes.},
  Doi                      = {10.1145/2897760},
  ISSN                     = {15577392},
  Publisher                = {Association for Computing Machinery}
}

@InProceedings{Hong2011,
  Title                    = {A novel segmentation method of high resolution remote sensing image based on multi-feature object-oriented Markov random fields model},
  Author                   = {Hong, Liang and Yang, Kun},
  Year                     = {2011},
  Pages                    = {8019--8024},

  Abstract                 = {A novel methodology base on multi-feature object-oriented MRF(MFOMRF) is proposed in order to obtain precise segmentation of high resolution satellite image. Conventional pixel-by-pixel MRF model methods only consider spatial correlation and texture of each pixel fixed square neighborhood,which are not satisfactory as the high resolution satellite contains complex spatial and texture information. the segmentation method of high resolution remote sensing image based on pixel-by-pixel MRF model usually suffer from salt and pepper noise. Based on the analysis of problems existing in pixelby-pixel MRF model methods of high-resolution remote sensed images, an multi-feature object-oriented MRF-based segmentation algorithm is proposed. The proposed method is made up of two blocks: (1) Mean-Shift algorithm is employed to obtain the over-segmentation results and the primary processing units are generated, based on which the object adjacent graph (OAG) can be constructed.(2) the generation of objects by overly segmented, the spectral, textural, and shape feature are extracted for each node in the OAG, all of these features are constructed in a feature vector, based on which the feature model is defined on the OAG, and the neighbor system, potential cliques and energy functions of OAG are exploited in the labeling model. The proposed segmentation method is evaluated on high resolution remote sensed image data set-GeoEye, And the experimental results verified that MFOMRF has the capability to obtain better segmentation results, especially for textural and shape richer images. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/RSETE.2011.5964014},
  ISBN                     = {9781424491711}
}

@InCollection{Hotz2014,
  Title                    = {Configuration Knowledge Representation and Reasoning},
  Author                   = {Hotz, Lothar and Felfernig, Alexander and Stumptner, Markus and Ryabokon, Anna and Bagley, Claire and Wolter, Katharina},
  Publisher                = {Elsevier Inc.},
  Year                     = {2014},
  Month                    = {apr},
  Pages                    = {41--72},

  Abstract                 = {Configuration models specify the set of possible configurations (solutions). A configuration model together with a defined set of (customer) requirements are the major elements of a configuration task (problem). In this chapter, we discuss different knowledge representations that can be used for the definition of a configuration model. We provide examples that help to further develop the understanding of the underlying concepts and include a UML-based personal computer (PC) configuration model that is used as a reference example throughout this book. {\textcopyright} 2014 Elsevier Inc. All rights reserved.},
  Doi                      = {10.1016/B978-0-12-415817-7.00006-2},
  ISBN                     = {9780124158177}
}

@Article{Hu2016,
  Title                    = {Extensions and evolution analysis method for software feature models},
  Author                   = {Hu, Jie and Wang, Qing},
  Year                     = {2016},

  Month                    = {may},
  Number                   = {5},
  Pages                    = {1212--1229},
  Volume                   = {27},

  Abstract                 = {Feature model is an essential concept and artifact in feature oriented software development (FOSD). It depicts commonality and variability (C{\&}V) of products in terms of features. With increasingly frequent software evolution, keeping the feature model in consistent with the evolution is very important. Most of the related researches usually analyze the C{\&}V on the requirement level, and modeling the analyzed C{\&}V by the feature model. However, since the feature changes may cause the ripple effect during the modeling process, some new commonalities and variability may be derived. The current researches are still not able to resolve this problem, which leads to some potential overlooking commonalities and inefficiency in reuse. This paper proposes an approach to extend the feature model and analyze the software evolution based on the feature model. The extensions of feature dependency and evolution meta-operators can support the ripple effect analysis of the feature changes, as well as the exploration of the potential commonalities. The new approach also develops some refactoring strategies and a semi-automated tool to support commonality extraction and feature refactoring. In addition, rules and strategies are designed to resolve typical configuration conflicts. Finally, the paper employs a case study to validate the applicability and effectiveness of the presented method.},
  Doi                      = {10.13328/j.cnki.jos.004829},
  ISSN                     = {10009825},
  Publisher                = {Chinese Academy of Sciences}
}

@InCollection{Hubaux2013,
  Title                    = {Separating concerns in feature models: Retrospective and support for multi-views},
  Author                   = {Hubaux, Arnaud and Acher, Mathieu and Tun, Thein Than and Heymans, Patrick and Collet, Philippe and Lahire, Philippe},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2013},
  Month                    = {jan},
  Pages                    = {3--28},

  Abstract                 = {Feature models (FMs) are a popular formalism to describe the commonality and variability of a set of assets in a software product line (SPL). SPLs usually involve large and complex FMs that describe thousands of features whose legal combinations are governed by many and often complex rules. The size and complexity of these models is partly explained by the large number of concerns considered by SPL practitioners when managing and configuring FMs. In this chapter, we first survey concerns and their separation in FMs, highlighting the need for more modular and scalable techniques. We then revisit the concept of view as a simplified representation of an FM. We finally describe a set of techniques to specify, visualise and verify the coverage of a set of views. These techniques are implemented in complementary tools providing practical support for feature-based configuration and large-scale management of FMs.},
  Doi                      = {10.1007/978-3-642-36654-3_1},
  ISBN                     = {9783642366543}
}

@Article{Hubaux2010a,
  Title                    = {A Preliminary Review on the Application of Feature Diagrams in Practice.},
  Author                   = {Hubaux, A and Classen, A and Mendon{\c{c}}a, M and Heymans, P},
  Journal                  = {VaMoS},
  Year                     = {2010},

  Url                      = {https://pdfs.semanticscholar.org/785d/d68b162ad4367921ef2607439c41fd68329d.pdf}
}

@Article{Hubaux2010,
  Title                    = {Towards multi-view feature-based configuration},
  Author                   = {Hubaux, A and Heymans, P and Schobbens, PY},
  Journal                  = {Work. Conf. {\ldots}},
  Year                     = {2010},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-14192-8{\_}12}
}

@Article{Hubaux2013a,
  Title                    = {Supporting multiple perspectives in feature-based configuration},
  Author                   = {Hubaux, Arnaud and Heymans, Patrick and Schobbens, Pierre Yves and Deridder, Dirk and Abbasi, Ebrahim Khalil},
  Year                     = {2013},

  Month                    = {jul},
  Number                   = {3},
  Pages                    = {641--663},
  Volume                   = {12},

  Abstract                 = {Feature diagrams have become commonplace in software product line engineering as a means to document variability early in the life cycle. Over the years, their application has also been extended to assist stakeholders in the configuration of software products. However, existing feature-based configuration techniques offer little support for tailoring configuration views to the profiles of the various stakeholders. In this paper, we propose a lightweight, yet formal and flexible, mechanism to leverage multidimensional separation of concerns in feature-based configuration. We propose a technique to specify concerns in feature diagrams and to generate automatically concern-specific configuration views. Three alternative visualisations are proposed. Our contributions are motivated and illustrated through excerpts from a real web-based meeting management application which was also used for a preliminary evaluation. We also report on the progress made in the development of a tool supporting multi-view feature-based configuration. {\textcopyright} 2011 Springer-Verlag.},
  Doi                      = {10.1007/s10270-011-0220-1},
  ISSN                     = {16191366}
}

@Article{Hubaux2012,
  Title                    = {Unifying Software, Product Configuration: A Research Roadmap.},
  Author                   = {Hubaux, A and Jannach, D and Drescher, C},
  Journal                  = {Configuration},
  Year                     = {2012},

  Url                      = {http://confws-12.cis.unisa.edu.au/papers/proceedings.pdf{\#}page=35}
}

@Article{Hubaux2013b,
  Title                    = {Separation of concerns in feature diagram languages: A systematic survey},
  Author                   = {Hubaux, Arnaud and Tun, Thein Than and Heymans, Patrick},
  Year                     = {2013},

  Month                    = {aug},
  Number                   = {4},
  Volume                   = {45},

  Abstract                 = {The need for flexible customization of large feature-rich software systems, according to requirements of various stakeholders, has become an important problem in software development. Among the many software engineering approaches dealing with variability management, the notion of Software Product Line (SPL) has emerged as a major unifying concept. Drawing from established disciplines of manufacturing, SPL approaches aim to design repertoires of software artifacts, from which customized software systems for specific stakeholder requirements can be developed. A major difficulty SPL approaches attempt to address is the modularization of software artifacts, which reconciles the user's needs for certain features and the development and technical constraints. Towards this end, many SPL approaches use feature diagrams to describe possible configurations of a feature set. There have been several proposals for feature diagram languages with varying degrees of expressiveness, intuitiveness, and precision. However, these feature diagram languages have limited scalability when applied to realistic software systems. This article provides a systematic survey of various concerns of feature diagrams and ways in which concerns have been separated. The survey shows how the uncertainty in the purpose of feature diagram languages creates both conceptual and practical limitations to scalability of those languages. {\textcopyright} 2013 ACM.},
  Doi                      = {10.1145/2501654.2501665},
  ISSN                     = {03600300}
}

@Article{Huber2010,
  Title                    = {Analysis of the performance-influencing factors of virtualization platforms},
  Author                   = {Huber, N and Quast, M Von and Brosig, F and Kounev, S},
  Journal                  = {Conf. Move {\ldots}},
  Year                     = {2010},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-16949-6{\_}10}
}

@InProceedings{Inrak2010,
  Title                    = {Applying latent semantic analysis to classify emotions in Thai text},
  Author                   = {Inrak, Piyatida and Sinthupinyo, Sukree},
  Year                     = {2010},
  Volume                   = {6},

  Abstract                 = {With a rapid growth of the internet communication, many types of text are produced. They can convey the meanings that can contribute to text categorization. Emotion classification also becomes more interesting, but emotion classification in Thai text is still not able to be correctly classified. Thus, this paper proposes a novel approach that takes advantage of bi-words occurrence to classify emotion hidden in a short sentence. In this paper, we classify Thai text into six basic universal emotions including anger, disgust, fear, happiness, sadness, and surprise based on latent semantic analysis approach. We compared the results between two models which construct features from the sentences and applied to three classification methods, i.e. Naive Bayes, SVM, and Decision Tree. The first feature model uses only single word occurrence in the classification. The second model uses single word combined with bi-words occurrence in the classification. The results show that the second model can yield higher accuracy than the first model based on the Na{\"{i}}ve Bayes classification method. {\textcopyright} 2010 IEEE.},
  Doi                      = {10.1109/ICCET.2010.5486137},
  ISBN                     = {9781424463503}
}

@Article{Istoan2011,
  Title                    = {A metamodel-based classification of variability modeling approaches},
  Author                   = {Istoan, P and Klein, J and Perrouin, G},
  Journal                  = {Work. Affil. with {\ldots}},
  Year                     = {2011},

  Url                      = {http://publications.uni.lu/handle/10993/3946}
}

@Article{Jezequel2012,
  Title                    = {Model-driven engineering for software product lines},
  Author                   = {J{\'{e}}z{\'{e}}quel, JM},
  Journal                  = {ISRN Softw. Eng.},
  Year                     = {2012},

  Url                      = {http://downloads.hindawi.com/journals/isrn.software.engineering/2012/670803.pdf}
}

@Article{Janota2010,
  Title                    = {SAT solving in interactive configuration},
  Author                   = {Janota, M},
  Year                     = {2010},

  Url                      = {http://130.226.142.164/documents/reports/Janota10.pdf}
}

@Article{Johansen2012,
  Title                    = {An algorithm for generating t-wise covering arrays from large feature models},
  Author                   = {Johansen, MF and Haugen, {\O} and Fleurey, F},
  Journal                  = {Proc. 16th},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2362547}
}

@InProceedings{Johansen2011,
  Title                    = {Properties of realistic feature models make combinatorial testing of product lines feasible},
  Author                   = {Johansen, Martin Fagereng and Haugen, {\O}ystein and Fleurey, Franck},
  Year                     = {2011},
  Pages                    = {638--652},
  Volume                   = {6981 LNCS},

  Abstract                 = {Feature models and associated feature diagrams allow modeling and visualizing the constraints leading to the valid products of a product line. In terms of their expressiveness, feature diagrams are equivalent to propositional formulas which makes them theoretically expensive to process and analyze. For example, satisfying propositional formulas, which translates into finding a valid product for a given feature model, is an NP-hard problem, which has no fast, optimal solution. This theoretical complexity could prevent the use of powerful analysis techniques to assist in the development and testing of product lines. However, we have found that satisfying realistic feature models is quick. Thus, we show that combinatorial interaction testing of product lines is feasible in practice. Based on this, we investigate covering array generation time and results for realistic feature models and find where the algorithms can be improved. {\textcopyright} 2011 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-24485-8_47},
  ISBN                     = {9783642244841},
  ISSN                     = {03029743}
}

@Article{Johansson2010,
  Title                    = {Reranking models in fine-grained opinion analysis},
  Author                   = {Johansson, R and Moschitti, A},
  Journal                  = {23rd Int. Conf. {\ldots}},
  Year                     = {2010},

  Url                      = {http://dl.acm.org/citation.cfm?id=1873840}
}

@Article{Kaestner2011,
  Title                    = {The road to feature modularity?},
  Author                   = {K{\"{a}}stner, C and Apel, S and Ostermann, K},
  Journal                  = {Proc. 15th Int.},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=2019142}
}

@Article{Kastner2011,
  Title                    = {Variability mining with leadt},
  Author                   = {K{\"{a}}stner, C and Dreiling, A and Ostermann, K},
  Journal                  = {Tec. Rep., Philipps Univ. Marbg.},
  Year                     = {2011},

  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.232.2001{\&}rep=rep1{\&}type=pdf}
}

@Article{Kastner2011a,
  Title                    = {Partial preprocessing C code for variability analysis},
  Author                   = {K{\"{a}}stner, C and Giarrusso, PG and Ostermann, K},
  Journal                  = {Proc. 5th},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=1944908}
}

@InProceedings{Kastner2012a,
  Title                    = {A variability-aware module system},
  Author                   = {K{\"{a}}stner, Christian and Ostermann, Klaus and Erdweg, Sebastian},
  Year                     = {2012},
  Month                    = {oct},
  Number                   = {10},
  Pages                    = {773--791},
  Volume                   = {47},

  Abstract                 = {Module systems enable a divide and conquer strategy to software development. To implement compile-time variability in software product lines, modules can be composed in different combinations. However, this way, variability dictates a dominant decomposition. As an alternative, we introduce a variability-aware module system that supports compile-time variability inside a module and its interface. So, each module can be considered a product line that can be type checked in isolation. Variability can crosscut multiple modules. The module system breaks with the antimodular tradition of a global variability model in product-line development and provides a path toward software ecosystems and product lines of product lines developed in an open fashion. We discuss the design and implementation of such a module system on a core calculus and provide an implementation for C as part of the TypeChef project. Our implementation supports variability inside modules from {\#}ifdef preprocessor directives and variable linking at the composition level. With our implementation, we type check all configurations of all modules of the open source product line Busybox with 811 compile-time options, perform linker check of all configurations, and report found type and linker errors - without resorting to a brute-force strategy. Copyright {\textcopyright} 2012 ACM.},
  Doi                      = {10.1145/2398857.2384673},
  ISSN                     = {15232867}
}

@InProceedings{Kamoun2016,
  Title                    = {Multiple software product lines for service oriented architecture},
  Author                   = {Kamoun, Akram and Kacem, Mohamed Hadj and Kacem, Ahmed Hadj},
  Year                     = {2016},
  Month                    = {aug},
  Pages                    = {56--61},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {Combining the Service Oriented Architecture (SOA) and Software Product Line (SPL) paradigms is an emerging research area that has gained a considerable interest in recent years. We observe that the approaches proposed in the literature address mostly the variability modeling of Service Providers (SPs) (e.g., developing and composing SPs). However, handling the variability of Service Consumers (SCs) and how to interrelate the variability of SCs and SPs have not been studied. In this paper, our objective is to carry out an in-depth and rigorous study that addresses these issues. We propose a new model-based, top-down, formal and end-to-end SOA approach based on the Multiple SPLs (MSPL) paradigm. The main idea is to develop an MSPL composed of two dependent SPLs for SP and SC in order to generate customized, valid and consistent SPs and SCs. We propose that the variability of each SPL is managed by a Feature Model (FM). In order to ensure the consistency between these two SPLs and in particular between their FMs, we define the automated analysis update operator based on formal propositional logical techniques. We developed a tool that implements all the required steps of our approach and we demonstrate its efficiency in a practical case study.},
  Doi                      = {10.1109/WETICE.2016.21},
  ISBN                     = {9781509016631}
}

@InProceedings{Kang2010,
  Title                    = {FODA: Twenty Years of Perspective on Feature Modeling.},
  Author                   = {Kang},
  Booktitle                = {Vamos},
  Year                     = {2010}
}

@Article{Karatas2016,
  Title                    = {Attribute-based variability in feature models},
  Author                   = {Karataş, Ahmet Serkan and Oğuzt{\"{u}}z{\"{u}}n, Halit},
  Year                     = {2016},

  Month                    = {jun},
  Number                   = {2},
  Pages                    = {185--208},
  Volume                   = {21},

  Abstract                 = {Extended feature models enable the expression of complex cross-tree constraints involving feature attributes. The inclusion of attributes in cross-tree relations not only enriches the constraints, but also engenders an extended type of variability that involves attributes. In this article, we elaborate on the effects of this new variability type on feature models. We start by analyzing the nature of the variability involving attributes and extend the definitions of the configuration and the product to suit the emerging requirements. Next, we propose classifications for the features, configurations, and products to identify and formalize the ramifications that arise due to the new type of variability. Then, we provide a semantic foundation grounded on constraint satisfaction for our proposal. We introduce an ordering relation between configurations and show that the set of all the configurations represented by a feature model forms a semilattice. This is followed by a demonstration of how the feature model analyses will be affected using illustrative examples selected from existing and novel analysis operations. Finally, we summarize our experiences, gained from a commercial research and development project that employs an extended feature model.},
  Doi                      = {10.1007/s00766-014-0216-9},
  ISSN                     = {1432010X},
  Publisher                = {Springer-Verlag London Ltd}
}

@InProceedings{Karatas2013,
  Title                    = {From extended feature models to constraint logic programming},
  Author                   = {Karataş, Ahmet Serkan and Oǧuzt{\"{u}}z{\"{u}}n, Halit and Doǧru, Ali},
  Year                     = {2013},
  Month                    = {dec},
  Number                   = {12},
  Pages                    = {2295--2312},
  Volume                   = {78},

  Abstract                 = {Since feature models for realistic product families may be quite complicated, the automated analysis of feature models is desirable. Although several approaches reported in the literature address this issue, complex cross-tree relationships involving attributes in extended feature models have not been handled. In this article, we introduce a mapping from extended feature models to constraint logic programming over finite domains. This mapping is used to translate into constraint logic programs; basic, cardinality-based and extended feature models, which can include complex cross-tree relationships involving attributes. This translation enables the use of off-the-shelf constraint solvers for the automated analysis of extended feature models involving such complex relationships. We also present the performance results of some well-known analysis operations on an example translated model. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.scico.2012.06.004},
  ISSN                     = {01676423}
}

@InProceedings{Karatas2010,
  Title                    = {Mapping extended feature models to constraint logic programming over finite domains},
  Author                   = {Karataş, Ahmet Serkan and Oǧuzt{\"{u}}z{\"{u}}n, Halit and Doǧru, Ali},
  Year                     = {2010},
  Pages                    = {286--299},
  Volume                   = {6287 LNCS},

  Abstract                 = {As feature models for realistic product families may be quite complicated, automated analysis of feature models is desirable. Although several approaches reported in the literature addressed this issue, complex feature-attribute and attribute-attribute relationships in extended feature models were not handled effectively. In this article, we introduce a mapping from extended feature models to constraint logic programming over finite domains. This mapping is used to translate basic, cardinality-based, and extended feature models, which may include complex feature-feature, feature-attribute and attribute-attribute cross-tree relationships, into constraint logic programs. It thus enables use of off-the-shelf constraint solvers for the automated analysis of extended feature models involving such complex relationships. We also briefly discuss the ramifications of including feature-attribute relationships in operations of analysis. We believe that this proposal will be effective for further leveraging of constraint logic programming for automated analysis of feature models. {\textcopyright} 2010 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-15579-6_20},
  ISBN                     = {3642155782},
  ISSN                     = {03029743}
}

@InProceedings{Karatas2010a,
  Title                    = {Global constraints on feature models},
  Author                   = {Karataş, Ahmet Serkan and Oǧuzt{\"{u}}z{\"{u}}n, Halit and Doǧru, Ali},
  Year                     = {2010},
  Pages                    = {537--551},
  Volume                   = {6308 LNCS},

  Abstract                 = {Feature modeling has been found very effective for modeling and managing variability in Software Product Lines. The nature of feature models invites, sometimes even requires, the use of global constraints. This paper lays the groundwork for the inclusion of global constraints in automated reasoning on feature models. We present a mapping from extended feature models to constraint logic programming over finite domains, and show that this mapping enables using global constraints on feature attributes, as well as features, for a variety of analysis operations on feature models. We also present performance test results and discuss the benefits of using global constraints. {\textcopyright} 2010 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-15396-9_43},
  ISBN                     = {364215395X},
  ISSN                     = {03029743}
}

@InProceedings{Karol2010,
  Title                    = {Using feature models for creating families of documents},
  Author                   = {Karol, Sven and Heinzerling, Martin and Heidenreich, Florian and A{\ss}mann, Uwe},
  Year                     = {2010},
  Pages                    = {259--262},

  Abstract                 = {Variants in a family of office documents are usually created by ad-hoc copy and paste actions from a set of base documents. As a result, the set of variants is decoupled from the original documents and is difficult to manage. In this paper we present a novel approach that uses concepts from Feature Oriented Domain Analysis (FODA) to specify document families to generate variants. As a proof of concept, we implemented the Document Feature Mapper tool, which is based on our previous experience in Software Product Line Engineering (SPLE) with FODA. In our tool, variant spaces are precisely specified using feature models and mappings relating features to slices in the document family. Given a selection of features satisfying the feature model's constraints, a variant can be derived. To show the applicability of our approach and tool, we conducted two case studies with documents in the Open Document Format (ODF). Copyright 2010 ACM.},
  Doi                      = {10.1145/1860559.1860618},
  ISBN                     = {9781450302319}
}

@Article{Kastner2014,
  Title                    = {Variability mining: Consistent semi-automatic detection of product-line features},
  Author                   = {Kastner, Christian and Dreiling, Alexander and Ostermann, Klaus},
  Year                     = {2014},
  Number                   = {1},
  Pages                    = {67--82},
  Volume                   = {40},

  Abstract                 = {Software product line engineering is an efficient means to generate a set of tailored software products from a common implementation. However, adopting a product-line approach poses a major challenge and significant risks, since typically legacy code must be migrated toward a product line. Our aim is to lower the adoption barrier by providing semi-automatic tool support-called variability mining-to support developers in locating, documenting, and extracting implementations of product-line features from legacy code. Variability mining combines prior work on concern location, reverse engineering, and variability-aware type systems, but is tailored specifically for the use in product lines. Our work pursues three technical goals: (1) we provide a consistency indicator based on a variability-aware type system, (2) we mine features at a fine level of granularity, and (3) we exploit domain knowledge about the relationship between features when available. With a quantitative study, we demonstrate that variability mining can efficiently support developers in locating features. {\textcopyright} 2014 IEEE.},
  Doi                      = {10.1109/TSE.2013.45},
  ISSN                     = {00985589},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.}
}

@Article{Kattepur2010,
  Title                    = {Variability modeling and qos analysis of web services orchestrations},
  Author                   = {Kattepur, A and Sen, S and Baudry, B},
  Journal                  = {Web Serv. (ICWS),},
  Year                     = {2010},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5552798}
}

@Article{Khalvati2014,
  Title                    = {A multi-parametric diffusion magnetic resonance imaging texture feature model for prostate cancer analysis},
  Author                   = {Khalvati, F and Modhafar, A and Cameron, A and Wong, A},
  Journal                  = {Comput. Diffus.},
  Year                     = {2014},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-319-11182-7{\_}8}
}

@Article{Kim2013,
  Title                    = {SPLat: lightweight dynamic analysis for reducing combinatorics in testing configurable systems},
  Author                   = {Kim, CHP and Marinov, D and Khurshid, S and Batory, D},
  Journal                  = {Proc.},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2491459}
}

@InProceedings{Kim2016,
  Title                    = {A formal modeling and analysis framework for software product line of preemptive real-time systems},
  Author                   = {Kim, Jin Hyun and Legay, Axel and Traonouez, Louis Marie and Acher, Mathieu and Kaist, Sungwon Kang},
  Year                     = {2016},
  Month                    = {apr},
  Pages                    = {1562--1565},
  Publisher                = {Association for Computing Machinery},

  Abstract                 = {This paper presents a formal analysis framework to analyze a family of platform products w.r.t. real-time properties. First, we propose an extension of the widely-used feature model, called Property Feature Model (PFM), that distinguishes features and properties explicitly Second, we present formal behavioral models of components of a realtime scheduling unit such that all real-time scheduling units implied by a PFM are automatically composed to be analyzed against the properties given by the PFM. We apply our approach to the verification of the schedulability of a family of scheduling units using the symbolic and statistical model checkers of Uppaal.},
  Doi                      = {10.1145/2851613.2851977},
  ISBN                     = {9781450337397}
}

@Article{Koch2016,
  Title                    = {Towards Feature-based Product Line Engineering of Technical Systems},
  Author                   = {Koch, T and Holtmann, J and Schubert, D and Lindemann, T},
  Journal                  = {Procedia Technol.},
  Year                     = {2016},

  Url                      = {http://www.sciencedirect.com/science/article/pii/S2212017316304042}
}

@Article{Kolesnikov2013,
  Title                    = {Predicting quality attributes of software product lines using software and network measures and sampling},
  Author                   = {Kolesnikov, SS and Apel, S and Siegmund, N},
  Journal                  = {Proc.},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2430511}
}

@Article{Krieter2016,
  Title                    = {An Efficient Algorithm for Feature-Model Slicing},
  Author                   = {Krieter, S and Schr{\"{o}}ter, R and Th{\"{u}}m, T and Saake, G},
  Year                     = {2016},

  Url                      = {https://www.isf.cs.tu-bs.de/cms/team/thuem/papers/2016-TR-Krieter.pdf}
}

@InProceedings{Kumara2013,
  Title                    = {Sharing with a difference: Realizing service-based SaaS applications with runtime sharing and variation in dynamic software product lines},
  Author                   = {Kumara, Indika and Han, Jun and Colman, Alan and Nguyen, Tuan and Kapuruge, Malinda},
  Year                     = {2013},
  Pages                    = {567--574},

  Abstract                 = {A single-instance multi-tenant (SIMT) SaaS application enables a SaaS provider to achieve economies of scale through runtime sharing. However, runtime sharing can make tenant-specific variations difficult to achieve in such an application. In this paper, we propose an approach to realizing SIMT SaaS applications, which is based on Dynamic Software Product Lines (DSPL) and supports runtime sharing and variation. With the collaboration among a subset of services as the unit of composition, the commonality among the tenants' requirements is realized in the DSPL architecture by sharing collaboration units, and their variability is realized by composing different collaboration units, all at runtime. In addition, we adopt a feature-based high-level representation of the commonality and variability between the tenants' requirements to facilitate the runtime creation and reconfiguration of their application variants. We compare our approach with two alternative approaches in terms of development effort and degree of sharing. We further quantify the runtime overhead incurred by our multi-tenancy support. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/SCC.2013.30},
  ISBN                     = {9780768550268}
}

@Article{Le2013,
  Title                    = {Validating consistency between a feature model and its implementation},
  Author                   = {Le, DM and Lee, H and Kang, KC and Keun, L},
  Journal                  = {Int. Conf. Softw.},
  Year                     = {2013},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-38977-1{\_}1}
}

@Article{Lee2014,
  Title                    = {Domain-oriented variability modeling for reuse of simulation models},
  Author                   = {Lee, Hyesun and Yang, Jin Seok and Kang, Kyo Chul and Pyun, Jai Jeong},
  Year                     = {2014},
  Number                   = {4},
  Pages                    = {438--459},
  Volume                   = {90},

  Abstract                 = {Reusability is an important quality attribute for defense modeling and simulation (MS) due to the ever-changing combat simulations and new requirements. There has been research conducted worldwide for reusing simulation models. The methods proposed in these studies (including One Semi-Automated Forces (OneSAF)) support reuse of simulation components in the development of new models. As the reuse units in the existing methods are at the simulation component level, when existing components do not satisfy new simulation requirements, new components have to be developed and maintained separately from the existing ones. However, simulation components in the same domain tend to have common parts; behavior models for tactical missions and battlefield functions in the same domain are derived from the same tactical doctrine/manual, and thus they tend to have a common structure. There is a need for a new method to maximize reusability by providing "fine-grained" reuse, i.e. composing simulation components from reusable fine-grained modules (i.e. behaviors/functions). We address the problem by applying the product line engineering concept to the development of simulation components. Commonalities and variabilities (CVs) of domain-specific simulation requirements and CVs of tactical behaviors and battlefield functions are identified in domain-oriented variability modeling. Then, the CVs are used to design and implement domain-specific simulation component assets with domain-specific tactical behaviors and battlefield functions while embedding the identified variabilities. These domain-specific component assets are instantiated based on selections of variabilities and then integrated to develop a simulation model. Feasibility of the method was demonstrated in an infantry squad combat domain of the Republic of Korea armed forces. {\textcopyright} 2014 The Society for Modeling and Simulation International.},
  Doi                      = {10.1177/0037549714525679},
  ISSN                     = {17413133},
  Publisher                = {SAGE Publications Ltd}
}

@Article{Lee2010,
  Title                    = {Combining service-orientation with product line engineering},
  Author                   = {Lee, J and Kotonya, G},
  Journal                  = {IEEE Softw.},
  Year                     = {2010},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5406497}
}

@Article{Lee2010a,
  Title                    = {Usage context as key driver for feature selection},
  Author                   = {Lee, K and Kang, KC},
  Journal                  = {Int. Conf. Softw. Prod. Lines},
  Year                     = {2010},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-15579-6{\_}3}
}

@InProceedings{Leitner2010,
  Title                    = {Managing ERP configuration variants: An experience report},
  Author                   = {Leitner, Andrea and Kreiner, Christian},
  Year                     = {2010},

  Abstract                 = {The concepts of Software Product Line Engineering (SPLE) have been adapted and applied to enterprise IT systems, in particular the ERP systems of a production company. Based on a 2-layer feature model for the domain of the company's business processes, individual, albeit similar division's ERP system configurations can be derived by feature selection forming a variant description model. It is indicated that regular release upgrades can also benefit from the SPLE approach. The customization capabilities of the ERP platform are captured in another model; building up this model is automated according to information extracted online. As well, customizing an ERP system - based on the models mentioned - is performed online with the help of a connector developed in this project. Quantitative analysis and lessons learned during the project conclude this experience report. {\textcopyright} 2010 ACM.},
  Doi                      = {10.1145/1964138.1964140},
  ISBN                     = {9781450305426}
}

@Article{Lettner2013,
  Title                    = {Custom-developed vs. model-based configuration tools: Experiences from an industrial automation ecosystem},
  Author                   = {Lettner, D and Petruzelka, M and Rabiser, R and Angerer, F},
  Journal                  = {Proc. 17th},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2500713}
}

@InProceedings{Li2012a,
  Title                    = {MbFM: A matrix-based tool for modeling and configuring feature models},
  Author                   = {Li, Long and Zhao, Haiyan and Zhang, Wei},
  Year                     = {2012},
  Pages                    = {325--326},

  Abstract                 = {Feature-oriented analysis and modeling is widely accepted in software reuse, which consists of two major phases that should be taken seriously. The first is to construct a feature model, and the second is to configure products based on the feature model attained in the first. This paper presents a matrix-based approach to constructing and configuring feature models, whose main advantage is its scalability compared to traditional graphic-based feature models, and the supporting tool is presented to demonstrate its feasibility. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/RE.2012.6345827},
  ISBN                     = {9781467327855}
}

@Article{Li2013a,
  Title                    = {An automatic-propagation strategy and selective-undo mechanism for feature model configuration},
  Author                   = {Li, Long and Zhao, Hai Yan and Zhang, Wei},
  Year                     = {2013},

  Month                    = {jan},
  Number                   = {1},
  Pages                    = {132--142},
  Volume                   = {36},

  Abstract                 = {Feature-oriented domain analysis methods have been adopted by most important software reuse methods, which regard features as the basic elements in the problem space, and employ features and the relationships between features (called feature model) to structure the problem space. By customization and extension, feature models support the reuse of domain requirements in some extent. In feature-oriented methods, it is a subject worthy of in-depth study on how to use intrinsic relationships in a feature model to realize automatic-propagation and selective-undo of feature model configuration. This paper presents an automatic-propagation algorithm and one selective-undo mechanism for configuring the matrix-based feature model, by taking both the simple and composite constraints into consideration, and investigating the details of the algorithms implementation.},
  Doi                      = {10.3724/SP.J.1016.2013.00132},
  ISSN                     = {02544164}
}

@Article{Liebig2013,
  Title                    = {Scalable analysis of variable software},
  Author                   = {Liebig, J and von Rhein, A and K{\"{a}}stner, C and Apel, S},
  Journal                  = {Proc.},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2491437}
}

@Article{Linsbauer2016,
  Title                    = {Variability extraction and modeling for product variants},
  Author                   = {Linsbauer, L and Lopez-Herrejon, RE and Egyed, A},
  Journal                  = {Softw. Syst. Model.},
  Year                     = {2016},

  Url                      = {http://link.springer.com/article/10.1007/s10270-015-0512-y}
}

@InProceedings{Linsbauer2014,
  Title                    = {Feature model synthesis with genetic programming},
  Author                   = {Linsbauer, Lukas and Lopez-Herrejon, Roberto Erick and Egyed, Alexander},
  Year                     = {2014},
  Pages                    = {153--167},
  Publisher                = {Springer Verlag},
  Volume                   = {8636 LNCS},

  Abstract                 = {Search-Based Software Engineering (SBSE) has proven successful on several stages of the software development life cycle. It has also been applied to different challenges in the context of Software Product Lines (SPLs) like generating minimal test suites. When reverse engineering SPLs from legacy software an important challenge is the reverse engineering of variability, often expressed in the form of Feature Models (FMs). The synthesis of FMs has been studied with techniques such as Genetic Algorithms. In this paper we explore the use of Genetic Programming for this task. We sketch our general workflow, the GP pipeline employed, and its evolutionary operators. We report our experience in synthesizing feature models from sets of feature combinations for 17 representative feature models, and analyze the results using standard information retrieval metrics. {\textcopyright} 2014 Springer International Publishing Switzerland.},
  Doi                      = {10.1007/978-3-319-09940-8_11},
  ISBN                     = {9783319099392},
  ISSN                     = {16113349}
}

@Article{Lisboa2010,
  Title                    = {A systematic review of domain analysis tools},
  Author                   = {Lisboa, LB and Garcia, VC and Lucr{\'{e}}dio, D},
  Journal                  = {Inf.},
  Year                     = {2010},

  Url                      = {http://www.sciencedirect.com/science/article/pii/S0950584909000834}
}

@InProceedings{Liu2014a,
  Title                    = {Combined goal and feature model reasoning with the User Requirements Notation and jUCMNav},
  Author                   = {Liu, Yanji and Su, Yukun and Yin, Xinshang and Mussbacher, Gunter},
  Year                     = {2014},
  Month                    = {sep},
  Pages                    = {321--322},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {The User Requirements Notation (URN) is an international requirements engineering standard published by the International Telecommunication Union. URN supports goal-oriented and scenario-based modeling and analysis. jUCMNav is an open-source, Eclipse-based modeling tool for URN. This tool demonstration focuses on recent extensions to jUCMNav that have incorporated feature models into a URN-based modeling and reasoning framework. Feature modeling is a well-establishing technique for capturing commonalities and variabilities of Software Product Lines. Combined with URN, it is possible to reason about the impact of feature configurations on stakeholder goals and system qualities, thus helping to identify the most appropriate features for a stakeholder. Furthermore, coordinated feature and goal model reasoning is fundamental to Concern-Driven Development, where concerns are defined with a three-part variation, customization, and usage interface. As the variation interface is described with feature and goal models, it is now possible with jUCMNav to define and reason about a concern's variation interface, which is a prerequisite for composing multiple concerns based on their three-part interfaces.},
  Doi                      = {10.1109/RE.2014.6912277},
  ISBN                     = {9781479930333}
}

@Article{Liu2010a,
  Title                    = {A semantic feature model in concurrent engineering},
  Author                   = {Liu, Yong Jin and Lai, Kam Lung and Dai, Gang and Yuen, Matthew Ming Fai},
  Year                     = {2010},

  Month                    = {jul},
  Number                   = {3},
  Pages                    = {659--665},
  Volume                   = {7},

  Abstract                 = {Concurrent engineering (CE) is a methodology applied to product lifecycle development so that high quality, well designed products can be provided at lower prices and in less time. Many research works have been proposed for efficiently modeling of different domains in CE. However, an integration of these works with consistent data flow is absent and still in great demand in industry. In this paper, we present a generic integration framework with a semantic feature model for knowledge representation and reasoning across domains in CE. An implementation of the proposed semantic feature model is presented to demonstrate its advantage in knowledge representation by feature transformation across domains in CE. {\textcopyright} 2010 IEEE.},
  Doi                      = {10.1109/TASE.2009.2039996},
  ISSN                     = {15455955}
}

@Article{Lochau2012,
  Title                    = {Model-based pairwise testing for feature interaction coverage in software product line engineering},
  Author                   = {Lochau, M and Oster, S and Goltz, U and Sch{\"{u}}rr, A},
  Journal                  = {Softw. Qual. J.},
  Year                     = {2012},

  Url                      = {http://link.springer.com/article/10.1007/s11219-011-9165-4}
}

@Article{Lochau2012a,
  Title                    = {Incremental model-based testing of delta-oriented software product lines},
  Author                   = {Lochau, M and Schaefer, I and Kamischke, J and Lity, S},
  Journal                  = {Int. Conf.},
  Year                     = {2012},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-30473-6{\_}7}
}

@Article{Lopez-Herrejon2012,
  Title                    = {Towards fixing inconsistencies in models with variability},
  Author                   = {Lopez-Herrejon, RE and Egyed, A},
  Journal                  = {Sixth Int. Work. {\ldots}},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2110158}
}

@InProceedings{Lopez-Herrejon2013,
  Title                    = {Multi-objective optimal test suite computation for software product line pairwise testing},
  Author                   = {Lopez-Herrejon, Roberto E. and Chicano, Francisco and Ferrer, Javier and Egyed, Alexander and Alba, Enrique},
  Year                     = {2013},
  Pages                    = {404--407},

  Abstract                 = {Software Product Lines (SPLs) are families of related software products, which usually provide a large number of feature combinations, a fact that poses a unique set of challenges for software testing. Recently, many SPL testing approaches have been proposed, among them pair wise combinatorial techniques that aim at selecting products to test based on the pairs of feature combinations such products provide. These approaches regard SPL testing as an optimization problem where either coverage (maximize) or test suite size (minimize) are considered as the main optimization objective. Instead, we take a multi-objective view where the two objectives are equally important. In this exploratory paper we propose a zero-one mathematical linear program for solving the multi-objective problem and present an algorithm to compute the true Pareto front, hence an optimal solution, from the feature model of a SPL. The evaluation with 118 feature models revealed an interesting trade-off between reducing the number of constraints in the linear program and the runtime which opens up several venues for future research. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/ICSM.2013.58}
}

@InProceedings{Lopez-Herrejon2013a,
  Title                    = {SBSE4VM: Search based software engineering for variability management},
  Author                   = {Lopez-Herrejon, Roberto E. and Egyed, Alexander},
  Year                     = {2013},
  Pages                    = {441--444},

  Abstract                 = {SBSE4VM is an ongoing Lise Meitner Fellowship project sponsored by the Austrian Science Fund (FWF) that runs for two years. The driving goal of the project is to explore the application of Search Based Software Engineering techniques to reverse engineer, evolve, and fix inconsistencies in systems with variability. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/CSMR.2013.67},
  ISBN                     = {9780769549484},
  ISSN                     = {15345351}
}

@InProceedings{Lopez-Herrejon2011,
  Title                    = {C2MV2: Consistency and composition for managing variability in multi-view systems},
  Author                   = {Lopez-Herrejon, Roberto E. and Egyed, Alexander},
  Year                     = {2011},
  Pages                    = {347--350},

  Abstract                 = {C2MV2 is an ongoing FP7-People Intra-European Marie Curie Fellowship project that runs for two years. The driving goal of the project is to apply and extend work on incremental consistency management to Software Product Lines that are developed with compositional approaches. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/CSMR.2011.49},
  ISBN                     = {9780769543437},
  ISSN                     = {15345351}
}

@InProceedings{Lopez-Herrejon2010,
  Title                    = {On the need of safe software product line architectures},
  Author                   = {Lopez-Herrejon, Roberto E. and Egyed, Alexander},
  Year                     = {2010},
  Pages                    = {493--496},
  Volume                   = {6285 LNCS},

  Abstract                 = {A Software Product Line (SPL) is a family of related software systems distinguished by the different sets of features each system provides. Over the last decade, the substantial benefits of SPL practices have been extensively documented and corroborated both in academia and industry. Several architecture methods have been proposed that employ different artifacts for expressing the components of a SPL, their properties and relationships. Of crucial importance for any SPL architecture method is to guarantee that the variability, for instance as expressed in feature models, is not only preserved but also kept consistent across all artifacts used. In this research challenge paper we argue that Safe Composition - the guarantee that all programs of a product line are type safe - can be leveraged to address this guarantee for structural properties of SPL architectures and the challenges that that entails. {\textcopyright} 2010 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-15114-9_48},
  ISBN                     = {3642151132},
  ISSN                     = {03029743}
}

@InCollection{Lopez-Herrejon2016,
  Title                    = {Evolutionary computation for software product line testing: An overview and open challenges},
  Author                   = {Lopez-Herrejon, Roberto E. and Ferrer, Javier and Chicano, Francisco and Egyed, Alexander and Alba, Enrique},
  Publisher                = {Springer Verlag},
  Year                     = {2016},
  Month                    = {jan},
  Pages                    = {59--87},
  Volume                   = {617},

  Abstract                 = {Because of economical, technological and marketing reasons today's software systems are more frequently being built as families where each product variant implements a different combination of features. Software families are commonly called Software Product Lines (SPLs) and over the past three decades have been the subject of extensive research and application. Among the benefits of SPLs are: increased software reuse, faster and easier product customization, and reduced time to market. However, testing SPLs is specially challenging as the number of product variants is usually large making it infeasible to test every single variant. In recent years there has been an increasing interest in applying evolutionary computation techniques for SPL testing. In this chapter, we provide a concise overview of the state of the art and practice in SPL testing with evolutionary techniques as well as to highlight open questions and areas for future research.},
  Doi                      = {10.1007/978-3-319-25964-2_4},
  ISSN                     = {1860949X}
}

@InProceedings{Lopez-Herrejon2014,
  Title                    = {Comparative analysis of classical multi-objective evolutionary algorithms and seeding strategies for pairwise testing of Software Product Lines},
  Author                   = {Lopez-Herrejon, Roberto E. and Ferrer, Javier and Chicano, Francisco and Egyed, Alexander and Alba, Enrique},
  Year                     = {2014},
  Month                    = {sep},
  Pages                    = {387--396},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {Software Product Lines (SPLs) are families of related software products, each with its own set of feature combinations. Their commonly large number of products poses a unique set of challenges for software testing as it might not be technologically or economically feasible to test of all them individually. SPL pairwise testing aims at selecting a set of products to test such that all possible combinations of two features are covered by at least one selected product. Most approaches for SPL pairwise testing have focused on achieving full coverage of all pairwise feature combinations with the minimum number of products to test. Though useful in many contexts, this single-objective perspective does not reflect the prevailing scenario where software engineers do face trade-offs between the objectives of maximizing the coverage or minimizing the number of products to test. In contrast and to address this need, our work is the first to propose a classical multi-objective formalisation where both objectives are equally important. In this paper, we study the application to SPL pairwise testing of four classical multi-objective evolutionary algorithms. We developed three seeding strategies - techniques that leverage problem domain knowledge - and measured their performance impact on a large and diverse corpus of case studies using two well-known multi-objective quality measures. Our study identifies the performance differences among the algorithms and corroborates that the more domain knowledge leveraged the better the search results. Our findings enable software engineers to select not just one solution (as in the case of single-objective techniques) but instead to select from an array of test suite possibilities the one that best matches the economical and technological constraints of their testing context.},
  Doi                      = {10.1109/CEC.2014.6900473},
  ISBN                     = {9781479914883}
}

@InProceedings{Lopez-Herrejon2014a,
  Title                    = {A parallel evolutionary algorithm for prioritized pairwise testing of software product lines},
  Author                   = {Lopez-Herrejon, Roberto E. and Ferrer, Javier and Chicano, Francisco and Haslinger, Evelyn Nicole and Egyed, Alexander and Alba, Enrique},
  Year                     = {2014},
  Pages                    = {1255--1262},
  Publisher                = {Association for Computing Machinery},

  Abstract                 = {Software Product Lines (SPLs) are families of related software systems, which provide different feature combinations. Different SPL testing approaches have been proposed. However, despite the extensive and successful use of evolutionary computation techniques for software testing, their application to SPL testing remains largely unexplored. In this paper we present the Parallel Prioritized product line Genetic Solver (PPGS), a parallel genetic algorithm for the generation of prioritized pairwise testing suites for SPLs. We perform an extensive and comprehensive analysis of PPGS with 235 feature models from a wide range of number of features and products, using 3 different priority assignment schemes and 5 product prioritization selection strategies. We also compare PPGS with the greedy algorithm prioritized-ICPL. Our study reveals that overall PPGS obtains smaller covering arrays with an acceptable performance difference with prioritized-ICPL. {\textcopyright} 2014 ACM.},
  Doi                      = {10.1145/2576768.2598305},
  ISBN                     = {9781450326629}
}

@InProceedings{Lopez-Herrejon2012a,
  Title                    = {Reverse engineering feature models with evolutionary algorithms: An exploratory study},
  Author                   = {Lopez-Herrejon, Roberto Erick and Galindo, Jos{\'{e}} A. and Benavides, David and Segura, Sergio and Egyed, Alexander},
  Year                     = {2012},
  Pages                    = {168--182},
  Volume                   = {7515 LNCS},

  Abstract                 = {Successful software evolves, more and more commonly, from a single system to a set of system variants tailored to meet the similiar and yet different functionality required by the distinct clients and users. Software Product Line Engineering (SPLE) is a software development paradigm that has proven effective for coping with this scenario. At the core of SPLE is variability modeling which employs Feature Models (FMs) as the de facto standard to represent the combinations of features that distinguish the systems variants. Reverse engineering FMs consist in constructing a feature model from a set of products descriptions. This research area is becoming increasingly active within the SPLE community, where the problem has been addressed with different perspectives and approaches ranging from analysis of configuration scripts, use of propositional logic or natural language techniques, to ad hoc algorithms. In this paper, we explore the feasibility of using Evolutionary Algorithms (EAs) to synthesize FMs from the feature sets that describe the system variants. We analyzed 59 representative case studies of different characteristics and complexity. Our exploratory study found that FMs that denote proper supersets of the desired feature sets can be obtained with a small number of generations. However, reducing the differences between these two sets with an effective and scalable fitness function remains an open question. We believe that this work is a first step towards leveraging the extensive wealth of Search-Based Software Engineering techniques to address this and other variability management challenges. {\textcopyright} 2012 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-33119-0_13},
  ISBN                     = {9783642331183},
  ISSN                     = {03029743}
}

@Misc{Lopez-Herrejon2015,
  Title                    = {A systematic mapping study of search-based software engineering for software product lines},

  Author                   = {Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Egyed, Alexander},
  Month                    = {may},
  Year                     = {2015},

  Abstract                 = {Context Search-Based Software Engineering (SBSE) is an emerging discipline that focuses on the application of search-based optimization techniques to software engineering problems. Software Product Lines (SPLs) are families of related software systems whose members are distinguished by the set of features each one provides. SPL development practices have proven benefits such as improved software reuse, better customization, and faster time to market. A typical SPL usually involves a large number of systems and features, a fact that makes them attractive for the application of SBSE techniques which are able to tackle problems that involve large search spaces. Objective The main objective of our work is to identify the quantity and the type of research on the application of SBSE techniques to SPL problems. More concretely, the SBSE techniques that have been used and at what stage of the SPL life cycle, the type of case studies employed and their empirical analysis, and the fora where the research has been published. Method A systematic mapping study was conducted with five research questions and assessed 77 publications from 2001, when the term SBSE was coined, until 2014. Results The most common application of SBSE techniques found was testing followed by product configuration, with genetic algorithms and multi-objective evolutionary algorithms being the two most commonly used techniques. Our study identified the need to improve the robustness of the empirical evaluation of existing research, a lack of extensive and robust tool support, and multiple avenues worthy of further investigation. Conclusions Our study attested the great synergy existing between both fields, corroborated the increasing and ongoing interest in research on the subject, and revealed challenging open research questions.},
  Doi                      = {10.1016/j.infsof.2015.01.008},
  ISSN                     = {09505849},
  Pages                    = {33--51},
  Publisher                = {Elsevier},
  Volume                   = {61}
}

@InProceedings{Lopez-Herrejon2015a,
  Title                    = {An assessment of search-based techniques for reverse engineering feature models},
  Author                   = {Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Galindo, Jos{\'{e}} A. and Parejo, Jos{\'{e}} A. and Benavides, David and Segura, Sergio and Egyed, Alexander},
  Year                     = {2015},
  Month                    = {may},
  Pages                    = {353--369},
  Publisher                = {Elsevier Inc.},
  Volume                   = {103},

  Abstract                 = {Successful software evolves from a single system by adding and changing functionality to keep up with users' demands and to cater to their similar and different requirements. Nowadays it is a common practice to offer a system in many variants such as community, professional, or academic editions. Each variant provides different functionality described in terms of features. Software Product Line Engineering (SPLE) is an effective software development paradigm for this scenario. At the core of SPLE is variability modelling whose goal is to represent the combinations of features that distinguish the system variants using feature models, the de facto standard for such task. As SPLE practices are becoming more pervasive, reverse engineering feature models from the feature descriptions of each individual variant has become an active research subject. In this paper we evaluated, for this reverse engineering task, three standard search based techniques (evolutionary algorithms, hill climbing, and random search) with two objective functions on 74 SPLs. We compared their performance using precision and recall, and found a clear trade-off between these two metrics which we further reified into a third objective function based on F$\beta$, an information retrieval measure, that showed a clear performance improvement. We believe that this work sheds light on the great potential of search-based techniques for SPLE tasks.},
  Doi                      = {10.1016/j.jss.2014.10.037},
  ISSN                     = {01641212}
}

@InProceedings{Lopez-Herrejon2011a,
  Title                    = {From requirements to features: An exploratory study of feature-oriented refactoring},
  Author                   = {Lopez-Herrejon, Roberto E. and Montalvillo-Mendizabal, Leticia and Egyed, Alexander},
  Year                     = {2011},
  Pages                    = {181--190},

  Abstract                 = {More and more frequently successful software systems need to evolve into families of systems, known as Software Product Lines (SPLs), to be able to cater to the different functionality requirements demanded by different customers while at the same time aiming to exploit as much common functionality as possible. As a first step, this evolution demands a clear understanding of how the functional requirements map into the features of the original system. Using this knowledge, features can be refactored so that they are reused for building the new systems of the evolved SPL. In this paper we present our experience in refactoring features based on the requirements specifications of a small and a medium size systems. Our work identified eight refactoring patterns that describe how to extract the elements of features which were subsequently implemented using Feature Oriented Software Development (FOSD) a novel modularization paradigm whose driving goal is to effectively modularize features for the development of variable systems. We argue that the identification of refactoring patterns are a stepping stone towards automating Feature-Oriented Refactoring, and present some open issues that should be addressed to that avail. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/SPLC.2011.52},
  ISBN                     = {9780769544878}
}

@Article{Lotufo2010,
  Title                    = {Evolution of the linux kernel variability model},
  Author                   = {Lotufo, R and She, S and Berger, T and Czarnecki, K},
  Journal                  = {Conf. Softw. {\ldots}},
  Year                     = {2010},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-15579-6{\_}10}
}

@Article{Luo2011,
  Title                    = {A of feature reuse method at requirement level based on aspect encapsulation},
  Author                   = {Luo, Shutong and Pei, Zhili and Zhang, Changhai and Jin, Ying},
  Year                     = {2011},

  Month                    = {sep},
  Number                   = {9},
  Pages                    = {1714--1721},
  Volume                   = {48},

  Abstract                 = {Identification of reusable software assets is the basis of software reusable exercise. Feature model can organize software requirements effectively in a certain domain by defining features and their relationship, which provides strong support for domain requirements reuse. Aspect-oriented system design emphasizes reducing entangles among requirements or codes produced during software development and achieving high modularity by encapsulating crosscutting concerns into aspects, which benefits maintenance and reuse. A method of aspect encapsulation of features from feature model at requirement level is proposed for the purpose of feature reuse, and it can identify the module reused from legacy systems in one domain. At first, through analyzing requirements documents of multi-legacy systems, system concerns are elicited and domain concern hierarchical structure is established. Next, a set of domain features are identified, and aspect encapsulation is done on similar features, and the feature layer model is set up. Finally a new system is developed with the assistance and reuse of feature layer model and encapsulated aspects. A case study is done by applying our method to design a new Web system from two legacy Web systems. It has been indicated that our approach is helpful for reusing multi-legacy systems in one domain.},
  ISSN                     = {10001239}
}

@Article{Ma2014,
  Title                    = {Building modeling tools based on metamodeling and product line technologies},
  Author                   = {Ma, Zhiyi and He, Xiao},
  Year                     = {2014},
  Number                   = {2},
  Pages                    = {219--226},
  Volume                   = {23},

  Abstract                 = {With the evolution of existing modeling languages and the emergence of more and more new modcling languages, it is necessary to rapidly build the corresponding software modeling tools with good quality. However, modeling tools for larger modeling languages are usually diversity in function and complexity in implementation technology. Taking building modeling tools as a domain, this paper presents an approach to building software modcling tools based on metamodeling and product line technologies. The paper provides the concept system of the approach and a feature model from diverse functions of modcling tools in order to specify the commonality and variability of the tools by deeply making the domain analysis, discusses the design and implementation of a general tool framework that provides the conveniences for reusing components and generating code for components, and specifies the mapping between the feature model and the components for modeling tools.},
  ISSN                     = {10224653},
  Publisher                = {Chinese Institute of Electronics}
}

@Misc{Maazoun2016,
  Title                    = {Change impact analysis for software product lines},

  Author                   = {Ma{\^{a}}zoun, Jihen and Bouassida, Nadia and Ben-Abdallah, Han{\^{e}}ne},
  Month                    = {oct},
  Year                     = {2016},

  Abstract                 = {A software product line (SPL) represents a family of products in a given application domain. Each SPL is constructed to provide for the derivation of new products by covering a wide range of features in its domain. Nevertheless, over time, some domain features may become obsolete with the apparition of new features while others may become refined. Accordingly, the SPL must be maintained to account for the domain evolution. Such evolution requires a means for managing the impact of changes on the SPL models, including the feature model and design. This paper presents an automated method that analyzes feature model evolution, traces their impact on the SPL design, and offers a set of recommendations to ensure the consistency of both models. The proposed method defines a set of new metrics adapted to SPL evolution to identify the effort needed to maintain the SPL models consistently and with a quality as good as the original models. The method and its tool are illustrated through an example of an SPL in the Text Editing domain. In addition, they are experimentally evaluated in terms of both the quality of the maintained SPL models and the precision of the impact change management.},
  Doi                      = {10.1016/j.jksuci.2016.01.005},
  ISSN                     = {22131248},
  Number                   = {4},
  Pages                    = {364--380},
  Publisher                = {King Saud bin Abdulaziz University},
  Volume                   = {28}
}

@InProceedings{Maazoun2013,
  Title                    = {Feature model extraction from product source codes based on the semantic aspect},
  Author                   = {Maazoun, Jihen and Bouassida, Nadia and Ben-Abdallah, Han{\^{e}}ne and Seriai, Abdelhak Djamel},
  Year                     = {2013},
  Pages                    = {154--161},

  Abstract                 = {Software Product Lines can be constructed through either a top-down or bottom-up process. A top-down process begins by a domain analysis where variabilities are specified then it derives the product line. It is especially interesting for the creation of new product lines. However, in practice, SPL are often set up after several similar product variants have been in use. This practice prompted the search for bottom-up processes that start from an analysis of existing product variants to identify the product line. The proposed bottom-up processes rely on two hypotheses: The product variants use the same vocabulary to name elements in their source code, and the product variants have very similar/identical structures. However, while the names represent the application domain of the products, when different developers were involved in the development of the product variants, the naming assumption becomes too restrictive. Furthermore, the variants' code structures are often different when developed separately and even when one variant is derived from another through several modifications. To loosen these two hypotheses, this paper proposes a bottom-up approach that integrates the semantic aspect of the product variants when extracting the SPL feature model. In addition, a second contribution of our approach is its capability to identify automatically the constraints among the identified features. Copyright {\textcopyright} 2013 SCITEPRESS.},
  ISBN                     = {9789898565686}
}

@Misc{Machado2014,
  Title                    = {On strategies for testing software product lines: A systematic literature review},

  Author                   = {Machado, Ivan Do Carmo and McGregor, John D. and Cavalcanti, Yguarat{\~{a}} Cerqueira and {De Almeida}, Eduardo Santana},
  Year                     = {2014},

  Abstract                 = {Context Testing plays an important role in the quality assurance process for software product line engineering. There are many opportunities for economies of scope and scale in the testing activities, but techniques that can take advantage of these opportunities are still needed. Objective The objective of this study is to identify testing strategies that have the potential to achieve these economies, and to provide a synthesis of available research on SPL testing strategies, to be applied towards reaching higher defect detection rates and reduced quality assurance effort. Method We performed a literature review of two hundred seventy-six studies published from the year 1998 up to the 1st semester of 2013. We used several filters to focus the review on the most relevant studies and we give detailed analyses of the core set of studies. Results The analysis of the reported strategies comprised two fundamental aspects for software product line testing: the selection of products for testing, and the actual test of products. Our findings indicate that the literature offers a large number of techniques to cope with such aspects. However, there is a lack of reports on realistic industrial experiences, which limits the inferences that can be drawn. Conclusion This study showed a number of leveraged strategies that can support both the selection of products, and the actual testing of products. Future research should also benefit from the problems and advantages identified in this study. {\textcopyright} 2014 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.infsof.2014.04.002},
  ISSN                     = {09505849},
  Number                   = {10},
  Pages                    = {1183--1199},
  Publisher                = {Elsevier},
  Volume                   = {56}
}

@Article{MaianideMello2014,
  Title                    = {Verification of Software Product Line artefacts: A checklist to support feature model inspections},
  Author                   = {{Maiani de Mello}, Rafael and {Nogueira Teixeira}, Eld{\^{a}}nae and Schots, Marcelo and {Lima Werner}, Cl{\'{a}}udia Maria and Travassos, Guilherme Horta},
  Year                     = {2014},
  Number                   = {5},
  Pages                    = {720--745},
  Volume                   = {20},

  Abstract                 = {Software Product Line Engineering (SPL) should ensure the correctness, completeness and consistency of its artefacts and related domain to prevent the propagation of defects in derived products. Software inspection techniques are effective in detecting defects in software artefacts and avoiding their propagation throughout the software development process. However, the results of a quasi-systematic review of the technical literature reported in this paper pointed to a lack of such techniques to support the inspection of SPL artefacts, including techniques to support the inspection of feature models (FMs) that are largely used in domain modelling. Therefore, a checklist-based inspection technique (FMCheck) has been developed to support the detection of defects on FMs. FMCheck is configurable and can be applied to the original feature model notation (the FODA approach) and its extensions, including the Odyssey-FEX notation. The inspection technique was empirically evaluated, having indicated its feasibility and effectiveness. It is possible to see that inspectors applying FMCheck to inspect FMs can be more effective than those applying ad-hoc techniques, regarding four distinct domains. {\textcopyright} J.UCS.},
  ISSN                     = {09486968},
  Publisher                = {IICM}
}

@InProceedings{Marinho2011,
  Title                    = {A verification mechanism of feature models for mobile and context-aware software product lines},
  Author                   = {Marinho, Fabiana G. and Andrade, Rossana M C and Werner, Cl{\'{a}}udia},
  Year                     = {2011},
  Pages                    = {1--10},

  Abstract                 = {Software Product Lines (SPLs) have been used to develop mobile and context-aware applications, which provide services and data for their users from anywhere and at any time using context information. In SPLs, commonality and variability of a system family are identified and often documented in a feature model. However, the development of a feature model for mobile and context-aware SPLs is not trivial, since it should comprise system and context information. Furthermore, the consistency check of feature models in the considered domain is also complex and demands advanced skills of software engineers. This paper proposes a mechanism to formalize and verify the correctness and consistency of feature models for mobile and context-aware SPLs based on a profile enriched with OCL specifications. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/SBCARS.2011.9},
  ISBN                     = {9780769546261}
}

@InProceedings{Martinez2016,
  Title                    = {Feature location benchmark for software families using eclipse community releases},
  Author                   = {Martinez, Jabier and Ziadi, Tewfik and Papadakis, Mike and Bissyand{\'{e}}, Tegawend{\'{e}} F. and Klein, Jacques and Traon, Yves Le},
  Year                     = {2016},
  Pages                    = {267--283},
  Publisher                = {Springer Verlag},
  Volume                   = {9679},

  Abstract                 = {It is common belief that high impact research in software reuse requires assessment in realistic, non-trivial, comparable, and reproducible settings. However, real software artefacts and common representations are usually unavailable. Also, establishing a representative ground truth is a challenging and debatable subject. Feature location in the context of software families is a research field that is becoming more mature with a high proliferation of techniques. We present EFLBench, a benchmark and a framework to provide a common ground for this field. EFLBench leverages the efforts made by the Eclipse Community which provides real feature-based family artefacts and their implementations. Eclipse is an active and non-trivial project and thus, it establishes an unbiased ground truth. EFLBench is publicly available and supports all tasks for feature location techniques integration, benchmark construction and benchmark usage. We demonstrate its usage and its simplicity and reproducibility by comparing four techniques.},
  Doi                      = {10.1007/978-3-319-35122-3_18},
  ISBN                     = {9783319351216},
  ISSN                     = {16113349}
}

@InProceedings{Mauro2016,
  Title                    = {Context aware reconfiguration in Software Product Lines},
  Author                   = {Mauro, Jacopo and Nieke, Michael and Seidl, Christoph and Yu, Ingrid Chieh},
  Year                     = {2016},
  Month                    = {jan},
  Pages                    = {41--48},
  Publisher                = {Association for Computing Machinery},

  Abstract                 = {Software Product Lines (SPLs) are a mechanism for largescale reuse where families of related software systems are represented in terms of commonalities and variabilities, e.g., using Feature Models (FMs). While FMs define all possible configurations of the SPL, when considering dynamic SPLs not every possible configuration may be valid in all possible contexts. Unfortunately, common FMs can not capture this context dependence. In this paper, we remedy this problem by extending attributed FMs with Validity Formulas (VFs) that constrain the selection of a particular feature to a speci fic context and that are located directly within the FM. We provide a reconfiguration engine that checks if the active configuration is valid in the current context and, if not, computes how to reconfigure it. Furthermore, we present our implementation and demonstrate its feasibility within a case study derived from scenarios of our industry partner in the automotive domain.},
  Doi                      = {10.1145/2866614.2866620},
  ISBN                     = {9781450340199}
}

@Article{Mazo2011,
  Title                    = {A generic approach for automated verification of product line models},
  Author                   = {Mazo, R},
  Year                     = {2011},

  Url                      = {https://hal.archives-ouvertes.fr/tel-00707351/}
}

@Article{Mazo2011a,
  Title                    = {Using constraint programming to verify DOPLER variability models},
  Author                   = {Mazo, R and Gr{\"{u}}nbacher, P and Heider, W and Rabiser, R},
  Journal                  = {Proc. 5th},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=1944904}
}

@InProceedings{Mazo2012,
  Title                    = {VariaMos: A tool for product line driven systems engineering with a constraint based approach},
  Author                   = {Mazo, Ra{\'{u}}l and Salinesi, Camille and Diaz, Daniel},
  Year                     = {2012},
  Pages                    = {147--154},
  Publisher                = {CEUR-WS},
  Volume                   = {855},

  Abstract                 = {The creation of error-free variability models and their usage in product line analysis and product derivation is central to product line engineering (PLE). The complexity of these tasks makes tool support a success-critical factor. Tools supporting the core activities of PLE are a challenge and a real need for academics, industrial researchers, and practitioners of the PLE domain. In this paper, we present a tool for variability modeling, model integration, verification and analysis, derivation requirements specification and product derivation.},
  ISSN                     = {16130073}
}

@Article{Mazo2012a,
  Title                    = {Constraints: The heart of domain and application engineering in the product lines engineering strategy},
  Author                   = {Mazo, Ra{\'{u}}l and Salinesi, Camille and Diaz, Daniel and Djebbi, Olfa and Lora-Michiels, Alberto},
  Year                     = {2012},

  Month                    = {apr},
  Number                   = {2},
  Pages                    = {33--68},
  Volume                   = {3},

  Abstract                 = {Drawing from an analogy between features based Product Line (PL) models and Constraint Programming (CP), this paper explores the use of CP in the Domain Engineering and Application Engineering activities that are put in motion in a Product Line Engineering strategy. Specifying a PL as a constraint program instead of a feature model carries out two important qualities of CP: expressiveness and direct automation. On the one hand, variables in CP can take values over boolean, integer, real or even complex domains and not only boolean values as in most PL languages such as the Feature-Oriented Domain Analysis (FODA). Specifying boolean, arithmetic, symbolic and reified constraint, provides a power of expression that spans beyond that provided by the boolean dependencies in FODA models. On the other hand, PL models expressed as constraint programs can directly be executed and analyzed by off-the-shelf solvers. This paper explores the issues of (a) how to specify a PL model using CP, including in the presence of multi-model representation, (b) how to verify PL specifications, (c) how to specify configuration requirements, and (d) how to support the product configuration activity. Tests performed on a benchmark of 50 PL models show that the approach is efficient and scales up easily to very large and complex PL specifications. Copyright {\textcopyright} 2012, IGI Global.},
  Doi                      = {10.4018/jismd.2012040102},
  ISSN                     = {19478186}
}

@InProceedings{Mazo2011b,
  Title                    = {Transforming attribute and clone-enabled feature models into constraint programs over finite domains},
  Author                   = {Mazo, Ra{\'{u}}l and Salinesi, Camille and Diaz, Daniel and Lora-Michiels, Alberto},
  Year                     = {2011},
  Pages                    = {188--199},

  Abstract                 = {Product line models are important artefacts in product line engineering. One of the most popular languages to model the variability of a product line is the feature notation. Since the initial proposal of feature models in 1990, the notation has evolved in different aspects. One of the most important improvements allows specify the number of instances that a feature can have in a particular product. This improvement implies an important increase on the number of variables needed to represent a feature model. Another improvement consists in allowing features to have attributes, which can take values on a different domain than the boolean one. These two extensions have increased the complexity of feature models and therefore have made more difficult the manually or even automated reasoning on feature models. To the best of our knowledge, very few works exist in literature to address this problem. In this paper we show that reasoning on extended feature models is easy and scalable by using constraint programming over integer domains. The aim of the paper is double (a) to show the rules for transforming extended feature models into constraint programs, and (b) to demonstrate, by means of 11 reasoning operations over feature models, the usefulness and benefits of our approach. We evaluated our approach by transforming 60 feature models of sizes up to 2000 features and by comparing it with 2 other approaches available in the literature. The evaluation showed that our approach is correct, useful and scalable to industry size models.},
  ISBN                     = {9789898425577}
}

@InProceedings{Mefteh2015,
  Title                    = {Implementation and evaluation of an approach for extracting feature models from documented UML use case diagrams},
  Author                   = {Mefteh, Mariem and Bouassida, Nadia and Ben-Abdallah, Han{\^{e}}ne},
  Year                     = {2015},
  Month                    = {apr},
  Pages                    = {1602--1609},
  Publisher                = {Association for Computing Machinery},

  Abstract                 = {Software product lines (SPL) aim at facing the increasing costs of software products by reusing core assets of existing products in a given domain. They are often described using feature models which, as we proposed in a previous work, can be built from possibly incomplete, documented UML use case diagrams assets using the Formal Concept Analysis method, semantic model and trigger model. In order to evaluate this approach, we present in this paper the UC2FM-tool which automates all its steps. In addition, we report on a comparison of the values of quality metrics of feature models produced by our approach with those of existing feature models built by experts for five different domains.},
  Doi                      = {10.1145/2695664.2695907},
  ISBN                     = {9781450331968}
}

@InProceedings{Mefteh2014,
  Title                    = {Feature model extraction from documented UML use case diagrams},
  Author                   = {Mefteh, Mariem and Bouassida, Nadia and Ben-Abdallah, Han{\^{e}}ne},
  Year                     = {2014},
  Number                   = {2},
  Pages                    = {107--116},
  Publisher                = {Ada-Europe},
  Volume                   = {35},

  Abstract                 = {The development of a feature model for a software product line requires a thorough domain analysis which needs a high expertise. Indeed, analysts must not only understand the requirements for one particular application, but they must also identify variable ways in which the requirements can be combined in all applications in the domain. Such an expertise being often hard to acquire, analysts need approaches that provide assistance based on any existing artefacts produced during the development of applications in the domain of the product line. In this paper, we present a fully automated approach that assists domain analysts in specifying the feature model of a software product line. Our approach exploits the use case diagrams of existing applications along with their textual documentation. Besides using the natural language documentation of the requirements, it has the merit of overcoming the possible incompleteness of such documentation.},
  ISSN                     = {13816551}
}

@Article{Meinicke2014,
  Title                    = {An overview on analysis tools for software product lines},
  Author                   = {Meinicke, J and Th{\"{u}}m, T and Schr{\"{o}}ter, R and Benduhn, F},
  Journal                  = {Proc. 18th},
  Year                     = {2014},

  Url                      = {http://dl.acm.org/citation.cfm?id=2655972}
}

@Article{Mendonca2010,
  Title                    = {Decision-making coordination and efficient reasoning techniques for feature-based configuration},
  Author                   = {Mendonca, Marcilio and Cowan, Donald},
  Year                     = {2010},

  Month                    = {may},
  Number                   = {5},
  Pages                    = {311--332},
  Volume                   = {75},

  Abstract                 = {Software Product Lines is a contemporary approach to software development that exploits the similarities and differences within a family of systems in a particular domain of interest in order to provide a common infrastructure for deriving members of this family in a timely fashion, with high-quality standards, and at lower costs. In Software Product Lines, feature-based product configuration is the process of selecting the desired features for a given software product from a repository of features called a feature model. This process is usually carried out collaboratively by people with distinct skills and interests called stakeholders. Collaboration benefits stakeholders by allowing them to directly intervene in the configuration process. However, collaboration also raises an important side effect, i.e., the need of stakeholders to cope with decision conflicts. Conflicts arise when decisions that are locally consistent cannot be applied globally because they violate one or more constraints in the feature model. Unfortunately, current product configuration systems are typically single-user-based in the sense that they do not provide means to coordinate concurrent decision-making on the feature model. As a consequence, configuration is carried out by a single person that is in charge of representing the interests of all stakeholders and managing decision conflicts on their own. This results in an error-prone and time-consuming process that requires past decisions to be revisited continuously either to correct misinterpreted stakeholder requirements or to handle decision conflicts. Yet another challenging issue related to configuration problems is the typically high computational cost of configuration algorithms. In fact, these algorithms frequently fall into the category of NP-hard and thus can become intractable in practice. In this paper, our goal is two-fold. First, we revisit our work on Collaborative Product Configuration (CPC) in which we proposed an approach to describe and validate collaborative configuration scenarios. We discuss how collaborative configuration can be described in terms of a workflow-like plan that safely guides stakeholders during the configuration process. Second, we propose a preliminary set of reasoning algorithms tailored to the feature modelling domain that can be used to provide automated support for product configuration. In addition, we compare empirically the performance of the proposed algorithms to that of a general-purpose solution. We hope that the insights provided in this paper will encourage other researchers to develop new algorithms in the near future. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.scico.2009.12.004},
  ISSN                     = {01676423}
}

@InProceedings{Menkyna2012,
  Title                    = {Aspect-oriented change realization based on multi-paradigm design with feature modeling},
  Author                   = {Menkyna, Radoslav and Vrani{\'{c}}, Valentino},
  Year                     = {2012},
  Pages                    = {40--53},
  Volume                   = {7054 LNCS},

  Abstract                 = {It has been shown earlier that aspect-oriented change realization based on a two-level change type framework can be employed to deal with changes so they can be realized in a modular, pluggable, and reusable way. In this paper, this idea is extended towards enabling direct change manipulation using multi-paradigm design with feature modeling. For this, generally applicable change types are considered to be (small-scale) paradigms and expressed by feature models. Feature models of the Method Substitution and Performing Action After Event change types are presented as examples. In this form, generally applicable change types enter an adapted process of the transformational analysis to determine their application by their instantiation over an application domain feature model. The application of the transformational analysis in identifying the details of change interaction is presented. {\textcopyright} 2012 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-28038-2_4},
  ISBN                     = {9783642280375},
  ISSN                     = {03029743}
}

@Article{Merschen2011,
  Title                    = {Experiences of applying model-based analysis to support the development of automotive software product lines},
  Author                   = {Merschen, D and Polzer, A and Botterweck, G},
  Journal                  = {Proc. 5th},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=1944910}
}

@InProceedings{Metzger2016,
  Title                    = {Coordinated run-time adaptation of variability-intensive systems: An application in cloud computing},
  Author                   = {Metzger, Andreas and Bayer, Andreas and Doyle, Daniel and Sharifloo, Amir Molzam and Pohl, Klaus and Wessling, Florian},
  Year                     = {2016},
  Month                    = {may},
  Pages                    = {5--11},
  Publisher                = {Association for Computing Machinery, Inc},

  Abstract                 = {Distributed systems, such as cloud systems or cyber-physical systems, involve the orchestration of different variability-intensive, adaptive sub-systems. Each of these sub-systems may perform adaptations simultaneously and independently from each other. Yet, if dependencies between the adaptations of the sub-systems are not considered, this may lead to conflicting adaptations or untapped synergies among adaptations. This paper introduces FCORE, a model-based approach, which facilitates coordinating adaptations among variability-intensive systems. The permissible run-time reconfigurations of each system is specified by an FCORE model, which combines feature models used in Dynamic Software Product Lines with goal models. FCORE models are mapped to constraint satisfaction problems to determine conflicts and synergies among the adaptations of the systems during execution. We demonstrate the FCORE approach by using a cloud system as a typical exemplar for a distributed system. The cloud system is part of an industrial use case concerned with offering value-added cloud services.},
  Doi                      = {10.1145/2897045.2897049},
  ISBN                     = {9781450341769}
}

@InProceedings{Metzger2014,
  Title                    = {Software product line engineering and variability management: Achievements and challenges},
  Author                   = {Metzger, Andreas and Pohl, Klaus},
  Year                     = {2014},
  Month                    = {may},
  Pages                    = {70--84},
  Publisher                = {Association for Computing Machinery, Inc},

  Abstract                 = {Software product line engineering has proven to empower organizations to develop a diversity of similar software-intensive systems (applications) at lower cost, in shorter time, and with higher quality when compared with the development of single systems. Over the last decade the software product line engineering research community has grown significantly. It has produced impressive research results both in terms of quality as well as quantity. We identified over 600 relevant research and experience papers published within the last seven years in established conferences and journals. We briefly summarize the major research achievements of these past seven years. We structure this research summary along a standardized software product line framework. Further, we outline current and future research challenges anticipated from major trends in software engineering and technology.},
  Doi                      = {10.1145/2593882.2593888},
  ISBN                     = {9781450328654}
}

@Article{Michel2011,
  Title                    = {A formal semantics for feature cardinalities in feature diagrams},
  Author                   = {Michel, R and Classen, A and Hubaux, A},
  Journal                  = {Proc. 5th},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=1944902}
}

@Article{Michel2012,
  Title                    = {An SMT-based approach to automated configuration},
  Author                   = {Michel, R and Hubaux, A and Ganesh, V and Heymans, P},
  Journal                  = {SMT Work. 2012 10th},
  Year                     = {2012},

  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.6031{\&}rep=rep1{\&}type=pdf{\#}page=111}
}

@InProceedings{Millo2013,
  Title                    = {Compositional verification of software product lines},
  Author                   = {Millo, Jean Vivien and Ramesh, S. and Krishna, Shankara Narayanan and Narwane, Ganesh Khandu},
  Year                     = {2013},
  Pages                    = {109--123},
  Volume                   = {7940 LNCS},

  Abstract                 = {This paper presents a novel approach to the design verification of Software Product Lines (SPL). The proposed approach assumes that the requirements and designs at the feature level are modeled as finite state machines with variability information. The variability information at the requirement and design levels are expressed differently and at different levels of abstraction. Also the proposed approach supports verification of SPL in which new features and variability may be added incrementally. Given the design and requirements of an SPL, the proposed design verification method ensures that every product at the design level behaviourally conforms to a product at the requirement level. The conformance procedure is compositional in the sense that the verification of an entire SPL consisting of multiple features is reduced to the verification of the individual features. The method has been implemented and demonstrated in a prototype tool SPLEnD (SPL Engine for Design Verification) on a couple of fairly large case studies. {\textcopyright} 2013 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-38613-8_8},
  ISBN                     = {9783642386121},
  ISSN                     = {03029743}
}

@InCollection{Mohabbati2014,
  Title                    = {Software product line engineering to develop variant-rich web services},
  Author                   = {Mohabbati, Bardia and Asadi, Mohsen and Ga{\v{s}}evi{\'{c}}, Dragan and Lee, Jaejoon},
  Publisher                = {Springer New York},
  Year                     = {2014},
  Month                    = {oct},
  Pages                    = {535--562},

  Abstract                 = {Service-Oriented Architecture (SOA) enables enterprise for distributed and flexible software development. SOA aims at promoting effective software asset reuse by means of encapsulating functionalities as reusable services accessible through well-defined interfaces. However, one of the challenging problems for the realization of this vision is an need for design and management of variants of SOA-based solutions. Such SOA-based solutions require customization to meet stakeholders' individual functional and non-functional requirements. In this chapter, a methodological foundation for modeling and developing variant-rich SOA-solutions by incorporating the principles of Software Product Line Engineering (SPLE) into the SOA development life cycle.},
  Doi                      = {10.1007/978-1-4614-7518-7_21},
  ISBN                     = {9781461475187}
}

@Article{Mohalik2012,
  Title                    = {Tracing SPLs precisely and efficiently},
  Author                   = {Mohalik, S and Ramesh, S and Millo, JV and Krishna, SN},
  Journal                  = {Proc. 16th},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2362562}
}

@InProceedings{Moriz2014,
  Title                    = {Assisted design for automation systems - From formal requirements to final designs},
  Author                   = {Moriz, Natalia and B{\"{o}}ttcher, Bj{\"{o}}rn and Niggemann, Oliver and Lackhove, Josef},
  Year                     = {2014},
  Month                    = {jan},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {In this paper, the authors present an engineering approach for generating automation system solutions based on formalised requirements. This enables assistant systems which guide engineers during the design phase of todays more and more complex automation systems. A software prototype is used for the evaluation of this approach in practice. The main contribution is to directly use a formal requirements model as input for the automated synthesis of automation systems and to formalise the expert knowledge for this synthesis. The result are consistent, maintainable automation systems and with that shorter and reproducible development cycles.},
  Doi                      = {10.1109/ETFA.2014.7005288},
  ISBN                     = {9781479948468}
}

@InProceedings{Murguzur2014,
  Title                    = {Context-aware staged configuration of process variants@runtime},
  Author                   = {Murguzur, Aitor and {De Carlos}, Xabier and Trujillo, Salvador and Sagardui, Goiuria},
  Year                     = {2014},
  Pages                    = {241--255},
  Publisher                = {Springer Verlag},
  Volume                   = {8484 LNCS},

  Abstract                 = {Process-based context-aware applications are increasingly becoming more complex and dynamic. Besides the large sets of process variants to be managed in such dynamic systems, process variants need to be context sensitive in order to accommodate new user requirements and intrinsic complexity. This paradigm shift forces us to defer decisions to runtime where process variants must be customized and executed based on a recognized context. However, there exists a lack of deferral of the entire process variant configuration and execution to perform an automated decision of subsequent variation points at runtime. In this paper, we present a holistic methodology to automatically resolve process variability at runtime. The proposed solution performs a staged configuration considering static and dynamic context data to accomplish effective decision making. We demonstrate our approach by exemplifying a storage operation process in a smart logistics scenario. Our evaluation demonstrates the performance and scalability results of our methodology. {\textcopyright} 2014 Springer International Publishing.},
  Doi                      = {10.1007/978-3-319-07881-6_17},
  ISBN                     = {9783319078809},
  ISSN                     = {16113349}
}

@Article{Mussbacher2012,
  Title                    = {AoURN-based modeling and analysis of software product lines},
  Author                   = {Mussbacher, Gunter and Ara{\'{u}}jo, Jo{\~{a}}o and Moreira, Ana and Amyot, Daniel},
  Year                     = {2012},

  Month                    = {sep},
  Number                   = {3-4},
  Pages                    = {645--687},
  Volume                   = {20},

  Abstract                 = {Software Product Line Engineering concerns itself with domain engineering and application engineering. During domain engineering, the whole product family is modeled with a preferred flavor of feature models and additional models as required (e. g., domain models or scenario-based models). During application engineering, the focus shifts toward a single family member and the configuration of the member's features. Recently, aspectual concepts have been employed to better encapsulate individual features of a Software Product Line (SPL), but the existing body of SPL work does not include a unified reasoning framework that integrates aspect-oriented feature description artifacts with the capability to reason about stakeholders' goals while taking feature interactions into consideration. Goal-oriented SPL approaches have been proposed, but do not provide analysis capabilities that help modelers meet the needs of the numerous stakeholders involved in an SPL while at the same time considering feature interactions. We present an aspect-oriented SPL approach for the requirements phase that allows modelers (a) to capture features, goals, and scenarios in a unified framework and (b) to reason about stakeholders' needs and perform trade-off analyses while considering undesirable interactions that are not obvious from the feature model. The approach is based on the Aspect-oriented User Requirements Notation (AoURN) and helps identify, prioritize, and choose products based on analysis results provided by AoURN editor and analysis tools. We apply the AoURN-based SPL framework to the Via Verde SPL to demonstrate the feasibility of this approach through the selection of a Via Verde product configuration that satisfies stakeholders' needs and results in a high-level, scenario-based specification that is free from undesirable feature interactions. {\textcopyright} 2011 Springer Science+Business Media, LLC.},
  Doi                      = {10.1007/s11219-011-9153-8},
  ISSN                     = {09639314}
}

@Article{Nohrer2013,
  Title                    = {C2O configurator: A tool for guided decision-making},
  Author                   = {N{\"{o}}hrer, Alexander and Egyed, Alexander},
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {265--296},
  Volume                   = {20},

  Abstract                 = {Decision models are widely used in software engineering to describe and restrict decision-making (e.g., deriving a product from a product-line). Since decisions are typically interdependent, it is often neither obvious which decisions have the most significant impact nor which decisions might ultimately conflict. Unfortunately, the current state-of-the-art provides little support for dealing with such situations. On the one hand, some conflicts can be avoided by providing more freedom in which order decisions are made (i.e., most important decisions first). On the other hand, conflicts are unavoidable at times, and living with conflicts may be preferable over forcing the user to fix them right away - particularly because fixing conflicts becomes easier as more is known about a user's intentions. This paper introduces the C2O (Configurator 2.0) tool for guided decision-making. The tool allows the user to answer questions in an arbitrary order - with and without the presence of inconsistencies. While giving users those freedoms, it still supports and guides them by (i) rearranging the order of questions according to their potential to minimize user input, (ii) providing guidance to avoid follow-on conflicts, and (iii) supporting users in fixing conflicts at a later time. {\textcopyright} 2013 Springer Science+Business Media New York.},
  Doi                      = {10.1007/s10515-012-0117-4},
  ISSN                     = {09288910}
}

@Article{Nadi2015,
  Title                    = {Where do configuration constraints stem from? An extraction approach and an empirical study},
  Author                   = {Nadi, Sarah and Berger, Thorsten and K{\"{a}}stner, Christian and Czarnecki, Krzysztof},
  Year                     = {2015},

  Month                    = {aug},
  Number                   = {8},
  Pages                    = {820--841},
  Volume                   = {41},

  Abstract                 = {Highly configurable systems allow users to tailor software to specific needs. Valid combinations of configuration options are often restricted by intricate constraints. Describing options and constraints in a variability model allows reasoning about the supported configurations. To automate creating and verifying such models, we need to identify the origin of such constraints. We propose a static analysis approach, based on two rules, to extract configuration constraints from code. We apply it on four highly configurable systems to evaluate the accuracy of our approach and to determine which constraints are recoverable from the code. We find that our approach is highly accurate (93{\%} and 77{\%} respectively) and that we can recover 28{\%} of existing constraints. We complement our approach with a qualitative study to identify constraint sources, triangulating results from our automatic extraction, manual inspections, and interviews with 27 developers. We find that, apart from low-level implementation dependencies, configuration constraints enforce correct runtime behavior, improve users' configuration experience, and prevent corner cases. While the majority of constraints is extractable from code, our results indicate that creating a complete model requires further substantial domain knowledge and testing. Our results aim at supporting researchers and practitioners working on variability model engineering, evolution, and verification techniques.},
  Doi                      = {10.1109/TSE.2015.2415793},
  ISSN                     = {00985589},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.}
}

@Article{Nadi2014,
  Title                    = {Mining configuration constraints: Static analyses and empirical results},
  Author                   = {Nadi, S and Berger, T and K{\"{a}}stner, C and Czarnecki, K},
  Journal                  = {Proc. 36th},
  Year                     = {2014},

  Url                      = {http://dl.acm.org/citation.cfm?id=2568283}
}

@Article{Nakajima2011,
  Title                    = {An architecture of dynamically adaptive php-based web applications},
  Author                   = {Nakajima, S},
  Journal                  = {2011 18th Asia-Pacific Softw. Eng.},
  Year                     = {2011},

  Abstract                 = {Self-adaptive systems, changing their functional behavior at runtime, provide desired a level of flexibility. Although various runtime frameworks have been studied, they tend to rely on a particular architecture. It is inadequate to study the characteristics of self-adaptive systems. This paper presents an abstract, declarative framework for them and relates it to an adaptive PHP-based Web application architecture, which takes a model-based adaptation approach. The formalism can be a basis for understanding the distinctive roles of the model information and runtime mechanism.},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6130688}
}

@Article{Narwane2016,
  Title                    = {Traceability analyses between features and assets in software product lines},
  Author                   = {Narwane, Ganesh Khandu and Galindo, Jos{\'{e}} A. and Krishna, Shankara Narayanan and Benavides, David and Millo, Jean Vivien and Ramesh, S.},
  Year                     = {2016},
  Number                   = {8},
  Volume                   = {18},

  Abstract                 = {In a Software Product Line (SPL), the central notion of implementability provides the requisite connection between specifications and their implementations, leading to the definition of products. While it appears to be a simple extension of the traceability relation between components and features, it involves several subtle issues that were overlooked in the existing literature. In this paper, we have introduced a precise and formal definition of implementability over a fairly expressive traceability relation. The consequent definition of products in the given SPL naturally entails a set of useful analysis problems that are either refinements of known problems or are completely novel. We also propose a new approach to solve these analysis problems by encoding them as Quantified Boolean Formulae (QBF) and solving them through Quantified Satisfiability (QSAT) solvers. QBF can represent more complex analysis operations, which cannot be represented by using propositional formulae. The methodology scales much better than the SAT-based solutions hinted in the literature and were demonstrated through a tool called SPLAnE (SPL Analysis Engine) on a large set of SPL models.},
  Doi                      = {10.3390/e18080269},
  ISSN                     = {10994300},
  Publisher                = {MDPI AG}
}

@Article{Nesic2016,
  Title                    = {Multi-view modeling and automated analysis of product line variability in systems engineering},
  Author                   = {Ne{\v{s}}i{\'{c}}, D and Nyberg, M},
  Journal                  = {Proc. 20th Int. Syst.},
  Year                     = {2016},

  Url                      = {http://dl.acm.org/citation.cfm?id=2946044}
}

@InProceedings{Nguyen2010,
  Title                    = {A feature-oriented approach for web service customization},
  Author                   = {Nguyen, T and Colman, A},
  Booktitle                = {2010 IEEE International Conference on Web Services},
  Year                     = {2010},

  Journal                  = {Web Serv. (ICWS), 2010 IEEE},
  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5552762}
}

@InProceedings{Nguyen2012,
  Title                    = {Enabling the delivery of customizable web services},
  Author                   = {Nguyen, Tuan and Colman, Alan and Han, Jun},
  Year                     = {2012},
  Pages                    = {138--145},

  Abstract                 = {Due to differences in consumer requirements, a Web service usually has multiple service variants for use in different business contexts. In such situations, delivering customizable services helps increase efficiency not only in service description and publication but also in service consumption. However, existing approaches for providing customizable services enforce the tight coupling between providers and consumers. Nor do they take into account recursive nature of service customization. Consequently, the approaches hamper the widespread use of customizable services in SOA. In this paper, we propose a language, namely Web Service Variability Description Language (WSVL), which formalizes the customization interface between providers and consumers using the XML technology to address these problems. We also describe a reference architecture for service deployment and a service engineering technique which together support the provisioning of WSVL-based customizable services. A proof-of-concept prototype system is introduced to demonstrate the feasibility of our approach. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/ICWS.2012.23},
  ISBN                     = {9780769547527}
}

@InProceedings{Nguyen2011,
  Title                    = {Modeling and managing variability in process-based service compositions},
  Author                   = {Nguyen, Tuan and Colman, Alan and Han, Jun},
  Year                     = {2011},
  Pages                    = {404--420},
  Volume                   = {7084 LNCS},

  Abstract                 = {Variability in process-based service compositions needs to be explicitly modeled and managed in order to facilitate service/process customization and increase reuse in service/process development. While related work has been able to capture variability and variability dependencies within a composition, these approaches fail to capture variability dependenciesbetween the composition and partner services. Consequently, these approaches cannot address the situation when a composite service is orchestrated from partner services some of which are customizable. In this paper, we propose a feature-based approach that is able to effectively model variability within and across compositions. The approach is supported by a process development methodology that enables the systematic reuse and management of variability. We develop a prototype system supporting extended BPMN 2.0 to demonstrate the feasibility of our approach. {\textcopyright} 2011 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-25535-9_27},
  ISBN                     = {9783642255342},
  ISSN                     = {03029743}
}

@Article{Noorian2014,
  Title                    = {Addressing non-functional properties in feature models: A goal-oriented approach},
  Author                   = {Noorian, Mehdi and Asadi, Mohsen and Bagheri, Ebrahim and Du, Weichang},
  Year                     = {2014},

  Month                    = {dec},
  Number                   = {10},
  Pages                    = {1439--1487},
  Volume                   = {24},

  Abstract                 = {Software Product Line (SPL) engineering is a systematic reuse-based software development approach which is founded on the idea of building software products using a set of core assets rather than developing individual software systems from scratch. Feature models are among the widely used artefacts for SPL development that mostly capture functional and operational variability of a system. Researchers have argued that connecting intentional variability models such as goal models with feature variability models in a target domain can enrich feature models with valuable quality and non-functional information. Interrelating goal models and feature models has already been proposed in the literature for capturing non-functional properties in software product lines; however, this manual integration process is cumbersome and tedious. In this paper, we propose a (semi) automated approach that systematically integrates feature models and goal models through standard ontologies. Our proposed approach connects feature model and goal model elements through measuring the semantic similarity of their annotated ontological concepts. Our work not only provides the means to systematically interrelate feature models and goal models but also allows domain engineers to identify and model the role and significance of non-functional properties in the domain represented by the feature model.},
  Doi                      = {10.1142/S0218194014400154},
  ISSN                     = {02181940},
  Publisher                = {World Scientific Publishing Co. Pte Ltd}
}

@InProceedings{Noorian2011,
  Title                    = {Feature model debugging based on description logic reasoning},
  Author                   = {Noorian, Mahdi and Ensan, Alireza and Bagheri, Ebrahim and Boley, Harold and Biletskiy, Yevgen},
  Year                     = {2011},
  Pages                    = {158--164},
  Publisher                = {Knowledge Systems Institute Graduate School},

  Abstract                 = {Software product line engineering refers to the concept of sharing commonalities and variabilities of a set of software products in a target domain of interest. Feature models are one of the prominent representation formalisms for software product lines. Given the fact that feature models cover all possible applications and products of a target domain, it is possible that the artifacts are not necessarily and always consistent. Therefore, identifying and resolving inconsistencies in feature models is a significant task; especially, due to the fact that a large number of possible products and complex interactions between the software product line features need to be checked. To address these challenges, in this paper, we propose a framework with an automated tool to find and fix the inconsistencies of feature models based on Description Logic (DL) reasoning. The basic idea of our approach is to first transform and represent a feature model using Description Logics. The second step is to identify the possible inconsistencies of the feature model using DL reasoning and then recommend appropriate solutions to a domain analyst for resolving existing inconsistencies.},
  ISBN                     = {1891706306}
}

@InProceedings{Nummenmaa2014,
  Title                    = {On the Use of LTSs to Analyze Software Product Line Products Composed of Features},
  Author                   = {Nummenmaa, Jyrki and Nummenmaa, Timo and Zhang, Zheying},
  Year                     = {2014},
  Pages                    = {531--541},
  Publisher                = {Springer Verlag},
  Volume                   = {214},

  Abstract                 = {In product line engineering, it is common to define the products as sets of features, where each feature has a related set of requirements. Typically, there is a common set of features/requirements, and some variable features/requirements for building different products. In an earlier proposal to use labeled transition systems (LTSs) to model and check the products, the products were composed using the feature-oriented approach and LTS models were analyzed using a related LTS analyzer tool. However, no further details or analysis about the models and possible conflicts were given. We investigate in more detail the types of conflicts that may arise and discuss the integration strategies for building an integrated LTS for the product composed of features. {\textcopyright} Springer-Verlag Berlin Heidelberg 2014.},
  Doi                      = {10.1007/978-3-642-37832-4_48},
  ISSN                     = {21945357}
}

@InProceedings{Oster2010,
  Title                    = {Automated incremental pairwise testing of software product lines},
  Author                   = {Oster, Sebastian and Markert, Florian and Ritter, Philipp},
  Year                     = {2010},
  Pages                    = {196--210},
  Volume                   = {6287 LNCS},

  Abstract                 = {Testing Software Product Lines is very challenging due to a high degree of variability leading to an enormous number of possible products. The vast majority of today's testing approaches for Software Product Lines validate products individually using different kinds of reuse techniques for testing. Due to the enormous number of possible products, individual product testing becomes more and more unfeasible. Combinatorial testing offers one possibility to test a subset of all possible products. In this contribution we provide a detailed description of a methodology to apply combinatorial testing to a feature model of a Software Product Line. We combine graph transformation, combinatorial testing, and forward checking for that purpose. Additionally, our approach considers predefined sets of products. {\textcopyright} 2010 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-15579-6_14},
  ISBN                     = {3642155782},
  ISSN                     = {03029743}
}

@Article{Oster2011,
  Title                    = {MoSo-PoLiTe: tool support for pairwise and model-based software product line testing},
  Author                   = {Oster, S and Zorcic, I and Markert, F and Lochau, M},
  Journal                  = {Proc. 5th Work.},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=1944901}
}

@Article{Paskevicius2012,
  Title                    = {Automatic extraction of features and generation of feature models from java programs},
  Author                   = {Pa{\v{s}}kevi{\v{c}}ius, Paulius and Dama{\v{s}}evi{\v{c}}ius, Robertas and Kar{\v{c}}iauskas, Eimutis and Marcinkevi{\v{c}}ius, Romas},
  Year                     = {2012},
  Number                   = {4},
  Pages                    = {376--384},
  Volume                   = {41},

  Abstract                 = {Feature modelling is a key technique for identifying common and variable features in software (software component families). The result of feature modelling is a feature model: a concise specification of product features and their relationships. Feature models have been proven to be useful for software variability modelling and management. However, there is a wide gap between feature models and program source code. Here we focus on reverse engineering of source code to feature models. We present a framework for the automated derivation of feature models from the existing software artefacts (components, libraries, etc.), which includes a formal description of a feature model, a program-feature relation meta-model, and a method for feature model generation based on feature dependency extraction and clustering. Feature models are generated in Feature Description Language (FDL) and as Prolog rules.},
  ISSN                     = {1392124X}
}

@InProceedings{Papakonstantinou2012,
  Title                    = {Using fault propagation analyses for early elimination of unreliable design alternatives of complex cyber-physical systems},
  Author                   = {Papakonstantinou, Nikolaos and Sierla, Seppo and Tumer, Irem Y. and Jensen, David C.},
  Year                     = {2012},
  Number                   = {PARTS A AND B},
  Pages                    = {1183--1191},
  Volume                   = {2},

  Abstract                 = {The Functional Failure Identification and Propagation (FFIP) framework has been proposed in prior work to study the reliability of early phase designs of complex systems. For the specified functionality, a model of mechanical, electrical and software components has been defined to support simulation and discovery of fault propagation paths. The advantage of this approach has been the possibility to identify unreliable designs before high cost design commitments have been made. However, a weakness is that the results are specific to the component model that is created for the purpose of running the FFIP simulations; it is unclear how the results would change if different modeling choices would have been made. Further, the usefulness of the method in design has been limited to evaluating reliability rather than actively finding more robust design alternatives. In order to address these weaknesses, the FFIP component model needs to incorporate a capability to describe design alternatives. The feature modeling syntax and semantics, which has been successfully used by software engineers to describe customer variations in product lines, is applied here to specify alternative mechanical, electrical and software features of a cyber-physical system. In the concept phase, all plausible design alternatives are described with a feature model. FFIP analyses can be performed for each valid configuration of this model, and all alternatives that are found unreliable are removed. The result is a restricted feature model, comprising significantly fewer design alternatives, that is delivered as source information for the detailed design phase. A toolchain for performing these analyses is presented, integrating open source feature modeling and configuration tools to the FFIP environment. The methodology is illustrated with a case study from boiling water nuclear reactor design. Copyright {\textcopyright} 2012 by ASME.},
  Doi                      = {10.1115/DETC2012-70241},
  ISBN                     = {9780791845011}
}

@Article{Parejo2016,
  Title                    = {Multi-objective test case prioritization in highly configurable systems: A case study},
  Author                   = {Parejo, Jos{\'{e}} A. and S{\'{a}}nchez, Ana B. and Segura, Sergio and Ruiz-Cort{\'{e}}s, Antonio and Lopez-Herrejon, Roberto E. and Egyed, Alexander},
  Year                     = {2016},

  Month                    = {dec},
  Pages                    = {287--310},
  Volume                   = {122},

  Abstract                 = {Test case prioritization schedules test cases for execution in an order that attempts to accelerate the detection of faults. The order of test cases is determined by prioritization objectives such as covering code or critical components as rapidly as possible. The importance of this technique has been recognized in the context of Highly-Configurable Systems (HCSs), where the potentially huge number of configurations makes testing extremely challenging. However, current approaches for test case prioritization in HCSs suffer from two main limitations. First, the prioritization is usually driven by a single objective which neglects the potential benefits of combining multiple criteria to guide the detection of faults. Second, instead of using industry-strength case studies, evaluations are conducted using synthetic data, which provides no information about the effectiveness of different prioritization objectives. In this paper, we address both limitations by studying 63 combinations of up to three prioritization objectives in accelerating the detection of faults in the Drupal framework. Results show that non–functional properties such as the number of changes in the features are more effective than functional metrics extracted from the configuration model. Results also suggest that multi-objective prioritization typically results in faster fault detection than mono-objective prioritization.},
  Doi                      = {10.1016/j.jss.2016.09.045},
  ISSN                     = {01641212},
  Publisher                = {Elsevier Inc.}
}

@Article{Park2010,
  Title                    = {An approach to developing reusable domain services for service oriented applications},
  Author                   = {Park, J and Kim, J and Yun, S and Moon, M and Yeom, K},
  Journal                  = {2010 ACM Symp. {\ldots}},
  Year                     = {2010},

  Url                      = {http://dl.acm.org/citation.cfm?id=1774559}
}

@Article{Parra2010,
  Title                    = {Feature-based composition of software architectures},
  Author                   = {Parra, C and Cleve, A and Blanc, X and Duchien, L},
  Journal                  = {Eur. Conf. Softw.},
  Year                     = {2010},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-15114-9{\_}18}
}

@Article{Pascual2015,
  Title                    = {Applying multiobjective evolutionary algorithms to dynamic software product lines for reconfiguring mobile applications},
  Author                   = {Pascual, Gustavo G. and Lopez-Herrejon, Roberto E. and Pinto, M{\'{o}}nica and Fuentes, Lidia and Egyed, Alexander},
  Year                     = {2015},
  Number                   = {C},
  Pages                    = {392--411},
  Volume                   = {103},

  Abstract                 = {Mobile applications require dynamic reconfiguration services (DRS) to self-adapt their behavior to the context changes (e.g., scarcity of resources). Dynamic Software Product Lines (DSPL) are a well-accepted approach to manage runtime variability, by means of late binding the variation points at runtime. During the system's execution, the DRS deploys different configurations to satisfy the changing requirements according to a multiobjective criterion (e.g., insufficient battery level, requested quality of service). Search-based software engineering and, in particular, multiobjective evolutionary algorithms (MOEAs), can generate valid configurations of a DSPL at runtime. Several approaches use MOEAs to generate optimum configurations of a Software Product Line, but none of them consider DSPLs for mobile devices. In this paper, we explore the use of MOEAs to generate at runtime optimum configurations of the DSPL according to different criteria. The optimization problem is formalized in terms of a Feature Model (FM), a variability model. We evaluate six existing MOEAs by applying them to 12 different FMs, optimizing three different objectives (usability, battery consumption and memory footprint). The results are discussed according to the particular requirements of a DRS for mobile applications, showing that PAES and NSGA-II are the most suitable algorithms for mobile environments.},
  Doi                      = {10.1016/jjss.2014.12.041},
  ISSN                     = {01641212},
  Publisher                = {Elsevier Inc.}
}

@InProceedings{Pascual2013,
  Title                    = {Run-time adaptation of mobile applications using genetic algorithms},
  Author                   = {Pascual, Gustavo G. and Pinto, M{\'{o}}nica and Fuentes, Lidia},
  Year                     = {2013},
  Pages                    = {73--82},

  Abstract                 = {Mobile applications run in environments where the context is continuously changing. Therefore, it is necessary to provide support for the run-time adaptation of these applications. This support is usually achieved by middleware platforms that offer a context-aware dynamic reconfiguration service. However, the main shortcoming of existing approaches is that both the list of possible configurations and the plans to adapt the application to a new configuration are usually specified at design-time. In this paper we present an approach that allows the automatic generation at run-time of application configurations and of reconfiguration plans. Moreover, the generated configurations are optimal regarding the provided functionality and, more importantly, without exceeding the available resources (e.g. battery). This is performed by: (1) having the information about the application variability available at runtime using feature models, and (2) using a genetic algorithm that allows generating an optimal configuration at runtime. We have specified a case study and evaluated our approach, and the results show that it is efficient enough as to be used on mobile devices without introducing an excessive overhead. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/SEAMS.2013.6595494},
  ISBN                     = {9781467344012},
  ISSN                     = {21572305}
}

@InProceedings{Paskevicius2012a,
  Title                    = {Change impact analysis of feature models},
  Author                   = {Paskevicius, Paulius and Damasevicius, Robertas and {\v{S}}tuikys, Vytautas},
  Year                     = {2012},
  Pages                    = {108--122},
  Volume                   = {319 CCIS},

  Abstract                 = {Changeability is a fundamental property of software systems. Every software system must evolve at all levels of abstraction (models, architecture, source code, documentation, etc.) to meet changing user and context requirements. To assess the extent of a change, change impact analysis must be performed. In this paper, we propose a taxonomy of change aspects in feature modelling domain, and analyse changeability of feature models, a high level representation of system's external user-visible characteristics. We propose the change impact model based on a feature dependency matrix to assess validity of feature change, to follow feature change propagation and to estimate changeability of a feature model using a Jaccard distance measure. The model is implemented using Prolog logic rules. A case study is presented. {\textcopyright} 2012 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-33308-8_10},
  ISBN                     = {9783642333071},
  ISSN                     = {18650929}
}

@Article{Passos2013,
  Title                    = {Feature-oriented software evolution},
  Author                   = {Passos, L and Czarnecki, K and Apel, S and W{\c{a}}sowski, A},
  Journal                  = {Proc.},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2430526}
}

@Article{Passos2011,
  Title                    = {A study of non-boolean constraints in variability models of an embedded operating system},
  Author                   = {Passos, L and Novakovic, M and Xiong, Y and Berger, T},
  Journal                  = {Proc. 15th},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=2019139}
}

@Misc{Peng2016b,
  Title                    = {Research on application classification method in cloud computing environment},

  Author                   = {Peng, Junjie and Chen, Jinbao and Zhi, Xiaofei and Qiu, Meikang and Xie, Xiaolan},
  Month                    = {feb},
  Year                     = {2016},

  Abstract                 = {Energy consumption is a very important issue that has attracted the attention of many cloud providers as it takes a large quotient of the operation cost for cloud data center. To decrease the energy consumption in cloud data center, one possible solution is to process different types of applications with different strategies. To reach this goal, it is important to know the type of application before it be dealt with. In this paper, we present an application type classification method by monitoring the usage of the resources of application. Through analysis, we find that only part of the parameters are much related to different types of applications. Using these parameters we put forward a feature model that can effectively classify the types of different applications. Extensive experiments show that the model put forward can effectively and accurately classify CPU intensive application, I/O intensive application and network intensive application. It can be used as the basis of efficient utilization of the cloud resources.},
  Doi                      = {10.1007/s11227-016-1663-5},
  ISSN                     = {15730484},
  Pages                    = {1--20},
  Publisher                = {Springer New York LLC}
}

@InProceedings{Peng2016,
  Title                    = {An approach for prioritizing software features based on node centrality in probability network},
  Author                   = {Peng, Zhenlian and Wang, Jian and He, Keqing and Li, Hongtao},
  Year                     = {2016},
  Pages                    = {106--121},
  Publisher                = {Springer Verlag},
  Volume                   = {9679},

  Abstract                 = {Due to the increasing complexity of software products as well as the restriction of the development budget and time, requirements prioritization, i.e., selecting more crucial requirements to be designed and developed firstly, has become increasingly important in the software development lifetime. Considering the fact that a feature in a feature model can be viewed as a set of closely related requirements, feature prioritization will contribute to requirements prioritization to a large extent. Therefore, how to measure the priority of features within a feature model becomes an important issue in requirements analysis. In this paper, a software feature prioritization approach is proposed, which utilizes the dependencies between features to build a feature probability network and measures feature prioritization through the nodes centrality in the network. Experiments conducted on real world feature models show that the proposed approach can accurately prioritize features in feature models.},
  Doi                      = {10.1007/978-3-319-35122-3_8},
  ISBN                     = {9783319351216},
  ISSN                     = {16113349}
}

@Article{Peng2016a,
  Title                    = {A requirements elicitation approach based on feature model and collaborative filtering},
  Author                   = {Peng, Zhenlian and Wang, Jian and He, Keqing and Tang, Mingdong},
  Year                     = {2016},

  Month                    = {sep},
  Number                   = {9},
  Pages                    = {2055--2066},
  Volume                   = {53},

  Abstract                 = {With the rapid development of Internet and Web service related technologies,developing software system on Internet is increasingly popular. Software development is a multi-knowledge-intensive process in which requirements elicitation plays a key role. Software systems deployed on Internet need to meet the needs of various kinds of customers and users who are geographically distributed,which increases the difficulties of software requirements elicitation. Meanwhile,more and more software systems that share similar functions are deployed on Internet,which provides a new way to elicit software requirements. Toward this end,recommender systems have been leveraged in the requirements elicitation to recommend missing features for software products by comparing the requirements descriptions of existing similar software systems. In order to improve the prediction accuracy of the recommended features of the software system,a requirements elicitation approach based on feature model and KNN (K-nearest neighbors) collaborative filtering recommendation system is proposed in this paper. An algorithm named FM{\_}KNN is presented by utilizing constraint relations between features in KNN collaborative filtering recommendation system. Experiments conducted on a real data set and a simulated data set, by comparing the proposed FM{\_}KNN with two existing methods, i.e., KNN and an approach that combines association rule mining with KNN, show that the proposed approach can achieve higher precision.},
  Doi                      = {10.7544/issn1000-1239.2016.20150426},
  ISSN                     = {10001239},
  Publisher                = {Science Press}
}

@InProceedings{Pereira2016,
  Title                    = {FeatureIDE: Scalable product configuration of variable systems},
  Author                   = {Pereira, Juliana Alves and Krieter, Sebastian and Meinicke, Jens and Schr{\"{o}}ter, Reimar and Saake, Gunter and Leich, Thomas},
  Year                     = {2016},
  Pages                    = {397--401},
  Publisher                = {Springer Verlag},
  Volume                   = {9679},

  Abstract                 = {In the last decades, variability management for similar products is one of the main challenges in software systems. In this context, feature models are used to describe the dependencies between reusable common and variable artifacts, called features. However, for large feature models it is a complex task to find a valid feature combination as product configuration. Our Eclipse plug-in FeatureIDE provides several mechanisms, such as information hiding and decision propagation, which support the configuration process to combine the reusable artifacts in various manners. We illustrate the applications of these mechanisms from a user's point of view.},
  Doi                      = {10.1007/978-3-319-35122-3_27},
  ISBN                     = {9783319351216},
  ISSN                     = {16113349}
}

@InProceedings{Pereira2013,
  Title                    = {Software variability management: An exploratory study with two feature modeling tools},
  Author                   = {Pereira, Juliana Alves and Souza, Carlos and Figueiredo, Eduardo and Abilio, Ramon and Vale, Gustavo and Costa, Heitor Augustus Xavier},
  Year                     = {2013},
  Pages                    = {20--29},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {Software Product Line (SPL) is becoming widely adopted in industry due to its capability of minimizing costs and improving quality of software systems through systematic reuse of software artifacts. An SPL is a set of software systems sharing a common, managed set of features that satisfies the specific needs of a particular market segment. A feature represents an increment in functionality relevant to some stakeholders. There are several tools to support variability management by modeling features in SPL. However, it is hard for a developer to choose the most appropriate feature modeling tool due to the several options available. This paper presents the results of an exploratory study aiming to support SPL engineers choosing the feature modeling tool that best fits their needs. This exploratory study compares and analyzes two feature modeling tools, namely FeatureIDE and SPLOT, based on data from 56 participants that used the analyzed tools. In this study, we performed a four-dimension qualitative analysis with respect to common functionalities provided by feature modeling tools: (i) Feature Model Editor, (ii) Automated Analysis of Feature Models, (iii) Product Configuration, and (iv) Tool Notation. The main issues we observed in SPLOT are related to its interface. FeatureIDE, on the other hand, revealed some constraints when creating feature models. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/SBCARS.2013.13},
  ISBN                     = {9780769551562}
}

@InProceedings{Perrouin2016,
  Title                    = {Featured model types: Towards systematic reuse in modelling language engineering},
  Author                   = {Perrouin, Gilles and Amrani, Moussa and Acher, Mathieu and Combemale, Benoit and Legay, Axel and Schobbens, Pierre Yves},
  Year                     = {2016},
  Month                    = {may},
  Pages                    = {1--7},
  Publisher                = {Association for Computing Machinery, Inc},

  Abstract                 = {By analogy with software product reuse, the ability to reuse (meta)models and model transformations is key to achieve better quality and productivity. To this end, various opportunistic reuse techniques have been developed, such as higher-order transformations, metamodel adaptation, and model types. However, in contrast to software product development that has moved to systematic reuse by adopting (model-driven) software product lines, we are not quite there yet for modelling languages, missing economies of scope and automation opportunities. Our vision is to transpose the product line paradigm at the metamodel level, where reusable assets are formed by metamodel and transformation fragments and "products" are reusable language building blocks (model types). We introduce featured model types to concisely model variability amongst metamodelling elements, enabling configuration, automated analysis, and derivation of tailored model types. We provide a wish list of software engineering activities to work with featured model types.},
  Doi                      = {10.1145/2896982.2896987},
  ISBN                     = {9781450341646}
}

@Article{Perrouin2012,
  Title                    = {Pairwise testing for software product lines: Comparison of two approaches},
  Author                   = {Perrouin, Gilles and Oster, Sebastian and Sen, Sagar and Klein, Jacques and Baudry, Benoit and le Traon, Yves},
  Year                     = {2012},

  Month                    = {sep},
  Number                   = {3-4},
  Pages                    = {605--643},
  Volume                   = {20},

  Abstract                 = {Software Product Lines (SPL) are difficult to validate due to combinatorics induced by variability, which in turn leads to combinatorial explosion of the number of derivable products. Exhaustive testing in such a large products space is hardly feasible. Hence, one possible option is to test SPLs by generating test configurations that cover all possible t feature interactions (t-wise). It dramatically reduces the number of test products while ensuring reasonable SPL coverage. In this paper, we report our experience on applying t-wise techniques for SPL with two independent toolsets developed by the authors. One focuses on generality and splits the generation problem according to strategies. The other emphasizes providing efficient generation. To evaluate the respective merits of the approaches, measures such as the number of generated test configurations and the similarity between them are provided. By applying these measures, we were able to derive useful insights for pairwise and t-wise testing of product lines. {\textcopyright} 2011 Springer Science+Business Media, LLC.},
  Doi                      = {10.1007/s11219-011-9160-9},
  ISSN                     = {09639314}
}

@Article{Perrouin2010,
  Title                    = {Automated and scalable t-wise test case generation strategies for software product lines},
  Author                   = {Perrouin, G and Sen, S and Klein, J and Baudry, B},
  Journal                  = {Softw. testing, {\ldots}},
  Year                     = {2010},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5477055}
}

@Article{Perrouin2012a,
  Title                    = {Weaving variability into domain metamodels},
  Author                   = {Perrouin, Gilles and Vanwormhoudt, Gilles and Morin, Brice and Lahire, Philippe and Barais, Olivier and J{\'{e}}z{\'{e}}quel, Jean Marc},
  Year                     = {2012},

  Month                    = {jul},
  Number                   = {3},
  Pages                    = {361--383},
  Volume                   = {11},

  Abstract                 = {Domain-specific modeling languages (DSMLs) are the essence of MDE. A DSML describes the concepts of a particular domain in a metamodel, as well as their relationships. Using a DSML, it is possible to describe a wide range of different models that often share a common base and vary on some parts. On the one hand, some current approaches tend to distinguish the variability language from the DSMLs themselves, implying greater learning curve for DSMLs stakeholders and a significant overhead in product line engineering. On the other hand, approaches integrating variability in DSMLs lack generality and tool support. We argue that aspect-oriented modeling techniques enabling flexible metamodel composition and results obtained by the software product line community to manage and resolve variability form the pillars for a solution for integrating variability into DSMLs. In this article, we consider variability as an independent and generic aspect to be woven into the DSML. In particular, we detail how variability is woven and how to perform product line derivation. We validate our approach through the weaving of variability into two different metamodels: Ecore-widely used for DSML definition-and SmartAdapters, our aspect model weaver. These results emphasize how new abilities of the language can be provided by this means. {\textcopyright} 2010 Springer-Verlag.},
  Doi                      = {10.1007/s10270-010-0186-4},
  ISSN                     = {16191366}
}

@Article{Pleuss2012,
  Title                    = {Visualization of variability and configuration options},
  Author                   = {Pleuss, Andreas and Botterweck, Goetz},
  Year                     = {2012},
  Number                   = {5},
  Pages                    = {497--510},
  Volume                   = {14},

  Abstract                 = {When designing, constructing, and maintaining diverse and variable software systems, a key challenge is the complexity of systems. A potential approach to tackle this challenge are techniques from variability management and product line engineering to handle the diversity and variability. A key asset in variability management is a variability model, which explicitly specifies the commonalities and variability of a system and the constraints between variants. However, handling variability and configurations remains a challenge due to the complexity on a cognitive level as human engineers reach their limits in identifying, understanding, and using all relevant details. In this paper we address this issue by providing concepts for interactive visual tool support for the configuration of systems with the help of feature models. We discuss relevant principles from the area of information visualization and their application to the domain of feature model configuration. We discuss techniques for interactive configuration support based on a reasoning engine, which, e.g., ensures the validity of configurations. We illustrate our findings by a concrete tool solution called S2T2 Configurator. {\textcopyright} 2012 Springer-Verlag.},
  Doi                      = {10.1007/s10009-012-0252-z},
  ISSN                     = {14332779}
}

@Article{Pleuss2010,
  Title                    = {Integrating automated product derivation and individual user interface design},
  Author                   = {Pleuss, A and Botterweck, G and Dhungana, D},
  Year                     = {2010},

  Url                      = {https://ulir.ul.ie/handle/10344/3212}
}

@Article{Pleuss2012a,
  Title                    = {Model-driven support for product line evolution on feature level},
  Author                   = {Pleuss, Andreas and Botterweck, Goetz and Dhungana, Deepak and Polzer, Andreas and Kowalewski, Stefan},
  Year                     = {2012},

  Month                    = {oct},
  Number                   = {10},
  Pages                    = {2261--2274},
  Volume                   = {85},

  Abstract                 = {Software Product Lines (SPL) are an engineering technique to efficiently derive a set of similar products from a set of shared assets. In particular in conjunction with model-driven engineering, SPL engineering promises high productivity benefits. There is however, a lack of support for systematic management of SPL evolution, which is an important success factor as a product line often represents a long term investment. In this article, we present a model-driven approach for managing SPL evolution on feature level. To reduce complexity we use model fragments to cluster related elements. The relationships between these fragments are specified using feature model concepts itself leading to a specific kind of feature model called EvoFM. A configuration of EvoFM represents an evolution step and can be transformed to a concrete instance of the product line (i.e., a feature model for the corresponding point in time). Similarly, automatic transformations allow the derivation of an EvoFM from a given set of feature models. This enables retrospective analysis of historic evolution and serves as a starting point for introduction of EvoFM, e.g., to plan future evolution steps. {\textcopyright} 2011 Elsevier Inc. All rights reserved.},
  Doi                      = {10.1016/j.jss.2011.08.008},
  ISSN                     = {01641212}
}

@InProceedings{Pleuss2012b,
  Title                    = {User interface engineering for software product lines - The dilemma between automation and usability},
  Author                   = {Pleuss, Andreas and Hauptmann, Benedikt and Dhungana, Deepak and Botterweck, Goetz},
  Year                     = {2012},
  Pages                    = {25--34},

  Abstract                 = {Software Product Lines (SPL) are systematic approach to develop families of similar software products by explicating their commonalities and variability, e.g., in a feature model. Using techniques from model-driven development, it is then possible to automatically derive a concrete product from a given configuration (i.e., selection of features). However, this is problematic for interactive applications with complex user interfaces (UIs) as automatically derived UIs often provide limited usability. Thus, in practice, the UI is mostly created manually for each product, which results in major drawbacks concerning efficiency and maintenance, e.g., when applying changes that affect the whole product family. This paper investigates these problems based on real-world examples and analyses the development of product families from a UI perspective. To address the underlying challenges, we propose the use of abstract UI models, as used in HCI, to bridge the gap between automated, traceable product derivation and customized, high quality user interfaces. We demonstrate the feasibility of the approach by a concrete example implementation for the suggested model-driven development process. Copyright 2012 ACM.},
  Doi                      = {10.1145/2305484.2305491},
  ISBN                     = {9781450311687}
}

@Article{Pleuss2011,
  Title                    = {Visualization techniques for application in interactive product configuration},
  Author                   = {Pleuss, A and Rabiser, R and Botterweck, G},
  Journal                  = {Proc. 15th},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=2019161}
}

@InProceedings{Pohl2011,
  Title                    = {A performance comparison of contemporary algorithmic approaches for automated analysis operations on feature models},
  Author                   = {Pohl, Richard and Lauenroth, Kim and Pohl, Klaus},
  Year                     = {2011},
  Pages                    = {313--322},

  Abstract                 = {The formalization of variability models (e.g. feature models) is a prerequisite for the automated analysis of these models. The efficient execution of the analysis operations depends on the selection of well-suited solver implementations. Regarding feature models, on the one hand, the formalization with Boolean expressions enables the use of SAT or BDD solvers. On the other hand, feature models can be transformed into a Constraint-Satisfaction Problem (CSP) in order to use CSP solvers for validation. This paper presents a performance comparison regarding nine contemporary high-performance solvers, three for each base problem structure (BDD, CSP, and SAT). Four operations on 90 feature models are run on each solver. The results will in turn clear the way for new improvements regarding the automatic verification of software product lines, since the efficient execution of analysis operations is essential to such automatic verification approaches. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/ASE.2011.6100068},
  ISBN                     = {9781457716393}
}

@InProceedings{Pohl2013,
  Title                    = {Measuring the structural complexity of feature models},
  Author                   = {Pohl, Richard and Stricker, Vanessa and Pohl, Klaus},
  Year                     = {2013},
  Pages                    = {454--464},

  Abstract                 = {The automated analysis of feature models (FM) is based on SAT, BDD, and CSP - known NP-complete problems. Therefore, the analysis could have an exponential worst-case execution time. However, for many practical relevant analysis cases, state-of-the-art (SOTA) analysis tools quite successfully master the problem of exponential worst-case execution time based on heuristics. So far, however, very little is known about the structure of FMs that cause the cases in which the execution time (hardness) for analyzing a given FM increases unpredictably for SOTA analysis tools. In this paper, we propose to use width measures from graph theory to characterize the structural complexity of FMs as a basis for an estimation of the hardness of analysis operations on FMs with SOTA analysis tools. We present an experiment that we use to analyze the reasonability of graph width measures as metric for the structural complexity of FMs and the hardness of FM analysis. Such a complexity metric can be used as a basis for a unified method to systematically improve SOTA analysis tools. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/ASE.2013.6693103},
  ISBN                     = {9781479902156}
}

@InProceedings{Quinton2014a,
  Title                    = {Consistency checking for the evolution of cardinality-based feature models},
  Author                   = {Quinton, Cl{\'{e}}ment and Pleuss, Andreas and {Le Berre}, Daniel and Duchien, Laurence and Botterweck, Goetz},
  Year                     = {2014},
  Month                    = {sep},
  Pages                    = {122--131},
  Publisher                = {Association for Computing Machinery},
  Volume                   = {1},

  Abstract                 = {Feature-models (fms) are a widely used approach to specify the commonalities and variability in variable systems and software product lines. Various works have addressed edits to fms for fm evolution and tool support to ensure consistency of fms. An important extension to fms are feature cardinalities and related constraints, as extensively used e.g., when modeling variability of cloud computing environments. Since cardinality-based fms pose additional complexity, additional support for evolution and consistency checking with respect to feature cardinalities would be desirable, but has not been addressed yet. In this paper, we discuss common cardinality-based fm edits and resulting inconsistencies based on experiences with fms in cloud domain. We introduce tool-support for automated inconsistency detection and explanation based on an off-the-shelf solver. We demonstrate the feasibility of the approach by an empirical evaluation showing the performance of the tool. Copyright 2014 ACM.},
  Doi                      = {10.1145/2648511.2648524},
  ISBN                     = {9781450327404}
}

@Article{Quinton2014,
  Title                    = {Automated selection and configuration of cloud environments using software product lines principles},
  Author                   = {Quinton, C and Romero, D and Duchien, L},
  Journal                  = {2014 IEEE 7th Int.},
  Year                     = {2014},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6973735}
}

@InProceedings{Quinton2013,
  Title                    = {Cardinality-based feature models with constraints: A pragmatic approach},
  Author                   = {Quinton, Cl{\'{e}}ment and Romero, Daniel and Duchien, Laurence},
  Year                     = {2013},
  Pages                    = {162--166},

  Abstract                 = {Feature models originating from Software Product Line Engineering are a well-known approach to variability modeling. In many situations, the variability does not apply only on features but also on the number of times these features can be cloned. In such a case, cardinality-based feature models are used to specify the number of clones for a given feature. Although previous works already investigated approaches for feature modeling with cardinality, there is still a lack of support for constraints in the presence of clones. To overcome this limitation, we present an abstract model to define constraints in cardinality-based feature models and propose a formal semantics for this kind of constraints. We illustrate the practical usage of our approach with examples from our recent experiences on cloud computing platform configuration. {\textcopyright} 2013 ACM.},
  Doi                      = {10.1145/2491627.2491638},
  ISBN                     = {9781450319683}
}

@Article{RaFat2013,
  Title                    = {Feature location in a collection of software product variants using formal concept analysis},
  Author                   = {Ra'Fat, AL and Seriai, A and Huchard, M and Urtado, C},
  Journal                  = {Conf. Softw. {\ldots}},
  Year                     = {2013},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-38977-1{\_}22}
}

@InCollection{Rabiser2014,
  Title                    = {Configuring and Generating Technical Documents},
  Author                   = {Rabiser, Rick and Vierhauser, Michael and Lehofer, Martin and Gr{\"{u}}nbacher, Paul and M{\"{a}}nnist{\"{o}}, Tomi},
  Publisher                = {Elsevier Inc.},
  Year                     = {2014},
  Month                    = {apr},
  Pages                    = {241--250},

  Abstract                 = {In industrial software development salespeople, product managers, or technical writers frequently create documents such as offers, contracts, user manuals, or technical documentation. For products that are configured specifically for different customers, the documentation also needs to be adapted to match the product. Such adaptation of documents is tedious and error-prone and can easily lead to inconsistencies. Stakeholders thus need configuration support for adapting documents. We describe a flexible approach for automatically generating product-specific documents based on product line variability models. We report on an industrial case example of applying the approach to support configuring and generating product-specific documents in an automation software product line. {\textcopyright} 2014 Elsevier Inc. All rights reserved.},
  Doi                      = {10.1016/B978-0-12-415817-7.00020-7},
  ISBN                     = {9780124158177}
}

@Article{Rauber2015,
  Title                    = {Heterogeneous feature models and feature selection applied to bearing fault diagnosis},
  Author                   = {Rauber, TW and Boldt, F de Assis},
  Journal                  = {IEEE Trans.},
  Year                     = {2015},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6823731}
}

@InProceedings{Razzaq2012,
  Title                    = {Automated separation of crosscutting concerns: Earlier automated identification and modularization of cross-cutting features at analysis phase},
  Author                   = {Razzaq, Abdul and Abbasi, Rabeeh},
  Year                     = {2012},
  Pages                    = {471--478},

  Abstract                 = {Early aspect mining captures the concerns that can propagate to other artifacts in later stage. However, current approaches and tools required a self made input by following specific grammatical patterns to expose to the approach what the concern is. Moreover, requirements are mostly communicated between the stakeholders in form of features. However, the early aspect mining from the feature introduced the labor intensive task of creating feature model that is unable to support cross-cutting relations. There seems to be a tradeoff between the requirement abstraction and automaticity for aspect discovery at early analysis phase. In this paper, we present an enhanced form of aspect-oriented feature analysis (AOFA), which discovers meaningful concerns and feature interactions, then associates them to feature modules without disbursing automaticity. It takes publically available unstructured features as input then creates a knowledge base of domain by natural language processing and finally models each feature's dependencies by utilizing this domain knowledge and variability patterns. We evaluate our approach against early aspect miner tool and statistical method and found our approach to be optimal. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/INMIC.2012.6511500},
  ISBN                     = {9781467322508}
}

@InProceedings{Regnell2011,
  Title                    = {Exploring Software Product Management decision problems with constraint solving - Opportunities for prioritization and release planning},
  Author                   = {Regnell, Bj{\"{o}}rn and Kuchcinski, Krzysztof},
  Year                     = {2011},
  Pages                    = {47--56},

  Abstract                 = {Decision-making is central to Software Product Management (SPM) and includes deciding on requirements priorities and the content of coming releases. Several algorithms for prioritization and release planning have been proposed, where humans with or without machine support enact a series of steps to produce a decision outcome. Instead of applying some specific algorithm to find an acceptable solution to a decision problem, we propose to model SPM decision-making as a Constraint Satisfaction Problem (CSP), where relative and absolute priorities, interdependencies, and other constraints are expressed as relations among variables representing entities such as feature priorities, stakeholder preferences, and resource constraints. The solution space is then explored with the help of a constraint solver without humans needing to care about specific algorithms. This paper discusses advantages and limitations of CSP modeling in SPM and gives principal examples as a proof-of-concept of CSP modeling in requirements prioritization and release planning. A discussion of further research on constraint solving in SPM is also given. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/IWSPM.2011.6046203},
  ISBN                     = {9781457711473}
}

@Article{Rhein2013,
  Title                    = {The PLA model: on the combination of product-line analyses},
  Author                   = {Rhein, A Von and Apel, S and K{\"{a}}stner, C and Th{\"{u}}m, T},
  Journal                  = {Proc.},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2430522}
}

@InProceedings{Ribeiro:2010:EFM:1869542.1869545,
  Title                    = {Emergent Feature Modularization},
  Author                   = {Ribeiro, M\'{a}rcio and Pacheco, Humberto and Teixeira, Leopoldo and Borba, Paulo},
  Booktitle                = {Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion},
  Year                     = {2010},

  Address                  = {New York, NY, USA},
  Pages                    = {11--18},
  Publisher                = {ACM},
  Series                   = {OOPSLA '10},

  Abstract                 = {Virtual Separation of Concerns reduces the drawbacks of implementing product line variability with preprocessors. Developers can focus on certain features and hide others of no interest. However, these features eventually share elements between them, which might break feature modularization, since modifications in a feature result in problems for another. We present the concept of emergent feature modularization, which aims to establish contracts between features, to prevent developers from breaking other features when performing a maintenance task. These interfaces are product-line-aware, in the sense that it only considers valid feature combinations. We also present a prototype tool that implements the concept.},
  Acmid                    = {1869545},
  Doi                      = {10.1145/1869542.1869545},
  ISBN                     = {978-1-4503-0240-1},
  Keywords                 = {modularity, preprocessors, product lines},
  Location                 = {Reno/Tahoe, Nevada, USA},
  Numpages                 = {8},
  Url                      = {http://doi.acm.org/10.1145/1869542.1869545}
}

@InProceedings{Ribeiro2012,
  Title                    = {Emergo: A tool for improving maintainability of preprocessor-based product lines},
  Author                   = {Ribeiro, M{\'{a}}rcio and Tol{\^{e}}do, T{\'{a}}rsis and Winther, Johnni and Brabrand, Claus and Borba, Paulo},
  Year                     = {2012},
  Pages                    = {23--26},

  Abstract                 = {When maintaining a feature in preprocessor-based Software Product Lines (SPLs), developers are susceptible to introduce problems into other features. This is possible because features eventually share elements (like variables and methods) with the maintained one. This scenario might be even worse when hiding features by using techniques like Virtual Separation of Concerns (VSoC), since developers cannot see the feature dependencies and, consequently, they become unaware of them. Emergent Interfaces was proposed to minimize this problem by capturing feature dependencies and then providing information about other features that can be impacted during a maintenance task. In this paper, we present Emergo, a tool capable of computing emergent interfaces between the feature we are maintaining and the others. Emergo relies on feature-sensitive dataflow analyses in the sense it takes features and the SPL feature model into consideration when computing the interfaces. {\textcopyright} 2012 ACM.},
  Doi                      = {10.1145/2162110.2162128},
  ISBN                     = {9781450312226}
}

@Article{Ries2016,
  Title                    = {Towards automatic bounding box annotations from weakly labeled images},
  Author                   = {Ries, Christian X. and Richter, Fabian and Lienhart, Rainer},
  Year                     = {2016},

  Month                    = {jun},
  Number                   = {11},
  Pages                    = {6091--6118},
  Volume                   = {75},

  Abstract                 = {In this work we discuss the problem of automatically determining bounding box annotations for objects in images whereas we only assume weak labeling in the form of global image labels. We therefore are only given a set of positive images all containing at least one instance of a desired object and a negative set of images which represent background. Our goal is then to determine the locations of the object instances within the positive images by bounding boxes. We also describe and analyze a method for automatic bounding box annotation which consists of two major steps. First, we apply a statistical model for determining visual features which are likely to be indicative for the respective object class. Based on these feature models we infer preliminary estimations for bounding boxes. Second, we use a CCCP training algorithm for latent structured SVM in order to improve the initial estimations by using them as initializations for latent variables modeling the optimal bounding box positions. We evaluate our approach on three publicly available datasets.},
  Doi                      = {10.1007/s11042-014-2434-z},
  ISSN                     = {15737721},
  Publisher                = {Springer New York LLC}
}

@Article{Rincon2014,
  Title                    = {An ontological rule-based approach for analyzing dead and false optional features in feature models},
  Author                   = {Rinc{\'{o}}n, L. F. and Giraldo, G. L. and Mazo, R. and Salinesi, C.},
  Year                     = {2014},

  Month                    = {feb},
  Pages                    = {111--132},
  Volume                   = {302},

  Abstract                 = {Feature models are a common way to represent variability requirements of software product lines by expressing the set of feature combinations that software products can have. Assuring quality of feature models is thus of paramount importance for assuring quality in software product line engineering. However, feature models can have several types of defects that disminish benefits of software product line engineering.Two of such defects are dead features and false optional features. Several state-of-the-art techniques identify these defects, but only few of them tackle the problem of identifying their causes. Besides, the explanations they provide are cumbersome and hard to understand by humans. In this paper, we propose an ontological rule-based approach to: (a) identify dead and false optional features; (b)identify certain causes of these defects; and (c) explain these causes in natural language helping modelers to correct found defects. We represent our approach with a feature model taken from literature. A preliminary empirical evaluation of our approach over 31 FMs shows that our proposal is effective, accurate and scalable to 150 features. {\textcopyright} 2014 Elsevier B.V.},
  Doi                      = {10.1016/j.entcs.2014.01.023},
  ISSN                     = {15710661}
}

@Article{Ripon2012,
  Title                    = {Modeling and analysis of product-line variants},
  Author                   = {Ripon, S and Azad, K and Hossain, SJ and Hassan, M},
  Journal                  = {Proc. 16th},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2364417}
}

@Article{Ripon2016,
  Title                    = {Verification of SPL feature model by using Bayesian Network},
  Author                   = {Ripon, Shamim and Rahman, Musfiqur and Ferdous, Javedul and Hossain, Md Delwar},
  Year                     = {2016},
  Number                   = {31},
  Volume                   = {9},

  Abstract                 = {Feature Tree represents all the features along with their relationship of a Software Product Line. Any defect in feature model can diminish the benefits of product line approach. Hence, the analysis of feature model plays a key role towards the success of any Software Product Line. This paper presents various analysis rules for cardinality-based feature model of both dead and false optional features. These rules are then verified by using Bayesian Network Based inference mechanism. Such verification not only confirms the analysis rules of the feature trees but also ensures the applicability of probabilistic information into the feature trees.},
  Doi                      = {10.17485/ijst/2016/v9i31/93731},
  ISSN                     = {09745645},
  Publisher                = {Indian Society for Education and Environment}
}

@InCollection{Rock2015,
  Title                    = {Variability management},
  Author                   = {Rock, Georg and Theis, Karsten and Wischnewski, Patrick},
  Publisher                = {Springer International Publishing},
  Year                     = {2015},
  Month                    = {jan},
  Pages                    = {491--519},

  Abstract                 = {The global market, different and changing environmental laws, the customer wish for individualization, time-to-market, product costs, and the pressure on manufacturers to discover new product niches, to name only a few variability drivers, result in an ever increasing number of product variants in nearly all engineering disciplines as, for example, in car manufacturing. Mastering the related increasing product complexity throughout the whole product lifecycle is and remains one of the key advantages in competition for the future. Currently for a manufacturer, as for any other discipline, it is no option not to invest in an efficient and effective variability handling machinery able to cope with the arising challenges. Not only the task to invent, develop, introduce and manage new variants is important but also to decide which variant to develop, which to remove and which to not develop at all. The consequences of such decisions with respect to productline variability have to be computed based on formalized bases such that an optimized product variability can assure on the one hand customer satisfaction and on the other hand cost reduction within the variability-related engineering processes. This chapter presents current research in the field of product variability configuration, analysis and visualisation. It presents solution sketches based on formal logic that were illustrated by some real world examples.},
  Doi                      = {10.1007/978-3-319-13776-6_17},
  ISBN                     = {9783319137766}
}

@Article{Romero2013,
  Title                    = {Splemma: a generic framework for controlled-evolution of software product lines},
  Author                   = {Romero, D and Urli, S and Quinton, C and Blay-Fornarino, M},
  Journal                  = {Proc. 17th},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2500709}
}

@Article{Roos-Frantz2012,
  Title                    = {Quality-aware analysis in product line engineering with the orthogonal variability model},
  Author                   = {Roos-Frantz, Fabricia and Benavides, David and Ruiz-Cort{\'{e}}s, Antonio and Heuer, A. and Lauenroth, Kim},
  Year                     = {2012},

  Month                    = {sep},
  Number                   = {3-4},
  Pages                    = {519--565},
  Volume                   = {20},

  Abstract                 = {Software product line engineering is about producing a set of similar products in a certain domain. A variability model documents the variability amongst products in a product line. The specification of variability can be extended with quality information, such as measurable quality attributes (e. g., CPU and memory consumption) and constraints on these attributes (e. g., memory consumption should be in a range of values). However, the wrong use of constraints may cause anomalies in the specification which must be detected (e. g., the model could represent no products). Furthermore, based on such quality information, it is possible to carry out quality-aware analyses, i. e., the product line engineer may want to verify whether it is possible to build a product that satisfies a desired quality. The challenge for quality-aware specification and analysis is threefold. First, there should be a way to specify quality information in variability models. Second, it should be possible to detect anomalies in the variability specification associated with quality information. Third, there should be mechanisms to verify the variability model to extract useful information, such as the possibility to build a product that fulfils certain quality conditions (e. g., is there any product that requires less than 512 MB of memory?). In this article, we present an approach for quality-aware analysis in software product lines using the orthogonal variability model (OVM) to represent variability. We propose to map variability represented in the OVM associated with quality information to a constraint satisfaction problem and to use an off-the-shelf constraint programming solver to automatically perform the verification task. To illustrate our approach, we use a product line in the automotive domain which is an example that was created in a national project by a leading car company. We have developed a prototype tool named FaMa-OVM, which works as a proof of concepts. We were able to identify void models, dead and false optional elements, and check whether the product line example satisfies quality conditions. {\textcopyright} 2011 Springer Science+Business Media, LLC.},
  Doi                      = {10.1007/s11219-011-9156-5},
  ISSN                     = {09639314}
}

@InProceedings{Rose2012,
  Title                    = {A feature model for model-to-text transformation languages},
  Author                   = {Rose, Louis M. and Matragkas, Nicholas and Kolovos, Dimitrios S. and Paige, Richard F.},
  Booktitle                = {2012 ICSE Workshop on Modeling in Software Engineering (MISE)},
  Year                     = {2012},
  Pages                    = {57--63},

  Abstract                 = {Model-to-text (M2T) transformation is an important model management operation, as it is used to implement code and documentation generation; model serialisation (enabling model interchange); and model visualisation and exploration. Despite the creation of the MOF Model-To-Text Transformation Language (MOFM2T) in 2008, many very different M2T languages exist today. Because there is little interoperability between M2T languages and rewriting an existing M2T transformation in a new language is costly, developers face a difficult choice when selecting a M2T language. In this paper, we use domain analysis to identify a preliminary feature model for M2T languages. We demonstrate the appropriateness of the feature model by describing two different M2T languages, and discuss potential applications for a tool-supported and model-driven approach to describing the features of M2T languages. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/MISE.2012.6226015},
  ISBN                     = {9781467317573}
}

@InProceedings{Rosenmuller2011,
  Title                    = {Multi-dimensional variability modeling},
  Author                   = {Rosenm{\"{u}}ller, Marko and Siegmund, Norbert and Th{\"{u}}m, Thomas and Saake, Gunter},
  Year                     = {2011},
  Pages                    = {11--20},

  Abstract                 = {The variability of a software product line (SPL) is often described with a feature model. To avoid highly complex models, stakeholders usually try to separate different variability dimensions, such as domain variability and implementation variability. This results in distinct variability models, which are easier to handle than one large model. On the other hand, it is sometimes required to analyze the variability dimensions of an SPL in combination using a single model only. To combine separate modeling and integrated analysis of variability, we present Velvet, a language for multi-dimensional variability modeling. Velvet allows stakeholders to model each variability dimension of an SPL separately and to compose the separated dimensions on demand. This improves reuse of feature models and supports independent modeling variability dimensions. Furthermore, Velvet integrates feature modeling and configuration in a single language. The combination of both concepts creates further reuse opportunities and allows stakeholders to independently configure variability dimensions. Copyright 2011 ACM.},
  Doi                      = {10.1145/1944892.1944894},
  ISBN                     = {9781450305709}
}

@InProceedings{Ryssel2012,
  Title                    = {Reasoning of feature models from derived features},
  Author                   = {Ryssel, Uwe and Ploennigs, Joern and Kabitzsch, Klaus},
  Year                     = {2012},
  Pages                    = {21--30},

  Abstract                 = {When using product lines, whose variability models are based on derived features, e.g., Simulink variant objects, the dependencies among the features are only described implicitly. This makes it difficult to verify the mapping of the features to the solution space and to create a comprehensive overview of the feature dependencies like in a feature model. In this paper, an OWL-based approach is presented, which permits the automatic verification of the feature mapping and an automatic feature model synthesis for derived features using OWL reasoning and formal concept analysis. Copyright 2012 ACM.},
  Doi                      = {10.1145/2371401.2371405},
  ISBN                     = {9781450311298}
}

@Article{Ryssel2011,
  Title                    = {Extraction of feature models from formal contexts},
  Author                   = {Ryssel, U and Ploennigs, J and Kabitzsch, K},
  Journal                  = {Proc. 15th},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=2019141}
}

@Article{Sanchez2014a,
  Title                    = {The drupal framework: A case study to evaluate variability testing techniques},
  Author                   = {S{\'{a}}nchez, AB and Segura, S and Ruiz-Cort{\'{e}}s, A},
  Journal                  = {Proc. Eighth},
  Year                     = {2014},

  Url                      = {http://dl.acm.org/citation.cfm?id=2556638}
}

@Misc{Sanchez2015,
  Title                    = {Variability testing in the wild: the Drupal case study},

  Author                   = {S{\'{a}}nchez, Ana B. and Segura, Sergio and Parejo, Jos{\'{e}} A. and Ruiz-Cort{\'{e}}s, Antonio},
  Month                    = {apr},
  Year                     = {2015},

  Abstract                 = {Variability testing techniques search for effective and manageable test suites that lead to the rapid detection of faults in systems with high variability. Evaluating the effectiveness of these techniques in realistic settings is a must, but challenging due to the lack of variability-intensive systems with available code, automated tests and fault reports. In this article, we propose using the Drupal framework as a case study to evaluate variability testing techniques. First, we represent the framework variability using a feature model. Then, we report on extensive non-functional data extracted from the Drupal Git repository and the Drupal issue tracking system. Among other results, we identified 3392 faults in single features and 160 faults triggered by the interaction of up to four features in Drupal v7.23. We also found positive correlations relating the number of bugs in Drupal features to their size, cyclomatic complexity, number of changes and fault history. To show the feasibility of our work, we evaluated the effectiveness of non-functional data for test case prioritization in Drupal. Results show that non-functional attributes are effective at accelerating the detection of faults, outperforming related prioritization criteria as test case similarity.},
  Doi                      = {10.1007/s10270-015-0459-z},
  ISSN                     = {16191374},
  Publisher                = {Springer Verlag}
}

@InProceedings{Sabouri2012,
  Title                    = {Scheduling and analysis of real-time software families},
  Author                   = {Sabouri, Hamideh and Jaghoori, Mohammad Mahdi and {De Boer}, Frank and Khosravi, Ramtin},
  Year                     = {2012},
  Pages                    = {680--689},

  Abstract                 = {A software product line describes explicitly the commonalities of and differences between different products in a family of (software) systems. A formalization of these commonalities and differences amounts to reduced development, analysis and maintenance costs in the practice of software engineering. An important feature common to next-generation real-time software systems is the need of application-level control over scheduling for optimized utilization of resources provided by for example many-core and cloud infrastructures. In this paper, we introduce a formal model of real-time software product lines which supports variability in scheduling policies and rigorous and efficient techniques for modular schedulability analysis. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/COMPSAC.2012.95},
  ISBN                     = {9780769547367},
  ISSN                     = {07303157}
}

@Article{Sabouri2014,
  Title                    = {Reducing the verification cost of evolving product families using static analysis techniques},
  Author                   = {Sabouri, Hamideh and Khosravi, Ramtin},
  Year                     = {2014},

  Month                    = {apr},
  Pages                    = {35--55},
  Volume                   = {83},

  Abstract                 = {Software product line engineering enables proactive reuse among a set of related products through explicit modeling of commonalities and differences among them. Software product lines are intended to be used in a long period of time. As a result, they evolve over time, due to the changes in the requirements. Having several individual products in a software family, verification of the entire family may take a considerable effort. In this paper we aim to decrease this cost by reducing the number of verified products using static analysis techniques. Furthermore, to reduce model checking costs after product line evolution, we restrict the number of products that should be re-verified by reusing the previous verification result. All proposed techniques are based on static analysis of the product family model with respect to the property and can be automated. To show the effectiveness of these techniques we apply them on a set of case studies and present the results. {\textcopyright} 2013 Elsevier B.V.},
  Doi                      = {10.1016/j.scico.2013.06.009},
  ISSN                     = {01676423}
}

@Article{Sabouri2013,
  Title                    = {Modeling and verification of reconfigurable actor families},
  Author                   = {Sabouri, Hamideh and Khosravi, Ramtin},
  Year                     = {2013},
  Number                   = {2},
  Pages                    = {207--232},
  Volume                   = {19},

  Abstract                 = {Software product line engineering enables proactive reuse among a set of related products through explicit modeling of commonalities and differences among them. Features are usually used to distinguish different products as a product is identified by its supported feature set that is represented by a configuration. Dynamic product lines enhance flexibility of a product by allowing run-time reconfiguration. In this paper, we focus on modeling and verification of families of concurrent and distributed systems that are reconfigurable. To this end, we introduce the notion of variability in actor models to achieve family of reconfigurable actors. Then, we present our methodology to model this concept using the actor-based modeling language Rebeca. The model checking backbone of Rebeca enables us to ensure establishment of certain constraints on reconfigurations. We show the applicability and effectiveness of our approach by applying it on a set of case studies. {\textcopyright} J.UCS.},
  ISSN                     = {0948695X}
}

@Article{Saeed2016,
  Title                    = {Empirical validating the cognitive effectiveness of a new feature diagrams visual syntax},
  Author                   = {Saeed, Mazin and Saleh, Faisal and Al-Insaif, Sadiq and El-Attar, Mohamed},
  Year                     = {2016},

  Month                    = {mar},
  Pages                    = {1--26},
  Volume                   = {71},

  Abstract                 = {Context Feature models are commonly used to capture and communicate the commonality and variability of features in a Software Product Line. The core component of Feature models is feature diagrams, which graphically depict features in a hierarchical form. In previous work we have proposed a new notation that aims to improve the cognitive effectiveness of feature diagrams. Objective The objective of this paper is to empirically validate the cognitive effectiveness of the new feature diagrams notation in comparison to its original form. Methods We use two distinct empirical user-studies to validate the new notation. The first empirical study uses the survey approach while the second study is a subject-based experiment. The survey study investigates the semantic transparency of the new notation while the second study investigates the speed and accuracy of reading the notation. Results The results of the studies indicate that the proposed changes have significantly improved its cognitive effectiveness. Conclusions The cognitive effectiveness of feature diagrams has been improved, however there remains further research for full acceptance of the new notation by its potential user community.},
  Doi                      = {10.1016/j.infsof.2015.10.012},
  ISSN                     = {09505849},
  Publisher                = {Elsevier}
}

@Article{Safilian2016,
  Title                    = {Multiset Theories of Cardinality-based Feature Diagrams},
  Author                   = {Safilian, A and Maibaum, T},
  Journal                  = {arXiv Prepr. arXiv1601.06242},
  Year                     = {2016},

  Url                      = {http://arxiv.org/abs/1601.06242}
}

@InProceedings{Safilian2016a,
  Title                    = {Hierarchical Multiset Theories of Cardinality-Based Feature Diagrams},
  Author                   = {Safilian, Aliakbar and Maibaum, Tom},
  Year                     = {2016},
  Month                    = {aug},
  Pages                    = {136--143},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {Feature modeling is the most common approach to specify software product lines. The main part of a feature model is a special tree of features called a feature diagram. Cardinality-based feature diagrams provide the most expressive tool among the current feature diagram languages. The most common characterization of the semantics of a cardinality-based diagram is the set of flat multisets over features satisfying the constraints. However, this semantics provides a poor abstract view of the diagram. We address this problem by proposing another multiset theory for the diagram, called the hierarchical theory. We show that the theory captures all information of the diagram so that one can retrieve the diagram from its theory. This provides us with a theoretical framework for addressing some challenging issues in feature modeling, e.g., feature model management and reverse engineering of feature models.},
  Doi                      = {10.1109/TASE.2016.14},
  ISBN                     = {9781509017638}
}

@Article{Salay2013,
  Title                    = {Change propagation due to uncertainty change},
  Author                   = {Salay, R and Gorzny, J and Chechik, M},
  Journal                  = {Int. Conf. Fundam.},
  Year                     = {2013},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-37057-1{\_}3}
}

@Book{Salinesi2012,
  Title                    = {Defects in Product Line Models and how to Identify them},
  Author                   = {Salinesi, C and Mazo, R},
  Year                     = {2012},

  Url                      = {https://hal.archives-ouvertes.fr/hal-00707461/}
}

@Article{Salinesi2011,
  Title                    = {Constraints: The core of product line engineering},
  Author                   = {Salinesi, C and Mazo, R and Djebbi, O and Diaz, D},
  Journal                  = {(RCIS), 2011 Fifth {\ldots}},
  Year                     = {2011},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6006825}
}

@InProceedings{Sanchez2014,
  Title                    = {A Comparison of test case prioritization criteria for software product lines},
  Author                   = {Sanchez, Ana B. and Segura, Sergio and Ruiz-Cortes, Antonio},
  Booktitle                = {IEEE Seventh International Conference on Verification and Validation (ICST)},
  Year                     = {2014},
  Pages                    = {41--50},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {Software Product Line (SPL) testing is challenging due to the potentially huge number of derivable products. To alleviate this problem, numerous contributions have been proposed to reduce the number of products to be tested while still having a good coverage. However, not much attention has been paid to the order in which the products are tested. Test case prioritization techniques reorder test cases to meet a certain performance goal. For instance, testers may wish to order their test cases in order to detect faults as soon as possible, which would translate in faster feedback and earlier fault correction. In this paper, we explore the applicability of test case prioritization techniques to SPL testing. We propose five different prioritization criteria based on common metrics of feature models and we compare their effectiveness in increasing the rate of early fault detection, i.e. a measure of how quickly faults are detected. The results show that different orderings of the same SPL suite may lead to significant differences in the rate of early fault detection. They also show that our approach may contribute to accelerate the detection of faults of SPL test suites based on combinatorial testing. {\textcopyright} 2014 IEEE.},
  Doi                      = {10.1109/ICST.2014.15},
  ISBN                     = {9780769551852}
}

@InProceedings{Sanchez2013,
  Title                    = {Metrics on feature models to optimize configuration adaptation at run time},
  Author                   = {Sanchez, Luis Emiliano and Moisan, Sabine and Rigault, Jean Paul},
  Year                     = {2013},
  Pages                    = {39--44},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {Feature models are widely used to capture variability, commonalities and configuration rules of software systems. We apply this technique to model component-based systems with many variants during specification, implementation, or run time. This representation allows us to determine the set of valid configurations befitting a given context, especially at run time. A key challenge is to determine the configuration most suitable, especially with respect to non-functional aspects: quality of service, performance, reconfiguration time. We propose an algorithm for selecting the configuration that optimizes a given quality metrics. This algorithm is a variant of the Best-First Search algorithm, a heuristic technique suitable for feature model optimization. The algorithm is parameterized with several strategies and heuristics on feature models leading to different optimality and efficiency properties. We discuss the algorithm, its strategies and heuristics, and we present experimental results showing that the algorithm meets the requirements for our real time systems. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/CMSBSE.2013.6604435},
  ISBN                     = {9781467362849}
}

@InProceedings{Sannier2013,
  Title                    = {From comparison matrix to Variability Model: The Wikipedia case study},
  Author                   = {Sannier, Nicolas and Acher, Mathieu and Baudry, Benoit},
  Year                     = {2013},
  Pages                    = {580--585},

  Abstract                 = {Product comparison matrices (PCMs) provide a convenient way to document the discriminant features of a family of related products and now abound on the internet. Despite their apparent simplicity, the information present in existing PCMs can be very heterogeneous, partial, ambiguous, hard to exploit by users who desire to choose an appropriate product. Variability Models (VMs) can be employed to formulate in a more precise way the semantics of PCMs and enable automated reasoning such as assisted configuration. Yet, the gap between PCMs and VMs should be precisely understood and automated techniques should support the transition between the two. In this paper, we propose variability patterns that describe PCMs content and conduct an empirical analysis of 300+ PCMs mined from Wikipedia. Our findings are a first step toward better engineering techniques for maintaining and configuring PCMs. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/ASE.2013.6693116},
  ISBN                     = {9781479902156}
}

@Article{Sayyad2013,
  Title                    = {Optimum feature selection in software product lines: Let your model and values guide your search},
  Author                   = {Sayyad, AS and Ingram, J and Menzies, T},
  Journal                  = {Model. Search- {\ldots}},
  Year                     = {2013},

  Url                      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6604432}
}

@InProceedings{Sayyad2012,
  Title                    = {Software feature model recommendations using data mining},
  Author                   = {Sayyad, Abdel Salam and Ammar, Hany and Menzies, Tim},
  Year                     = {2012},
  Pages                    = {47--51},

  Abstract                 = {Feature Models are popular tools for describing software product lines. Analysis of feature models has traditionally focused on consistency checking (yielding a yes/no answer) and product selection assistance, interactive or offline. In this paper, we describe a novel approach to identify the most critical decisions in product selection/configuration by taking advantage of a large pool of randomly generated, generally inconsistent, product variants. Range Ranking, a data mining technique, is utilized to single out the most critical design choices, reducing the job of the human designer to making less consequential decisions. A large feature model is used as a case study; we show preliminary results of the new approach to illustrate its usefulness for practical product derivation. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/RSSE.2012.6233409},
  ISBN                     = {9781467317597}
}

@InProceedings{Sayyad2013c,
  Title                    = {On parameter tuning in search based software engineering: A replicated empirical study},
  Author                   = {Sayyad, Abdel Salam and Goseva-Popstojanova, Katerina and Menzies, Tim and Ammar, Hany},
  Year                     = {2013},
  Pages                    = {84--90},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {Multiobjective Evolutionary Algorithms are increasingly used to solve optimization problems in software engineering. The choice of parameters for those algorithms usually follows the "default" settings, often accepted as "rule of thumb" or common wisdom. The fact is that each algorithms needs to be tuned for the problem at hand. Previous work [Arcuri and Fraser, 2011] has shown that variations in parameter values had large effects on the performance of the algorithms. This project seeks to partially replicate the statistical analysis performed by Arcuri and Fraser. We seek to investigate the effects of parameter tuning on the performance of the two algorithms: Indicator-Based Evolutionary Algorithm (IBEA), and Nondominated Sorting Genetic Algorithm (NSGA-II) when applied to the problem of configuring Software Product Lines (SPLs) in the presence of stakeholder preferences such as cost and reliability. The results of this study confirm and strengthen the findings in the original study by Arcuri and Fraser. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/RESER.2013.6},
  ISBN                     = {9780769551210}
}

@InProceedings{Sayyad2013a,
  Title                    = {Scalable product line configuration: A straw to break the camel's back},
  Author                   = {Sayyad, Abdel Salam and Ingram, Joseph and Menzies, Tim and Ammar, Hany},
  Year                     = {2013},
  Pages                    = {465--474},

  Abstract                 = {Software product lines are hard to configure. Techniques that work for medium sized product lines fail for much larger product lines such as the Linux kernel with 6000+ features. This paper presents simple heuristics that help the Indicator-Based Evolutionary Algorithm (IBEA) in finding sound and optimum configurations of very large variability models in the presence of competing objectives. We employ a combination of static and evolutionary learning of model structure, in addition to utilizing a pre-computed solution used as a 'seed' in the midst of a randomly-generated initial population. The seed solution works like a single straw that is enough to break the camel's back -given that it is a feature-rich seed. We show promising results where we can find 30 sound solutions for configuring upward of 6000 features within 30 minutes. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/ASE.2013.6693104},
  ISBN                     = {9781479902156}
}

@InProceedings{Sayyad2013b,
  Title                    = {On the value of user preferences in search-based software engineering: A case study in software product lines},
  Author                   = {Sayyad, Abdel Salam and Menzies, Tim and Ammar, Hany},
  Year                     = {2013},
  Pages                    = {492--501},

  Abstract                 = {Software design is a process of trading off competing objectives. If the user objective space is rich, then we should use optimizers that can fully exploit that richness. For example, this study configures software product lines (expressed as feature maps) using various search-based software engineering methods. As we increase the number of optimization objectives, we find that methods in widespread use (e.g. NSGA-II, SPEA2) perform much worse than IBEA (Indicator-Based Evolutionary Algorithm). IBEA works best since it makes most use of user preference knowledge. Hence it does better on the standard measures (hypervolume and spread) but it also generates far more products with 0{\%} violations of domain constraints. Our conclusion is that we need to change our methods for search-based software engineering, particularly when studying complex decision spaces. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/ICSE.2013.6606595},
  ISBN                     = {9781467330763},
  ISSN                     = {02705257}
}

@Article{Schaefer2010,
  Title                    = {Variability Modelling for Model-Driven Development of Software Product Lines.},
  Author                   = {Schaefer, I},
  Journal                  = {VaMoS},
  Year                     = {2010},

  Url                      = {https://people.cs.clemson.edu/{~}johnmc/courses/cpsc950/paper2.pdf}
}

@Article{Schaefer2010a,
  Title                    = {Delta-oriented programming of software product lines},
  Author                   = {Schaefer, I and Bettini, L and Bono, V and Damiani, F},
  Journal                  = {Conf. Softw. {\ldots}},
  Year                     = {2010},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-15579-6{\_}6}
}

@Article{Schaefer2012,
  Title                    = {Software diversity: State of the art and perspectives},
  Author                   = {Schaefer, Ina and Rabiser, Rick and Clarke, Dave and Bettini, Lorenzo and Benavides, David and Botterweck, Goetz and Pathak, Animesh and Trujillo, Salvador and Villela, Karina},
  Year                     = {2012},
  Number                   = {5},
  Pages                    = {477--495},
  Volume                   = {14},

  Abstract                 = {Diversity is prevalent in modern software systems to facilitate adapting the software to customer requirements or the execution environment. Diversity has an impact on all phases of the software development process. Appropriate means and organizational structures are required to deal with the additional complexity introduced by software variability. This introductory article to the special section "Software Diversity-Modeling, Analysis and Evolution" provides an overview of the current state of the art in diverse systems development and discusses challenges and potential solutions. The article covers requirements analysis, design, implementation, verification and validation, maintenance and evolution as well as organizational aspects. It also provides an overview of the articles which are part of this special section and addresses particular issues of diverse systems development. {\textcopyright} 2012 Springer-Verlag.},
  Doi                      = {10.1007/s10009-012-0253-y},
  ISSN                     = {14332779}
}

@InProceedings{Schmid2011,
  Title                    = {A comparison of decision modeling approaches in product lines},
  Author                   = {Schmid, Klaus and Rabiser, Rick and Gr{\"{u}}nbacher, Paul},
  Booktitle                = {VAMOS},
  Year                     = {2011},
  Pages                    = {119--126},

  Abstract                 = {It has been shown that product line engineering can significantly improve the productivity, quality and time-to-market of software development by leveraging extensive reuse. Variability models are currently the most advanced approach to define, document and manage the commonalities and variabilities of reusable artifacts such as software components, requirements, test cases, etc. These models provide the basis for automating the derivation of new products and are thus the key artifact to leverage the flexibility and adaptability of systems in a product line. Among the existing approaches to variability modeling feature modeling and decision modeling have gained most importance. A significant amount of research exists on comparing and analyzing different feature modeling approaches. However, despite their significant role in product line research and practical applications, only little effort has been devoted to compare and analyze decision modeling approaches. In order to address this shortcoming and to provide a basis for more structured research on decision modeling in the future, we present a comparative analysis of representative approaches. We identify their major modeling concepts and present an analysis of their commonalities and variabilities. Copyright 2011 ACM.},
  Doi                      = {10.1145/1944892.1944907},
  ISBN                     = {9781450305709}
}

@InProceedings{Schnabel2016,
  Title                    = {CardyGAn: Tool support for cardinality-based feature models},
  Author                   = {Schnabel, Thomas and Weckesser, Markus and Kluge, Roland and Lochau, Malte and Sch{\"{u}}rr, Andy},
  Year                     = {2016},
  Month                    = {jan},
  Pages                    = {33--40},
  Publisher                = {Association for Computing Machinery},

  Abstract                 = {Cardinality-based feature models (CFM) constitute a crucial and non-trivial extension to FODA feature models in terms of UML-like feature multiplicities and corresponding cardinality constraints. CFM allow for specifying configuration choices of software systems incorporating multiple instances (copies) of features, e.g., for tailoring customer-specific and even potentially unrestricted application resources. Nevertheless, the improved expressiveness of CFM compared to FODA feature models complicates configuration semantics, including sub-tree cloning and potentially unbounded configuration spaces. As a consequence, entirely novel anomalies might arise such as dead cardinality intervals, false unboundedness, and cardinality gaps, which are not properly treated by recent feature-modeling tools. In this paper, we present comprehensive tool support for assisting specification, validation, and configuration of CFM. Our tool CardyGAn, therefore, incorporates capabilities for CFM editing, automated CFM validation including anomaly detection based on a combination of ILP and SMT solvers, as well as a CFM configuration engine based on Alloy.},
  Doi                      = {10.1145/2866614.2866619},
  ISBN                     = {9781450340199}
}

@Article{Schneeweiss2013,
  Title                    = {FdConfig: a constraint-based interactive product configurator},
  Author                   = {Schneeweiss, D and Hofstedt, P},
  Journal                  = {Appl. Declar. Program.},
  Year                     = {2013},

  Url                      = {http://link.springer.com/chapter/10.1007/978-3-642-41524-1{\_}13}
}

@InProceedings{Schroter2016,
  Title                    = {Feature-model interfaces: The highway to compositional analyses of highly-configurable systems},
  Author                   = {Schr{\"{o}}ter, Reimar and Krieter, Sebastian and Th{\"{u}}m, Thomas and Benduhn, Fabian and Saake, Gunter},
  Year                     = {2016},
  Month                    = {may},
  Pages                    = {667--678},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {Today's software systems are often customizable by means of load-time or compile-time configuration options. These options are typically not independent and their dependencies can be specified by means of feature models. As many industrial systems contain thousands of options, the maintenance and utilization of feature models is a challenge for all stakeholders. In the last two decades, numerous approaches have been presented to support stakeholders in analyzing feature models. Such analyses are commonly reduced to satis fiability problems, which suffer from the growing number of options. While first attempts have been made to decompose feature models into smaller parts, they still require to compose all parts for analysis. We propose the concept of a feature-model interface that only consists of a subset of features, typically selected by experts, and hides all other features and dependencies. Based on a formalization of feature-model interfaces, we prove compositionality properties. We evaluate feature-model interfaces using a three-month history of an industrial feature model from the automotive domain with 18,616 features. Our results indicate performance benefits especially under evolution as often only parts of the feature model need to be analyzed again.},
  Doi                      = {10.1145/2884781.2884823},
  ISBN                     = {9781450339001},
  ISSN                     = {02705257}
}

@Article{Schroter2013,
  Title                    = {Towards modular analysis of multi product lines},
  Author                   = {Schr{\"{o}}ter, R and Siegmund, N and Th{\"{u}}m, T},
  Journal                  = {Proc. 17th Int.},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2500719}
}

@Article{Schroter2014,
  Title                    = {Feature-context interfaces: tailored programming interfaces for software product lines},
  Author                   = {Schr{\"{o}}ter, R and Siegmund, N and Th{\"{u}}m, T and Saake, G},
  Journal                  = {Proc. 18th},
  Year                     = {2014},

  Url                      = {http://dl.acm.org/citation.cfm?id=2648522}
}

@Article{Schroter2013a,
  Title                    = {Automated analysis of dependent feature models},
  Author                   = {Schr{\"{o}}ter, R and Th{\"{u}}m, T and Siegmund, N and Saake, G},
  Journal                  = {Proc. Seventh},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2430515}
}

@InProceedings{Schroeter2012b,
  Title                    = {Multi-perspectives on feature models},
  Author                   = {Schroeter, Julia and Lochau, Malte and Winkelmann, Tim},
  Year                     = {2012},
  Pages                    = {252--268},
  Volume                   = {7590 LNCS},

  Abstract                 = {Domain feature models concisely express commonality and variability among variants of a software product line. For supporting separation of concerns, e.g., due to legal restrictions, technical considerations and business requirements, multi-view approaches restrict the configuration choices on feature models for different stakeholders. However, recent approaches lack a formalization for precise, yet flexible specifications of views that ensure every derivable configuration perspective to obey feature model semantics. Here, we introduce a novel approach for preconfiguring feature models to create multi-perspectives. Such customized perspectives result from composition of various concern-relevant views. A structured view model is used to organize features in view groups, wherein a feature may be contained in multiple views. We provide formalizations for view composition and guaranteed consistency of perspectives w.r.t. feature model semantics. Thereupon, an efficient algorithm to verify consistency for entire multi-perspectives is provided. We present an implementation and evaluate our concepts by means of various experiments. {\textcopyright} 2012 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-33666-9_17},
  ISBN                     = {9783642336652},
  ISSN                     = {03029743}
}

@InProceedings{Schroeter2012a,
  Title                    = {Dynamic configuration management of cloud-based applications},
  Author                   = {Schroeter, Julia and Mucha, Peter and Muth, Marcel and Jugel, Kay and Lochau, Malte},
  Year                     = {2012},
  Pages                    = {171--178},
  Volume                   = {2},

  Abstract                 = {Cloud-based applications are multi-tenant aware, whereas customers (i.e. tenants) share hardware and software resources. Offering highly configurable applications to thousands of tenants in a shared cloud environment demands for scalable configuration management. Based on an example scenario taken from the Indenica project, we identify requirements for applying methods from software product line (SPL) engineering to configure cloud-based multi-tenant aware applications. Using an extended feature model (EFM) to express variability of functionality and service qualities, we propose a concept for dynamic configuration management to address the identified requirements. Our proposed configuration management includes an adaptive staged configuration process that is capable of adding and removing stakeholders dynamically and that allows for reconfiguration of variants as stakeholders' objectives change. Copyright 2012 ACM.},
  Doi                      = {10.1145/2364412.2364441},
  ISBN                     = {9781450310956}
}

@InProceedings{Sebastian2016,
  Title                    = {A Feature-Based Personalized Recommender System for Product-Line Configuration},
  Author                   = {Sebastian, JAPPM and Saake, KMSG},
  Booktitle                = {A Feature-Based Personalized Recommender System for Product-Line Configuration},
  Year                     = {2016},

  Url                      = {http://wwwiti.cs.uni-magdeburg.de/iti{\_}db/publikationen/ps/auto/PereiraMK+:GPCE16.pdf}
}

@Article{Segura2011,
  Title                    = {Functional testing of feature model analysis tools: A test suite},
  Author                   = {Segura, S. and Benavides, D. and Ruiz-Cort{\'{e}}s, A.},
  Year                     = {2011},

  Month                    = {feb},
  Number                   = {1},
  Pages                    = {70--82},
  Volume                   = {5},

  Abstract                 = {A feature model is a compact representation of all the products of a software product line. Automated analysis of feature models is rapidly gaining importance: new operations of analysis have been proposed, new tools have been developed to support those operations and different logical paradigms and algorithms have been proposed to perform them. Implementing operations is a complex task that easily leads to errors in analysis solutions. In this context, the lack of specific testing mechanisms is becoming a major obstacle hindering the development of tools and affecting their quality and reliability. In this article, the authors present FaMa test suite, a set of implementation- independent test cases to validate the functionality of feature model analysis tools. This is an efficient and handy mechanism to assist in the development of tools, detecting faults and improving their quality. In order to show the effectiveness of their proposal, the authors evaluated the suite using mutation testing as well as real faults and tools. Their results are promising and directly applicable in the testing of analysis solutions. The authors intend this work to be a first step towards the development of a widely accepted test suite to support functional testing in the community of automated analysis of feature models. {\textcopyright} 2011 The Institution of Engineering and Technology.},
  Doi                      = {10.1049/iet-sen.2009.0096},
  ISSN                     = {17518806}
}

@Article{Segura2015,
  Title                    = {Automated metamorphic testing of variability analysis tools},
  Author                   = {Segura, Sergio and Dur{\'{a}}n, Amador and S{\'{a}}nchez, Ana B. and {Le Berre}, Daniel and Lonca, Emmanuel and Ruiz-Cort{\'{e}}s, Antonio},
  Year                     = {2015},

  Month                    = {mar},
  Number                   = {2},
  Pages                    = {138--163},
  Volume                   = {25},

  Abstract                 = {Variability determines the capability of software applications to be configured and customized. A common need during the development of variability-intensive systems is the automated analysis of their underlying variability models, for example, detecting contradictory configuration options. The analysis operations that are performed on variability models are often very complex, which hinders the testing of the corresponding analysis tools and makes difficult, often infeasible, to determine the correctness of their outputs, that is, the well-known oracle problem in software testing. In this article, we present a generic approach for the automated detection of faults in variability analysis tools overcoming the oracle problem. Our work enables the generation of random variability models together with the exact set of valid configurations represented by these models. These test data are generated from scratch using stepwise transformations and assuring that certain constraints (a.k.a. metamorphic relations) hold at each step. To show the feasibility and generalizability of our approach, it has been used to automatically test several analysis tools in three variability domains: feature models, common upgradeability description format documents and Boolean formulas. Among other results, we detected 19 real bugs in 7 out of the 15 tools under test.},
  Doi                      = {10.1002/stvr.1566},
  ISSN                     = {10991689},
  Publisher                = {John Wiley and Sons Ltd}
}

@Article{Segura2016,
  Title                    = {A Survey on Metamorphic Testing},
  Author                   = {Segura, Sergio and Fraser, Gordon and Sanchez, Ana B. and Ruiz-Cortes, Antonio},
  Year                     = {2016},

  Month                    = {sep},
  Number                   = {9},
  Pages                    = {805--824},
  Volume                   = {42},

  Abstract                 = {A test oracle determines whether a test execution reveals a fault, often by comparing the observed program output to the expected output. This is not always practical, for example when a program's input-output relation is complex and difficult to capture formally. Metamorphic testing provides an alternative, where correctness is not determined by checking an individual concrete output, but by applying a transformation to a test input and observing how the program output 'morphs' into a different one as a result. Since the introduction of such metamorphic relations in 1998, many contributions on metamorphic testing have been made, and the technique has seen successful applications in a variety of domains, ranging from web services to computer graphics. This article provides a comprehensive survey on metamorphic testing: It summarises the research results and application areas, and analyses common practice in empirical studies of metamorphic testing as well as the main open challenges.},
  Doi                      = {10.1109/TSE.2016.2532875},
  ISSN                     = {00985589},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.}
}

@InProceedings{Segura2012,
  Title                    = {BeTTy: Benchmarking and Testing on the automated analysis of feature models},
  Author                   = {Segura, Sergio and Galindo, Jos{\'{e}} A. and Benavides, David and Parejo, Jos{\'{e}} A. and Ruiz-Cort{\'{e}}s, Antonio},
  Year                     = {2012},
  Pages                    = {63--71},

  Abstract                 = {The automated analysis of feature models is a ourishing research topic that has called the attention of both researchers and practitioners during the last two decades. During this time, the number of tools and techniques enabling the analysis of feature models has increased and also their complexity. In this scenario, the lack of specific testing mechanisms to assess the correctness and good performance of analysis tools is becoming a major obstacle hindering the development of tools and affecting their quality and reliability. In this paper, we present BeTTy, a framework for BEnchmarking and TesTing on the analY sis of feature models. Among other features, BeTTy enables the automated detection of faults in feature model analysis tools. Also, it supports the generation of motivating test data to evaluate the performance of analysis tools in both average and pessimistic cases. Part of the functionality of the framework is provided through a web-based interface facilitating the random generation of both classic and attributed feature models. Copyright {\textcopyright} 2012.},
  Doi                      = {10.1145/2110147.2110155},
  ISBN                     = {9781450310581}
}

@Article{Segura2011a,
  Title                    = {Mutation testing on an object-oriented framework: An experience report},
  Author                   = {Segura, Sergio and Hierons, Robert M. and Benavides, David and Ruiz-Cort{\'{e}}s, Antonio},
  Year                     = {2011},

  Month                    = {oct},
  Number                   = {10},
  Pages                    = {1124--1136},
  Volume                   = {53},

  Abstract                 = {Context: The increasing presence of Object-Oriented (OO) programs in industrial systems is progressively drawing the attention of mutation researchers toward this paradigm. However, while the number of research contributions in this topic is plentiful, the number of empirical results is still marginal and mostly provided by researchers rather than practitioners. Objective: This article reports our experience using mutation testing to measure the effectiveness of an automated test data generator from a user perspective. Method: In our study, we applied both traditional and class-level mutation operators to FaMa, an open source Java framework currently being used for research and commercial purposes. We also compared and contrasted our results with the data obtained from some motivating faults found in the literature and two real tools for the analysis of feature models, FaMa and SPLOT. Results: Our results are summarized in a number of lessons learned supporting previous isolated results as well as new findings that hopefully will motivate further research in the field. Conclusion: We conclude that mutation testing is an effective and affordable technique to measure the effectiveness of test mechanisms in OO systems. We found, however, several practical limitations in current tool support that should be addressed to facilitate the work of testers. We also missed specific techniques and tools to apply mutation testing at the system level. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.infsof.2011.03.006},
  ISSN                     = {09505849}
}

@Article{Segura2011b,
  Title                    = {Automated metamorphic testing on the analyses of feature models},
  Author                   = {Segura, Sergio and Hierons, Robert M. and Benavides, David and Ruiz-Cort{\'{e}}s, Antonio},
  Year                     = {2011},

  Month                    = {mar},
  Number                   = {3},
  Pages                    = {245--258},
  Volume                   = {53},

  Abstract                 = {Context: A feature model (FM) represents the valid combinations of features in a domain. The automated extraction of information from FMs is a complex task that involves numerous analysis operations, techniques and tools. Current testing methods in this context are manual and rely on the ability of the tester to decide whether the output of an analysis is correct. However, this is acknowledged to be time-consuming, error-prone and in most cases infeasible due to the combinatorial complexity of the analyses, this is known as the oracle problem. Objective: In this paper, we propose using metamorphic testing to automate the generation of test data for feature model analysis tools overcoming the oracle problem. An automated test data generator is presented and evaluated to show the feasibility of our approach. Method: We present a set of relations (so-called metamorphic relations) between input FMs and the set of products they represent. Based on these relations and given a FM and its known set of products, a set of neighbouring FMs together with their corresponding set of products are automatically generated and used for testing multiple analyses. Complex FMs representing millions of products can be efficiently created by applying this process iteratively. Results: Our evaluation results using mutation testing and real faults reveal that most faults can be automatically detected within a few seconds. Two defects were found in FaMa and another two in SPLOT, two real tools for the automated analysis of feature models. Also, we show how our generator outperforms a related manual suite for the automated analysis of feature models and how this suite can be used to guide the automated generation of test cases obtaining important gains in efficiency. Conclusion: Our results show that the application of metamorphic testing in the domain of automated analysis of feature models is efficient and effective in detecting most faults in a few seconds without the need for a human oracle. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.infsof.2010.11.002},
  ISSN                     = {09505849}
}

@InProceedings{Segura2010,
  Title                    = {Automated test data generation on the analyses of feature models: A metamorphic testing approach},
  Author                   = {Segura, Sergio and Hierons, Robert M. and Benavides, David and Ruiz-Cort{\'{e}}s, Antonio},
  Year                     = {2010},
  Pages                    = {35--44},

  Abstract                 = {A Feature Model (FM) is a compact representation of all the products of a software product line. The automated extraction of information from FMs is a thriving research topic involving a number of analysis operations, algorithms, paradigms and tools. Implementing these operations is far from trivial and easily leads to errors and defects in analysis solutions. Current testing methods in this context mainly rely on the ability of the tester to decide whether the output of an analysis is correct. However, this is acknowledged to be time-consuming, error-prone and in most cases infeasible due to the combinatorial complexity of the analyses. In this paper, we present a set of relations (so-called metamorphic relations) between input FMs and their set of products and a test data generator relying on them. Given an FM and its known set of products, a set of neighbour FMs together with their corresponding set of products are automatically generated and used for testing different analyses. Complex FMs representing millions of products can be efficiently created applying this process iteratively. The evaluation of our approach using mutation testing as well as real faults and tools reveals that most faults can be automatically detected within a few seconds. {\textcopyright} 2010 IEEE.},
  Doi                      = {10.1109/ICST.2010.20},
  ISBN                     = {9780769539904}
}

@Article{Segura2014,
  Title                    = {Automated generation of computationally hard feature models using evolutionary algorithms},
  Author                   = {Segura, Sergio and Parejo, Jos{\'{e}} A. and Hierons, Robert M. and Benavides, David and Ruiz-Cort{\'{e}}s, Antonio},
  Year                     = {2014},

  Month                    = {jun},
  Number                   = {8},
  Pages                    = {3975--3992},
  Volume                   = {41},

  Abstract                 = {A feature model is a compact representation of the products of a software product line. The automated extraction of information from feature models is a thriving topic involving numerous analysis operations, techniques and tools. Performance evaluations in this domain mainly rely on the use of random feature models. However, these only provide a rough idea of the behaviour of the tools with average problems and are not sufficient to reveal their real strengths and weaknesses. In this article, we propose to model the problem of finding computationally hard feature models as an optimization problem and we solve it using a novel evolutionary algorithm for optimized feature models (ETHOM). Given a tool and an analysis operation, ETHOM generates input models of a predefined size maximizing aspects such as the execution time or the memory consumption of the tool when performing the operation over the model. This allows users and developers to know the performance of tools in pessimistic cases providing a better idea of their real power and revealing performance bugs. Experiments using ETHOM on a number of analyses and tools have successfully identified models producing much longer executions times and higher memory consumption than those obtained with random models of identical or even larger size. {\textcopyright} 2013 Elsevier Ltd. All rights reserved.},
  Doi                      = {10.1016/j.eswa.2013.12.028},
  ISSN                     = {09574174}
}

@Article{Segura2012a,
  Title                    = {Ethom: An evolutionary algorithm for optimized feature models generation (v. 1.1)},
  Author                   = {Segura, S and Parejo, JA and Hierons, RM and Benavides, D},
  Year                     = {2012},

  Url                      = {http://www.lsi.us.es/{~}segura/files/material/ESWA13/segura13-ETHOM.pdf}
}

@InProceedings{Segura2014a,
  Title                    = {Automated variability analysis and testing of an e-commerce site. An experience report},
  Author                   = {Segura, Sergio and S{\'{a}}nchez, Ana B. and Ruiz-Cort{\'{e}}s, Antonio},
  Year                     = {2014},
  Pages                    = {139--149},
  Publisher                = {Association for Computing Machinery, Inc},

  Abstract                 = {In this paper, we report on our experience on the development of La Hilandera, an e-commerce site selling haberdashery products and craft supplies in Europe. The store has a huge input space where customers can place almost three millions of different orders which made testing an extremely difficult task. To address the challenge, we explored the applicability of some of the practices for variability management in software product lines. First, we used a feature model to represent the store input space which provided us with a variability view easy to understand, share and discuss with all the stakeholders. Second, we used techniques for the automated analysis of feature models for the detection and repair of inconsistent and missing configuration settings. Finally, we used test selection and prioritization techniques for the generation of a manageable and effective set of test cases. Our findings, summarized in a set of lessons learnt, suggest that variability techniques could successfully address many of the challenges found when developing e-commerce sites.},
  Doi                      = {10.1145/2642937.2642939},
  ISBN                     = {9781450330138}
}

@Article{Seidl2014,
  Title                    = {Capturing variability in space and time with hyper feature models},
  Author                   = {Seidl, C and Schaefer, I and A{\ss}mann, U},
  Journal                  = {Eighth Int. Work. {\ldots}},
  Year                     = {2014},

  Url                      = {http://dl.acm.org/citation.cfm?id=2556625}
}

@InProceedings{Shao2014,
  Title                    = {A static semantic model for trusted forensics using OCL},
  Author                   = {Shao, Zehui and Ding, Qiufeng and Jin, Xianli and Sun, Guozi},
  Year                     = {2014},
  Pages                    = {259--268},
  Publisher                = {Springer Verlag},
  Volume                   = {276 LNEE},

  Abstract                 = {According to the features of various properties of digital data, a static semantic model of features for trusted digital data using OCL (Object Constraint Language) is proposed. These features obtained from the forensic domain of digital data are hierarchically decomposed and merged based on FODA (Feature Oriented Domain Analysis) modeling process. Then a feature tree is built with semantic logical relation in order to get the overall semantic description of features in the forensic domain of digital data, meanwhile, formally describing the features of various attributes of digital data by OCL which has a rigorous mathematical semantics and is easy to understand. The features of digital data are classified with the concept of set in OCL, and the relevance and dependence among various features are described with the operations of set in OCL. Finally, a feature model is built in digital data of Windows system with the use of OCL operations. {\textcopyright} 2014 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-40861-8_39},
  ISBN                     = {9783642408601},
  ISSN                     = {18761119}
}

@Article{She2012,
  Title                    = {Usage scenarios for feature model synthesis},
  Author                   = {She, S and Czarnecki, K and W{\c{a}}sowski, A},
  Journal                  = {Var. You Work. {\ldots}},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2425419}
}

@Article{She2010,
  Title                    = {The Variability Model of The Linux Kernel.},
  Author                   = {She, S and Lotufo, R and Berger, T and Wasowski, A and Czarnecki, K},
  Journal                  = {VaMoS},
  Year                     = {2010},

  Url                      = {http://gsd.uwaterloo.ca/sites/default/files/camera-vamos-20100107.pdf}
}

@InProceedings{She2011,
  Title                    = {Reverse engineering feature models},
  Author                   = {She, Steven and Lotufo, Rafael and Berger, Thorsten and Wa̧sowski, Andrzej and Czarnecki, Krzysztof},
  Year                     = {2011},
  Pages                    = {461--470},

  Abstract                 = {Feature models describe the common and variable characteristics of a product line. Their advantages are well recognized in product line methods. Unfortunately, creating a feature model for an existing project is time-consuming and requires substantial effort from a modeler. We present procedures for reverse engineering feature models based on a crucial heuristic for identifying parents - the major challenge of this task. We also automatically recover constructs such as feature groups, mandatory features, and implies/excludes edges. We evaluate the technique on two large-scale software product lines with existing reference feature models - the Linux and eCos kernels - and FreeBSD, a project without a feature model. Our heuristic is effective across all three projects by ranking the correct parent among the top results for a vast majority of features. The procedures effectively reduce the information a modeler has to consider from thousands of choices to typically five or less. {\textcopyright} 2011 ACM.},
  Doi                      = {10.1145/1985793.1985856},
  ISBN                     = {9781450304450},
  ISSN                     = {02705257}
}

@Article{She2014,
  Title                    = {Efficient synthesis of feature models},
  Author                   = {She, Steven and Ryssel, Uwe and Andersen, Nele and Wa̧sowski, Andrzej and Czarnecki, Krzysztof},
  Year                     = {2014},
  Number                   = {9},
  Pages                    = {1122--1143},
  Volume                   = {56},

  Abstract                 = {Context Variability modeling, and in particular feature modeling, is a central element of model-driven software product line architectures. Such architectures often emerge from legacy code, but, creating feature models from large, legacy systems is a long and arduous task. We describe three synthesis scenarios that can benefit from the algorithms in this paper. Objective This paper addresses the problem of automatic synthesis of feature models from propositional constraints. We show that the decision version of the problem is NP-hard. We designed two efficient algorithms for synthesis of feature models from CNF and DNF formulas respectively. Method We performed an experimental evaluation of the algorithms against a binary decision diagram (BDD)-based approach and a formal concept analysis (FCA)-based approach using models derived from realistic models. Results Our evaluation shows a 10 to 1,000-fold performance improvement for our algorithms over the BDD-based approach. The performance of the DNF-based algorithm was similar to the FCA-based approach, with advantages for both techniques. We identified input properties that affect the runtimes of the CNF- and DNF-based algorithms. Conclusions Our algorithms are the first known techniques that are efficient enough to be used on dependencies extracted from real systems, opening new possibilities of creating reverse engineering and model management tools for variability models. {\textcopyright} 2014 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.infsof.2014.01.012},
  ISSN                     = {09505849},
  Publisher                = {Elsevier}
}

@InProceedings{Sheikhalishahi2016,
  Title                    = {On the abstraction of a categorical clustering algorithm},
  Author                   = {Sheikhalishahi, Mina and Mejri, Mohamed and Tawbi, Nadia},
  Year                     = {2016},
  Pages                    = {659--675},
  Publisher                = {Springer Verlag},
  Volume                   = {9729},

  Abstract                 = {Despite being one of the most common approach in unsupervised data analysis, a very small literature exists on the formalization of clustering algorithms. This paper proposes a semiring-based methodology, named Feature-Cluster Algebra, which is applied to abstract the representation of a labeled tree structure representing a hierarchical categorical clustering algorithm, named CCTree. The elements of the feature-cluster algebra are called terms. We prove that a specific kind of a term, under some conditions, fully abstracts a labeled tree structure. The abstraction methodology maps the original problem to a new representation by removing unwanted details, which makes it simpler to handle. Moreover, we present a set of relations and functions on the algebraic structure to shape the requirements of a term to represent a CCTree structure. The proposed formal approach can be generalized to other categorical clustering (classification) algorithms in which features play key roles in specifying the clusters (classes).},
  Doi                      = {10.1007/978-3-319-41920-6_51},
  ISBN                     = {9783319419190},
  ISSN                     = {16113349}
}

@InProceedings{Shi2010,
  Title                    = {A preliminary experimental study on optimal feature selection for product derivation using knapsack approximation},
  Author                   = {Shi, Runyu and Guo, Jianmei and Wang, Yinglin},
  Year                     = {2010},
  Pages                    = {665--669},
  Volume                   = {1},

  Abstract                 = {Software product lines (SPLs) technology produce software by integrating reusable software components based on customer requirements. Current researchers pay great attention to feature modeling technology that can represent SPLs' production requirements and functionalities. A key challenge is selecting valid and optimal feature combinations from the feature model to satisfy various requirements of customers and vendors, including various value and cost constraints. This paper experimentally studies a knapsack approximation algorithm of feature selection for automated product derivation in SPLs. Our approach generates an approximation solution by a modified Filtered Cartesian Flattening algorithm and obtains the optimal solution with a greed search. We performed experiments on randomly generated feature models with different characteristics. Experiments show that our approach can select highly optimal feature combinations effectively. {\textcopyright}2010 IEEE.},
  Doi                      = {10.1109/PIC.2010.5687874},
  ISBN                     = {9781424467860}
}

@Article{Siegmund2012,
  Title                    = {Predicting performance via automated feature-interaction detection},
  Author                   = {Siegmund, N and Kolesnikov, SS and K{\"{a}}stner, C},
  Journal                  = {Proc. 34th},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2337243}
}

@InProceedings{Silva2016,
  Title                    = {JPI feature models-Exploring a JPI and FOP symbiosis for software modeling},
  Author                   = {Silva, Cristian Vidal and Galindo, Jose Angel and Villarroel, Rodolfo and Benavides, David and Leger, Paul and Valenzuela, Sebastian},
  Year                     = {2016},
  Month                    = {feb},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {Looking for a complete modular software development paradigm, this article presents Join Point Interface JPI Feature Models, in the context of a JPI and Feature-Oriented Programming FOP symbiosis paradigm. Therefore, this article describes pros and cons of JPI and FOP approaches for the modular software and software product line production, respective; and highlights the benefits of this mixing proposal; in particular, the JPI Feature Model benefits for a high-level software product line modeling. As an application example, this article applies JPI Features Models on a classic FOP example already modeled using a previous aspect-oriented feature model proposal. Main goals of this application are to visualize traditional feature models preserved components such alternative and optional feature sets and optional and mandatory features as well as special features associations (cross-tree constraints), and differences and advantages with respect to previous research works about extending feature model to support aspect-oriented modeling principles.},
  Doi                      = {10.1109/SCCC.2015.7416583},
  ISBN                     = {9781467398176},
  ISSN                     = {15224902}
}

@InProceedings{Simmonds2013,
  Title                    = {Variability in software process models: Requirements for adoption in industrial settings},
  Author                   = {Simmonds, Jocelyn and Bastarrica, Mar{\'{i}}a Cecilia and Silvestre, Luis and Quispe, Alcides},
  Year                     = {2013},
  Pages                    = {33--36},

  Abstract                 = {It is an increasing trend to apply Software Product Line (SPL) concepts and techniques for software process tailoring, generating a Software PRocess Line (SPrL). However, there are several aspects that must be addressed before SPrLs can be fully adopted by industry, a key aspect being how software process variability is specified and managed. In the literature, there are several general-purpose as well as domain-specific proposals for specifying process variability. In this paper, we analyze the benefits and drawbacks of two general-purpose (feature models and OVM) and two domain-specific (SPEM variability primitives and vSPEM) approaches, as well as discuss what hinders industry adoption in each case. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/PLEASE.2013.6608661},
  ISBN                     = {9781467364492}
}

@Article{Sincero2010,
  Title                    = {Efficient extraction and analysis of preprocessor-based variability},
  Author                   = {Sincero, J and Tartler, R and Lohmann, D},
  Journal                  = {ACM SIGPLAN},
  Year                     = {2010},

  Url                      = {http://dl.acm.org/citation.cfm?id=1868300}
}

@InProceedings{Soltani2012,
  Title                    = {Automated planning for feature model configuration based on functional and non-functional requirements},
  Author                   = {Soltani, Samaneh and Asadi, Mohsen and Ga{\v{s}}evi{\'{c}}, Dragan and Hatala, Marek and Bagheri, Ebrahim},
  Year                     = {2012},
  Pages                    = {56--65},
  Volume                   = {1},

  Abstract                 = {Feature modeling is one of the main techniques used in Software Product Line Engineering to manage the variability within the products of a family. Concrete products of the family can be generated through a configuration process. The configuration process selects and/or removes features from the feature model according to the stakeholders' requirements. Selecting the right set of features for one product from amongst all of the available features in the feature model is a complex task because: 1) the multiplicity of stakeholders' functional requirements; 2) the positive or negative impact of features on non-functional properties; and 3) the stakeholders' preferences w.r.t. the desirable non-functional properties of the final product. Many configurations techniques have already been proposed to facilitate automated product derivation. However, most of the current proposals are not designed to consider stakeholders' preferences and constraints especially with regard to non-functional properties. We address the software product line configuration problem and propose a framework, which employs an artificial intelligence planning technique to automatically select suitable features that satisfy both the stakeholders' functional and non-functional preferences and constraints. We also provide tooling support to facilitate the use of our framework. Our experiments show that despite the complexity involved with the simultaneous consideration of both functional and non-functional properties our configuration technique is scalable. Copyright {\textcopyright} 2012 ACM.},
  Doi                      = {10.1145/2362536.2362548},
  ISBN                     = {9781450310956}
}

@InProceedings{Soltani2011,
  Title                    = {Automated planning for feature model configuration based on stakeholders' business concerns},
  Author                   = {Soltani, Samaneh and Asadi, Mohsen and Hatala, Marek and Ga{\v{s}}evi{\'{c}}, Dragan and Bagheri, Ebrahim},
  Year                     = {2011},
  Pages                    = {536--539},

  Abstract                 = {In Software Product Line Engineering, concrete products of a family can be generated through a configuration process over a feature model. The configuration process selects features from the feature model according to the stakeholders' requirements. Selecting the right set of features for one product from all the available features in the feature model is a cumbersome task because 1) the stakeholders may have diverse business concerns and limited resources that they can spend on a product and 2) features may have negative and positive contributions on different business concern. Many configurations techniques have been proposed to facilitate software developers' tasks through automated product derivation. However, most of the current proposals for automatic configuration are not devised to cope with business oriented requirements and stakeholders' resource limitations. We propose a framework, which employs an artificial intelligence planning technique to automatically select suitable features that satisfy the stakeholders' business concerns and resource limitations. We also provide tooling support to facilitate the use of our framework. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/ASE.2011.6100118},
  ISBN                     = {9781457716393}
}

@Article{Sousa2016,
  Title                    = {Software Product Lines for Multi-Cloud Microservices-Based Applications},
  Author                   = {Sousa, G and Rudametkin, W and Duchien, L},
  Journal                  = {6th Int. Work.},
  Year                     = {2016},

  Url                      = {https://hal.inria.fr/hal-01302184/}
}

@Article{Sree-Kumar2016,
  Title                    = {Analysis of Feature Models Using Alloy: A Survey},
  Author                   = {Sree-Kumar, A and Planas, E and Claris{\'{o}}, R},
  Journal                  = {arXiv Prepr. arXiv1604.00349},
  Year                     = {2016},

  Url                      = {http://arxiv.org/abs/1604.00349}
}

@Article{Stein2014,
  Title                    = {Preference-based feature model configuration with multiple stakeholders},
  Author                   = {Stein, J and Nunes, I and Cirilo, E},
  Journal                  = {Proc. 18th Int. Softw.},
  Year                     = {2014},

  Url                      = {http://dl.acm.org/citation.cfm?id=2648525}
}

@Article{Strickler2016,
  Title                    = {Deriving products for variability test of Feature Models with a hyper-heuristic approach},
  Author                   = {Strickler, A and Lima, JAP and Vergilio, SR and Pozo, ATR},
  Journal                  = {Appl. Soft Comput.},
  Year                     = {2016},

  Url                      = {http://www.sciencedirect.com/science/article/pii/S1568494616303994}
}

@Article{Sun2016,
  Title                    = {A novel efficient SVM-based fault diagnosis method for multi-split air conditioning system's refrigerant charge fault amount},
  Author                   = {Sun, Kaizheng and Li, Guannan and Chen, Huanxin and Liu, Jiangyan and Li, Jiong and Hu, Wenju},
  Year                     = {2016},

  Month                    = {sep},
  Pages                    = {989--998},
  Volume                   = {108},

  Abstract                 = {For the multi-split variable refrigerant flow (VRF) system, the key of efficient operation is to achieve the appropriate refrigerant charge amount (RCA). However, it is difficult to achieve because of the complexity of VRF systems. To overcome the difficulty, this paper presents a hybrid RCA fault diagnosis model combined support vector machine (SVM) with wavelet de-noising (WD) and improved max-relevance and min-redundancy (mRMR) algorithm. WD is responsible for improving the quality of collected VRF experimental data. In addition, mRMR is firstly used to rank all the variables in descending order in terms of their importance for identify RCA faults. After top-ranked variable is determined, correlation analysis of features is implemented for further feature selection removing the redundant variables in linkage to the variable at the top. Finally, a subset of seven features are selected to develop the SVM model. Results indicate that fault diagnosis accuracy of the seven-feature SVM model decreases only 2.14{\%} compared with the initial eighteen-feature model. The proposed wavelet de-noising-max-relevance and min-redundancy-support vector machine (WD-mRMR-SVM) model shows good fault diagnosis performance for RCA faults.},
  Doi                      = {10.1016/j.applthermaleng.2016.07.109},
  ISSN                     = {13594311},
  Publisher                = {Elsevier Ltd}
}

@Article{Tanhaei2016,
  Title                    = {Automating feature model refactoring: A Model transformation approach},
  Author                   = {Tanhaei, Mohammad and Habibi, Jafar and Mirian-Hosseinabadi, Seyed Hassan},
  Year                     = {2016},

  Month                    = {dec},
  Pages                    = {138--157},
  Volume                   = {80},

  Abstract                 = {Context: Feature model is an appropriate and indispensable tool for modeling similarities and differences among products of the Software Product Line (SPL). It not only exposes the validity of the products' configurations in an SPL but also changes in the course of time to support new requirements of the SPL. Modifications made on the feature model in the course of time raise a number of issues. Useless enlargements of the feature model, the existence of dead features, and violated constraints in the feature model are some of the key problems that make its maintenance difficult. Objective: The initial approach to dealing with the above-mentioned problems and improving maintainability of the feature model is refactoring. Refactoring modifies software artifacts in a way that their externally visible behavior does not change. Method: We introduce a method for defining refactoring rules and executing them on the feature model. We use the ATL model transformation language to define the refactoring rules. Moreover, we provide an Alloy model to check the feature model and the safety of the refactorings that are performed on it. Results: In this research, we propose a safe framework for refactoring a feature model. This framework enables users to perform automatic and semi-automatic refactoring on the feature model. Conclusions: Automated tool support for refactoring is a key issue for adopting approaches such as utilizing feature models and integrating them into the software development process of companies. In this work, we define some of the important refactoring rules on the feature model and provide tools that enable users to add new rules using the ATL M2M language. Our framework assesses the correctness of the refactorings using the Alloy language.},
  Doi                      = {10.1016/j.infsof.2016.08.011},
  ISSN                     = {09505849},
  Publisher                = {Elsevier}
}

@InProceedings{Tawhid2011,
  Title                    = {Product model derivation by model transformation in software product lines},
  Author                   = {Tawhid, Rasha and Petriu, Dorina C.},
  Year                     = {2011},
  Pages                    = {72--79},

  Abstract                 = {Product derivation is an essential part of the Software Product Line (SPL) development process. The paperproposes a model transformation for deriving automatically a UML model of a specific product from the UML model of a product line. This work is a part of a larger project aiming to integrate performance analysis in the SPL model-driven development. The SPL source model is expressed in UML extended with two separate profiles: a "product line" profile from literature for specifying the commonality and variability between products, and the MARTE profile recently standardized by OMG for performance annotations. The automatic derivation of a concrete product model based on a given feature configuration is enabled through the mapping between features from the feature model and their realizations in the design model. The paper proposes an efficient mapping technique that aims to minimize the amount of explicit feature annotations in the UML design model of SPL. Implicit feature mapping is inferred during product derivation from the relationships between annotated and non-annotated model elements as defined in the UML metamodel and well formedness rules. The transformation is realized in the Atlas Transformation Language (ATL) and illustrated with an ecommerce case study that models structural and behavioural SPL views. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/ISORCW.2011.18},
  ISBN                     = {9780769543772}
}

@InProceedings{Tawhid2011a,
  Title                    = {Automatic derivation of a product performance model from a software product line model},
  Author                   = {Tawhid, Rasha and Petriu, Dorina C.},
  Year                     = {2011},
  Pages                    = {80--89},

  Abstract                 = {We propose to integrate performance analysis in the early phases of the model-driven development process for Software Product Lines (SPL). We start with a multi-view UML model of the core family assets representing the commonality and variability between different products, which we call the SPL model. We add another perspective to the SPL model, annotating it with generic performance specifications expressed in the standard UML profile MARTE, recently adopted by OMG. The runtime performance of a product is affected by factors contained in the UML model of the product (derived from the SPL model), but also by external factors depending on the implementation and execution environments. The external factors not contained in the SPL model need to be eventually represented in the performance model. In order to do so, we propose to represent the variability space of different possible implementation and execution environments through a so called "performance completion (PC) feature model". These PC features are mapped to MARTE performance-related stereotypes and attributes attached to the SPL model elements. A first model transformation realized in the Atlas Transformation Language (ATL) derives the UML model of a specific product with concrete MARTE annotations from the SPL model. A second transformation generates a Layered Queueing Network (LQN) performance model for the given product by applying an existing transformation named PUMA, developed in previous work. The proposed technique is illustrated with an e-commerce case study. A LQN model is derived for a product and the impact of different levels of secure communication channels on its performance is analyzed by using the LQN model. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/SPLC.2011.27},
  ISBN                     = {9780769544878}
}

@InProceedings{Teixeira2013,
  Title                    = {Safe composition of configuration knowledge-based software product lines},
  Author                   = {Teixeira, Leopoldo and Borba, Paulo and Gheyi, Rohit},
  Year                     = {2013},
  Month                    = {apr},
  Number                   = {4},
  Pages                    = {1038--1053},
  Volume                   = {86},

  Abstract                 = {Mistakes made when implementing or specifying the models of a Software Product Line (SPL) can result in ill-formed products - the safe composition problem. Such problem can hinder productivity and it might be hard to detect, since SPLs can have thousands of products. In this article, we propose a language independent approach for verifying safe composition of SPLs with dedicated Configuration Knowledge models. We translate feature model and Configuration Knowledge into propositional logic and use the Alloy Analyzer to perform the verification. To provide evidence for the generality of our approach, we instantiate this approach in different compositional settings. We deal with different kinds of assets such as use case scenarios and Eclipse RCP components. We analyze both the code and the requirements for a larger scale SPL, finding problems that affect thousands of products in minutes. Moreover, our evaluation suggests that the analysis time grows linearly with respect to the number of products in the analyzed SPLs. {\textcopyright} 2012 Elsevier Inc.},
  Doi                      = {10.1016/j.jss.2012.11.006},
  ISSN                     = {01641212}
}

@InProceedings{Tekinerdogan2011,
  Title                    = {Modeling and reasoning about design alternatives of software as a service architectures},
  Author                   = {Tekinerdogan, Bedir and {\"{O}}zt{\"{u}}rk, Karahan and Doǧru, Ali},
  Year                     = {2011},
  Pages                    = {312--319},

  Abstract                 = {In general, a common reference architecture can be derived for Software as a Service (SaaS). However, while designing particular applications one may derive various application design alternatives from the same reference SaaS architecture specification. To meet the required functional and nonfunctional requirements of different enterprise applications it is important to model the possible design so that a feasible alternative can be defined. In this paper, we propose a systematic approach and corresponding tool support for guiding the design of SaaS application architectures. The approach defines a SaaS reference architecture, a family feature model and a set of reference design rules. Based on the business requirements an application feature model is defined using the family feature model. Selected features are related to design decisions and a SaaS application architecture design is derived. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/WICSA.2011.49},
  ISBN                     = {9780769543512}
}

@InProceedings{TerBeek2014,
  Title                    = {Software product line analysis with mCRL2},
  Author                   = {{Ter Beek}, Maurice H. and {De Vink}, Erik P.},
  Year                     = {2014},
  Month                    = {sep},
  Pages                    = {78--85},
  Publisher                = {Association for Computing Machinery},
  Volume                   = {2},

  Abstract                 = {The mCRL2 language and supporting software provide a state-of-the-art tool suite for the verification of distributed systems. In this paper, we present the general principles, extrapolated from [7,8], which make us believe that mCRL2 can also be used for behavioral variability analysis of product families. The mCRL2 data language allows to smoothly deal with feature sets and attributes, its process language is sufficiently rich to model feature selection, as well as product behavior based on an FTS-like semantics. Because of the feature-orientation, our modeling strategy allows a natural refactoring of the semantic model of a product family into a parallel composition of components that reflects coherent sets of features. This opens the way for dedicated abstraction and reduction techniques that strengthen the prospect of a scalable verification approach to software product lines. In this paper, we sketch how to model product families in mCRL2 and how to apply a modular verification method, preparing the ground to further assess the scalability of our approach, in particular regarding model checking. Copyright 2014 ACM.},
  Doi                      = {10.1145/2647908.2655970},
  ISBN                     = {9781450327398}
}

@InProceedings{TerBeek2014a,
  Title                    = {Using mCRL2 for the analysis of software product lines},
  Author                   = {{Ter Beek}, Maurice H. and {De Vink}, Erik P.},
  Year                     = {2014},
  Month                    = {jun},
  Pages                    = {31--37},
  Publisher                = {Association for Computing Machinery, Inc},

  Abstract                 = {We show how the formal specification language mCRL2 and its state-of-the-art toolset can be used successfully to model and analyze variability in software product lines. The mCRL2 toolset supports parametrized modeling, model reduction and quality assurance techniques like model checking. We present a proof-of-concept, which moreover illustrates the use of data in mCRL2 and also how to exploit its data language to manage feature attributes of software product lines and quantitative constraints between attributes and features.},
  Doi                      = {10.1145/2593489.2593493},
  ISBN                     = {9781450328531}
}

@InProceedings{TerBeek2015b,
  Title                    = {Applying the product lines paradigm to the quantitative analysis of collective adaptive systems},
  Author                   = {{Ter Beek}, Maurice H. and Fantechi, Alessandro and Gnesi, Stefania},
  Year                     = {2015},
  Month                    = {jul},
  Pages                    = {321--326},
  Publisher                = {Association for Computing Machinery},

  Abstract                 = {Engineering a Collective Adaptive System (CAS) requires the support of a framework for quantitative modeling and analysis of the system. In order to jointly address variability and quantitative analysis, we apply the Product Lines paradigm, considered at the level of system engineering, to a case study of the European project QUANTICOL, by first defining a reference feature model and then adding feature attributes and global quantitative constraints, in the form of a Clafer attributed feature model. ClaferMOOVisualizer is subsequently used for quantitative analyses and multiobjective optimization of the resulting attributed feature model.},
  Doi                      = {10.1145/2791060.2791100},
  ISBN                     = {9781450336130}
}

@Article{Thum2012,
  Title                    = {Analysis strategies for software product lines},
  Author                   = {Th{\"{u}}m, T and Apel, S and K{\"{a}}stner, C and Kuhlemann, M},
  Journal                  = {Sch. Comput.},
  Year                     = {2012},

  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.696.8877{\&}rep=rep1{\&}type=pdf}
}

@Article{Thum2014,
  Title                    = {A classification and survey of analysis strategies for software product lines},
  Author                   = {Th{\"{u}}m, Thomas and Apel, Sven and K{\"{a}}stner, Christian and Schaefer, Ina and Saake, Gunter},
  Journal                  = {ACM Computing Surveys (CSUR)},
  Year                     = {2014},
  Number                   = {1},
  Volume                   = {47},

  Abstract                 = {Software-product-line engineering has gained considerable momentum in recent years, both in industry and in academia. A software product line is a family of software products that share a common set of features. Software product lines challenge traditional analysis techniques, such as type checking, model checking, and theorem proving, in their quest of ensuring correctness and reliability of software. Simply creating and analyzing all products of a product line is usually not feasible, due to the potentially exponential number of valid feature combinations. Recently, researchers began to develop analysis techniques that take the distinguishing properties of software product lines into account, for example, by checking feature-related code in isolation or by exploiting variability information during analysis. The emerging field of productline analyses is both broad and diverse, so it is difficult for researchers and practitioners to understand their similarities and differences. We propose a classification of product-line analyses to enable systematic research and application. Based on our insights with classifying and comparing a corpus of 123 research articles, we develop a research agenda to guide future research on product-line analyses. {\textcopyright} 2014 ACM.},
  Doi                      = {10.1145/2580950},
  ISSN                     = {15577341},
  Publisher                = {Association for Computing Machinery}
}

@Article{Thum2014a,
  Title                    = {FeatureIDE: An extensible framework for feature-oriented software development},
  Author                   = {Th{\"{u}}m, T and K{\"{a}}stner, C and Benduhn, F and Meinicke, J},
  Journal                  = {Sci. Comput.},
  Year                     = {2014},

  Url                      = {http://www.sciencedirect.com/science/article/pii/S0167642312001128}
}

@InProceedings{Thum2011,
  Title                    = {Abstract features in feature modeling},
  Author                   = {Th{\"{u}}m, Thomas and K{\"{a}}stner, Christian and Erdweg, Sebastian and Siegmund, Norbert},
  Year                     = {2011},
  Pages                    = {191--200},

  Abstract                 = {A software product line is a set of program variants, typically generated from a common code base. Feature models describe variability in product lines by documenting features and their valid combinations. In product-line engineering, we need to reason about variability and program variants for many different tasks. For example, given a feature model, we might want to determine the number of all valid feature combinations or compute specific feature combinations for testing. However, we found that contemporary reasoning approaches can only reason about feature combinations, not about program variants, because they do not take abstract features into account. Abstract features are features used to structure a feature model that, however, do not have any impact at implementation level. Using existing feature-model reasoning mechanisms for program variants leads to incorrect results. Hence, although abstract features represent domain decisions that do not affect the generation of a program variant. We raise awareness of the problem of abstract features for different kinds of analyses on feature models. We argue that, in order to reason about program variants, abstract features should be made explicit in feature models. We present a technique based on propositional formulas that enables to reason about program variants rather than feature combinations. In practice, our technique can save effort that is caused by considering the same program variant multiple times, for example, in product-line testing. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/SPLC.2011.53},
  ISBN                     = {9780769544878}
}

@InProceedings{Thuem2012,
  Title                    = {Applying design by contract to feature-oriented programming},
  Author                   = {Th{\"{u}}m, Thomas and Schaefer, Ina and Kuhlemann, Martin and Apel, Sven and Saake, Gunter},
  Year                     = {2012},
  Pages                    = {255--269},
  Volume                   = {7212 LNCS},

  Abstract                 = {Feature-oriented programming (FOP) is an extension of ob- ject-oriented programming to support software variability by refining existing classes and methods. In order to increase the reliability of all implemented program variants, we integrate design by contract (DbC) with FOP. DbC is an approach to build reliable object-oriented software by specifying methods with contracts. Contracts are annotations that document and formally specify behavior, and can be used for formal verification of correctness or as test oracles. We present and discuss five approaches to define contracts of methods and their refinements in FOP. Furthermore, we share our insights gained by performing five case studies. This work is a foundation for research on the analysis of feature-oriented programs (e.g., for verifying functional correctness or for detecting feature interactions). {\textcopyright} 2012 Springer-Verlag Berlin Heidelberg.},
  Doi                      = {10.1007/978-3-642-28872-2_18},
  ISBN                     = {9783642288715},
  ISSN                     = {03029743}
}

@InProceedings{Thum2016,
  Title                    = {Variability hiding in contracts for dependent software product lines},
  Author                   = {Th{\"{u}}m, Thomas and Winkelmann, Tim and Schr{\"{o}}ter, Reimar and Hentschel, Martin and Kr{\"{u}}ger, Stefan},
  Year                     = {2016},
  Month                    = {jan},
  Pages                    = {97--104},
  Publisher                = {Association for Computing Machinery},

  Abstract                 = {Software product lines are used to efficiently develop and verify similar software products. While they focus on reuse of artifacts between products, a product line may also be reused itself in other product lines. A challenge with such dependent product lines is evolution; every change in a product line may inuence all dependent product lines. With variability hiding, we aim to hide certain features and their artifacts in dependent product lines. In prior work, we focused on feature models and implementation artifacts. We build on this by discussing how variability hiding can be extended to specifications in terms of method contracts. We illustrate variability hiding in contracts by means of a running example and share our insights with preliminary experiments on the benefits for formal verification. In particular, we find that not every change in a certain product line requires a re-verification of other dependent product lines.},
  Doi                      = {10.1145/2866614.2866628},
  ISBN                     = {9781450340199}
}

@InProceedings{Thum2011a,
  Title                    = {Proof composition for deductive verification of software product lines},
  Author                   = {Thum, Thomas and Schaefer, Ina and Kuhlemann, Martin and Apel, Sven},
  Year                     = {2011},
  Pages                    = {270--277},

  Abstract                 = {Software product line engineering aims at the efficient development of program variants that share a common set of features and that differ in other features. Product lines can be efficiently developed using feature-oriented programming. Given a feature selection and the code artifacts for each feature, program variants can be generated automatically. The quality of the program variants can be rigorously ensured by formal verification. However, verification of all program variants can be expensive and include redundant verification tasks. We introduce a classification of existing software product line verification approaches and propose proof composition as a novel approach. Proof composition generates correctness proofs of each program variant based on partial proofs of each feature. We present a case study to evaluate proof composition and demonstrate that it reduces the effort for verification. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/ICSTW.2011.48},
  ISBN                     = {9780769543451}
}

@InProceedings{Tiihonen2016,
  Title                    = {Carrying ideas from knowledge-based configuration to software product lines},
  Author                   = {Tiihonen, Juha and Raatikainen, Mikko and Myll{\"{a}}rniemi, Varvana and M{\"{a}}nnist{\"{o}}, Tomi},
  Year                     = {2016},
  Pages                    = {55--62},
  Publisher                = {Springer Verlag},
  Volume                   = {9679},

  Abstract                 = {Software variability modelling (SVM) has become a central concern in software product lines - especially configurable software product lines (CSPL) require rigorous SVM. Dynamic SPLs, service oriented SPLs, and autonomous or pervasive systems are examples where CSPLs are applied. Knowledge-based configuration (KBC) is an established way to address variability modelling aiming for the automatic product configuration of physical products. Our aim was to study what major ideas from KBC can be applied to SVM, particularly in the context of CSPLs. Our main contribution is the identification of major ideas from KBC that could be applied to SVM. First, we call for the separation of types and instances. Second, conceptual clarity of modelling concepts, e.g., having both taxonomical and compositional relations would be useful. Third, we argue for the importance of a conceptual basis that provides a foundation for multiple representations, e.g., graphical and textual. Applying the insights and experiences embedded in these ideas may help in the development of modelling support for software product lines, particularly in terms of conceptual clarity and as a basis for tool support with a high level of automation.},
  Doi                      = {10.1007/978-3-319-35122-3_4},
  ISBN                     = {9783319351216},
  ISSN                     = {16113349}
}

@InProceedings{Tizzei2012,
  Title                    = {An aspect-based feature model for architecting component product lines},
  Author                   = {Tizzei, Leonardo P. and Rubira, Cec{\'{i}}lia M F and Lee, Jaejoon},
  Year                     = {2012},
  Pages                    = {85--92},

  Abstract                 = {Feature modeling is widely used for software product line analysis to capture commonality and variability of a product line. As product line variations are mainly captured in a feature model, the mapping between features and architectural components is essential to enable the derivation of product architectures from the feature model. However, current SPL architecture design approaches that map features to architectural components do not model crosscutting concerns explicitly either at a feature model or at product line architecture design. We propose a feature-oriented solution with aspects for product line architecture design aiming at improving product line architecture evolvability by adopting aspect-oriented techniques, which provide a promising support for modeling crosscutting concerns. Our approach includes guidelines for developing and refining SPL requirements into component-based product line architecture with aspects. We evaluated our approach through a preliminary evaluation which has shown promising results. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/SEAA.2012.64},
  ISBN                     = {9780769547909}
}

@InProceedings{Tran2014,
  Title                    = {An approach for decision support on the uncertainty in feature model evolution},
  Author                   = {Tran, Le Minh Sang and Massacci, Fabio},
  Year                     = {2014},
  Month                    = {sep},
  Pages                    = {93--102},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {Software systems could be seen as a hierarchy of features which are evolving due to the dynamic of the working environments. The companies who build software thus need to make an appropriate strategy, which takes into consideration of such dynamic, to select features to be implemented. In this work, we propose an approach to facilitate such selection by providing a means to capture the uncertainty of evolution in feature models. We also provide two analyses to support the decision makers. The approach is exemplified in the Smart Grid scenario.},
  Doi                      = {10.1109/RE.2014.6912251},
  ISBN                     = {9781479930333}
}

@InCollection{Turner2013,
  Title                    = {Building a cloud-based mobile application testbed},
  Author                   = {Turner, Hamilton and White, Jules and Reed, Jeff and Galindo, Jos{\'{e}} and Porter, Adam and Marathe, Madhav and Vullikanti, Anil and Gokhale, Aniruddha},
  Publisher                = {IGI Global},
  Year                     = {2013},
  Month                    = {feb},
  Pages                    = {879--899},
  Volume                   = {2-3},

  Abstract                 = {A proliferation of mobile smartphone platforms, including Android devices, has triggered a rise in mobile application development for a diverse set of situations. Testing of these smartphone applications can be exceptionally difficult, due to the challenges of orchestrating production-scale quantities of smartphones such as difficulty in managing thousands of sensory inputs to each individual smartphone device. This work presents the Android Tactical Application Assessment and Knowledge (ATAACK) Cloud, which utilizes a cloud computing environment to allow smartphone-based security, sensing, and social networking researchers to rapidly use model-based tools to provision experiments with a combination of 1,000+ emulated smartphone instances and tens of actual devices. The ATAACK Cloud provides a large-scale smartphone application research testbed.},
  Doi                      = {10.4018/978-1-4666-2919-6.ch040},
  ISBN                     = {9781466629202}
}

@InProceedings{Urli2014,
  Title                    = {Managing a software ecosystem using a multiple software product line: A case study on digital signage systems},
  Author                   = {Urli, Simon and Blay-Fornarino, Mireille and Collet, Philippe and Mosser, Sebastien and Riveill, Michel},
  Year                     = {2014},
  Month                    = {oct},
  Pages                    = {344--351},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {With the advent of Web 2.0, the growth of developer teams and user communities increases the number of software ecosystems: software platforms developed and maintained in a decentralized way by external contributors. As complexity grows, these large software systems become more and more complex to manage and to adapt to specific user needs. In this paper, we report on a case study on the development of a digital signage software system called Your Cast. Based on several years experience evolving Your Cast from a single system to a medium-scale ecosystem, we show how organizing it as a multiple software product line helps in organizing the software platform, taming some management tasks for a growing community, and giving more capabilities to final users to build their own products.},
  Doi                      = {10.1109/SEAA.2014.23},
  ISBN                     = {9781479957941}
}

@InProceedings{Urli2013,
  Title                    = {How to exploit domain knowledge in Multiple Software Product Lines?},
  Author                   = {Urli, Simon and Mosser, S{\'{e}}bastien and Blay-Fornarino, Mireille and Collet, Philippe},
  Year                     = {2013},
  Pages                    = {13--16},

  Abstract                 = {As Software Product Lines (SPL) are inevitably moving towards a multiple form to tackle issues of reuse and complexity, variability management across the composed SPLs is still addressed with basic inter-constraints. Based on two disjoint case studies (digital signage and cloud computing), we identified this challenging problem for the SPL community. In this paper we describe how the domain knowledge needs to be exploited to support a more complete definition of Multiple Software Product Lines (MSPL). Such an exploitation implies the definition of a domain-driven definition of configuration and an order independent configuration process. {\textcopyright} 2013 IEEE.},
  Doi                      = {10.1109/PLEASE.2013.6608656},
  ISBN                     = {9781467364492}
}

@InProceedings{Varela2011,
  Title                    = {Aspect-oriented analysis for software product lines requirements engineering},
  Author                   = {Varela, Patr{\'{i}}cia and Ara{\'{u}}jo, Jo{\~{a}}o and Brito, Isabel and Moreira, Ana},
  Year                     = {2011},
  Pages                    = {667--674},

  Abstract                 = {Requirements analysis and modeling for Software Product Lines demands the use of feature models, but also requires additional models to help identifying, describing, and specifying features. Traditional approaches usually perform this manually and, in general, the identification and modularization of crosscutting features is ignored, or not handled systematically. This hinders requirements change. We propose an aspect-oriented approach for SPL enriched to automatically derive feature models where crosscutting features are identified and modularized using aspect-oriented concepts and techniques. This is achieved by adapting and extending the AORA (Aspect-Oriented Requirements Analysis) approach. AORA provides templates to specify and organize requirements based on concerns and responsibilities. A set of heuristics is defined to help identifying features and their dependencies in a product line. A tool was developed to automatically generate the feature model from AORA templates. {\textcopyright} 2011 ACM.},
  Doi                      = {10.1145/1982185.1982333},
  ISBN                     = {9781450301138}
}

@Article{Varela-Vaca2013,
  Title                    = {Towards the automatic and optimal selection of risk treatments for business processes using a constraint programming approach},
  Author                   = {Varela-Vaca, Angel Jesus and Gasca, Rafael M.},
  Year                     = {2013},

  Month                    = {nov},
  Number                   = {11},
  Pages                    = {1948--1973},
  Volume                   = {55},

  Abstract                 = {Context The use of Business Process Management Systems (BPMS) has emerged in the IT arena for the automation of business processes. In the majority of cases, the issue of security is overlooked by default in these systems, and hence the potential cost and consequences of the materialization of threats could produce catastrophic loss for organizations. Therefore, the early selection of security controls that mitigate risks is a real and important necessity. Nevertheless, there exists an enormous range of IT security controls and their configuration is a human, manual, time-consuming and error-prone task. Furthermore, configurations are carried out separately from the organization perspective and involve many security stakeholders. This separation makes difficult to ensure the effectiveness of the configuration with regard to organizational requirements. Objective In this paper, we strive to provide security stakeholders with automated tools for the optimal selection of IT security configurations in accordance with a range of business process scenarios and organizational multi-criteria. Method An approach based on feature model analysis and constraint programming techniques is presented, which enable the automated analysis and selection of optimal security configurations. Results A catalogue of feature models is determined by analyzing typical IT security controls for BPMSs for the enforcement of the standard goals of security: integrity, confidentiality, availability, authorization, and authentication. These feature models have been implemented through constraint programs, and Constraint Programming techniques based on optimized and non-optimized searches are used to automate the selection and generation of configurations. In order to compare the results of the determination of configuration a comparative analysis is given. Conclusion In this paper, we present innovative tools based on feature models, Constraint Programming and multi-objective techniques that enable the agile, adaptable and automatic selection and generation of security configurations in accordance with the needs of the organization. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.infsof.2013.05.007},
  ISSN                     = {09505849}
}

@Article{Varshosaz2013,
  Title                    = {Discrete time Markov chain families: modeling and verification of probabilistic software product lines},
  Author                   = {Varshosaz, M and Khosravi, R},
  Journal                  = {17th Int. Softw. Prod. {\ldots}},
  Year                     = {2013},

  Url                      = {http://dl.acm.org/citation.cfm?id=2500725}
}

@Article{Vasconcelos2014,
  Title                    = {An information visualization feature model for supporting the selection of software visualizations},
  Author                   = {Vasconcelos, R and Schots, M and Werner, C},
  Journal                  = {Proc. 22nd},
  Year                     = {2014},

  Url                      = {http://dl.acm.org/citation.cfm?id=2597796}
}

@Article{Vidal2016,
  Title                    = {Mixing of Join Point Interfaces and Feature-Oriented Programming for Modular Software Product Line},
  Author                   = {Vidal, C and Benavides, D and Leger, P and Galindo, J},
  Journal                  = {Proc. 9th},
  Year                     = {2016},

  Url                      = {http://dl.acm.org/citation.cfm?id=2954813}
}

@InProceedings{Vierhauser2010,
  Title                    = {Flexible and scalable consistency checking on product line variability models},
  Author                   = {Vierhauser, Michael and Gr{\"{u}}nbacher, Paul and Egyed, Alexander and Rabiser, Rick and Heider, Wolfgang},
  Year                     = {2010},
  Pages                    = {63--72},

  Abstract                 = {The complexity of product line variability models makes it hard to maintain their consistency over time regardless of the modeling approach used. Engineers thus need support for detecting and resolving inconsistencies. We describe experiences of applying a tool-supported approach for incremental consistency checking on variability models. Our approach significantly improves the overall performance and scalability compared to batch-oriented techniques and allows providing immediate feedback to modelers. It is extensible as new consistency constraints can easily be added. Furthermore, the approach is flexible as it is not limited to variability models and it also checks the consistency of the models with the underlying code base of the product line. We report the results of a thorough evaluation based on real-world product line models and discuss lessons learned. {\textcopyright} 2010 ACM.},
  Doi                      = {10.1145/1858996.1859009},
  ISBN                     = {9781450301169}
}

@Article{Vijaya2016,
  Title                    = {A model driven framework for portable cloud services},
  Author                   = {Vijaya, Aparna and Neelanarayanan, V.},
  Year                     = {2016},

  Month                    = {apr},
  Number                   = {2},
  Pages                    = {708--716},
  Volume                   = {6},

  Abstract                 = {Cloud Computing is an evolving technology as it offers significant benefits like pay only for what you use, scale the resources according to the needs and less in-house staff and resources. These benefits have resulted in tremendous increase in the number of applications and services hosted in the cloud which inturn has resulted in increase in the number of cloud providers in the market. Cloud service providers have a lot of heterogeneity in the resources they use. They have their own servers, different cloud infrastructures, API's and methods to access the cloud resources. Despite its benefits; lack of standards among service providers has caused a high level of vendor lock-in when a software developer tries to change its cloud provider. In this paper we give an overview on the ongoing and current trends in the area of cloud service portability and we also propose a new cloud portability platform. Our new platform is based on establishing feature models which offers the desired cloud portability. Our solution DSkyL uses feature models and domain model analysis to support development, customization and deployment of application components across multiple clouds. The main goal of our approach is to reduce the effort and time needed for porting applications across different clouds. This paper aims to give an overview on DSkyL.},
  Doi                      = {10.11591/ijece.v6i1.8270},
  ISSN                     = {20888708},
  Publisher                = {Institute of Advanced Engineering and Science}
}

@InProceedings{VonRhein2015,
  Title                    = {Presence-condition simplification in highly configurable systems},
  Author                   = {{Von Rhein}, Alexander and Grebhahn, Alexander and Apel, Sven and Siegmund, Norbert and Beyer, Dirk and Berger, Thorsten},
  Year                     = {2015},
  Month                    = {aug},
  Pages                    = {178--188},
  Publisher                = {IEEE Computer Society},
  Volume                   = {1},

  Abstract                 = {For the analysis of highly configurable systems, analysis approaches need to take the inherent variability of these systems into account. The notion of presence conditions is central to such approaches. A presence condition specifies a subset of system configurations in which a certain artifact or a concern of interest is present (e.g., a defect associated with this subset). In this paper, we introduce and analyze the problem of presence-condition simplification. A key observation is that presence conditions often contain redundant information, which can be safely removed in the interest of simplicity and efficiency. We present a formalization of the problem, discuss application scenarios, compare different algorithms for solving the problem, and empirically evaluate the algorithms by means of a set of substantial case studies.},
  Doi                      = {10.1109/ICSE.2015.39},
  ISBN                     = {9781479919345},
  ISSN                     = {02705257}
}

@Article{Wanderley2012,
  Title                    = {Generating feature model from creative requirements using model driven design},
  Author                   = {Wanderley, F and da Silveira, DS and Araujo, J},
  Journal                  = {Proc. 16th},
  Year                     = {2012},

  Url                      = {http://dl.acm.org/citation.cfm?id=2364416}
}

@InProceedings{Wang2010,
  Title                    = {A dynamic-priority based approach to fixing inconsistent feature models},
  Author                   = {Wang, Bo and Xiong, Yingfei and Hu, Zhenjiang and Zhao, Haiyan and Zhang, Wei and Mei, Hong},
  Booktitle                = {International Conference on Model Driven Engineering Languages and Systems (MODELS)},
  Year                     = {2010},
  Number                   = {PART 1},
  Pages                    = {181--195},
  Volume                   = {6394 LNCS},

  Abstract                 = {In feature models' construction, one basic task is to ensure the consistency of feature models, which often involves detecting and fixing of inconsistencies in feature models. Several approaches have been proposed to detect inconsistencies, but few focus on the problem of fixing inconsistent feature models. In this paper, we propose a dynamic-priority based approach to fixing inconsistent feature models, with the purpose of helping domain analysts find solutions to inconsistencies efficiently. The basic idea of our approach is to first recommend a solution automatically, then gradually reach the desirable solution by dynamically adjusting priorities of constraints. To this end, we adopt the constraint hierarchy theory to express the degree of domain analysts' confidence on constraints (i.e. the priorities of constraints) and resolve inconsistencies among constraints. Two case studies have been conducted to demonstrate the usability and scalability of our approach. {\textcopyright} 2010 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-16145-2_13},
  ISBN                     = {3642161448},
  ISSN                     = {03029743}
}

@InProceedings{Wang2013,
  Title                    = {Developing a holistic modeling approach for search-based system architecting},
  Author                   = {Wang, Renzhong and Dagli, Cihan H.},
  Year                     = {2013},
  Pages                    = {206--215},
  Volume                   = {16},

  Abstract                 = {This paper proposes a holistic modeling approach that combines the capabilities of Object Process Methodology (OPM), Colored Petri Net (CPN), and feature model. The resultant holistic model not only can capture the structural, behavioral, and dynamic aspects of a system, allowing simulation and strong analysis methods to be applied, it can also specify the architectural design space. This modeling approach is developed to facilitate the implementation of search-based system architecting where search algorithms are used to explore design trade space for good architecture alternatives. Such architecting approach integrates certain model construction, alternative generation, simulation, and assessment processes into a coherent and automated framework. Both the proposed holistic modeling approach and the search-based architecting framework are generic. They are targeted at systems that can be specified by conceptual models using object-oriented or process-oriented paradigms. The broad applicability of the proposed approach is demonstrated with the configuration of reconfigurable manufacturing systems (RMSs) under multiobjective optimization as an example. The test results showed that the proposed modeling approach could cover a huge number of architecture alternatives and supported the assessment of several performance measures. A set of quality results was obtained after running the optimization algorithm following the proposed search-based architecting framework. {\textcopyright} 2013 The authors. Published by Elsevier B.V.},
  Doi                      = {10.1016/j.procs.2013.01.022},
  ISSN                     = {18770509}
}

@InProceedings{Wang2012,
  Title                    = {Computational System Architecture Development Using a Holistic Modeling Approach},
  Author                   = {Wang, Renzhong and Dagli, Cihan H.},
  Year                     = {2012},
  Pages                    = {13--20},
  Publisher                = {Elsevier},
  Volume                   = {12},

  Abstract                 = {This paper presents an innovative system architecture development framework that allows the search of optimum architecture solutions within large design space by automating certain model construction, alternative generation, simulation, and assessment tasks. Such framework is facilitated by a holistic modeling approach that combines the capabilities of Object Process Methodology (OPM), Colored Petri Net (CPN) and feature model. The resultant holistic model not only can capture the structural, behavior, and dynamic aspects of a system, allowing strong analysis methods to be applied, but also can specify the architectural design space allowing generation of architecture alternatives that cover it. The proposed framework and suggested implementation is generic targeted at systems that can be specified by logic models using object-oriented paradigm. A partial implementation of the proposed approaches is presented with the design of reconfigurable manufacturing systems (RMSs) as an example, which is formulated as a multi-objective optimization problem with the Genetic Algorithm (GA, particularly, NSGA-2) as the search algorithm. The RMS is a multi-part flow line structure with identical machines in each production stage. {\textcopyright} 2012 Published by Elsevier B.V.},
  Doi                      = {10.1016/j.procs.2012.09.023},
  ISSN                     = {18770509}
}

@Article{Wang2015a,
  Title                    = {Cost-effective test suite minimization in product lines using search techniques},
  Author                   = {Wang, Shuai and Ali, Shaukat and Gotlieb, Arnaud},
  Year                     = {2015},
  Number                   = {C},
  Pages                    = {370--391},
  Volume                   = {103},

  Abstract                 = {Cost-effective testing of a product in a product line requires obtaining a set of relevant test cases from the entire test suite via test selection and minimization techniques. In this paper, we particularly focus on test minimization for product lines, which identifies and eliminates redundant test cases from test suites in order to reduce the total number of test cases to execute, thereby improving the efficiency of testing. However, such minimization may result in the minimized test suite with low test coverage, low fault revealing capability, low priority test cases, and require more time than the allowed testing budget (e.g., time) as compared to the original test suite. To deal with the above issues, we formulated the minimization problem as a search problem and defined a fitness function considering various optimization objectives based on the above issues. To assess the performance of our fitness function, we conducted an extensive empirical evaluation by investigating the fitness function with three weight-based Genetic Algorithms (GAs) and seven multi-objective search algorithms using an industrial case study and 500 artificial problems inspired from the industrial case study. The results show that Random-Weighted Genetic Algorithm (RWGA) significantly outperforms the other algorithms since RWGA can balance all the objectives together by dynamically updating weights during each generation. Based on the results of our empirical evaluation, we also implemented a tool called TEst Minimization using Search Algorithms (TEMSA) to support test minimization using various search algorithms in the context of product lines.},
  Doi                      = {10.1016/jjss.2014.08.024},
  ISSN                     = {01641212},
  Publisher                = {Elsevier Inc.}
}

@InProceedings{Wang2013a,
  Title                    = {Minimizing test suites in software product lines using weight-based genetic algorithms},
  Author                   = {Wang, Shuai and Ali, Shaukat and Gotlieb, Arnaud},
  Year                     = {2013},
  Pages                    = {1493--1500},

  Abstract                 = {Test minimization techniques aim at identifying and eliminating redundant test cases from test suites in order to reduce the total number of test cases to execute, thereby improving the efficiency of testing. In the context of software product line, we can save effort and cost in the selection and minimization of test cases for testing a specific product by modeling the product line. However, minimizing the test suite for a product requires addressing two potential issues: 1) the minimized test suite may not cover all test requirements compared with the original suite; 2) the minimized test suite may have less fault revealing capability than the original suite. In this paper, we apply weight-based Genetic Algorithms (GAs) to minimize the test suite for testing a product, while preserving fault detection capability and testing coverage of the original test suite. The challenge behind is to define an appropriate fitness function, which is able to preserve the coverage of complex testing criteria (e.g., Combinatorial Interaction Testing criterion). Based on the defined fitness function, we have empirically evaluated three different weight-based GAs on an industrial case study provided by Cisco Systems, Inc. Norway. We also presented our results of applying the three weight-based GAs on five existing case studies from the literature. Based on these case studies, we conclude that among the three weight-based GAs, Random-Weighted GA (RWGA) achieved significantly better performance than the other ones. Copyright {\textcopyright} 2013 ACM.},
  Doi                      = {10.1145/2463372.2463545},
  ISBN                     = {9781450319638}
}

@Misc{Wang2016,
  Title                    = {A systematic test case selection methodology for product lines: results and insights from an industrial case study},

  Author                   = {Wang, Shuai and Ali, Shaukat and Gotlieb, Arnaud and Liaaen, Marius},
  Month                    = {aug},
  Year                     = {2016},

  Abstract                 = {In the context of product lines, test case selection aims at obtaining a set of relevant test cases for a product from the entire set of test cases available for a product line. While working on a research-based innovation project on automated testing of product lines of Video Conferencing Systems (VCSs) developed by Cisco, we felt the need to devise a cost-effective way of selecting relevant test cases for a product. To fulfill such need, we propose a systematic and automated test selection methodology using: 1) Feature Model for Testing (FM{\_}T) to capture commonalities and variabilities of a product line; 2) Component Family Model for Testing (CFM{\_}T) to model the structure of test case repository; 3) A tool to automatically build restrictions from CFM{\_}T to FM{\_}T and traces from CFM{\_}T to the actual test cases. Using our methodology, a test engineer is only required to select relevant features through FM{\_}T at a higher level of abstraction for a product and the corresponding test cases will be obtained automatically. We evaluate our methodology by applying it to a VCS product line called Saturn with seven commercial products and the results show that our methodology can significantly reduce cost measured as test selection time and at the same time achieves higher effectiveness (feature coverage, feature pairwise coverage and fault detection) as compared with the current manual process. Moreover, we conduct a questionnaire-based study to solicit the views of test engineers who are involved in developing FM{\_}T and CFM{\_}T. The results show that test engineers are positive about adapting our methodology in their current practice. Finally, we present a set of lessons learnt while applying product line engineering at Cisco for test case selection.},
  Doi                      = {10.1007/s10664-014-9345-5},
  ISSN                     = {15737616},
  Number                   = {4},
  Pages                    = {1586--1622},
  Publisher                = {Springer New York LLC},
  Volume                   = {21}
}

@Misc{Wang2015,
  Title                    = {Automated product line test case selection: industrial case study and controlled experiment},

  Author                   = {Wang, Shuai and Ali, Shaukat and Gotlieb, Arnaud and Liaaen, Marius},
  Month                    = {apr},
  Year                     = {2015},

  Abstract                 = {Automated test case selection for a new product in a product line is challenging due to several reasons. First, the variability within the product line needs to be captured in a systematic way; second, the reusable test cases from the repository are required to be identified for testing a new product. The objective of such automated process is to reduce the overall effort for selection (e.g., selection time), while achieving an acceptable level of the coverage of testing functionalities. In this paper, we propose a systematic and automated methodology using a feature model for testing (FM{\_}T) to capture commonalities and variabilities of a product line and a component family model for testing (CFM{\_}T) to capture the overall structure of test cases in the repository. With our methodology, a test engineer does not need to manually go through the repository to select a relevant set of test cases for a new product. Instead, a test engineer only needs to select a set of relevant features using FM{\_}T at a higher level of abstraction for a product and a set of relevant test cases will be selected automatically. We evaluated our methodology via three different ways: (1) We applied our methodology to a product line of video conferencing systems called Saturn developed by Cisco, and the results show that our methodology can reduce the selection effort significantly; (2) we conducted a questionnaire-based study to solicit the views of test engineers who were involved in developing FM{\_}T and CFM{\_}T. The results show that test engineers are positive about adapting our methodology and models (FM{\_}T and CFM{\_}T) in their current practice; (3) we conducted a controlled experiment with 20 graduate students to assess the performance (i.e., cost, effectiveness and efficiency) of our automated methodology as compared to the manual approach. The results showed that our methodology is cost-effective as compared to the manual approach, and at the same time, its efficiency is not affected by the increased complexity of products.},
  Doi                      = {10.1007/s10270-015-0462-4},
  ISSN                     = {16191374},
  Publisher                = {Springer Verlag}
}

@InProceedings{Wang2013b,
  Title                    = {Automated test case selection using feature model: An industrial case study},
  Author                   = {Wang, Shuai and Gotlieb, Arnaud and Ali, Shaukat and Liaaen, Marius},
  Year                     = {2013},
  Pages                    = {237--253},
  Volume                   = {8107 LNCS},

  Abstract                 = {Automated test case selection for a new product in a product line is challenging due to several reasons. First, the variability within the product line needs to be captured in a systematic way; second, the reusable test cases from the repository are required to be identified for testing a new product. The objective of such automated process is to reduce the overall effort for selection (e.g., selection time), while achieving an acceptable level of the coverage of testing functionalities. In this paper, we propose a systematic and automated methodology using a Feature Model for Testing (FM-T) to capture commonalities and variabilities of a product line and a Component Family Model for Testing (CFM-T) to capture the overall structure of test cases in the repository. With our methodology, a test engineer does not need to manually go through the repository to select a relevant set of test cases for a new product. Instead, a test engineer only needs to select a set of relevant features using FM-T at a higher level of abstraction for a product and a set of relevant test cases will be selected automatically. We applied our methodology to a product line of video conferencing systems called Saturn developed by Cisco and the results show that our methodology can reduce the selection effort significantly. Moreover, we conducted a questionnaire-based study to solicit the views of test engineers who were involved in developing FM-T and CFM-T. The results show that test engineers are positive about adapting our methodology and models (FM-T and CFM-T) in their current practice. {\textcopyright} 2013 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-41533-3_15},
  ISBN                     = {9783642415326},
  ISSN                     = {03029743}
}

@InProceedings{Wang2012a,
  Title                    = {Automatic selection of test execution plans from a video conferencing system product line},
  Author                   = {Wang, Shuai and Gotlieb, Arnaud and Liaaen, Marius and Briand, Lionel C.},
  Year                     = {2012},
  Pages                    = {32--37},

  Abstract                 = {The Cisco Video Conferencing Systems (VCS) Product Line is composed of many distinct products that can be configured in many different ways. The validation of this product line is currently performed manually during test plan design and test executions' scheduling. For example, the testing of a specific VCS product leads to the manual selection of a set of test cases to be executed and scheduled, depending on the functionalities that are available on the product. In this paper, we develop an alternative approach where the variability of the VCS Product Line is captured by a feature model, while the variability within the set of test cases is captured by a component family model. Using the well-known pure::variants tool approach that establishes links between those two models through restrictions, we can obtain relevant test cases automatically for the testing of a new VCS product. The novelty in this paper lies in the design of a large component family model that organizes a complex test cases structure. We envision a large gain in terms of man-power when a new product is issued and needs to be tested before being marketed. {\textcopyright} 2012 ACM.},
  Doi                      = {10.1145/2425415.2425422},
  ISBN                     = {9781450318099}
}

@InProceedings{Wang2010b,
  Title                    = {Research on method of virtual modeling based on reconstruction of virtual assembly feature},
  Author                   = {Wang, Tao and Yan, Qing Dong and Li, Hong Cai},
  Year                     = {2010},
  Pages                    = {1295--1300},

  Abstract                 = {According to the concept and characteristics of virtual assembly feature, reconstruction method of virtual assembly feature model is proposed. Using the secondary development tools provided by ProEngineer, namely, ToolKit, getting assembly information is implemented. Based on analysis about three kinds mapping methods between the geometric elements and triangulated patches, an complete information model of virtual assembly features is established that regard model information database as underlying data to support, and finally, virtual assembly modeling method of a certain type of hydraulic torque converter in the transmission system is taken as an example to be verified. {\textcopyright}2010 IEEE.},
  Doi                      = {10.1109/ICALIP.2010.5685085},
  ISBN                     = {9781424458653}
}

@InProceedings{Wang2010a,
  Title                    = {Multi-class target recognition based on adaptive feature selection},
  Author                   = {Wang, Yuehuan and Yao, Wei and Song, Yunfeng and Sang, Nong and Zhang, Tianxu},
  Year                     = {2010},
  Volume                   = {7696},

  Abstract                 = {In this paper, a new approach of multi-class target recognition is proposed for remote sensing image analysis. A multi-class feature model is built, which is based on sharing features among classes. In order to make the recognition process efficient, we adopted the idea of adaptive feature selection. In each layer of the integrated feature model, the most salient and stable feature are selected first, and then the less ones. Experiments demonstrated the approach proposed is efficient in computation and is adaptive to scene variation. {\textcopyright} 2010 SPIE.},
  Doi                      = {10.1117/12.850649},
  ISBN                     = {9780819481603},
  ISSN                     = {0277786X}
}

@InProceedings{Weckesser2016,
  Title                    = {Mind the gap! automated anomaly detection for potentially unbounded cardinality-based feature models},
  Author                   = {Weckesser, Markus and Lochau, Malte and Schnabel, Thomas and Richerzhagen, Bj{\"{o}}rn and Sch{\"{u}}rr, Andy},
  Year                     = {2016},
  Pages                    = {158--175},
  Publisher                = {Springer Verlag},
  Volume                   = {9633},

  Abstract                 = {Feature models are frequently used for specifying variability of user-configurable software systems, e.g., software product lines. Numerous approaches have been developed for automating feature model validation concerning constraint consistency and absence of anomalies. As a crucial extension to feature models, cardinality annotations and respective constraints allow for multiple, and even potentially unbounded occurrences of feature instances within configurations. This is of particular relevance for user-adjustable application resources as prevalent, e.g., in cloud computing. However, a precise semantic characterization and tool support for automated and scalable validation of cardinality-based feature models is still an open issue. In this paper, we present a comprehensive formalization of cardinality-based feature models with potentially unbounded feature multiplicities. We apply a combination of ILP and SMT solvers to automate consistency checking and anomaly detection, including novel anomalies, e.g., interval gaps.We present evaluation results gained from our tool implementation showing applicability and scalability to larger-scale models.},
  Doi                      = {10.1007/978-3-662-49665-7_10},
  ISBN                     = {9783662496640},
  ISSN                     = {16113349}
}

@Article{White2010,
  Title                    = {Automated diagnosis of feature model configurations},
  Author                   = {White, J. and Benavides, D. and Schmidt, D. C. and Trinidad, P. and Dougherty, B. and Ruiz-Cortes, A.},
  Year                     = {2010},

  Month                    = {jul},
  Number                   = {7},
  Pages                    = {1094--1107},
  Volume                   = {83},

  Abstract                 = {Software product-lines (SPLs) are software platforms that can be readily reconfigured for different project requirements. A key part of an SPL is a model that captures the rules for reconfiguring the software. SPLs commonly use feature models to capture SPL configuration rules. Each SPL configuration is represented as a selection of features from the feature model. Invalid SPL configurations can be created due to feature conflicts introduced via staged or parallel configuration or changes to the constraints in a feature model. When invalid configurations are created, a method is needed to automate the diagnosis of the errors and repair the feature selections. This paper provides two contributions to research on automated configuration of SPLs. First, it shows how configurations and feature models can be transformed into constraint satisfaction problems to automatically diagnose errors and repair invalid feature selections. Second, it presents empirical results from diagnosing configuration errors in feature models ranging in size from 100 to 5,000 features. The results of our experiments show that our CSP-based diagnostic technique can scale up to models with thousands of features. {\textcopyright} 2010 Elsevier Inc. All rights reserved.},
  Doi                      = {10.1016/j.jss.2010.02.017},
  ISSN                     = {01641212}
}

@Article{White2009,
  Title                    = {Automated reasoning for multi-step feature model configuration problems},
  Author                   = {White, J and Dougherty, B and Schmidt, DC},
  Journal                  = {Proc. 13th},
  Year                     = {2009},

  Url                      = {http://dl.acm.org/citation.cfm?id=1753238}
}

@Article{White2014,
  Title                    = {Evolving feature model configurations in software product lines},
  Author                   = {White, Jules and Galindo, Jose A. and Saxena, Tripti and Dougherty, Brian and Benavides, David and Schmidt, Douglas C.},
  Year                     = {2014},

  Month                    = {jan},
  Number                   = {1},
  Pages                    = {119--136},
  Volume                   = {87},

  Abstract                 = {The increasing complexity and cost of software-intensive systems has led developers to seek ways of reusing software components across development projects. One approach to increasing software reusability is to develop a software product-line (SPL), which is a software architecture that can be reconfigured and reused across projects. Rather than developing software from scratch for a new project, a new configuration of the SPL is produced. It is hard, however, to find a configuration of an SPL that meets an arbitrary requirement set and does not violate any configuration constraints in the SPL. Existing research has focused on techniques that produce a configuration of an SPL in a single step. Budgetary constraints or other restrictions, however, may require multi-step configuration processes. For example, an aircraft manufacturer may want to produce a series of configurations of a plane over a span of years without exceeding a yearly budget to add features. This paper provides three contributions to the study of multi-step configuration for SPLs. First, we present a formal model of multi-step SPL configuration and map this model to constraint satisfaction problems (CSPs). Second, we show how solutions to these SPL configuration problems can be automatically derived with a constraint solver by mapping them to CSPs. Moreover, we show how feature model changes can be mapped to our approach in a multi-step scenario by using feature model drift. Third, we present empirical results demonstrating that our CSP-based reasoning technique can scale to SPL models with hundreds of features and multiple configuration steps. {\textcopyright} 2013 Elsevier Inc.},
  Doi                      = {10.1016/j.jss.2013.10.010},
  ISSN                     = {01641212}
}

@InProceedings{Wittern2012,
  Title                    = {Cloud service selection based on variability modeling},
  Author                   = {Wittern, Erik and Kuhlenkamp, J{\"{o}}rn and Menzel, Michael},
  Year                     = {2012},
  Pages                    = {127--141},
  Volume                   = {7636 LNCS},

  Abstract                 = {The selection among Cloud services is a recent problem in research and practice. The diversity of decision-relevant criteria, configurability of Cloud services and the need to involve human decisionmakers require holistic support through models, methodologies and tools. Existing Cloud service selection approaches do not address all stated difficulties at the same time. We present an approach to capture capabilities of Cloud services and requirements using variability modeling. We use Cloud feature models (CFMs) as a representation mechanism and describe how they are utilized for requirements elicitation and filtering within a presented Cloud service selection process (CSSP) that includes human decision-makers. Filtering produces a reduced number of valid Cloud service configurations that can be further assessed with current multi-criteria decision making-based selection approaches. We present software tools that we use to demonstrate the applicability of our approach in a use case about selecting among Cloud storage services. {\textcopyright} Springer-Verlag Berlin Heidelberg 2012.},
  Doi                      = {10.1007/978-3-642-34321-6-9},
  ISBN                     = {9783642343209},
  ISSN                     = {03029743}
}

@Article{Wittern2016,
  Title                    = {Service feature modeling: modeling and participatory ranking of service design alternatives},
  Author                   = {Wittern, Erik and Zirpins, Christian},
  Year                     = {2016},

  Month                    = {may},
  Number                   = {2},
  Pages                    = {553--578},
  Volume                   = {15},

  Abstract                 = {The design of software-intensive service systems involves and affects numerous stakeholders including software engineers, legal and business experts as well as a potentially large number of consumers. In consequence, the challenge arises to adequately represent the interests of these groups with respect to service design decisions. Specifically, shared service design artifacts and participatory methods for influencing their development in consensus are required, which are not yet state of the art in software service engineering. To this end, we present service feature modeling. Using a modeling notation based on feature-oriented analysis, our approach can represent and interrelate diverse service design concerns and capture their potential combinations as service design alternatives. We further present a method that allows stakeholders to rank service design alternatives based on their preferences. The ranking can support service engineers in selecting viable alternatives for implementation. To exploit this potential, we have implemented a toolkit to enable both modeling and participative ranking of service design alternatives. It has been used to apply service feature modeling in the context of public service design and evaluate the approach in this context.},
  Doi                      = {10.1007/s10270-014-0414-4},
  ISSN                     = {16191374},
  Publisher                = {Springer Verlag}
}

@InProceedings{Wittern2011,
  Title                    = {On the use of feature models for service design: The case of value representation},
  Author                   = {Wittern, Erik and Zirpins, Christian},
  Year                     = {2011},
  Pages                    = {110--118},
  Volume                   = {6569 LNCS},

  Abstract                 = {Current findings in the field of service science have revealed many specific characteristics of service systems, but these results have not yet been fully adopted by the service engineering discipline. In particular we are now aware that the value proposition of a service is not only vital for its success but also deeply depending on context and co-creation. So far, there is only limited work on considering this fact for the design of service systems. In this paper, we discuss the utilization of feature modeling, which is known from the software engineering domain, for service design. We argue that feature modeling offers considerable potential to not only represent value from diverse perspectives but also to involve service customers in participatory service design. {\textcopyright} 2011 Springer-Verlag.},
  Doi                      = {10.1007/978-3-642-22760-8_12},
  ISBN                     = {9783642227592},
  ISSN                     = {03029743}
}

@InProceedings{Wulf-Hadash2013,
  Title                    = {Cross product line analysis},
  Author                   = {Wulf-Hadash, Ora and Reinhartz-Berger, Iris},
  Year                     = {2013},

  Abstract                 = {Due to increase in market competition and merger and acquisition of companies, different software product lines (SPLs) may exist under the same roof. These SPLs may be developed applying different domain analysis processes, but are likely not disjoint. Cross product line analysis aims to examine the common and variable aspects of different SPLs for improving maintenance and future development of related SPLs. Currently different SPL artifacts, or more accurately feature models, are compared, matched, and merged for supporting scalability, increasing modularity and reuse, synchronizing feature model versions, and modeling multiple SPLs for software supply chains. However, in all these cases the focus is on creating valid merged models from the input feature models. Furthermore, the terminology used in all the input feature models is assumed to be the same, namely similar features are named the same. As a result these methods cannot be simply applied to feature models that represent different SPLs. In this work we offer adapting similarity metrics and text clustering techniques in order to enable cross product line analysis. This way analysis of feature models that use different terminologies in the same domain can be done in order to improve the management of the involved SPLs. Preliminary results reveal that the suggested method helps systematically analyze the commonality and variability between related SPLs, potentially suggesting improvements to existing SPLs and to the maintenance of sets of SPLs. {\textcopyright} 2013 ACM.},
  Doi                      = {10.1145/2430502.2430531},
  ISBN                     = {9781450315418}
}

@InProceedings{Xue2010,
  Title                    = {Understanding feature evolution in a family of product variants},
  Author                   = {Xue, Yinxing and Xing, Zhenchang and Jarzabek, Stan},
  Year                     = {2010},
  Pages                    = {109--118},

  Abstract                 = {Existing software product variants, developed by ad hoc reuse such as copy-paste-modify, are often a starting point for building Software Product Line (SPL). Understanding of how features evolved in product variants is a prerequisite to transition from ad hoc to systematic SPL reuse. We propose a method that assists analysts in detecting changes to product features during evolution. We first entail that features and their inter-dependencies for each product variant are documented as product feature model. We then apply model differencing algorithm to identify evolutionary changes that occurred to features of different product variants. We evaluate the effectiveness of our approach on a family of medium-size financial systems. We also investigate the scalability of our approach with synthetic data. The evaluation demonstrates that our approach yields good results and scales to large systems. Our approach enables the subsequent variability analysis and consolidation of product variants in the task of reengineering product variants into SPL. {\textcopyright} 2010 IEEE.},
  Doi                      = {10.1109/WCRE.2010.20},
  ISBN                     = {9780769541235},
  ISSN                     = {10951350}
}

@Article{Xue2016,
  Title                    = {IBED: Combining IBEA and DE for optimal feature selection in software product line engineering},
  Author                   = {Xue, Y and Zhong, J and Tan, TH and Liu, Y and Cai, W and Chen, M},
  Journal                  = {Appl. Soft},
  Year                     = {2016},

  Url                      = {http://www.sciencedirect.com/science/article/pii/S1568494616303751}
}

@Article{Yan2010,
  Title                    = {BDD-based approach to the verification of feature models},
  Author                   = {Yan, Hua and Zhang, Wei and Zhao, Hai Yan and Mei, Hong},
  Year                     = {2010},

  Month                    = {jan},
  Number                   = {1},
  Pages                    = {84--97},
  Volume                   = {21},

  Abstract                 = {The feature model is a reusable requirements model generated from the domain analysis. The reuse of feature models is usually achieved by a customizing-based approach. One important issue in feature models' customization is the verification problem, caused by the fact that there are usually constraints among features, and that a valid customizing result must satisfy all these constraints. Because of the NP-hard nature of this problem, it is usually difficult to verify feature models in an efficient way. This paper presents a BDD (binary decision diagram)-based approach to verifying feature models by only traversing once to the nodes in BDDs, an approach that makes an efficient use of the BDD data structures based on the unique characteristics of feature models' verification. It should be pointed out that this approach does not attempt to resolve the NP-hard difficulty of the verification problem in a general sense, but just tries to improve the scalability and efficiency of methods for feature models' verification based on the utilization of this problem's uniqueness. Experimental results show that this BDD-based approach is more efficient and can verify more complex feature models than the previous method. {\textcopyright} by Institute of Software, the Chinese Academy of Sciences. All rights reserved.},
  Doi                      = {10.3724/SP.J.1001.2010.03525},
  ISSN                     = {10009825}
}

@InProceedings{Yang2016,
  Title                    = {A feature-oriented modeling approach for embedded product line engineering},
  Author                   = {Yang, Guanzhong and Zhang, Yaru},
  Year                     = {2016},
  Month                    = {jan},
  Pages                    = {1607--1612},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Abstract                 = {Feature model is an important model of capturing domain requirements. The traditional feature modeling methods extract the characteristics from the extension of the system. However, the methods fail to describe feature in details especially for embedded software product line engineering. As for these deficiencies, this paper combines the characteristics of the embedded products, with the domain ontology as the basis of feature modeling, dividing the feature modeling into building domain ontology and the feature analysis. First, it will identify the concept of mutual recognition through acquiring, describing and denoting the related domain knowledge. Then, it will divide the feature into three parts which are concept, attribute and the relation, and describe the feature from connotation and extension. It defines and normalizes feature in a clear way. Finally, the effectiveness of the proposed modeling method will be verified through a ventilator embedded product line.},
  Doi                      = {10.1109/FSKD.2015.7382185},
  ISBN                     = {9781467376822}
}

@InProceedings{Yi2012,
  Title                    = {Mining binary constraints in the construction of feature models},
  Author                   = {Yi, Li and Zhang, Wei and Zhao, Haiyan and Jin, Zhi and Mei, Hong},
  Year                     = {2012},
  Pages                    = {141--150},

  Abstract                 = {Feature models provide an effective way to organize and reuse requirements in a specific domain. A feature model consists of a feature tree and cross-tree constraints. Identifying features and then building a feature tree takes a lot of effort, and many semi-automated approaches have been proposed to help the situation. However, finding cross-tree constraints is often more challenging which still lacks the help of automation. In this paper, we propose an approach to mining cross-tree binary constraints in the construction of feature models. Binary constraints are the most basic kind of cross-tree constraints that involve exactly two features and can be further classified into two sub-types, i.e. requires and excludes. Given these two sub-types, a pair of any two features in a feature model falls into one of the following classes: no constraints between them, a requires between them, or an excludes between them. Therefore we perform a 3-class classification on feature pairs to mine binary constraints from features. We incorporate a support vector machine as the classifier and utilize a genetic algorithm to optimize it. We conduct a series of experiments on two feature models constructed by third parties, to evaluate the effectiveness of our approach under different conditions that might occur in practical use. Results show that we can mine binary constraints at a high recall (near 100{\%} in most cases), which is important because finding a missing constraint is very costly in real, often large, feature models. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/RE.2012.6345798},
  ISBN                     = {9781467327855}
}

@Article{Yi2013,
  Title                    = {Research on the merging of feature models},
  Author                   = {Yi, Li and Zhao, Hai Yan and Zhang, Wei and Jin, Zhi and Mei, Hong},
  Year                     = {2013},

  Month                    = {jan},
  Number                   = {1},
  Pages                    = {1--9},
  Volume                   = {36},

  Abstract                 = {Feature models provide an effective way to organize and reuse software requirements in a specific domain. Constructing a feature model needs a systematic analysis of as many applications as possible in a domain, to identify commonality, variability, and dependencies among requirements. With the increasing complexity of domains, the scale of feature models can be extremely large, and the construction of large feature models is an overwhelming task for human that computer-aided automation is needed. A feasible way is to merge existing feature models into a large one, and human developers only need to do some refactoring work. In this paper, we survey six methods of merging feature models. We propose a conceptual framework first, and then analyze and compare the six methods. Finally, we identify three problems in existing research, and propose possible ideas to handle these problems.},
  Doi                      = {10.3724/SP.J.1016.2013.00001},
  ISSN                     = {02544164}
}

@InProceedings{Ying2011,
  Title                    = {Domain service acquisition and domain modeling based on feature model},
  Author                   = {Ying, Guo and Xiao-Yan, Zhang and Jun, Wang and Meihong, Yang},
  Year                     = {2011},
  Pages                    = {26--33},

  Abstract                 = {Domain engineering is the core technology of systematic software reuse and the precedent period of software requirements engineering. FODA method and other FODA-based methods of domain analysis have made great progress. In these methods, feature model and feature-oriented modeling methodology are widely accepted. However, they have three limitations: 1) Feature model cannot be applied separately, it must work together with other models, such as entity-relationship model and function model to present the whole domain. 2) Feature model is a conceptual tree model, which needs standardized description mechanism to support better conversion to domain design, domain implementation and application engineering. 3) With the service-oriented method permeating into current software development process, traditional domain model encounters challenges in providing more effective reuse to service-oriented software requirements activities. To solve these problems, we proposed to combine service-oriented method and domain engineering together, introduced a new concept of Domain Service, and gave its acquisition process and OWL-S based ontology definition. Domain Service is acquired from the classic feature model and could encapsulate features and their relations to model domain commonalities and differences. OWL-S based specification of Domain Service enhances the application of domain model. After Domain Service acquisition and specification, we can get a domain model composed of a set of Domain Services with different granularity. The model has two layers: Domain Service Layer and Ontology Layer, which can be mapped to the domain model produced from the FODA method. Finally, we applied our method in the domain of Public Travel Information Systems. {\textcopyright} 2011 IEEE.},
  Doi                      = {10.1109/CSE.2011.20},
  ISBN                     = {9780769544779}
}

@Article{Yu2014,
  Title                    = {TDL: a transformation description language from feature model to use case for automated use case derivation},
  Author                   = {Yu, W and Zhang, W and Zhao, H and Jin, Z},
  Journal                  = {Proc. 18th Int.},
  Year                     = {2014},

  Url                      = {http://dl.acm.org/citation.cfm?id=2648531}
}

@Misc{Yu2016a,
  Title                    = {A survey of the feature model based approaches to automated product derivation},

  Author                   = {Yu, Wen Jing and Zhao, Hai Yan and Zhang, Wei and Jin, Zhi},
  Month                    = {jan},
  Year                     = {2016},

  Abstract                 = {One of the basic activities in domain-specific software reuse is product derivation, which is deriving individual software products from the reusable software artifacts produced beforehand in the domain. The efficiency of product derivation decides the benefits of software reuse. Among all of the factors affecting the efficiency of product derivation, derivation being carried out manually is a major aspect with negative impacts that reduces the benefits of software reuse as a result. To improve the efficiency of product derivation, some approaches have been proposed to automate the derivation activity. A widely adopted idea in the approaches is automating the derivation activity based on feature models. In the approaches sharing the idea above, the implementation methods differ widely from one to another. To provide better support for feature model-based automated product derivation, this paper proposes a framework for classifying and analyzing these approaches. The paper also points out the problems in the existing researches and the possible solutions to the problems.},
  Doi                      = {10.13328/j.cnki.jos.004929},
  ISSN                     = {10009825},
  Number                   = {1},
  Pages                    = {26--44},
  Publisher                = {Chinese Academy of Sciences},
  Volume                   = {27}
}

@Article{Zhang2014,
  Title                    = {Quality attribute modeling and quality aware product configuration in software product lines},
  Author                   = {Zhang, G and Ye, H and Lin, Y},
  Journal                  = {Softw. Qual. J.},
  Year                     = {2014},

  Url                      = {http://link.springer.com/article/10.1007/s11219-013-9197-z}
}

@Article{Zhang2011,
  Title                    = {Using knowledge-based systems to manage quality attributes in software product lines},
  Author                   = {Zhang, G and Ye, H and Lin, Y},
  Journal                  = {Proc. 15th Int. Softw.},
  Year                     = {2011},

  Url                      = {http://dl.acm.org/citation.cfm?id=2019172}
}

@Article{Zhang2011a,
  Title                    = {Feature model validation: A constraint propagation-based approach},
  Author                   = {Zhang, G and Ye, H and Lin, Y},
  Journal                  = {10th Int. Conf.},
  Year                     = {2011},

  Url                      = {http://weblidi.info.unlp.edu.ar/worldcomp2011-mirror/SER8181.pdf}
}

@InProceedings{Zhang2012,
  Title                    = {A Role-based feature model componentization framework and related algorithms},
  Author                   = {Zhang, Jun and Liu, Shufen},
  Year                     = {2012},
  Pages                    = {366--371},

  Abstract                 = {As a kind of requirement model, feature model represents functions of a family of products in a uniform form. To solve the chaos and entanglement problem in the process of feature model description and configuration, this paper designs a feature model componentization framework. With the help of the concept of Role and Reference Role, the framework proposes a process to analyze and decompose complex requirement specification to simple and coherent roles, and then implements Feature -Role-Component algorithms which map all features generated by requirement elicitation and analysis to different model components. In the framework and algorithms, role and reference role plays as an intermediary who decouple the feature and component, which makes convenient feature variants selection and composition and enhances the componentization level of the system. By decomposing the system functions in the early phase of software lifecycle, the framework improves the flexibility and adaptability of software artifact, which makes a stable foundation for higher quality product. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/CSCWD.2012.6221844},
  ISBN                     = {9781467312127}
}

@InProceedings{Zhang2011b,
  Title                    = {A feature model componentization method based on Role},
  Author                   = {Zhang, Jun and Liu, Shu Fen and Yao, Zhi Lin},
  Booktitle                = {2012 IEEE 16th International Conference on Computer Supported Cooperative Work in Design (CSCWD)},
  Year                     = {2011},
  Month                    = {feb},
  Number                   = {2},
  Pages                    = {304--308},
  Volume                   = {39},

  Abstract                 = {To solve feature model's chaos and entanglement problems in certain domain and decouple the feature model and requirement model, we design a feature model componentization method. The method introduces the concept of Role, and implements an algorithm based on it called Feature-Role-Component Algorithm which maps domain features generated by requirement elicitation and analysis to different model components. The Role plays the role of intermediary, and decouples the feature and component, which enables convenient selection and composition between feature variants and enhances the componentization level of the system.},
  ISSN                     = {03722112}
}

@InProceedings{Zhou2016,
  Title                    = {Feature model augmentation with sentiment analysis for product line planning},
  Author                   = {Zhou, F. and Jiao, R. J.},
  Year                     = {2016},
  Month                    = {jan},
  Pages                    = {1689--1693},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {A feature model is able to identify commonality and variability within a product line, helping stakeholders configure product variants and seize opportunities for reuse. However, no direct customer preference information is incorporated in the feature model when it comes to the question-how many product variants are needed in order to satisfy individual customer needs. This paper proposes to mine customer preference information for individual product features by sentiment analysis of online product reviews. The features commented by the users of a product are used to augment a simple feature model predefined with customer opinionated preference information. In such a way, the customer preference information is considered as one attribute of the features in the model, helping designers make informed decisions when trading off between commonality and variability of a product line. Finally, we present a Kindle Fire tablet case study to demonstrate the proposed method.},
  Doi                      = {10.1109/IEEM.2015.7385935},
  ISBN                     = {9781467380669},
  ISSN                     = {2157362X}
}

@InProceedings{Ziadi2012,
  Title                    = {Feature identification from the source code of product variants},
  Author                   = {Ziadi, Tewfik and Frias, Luz and {Da Silva}, Marcos Aur{\'{e}}lio Almeida and Ziane, Mikal},
  Year                     = {2012},
  Pages                    = {417--422},

  Abstract                 = {In order to migrate software products which are deemed similar into a product line, it is essential to identify the common features and the variations between the product variants. This can however be tedious and error-prone as it may involve browsing complex software and a lot of more or less similar variants. Fortunately, if artefacts of the product variants (source code files and/or models) are available, feature identification can be at least partially automated. In this paper, we thus propose a three-step approach to feature identification from source code of which the first two steps are automated. {\textcopyright} 2012 IEEE.},
  Doi                      = {10.1109/CSMR.2012.52},
  ISBN                     = {9780769546667},
  ISSN                     = {15345351}
}

@InProceedings{Ziadi2014,
  Title                    = {Towards a language-independent approach for reverse-engineering of Software Product Lines},
  Author                   = {Ziadi, Tewfik and Henard, Christopher and Papadakis, Mike and Ziane, Mikal and {Le Traon}, Yves},
  Year                     = {2014},
  Pages                    = {1064--1071},
  Publisher                = {Association for Computing Machinery},

  Abstract                 = {Common industrial practices lead to the development of similar software products. These products are usually managed in an ad-hoc way which gradually results in a low product quality. To overcome this problem, it is essential to migrate these products into a Software Product Line (SPL). Towards this direction, this paper proposes a language-independent approach capable of reverse-engineering an SPL from the source code of product variants. A prototype tool and a case study show the feasibility and the practicality of the proposed approach. Copyright 2014 ACM.},
  Doi                      = {10.1145/2554850.2554874},
  ISBN                     = {9781450324694}
}

@comment{jabref-meta: databaseType:bibtex;}

