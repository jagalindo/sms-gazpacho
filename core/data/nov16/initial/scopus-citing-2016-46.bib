@inproceedings{Arcaini2016,
abstract = {Building a feature model for an existing SPL can improve the automatic analysis of the SPL and reduce the effort in maintenance. However, developing a feature model can be error prone, and checking that it correctly identifies each actual product of the SPL may be unfeasible due to the huge number of possible configurations. We apply mutation analysis and propose a method to detect and remove conformance faults by selecting special configurations that distinguish a feature model from its mutants. We propose a technique that, by iterating this process, is able to repair a faulty model. We devise several variations of a simple hill climbing algorithm for automatic fault removal and we compare them by a series of experiments on three different sets of feature models. We find that our technique is able to improve the conformance of around 90{\%} of the models and find the correct model in around 40{\%} of the cases.},
author = {Arcaini, Paolo and Gargantini, Angelo and Vavassori, Paolo},
doi = {10.1109/ICST.2016.10},
isbn = {9781509018260},
month = {jul},
pages = {102--112},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Automatic Detection and Removal of Conformance Faults in Feature Models}},
year = {2016}
}
@article{Asadi2016,
abstract = {A Software Product Line is a set of software systems of a domain, which share some common features but also have significant variability. A feature model is a variability modeling artifact which represents differences among software products with respect to variability relationships among their features. Having a feature model along with a reference model developed in the domain engineering lifecycle, a concrete product of the family is derived by selecting features in the feature model (referred to as the configuration process) and by instantiating the reference model. However, feature model configuration can be a cumbersome task because: 1) feature models may consist of a large number of features, which are hard to comprehend and maintain; and 2) many factors including technical limitations, implementation costs, stakeholders' requirements and expectations must be considered in the configuration process. Recognizing these issues, a significant amount of research efforts has been dedicated to different aspects of feature model configuration such as automating the configuration process. Several approaches have been proposed to alleviate the feature model configuration challenges through applying visualization and interaction techniques. However, there have been limited empirical insights available into the impact of visualization and interaction techniques on the feature model configuration process. In this paper, we present a set of visualization and interaction interventions for representing and configuring feature models, which are then empirically validated to measure the impact of the proposed interventions. An empirical study was conducted by following the principles of control experiments in software engineering and by applying the well-known software quality standard ISO 9126 to operationalize the variables investigated in the experiment. The results of the empirical study revealed that the employed visualization and interaction interventions significantly improved completion time of comprehension and changing of the feature model configuration. Additionally, according to results, the proposed interventions are easy-to-use and easy-to-learn for the participants.},
author = {Asadi, Mohsen and Soltani, Samaneh and Ga{\v{s}}evi{\'{c}}, Dragan and Hatala, Marek},
doi = {10.1007/s10664-014-9353-5},
issn = {15737616},
month = {aug},
number = {4},
pages = {1706--1743},
publisher = {Springer New York LLC},
title = {{The effects of visualization and interaction techniques on feature model configuration}},
volume = {21},
year = {2016}
}
@article{Becan2016,
abstract = {Feature Models (FMs) are a popular formalism for modeling and reasoning about the configurations of a software product line. As the manual construction of an FM is time-consuming and error-prone, management operations have been developed for reverse engineering, merging, slicing, or refactoring FMs from a set of configurations/dependencies. Yet the synthesis of meaningless ontological relations in the FM – as defined by its feature hierarchy and feature groups – may arise and cause severe difficulties when reading, maintaining or exploiting it. Numerous synthesis techniques and tools have been proposed, but only a few consider both configuration and ontological semantics of an FM. There are also few empirical studies investigating ontological aspects when synthesizing FMs. In this article, we define a generic, ontologic-aware synthesis procedure that computes the likely siblings or parent candidates for a given feature. We develop six heuristics for clustering and weighting the logical, syntactical and semantical relationships between feature names. We then perform an empirical evaluation on hundreds of FMs, coming from the SPLOT repository and Wikipedia. We provide evidence that a fully automated synthesis (i.e., without any user intervention) is likely to produce FMs far from the ground truths. As the role of the user is crucial, we empirically analyze the strengths and weaknesses of heuristics for computing ranking lists and different kinds of clusters. We show that a hybrid approach mixing logical and ontological techniques outperforms state-of-the-art solutions. We believe our approach, environment, and empirical results support researchers and practitioners working on reverse engineering and management of FMs.},
author = {B{\'{e}}can, Guillaume and Acher, Mathieu and Baudry, Benoit and Nasr, Sana Ben},
doi = {10.1007/s10664-014-9357-1},
issn = {15737616},
month = {aug},
number = {4},
pages = {1794--1841},
publisher = {Springer New York LLC},
title = {{Breathing ontological knowledge into feature model synthesis: an empirical study}},
volume = {21},
year = {2016}
}
@inproceedings{Bessai2016,
abstract = {We describe a method for automatically transforming feature grammars into type-specifications which are subsequently used to synthesize a code-generator for a product of a given feature selection. Feature models are assumed to be given in the form of feature grammars with constraints, and we present a generic type-theoretic representation of such grammars. Our synthesis method is based on an extension of previous work in combinatory logic synthesis, where semantic types can be superimposed onto native APIs to specify a repository of components as well as synthesis goals. In our case, semantic types correspond to feature selections. We use an encoding of boolean logic in intersection types, which allows us to directly represent logical formulas expressing complex feature selection constraints. The novelty of our approach is the possibility to perform retrieval, selection and composition of products in a unified form, without sacrificing modularity. In contrast to constraint based methods, multiple selections of a single feature can coexist.},
author = {Bessai, Jan and D{\"{u}}dder, Boris and Heineman, George T. and Rehof, Jakob},
doi = {10.1007/978-3-319-28934-2_7},
isbn = {9783319289335},
issn = {16113349},
pages = {123--140},
publisher = {Springer Verlag},
title = {{Combinatory synthesis of classes using feature grammars}},
volume = {9539},
year = {2016}
}
@article{Camacho2016,
abstract = {Software Product Lines modeling improves software development processes by automating system debugging and analysis. The objective of this paper focuses on extending the formal framework SPLA to represent features such as cost objects and comparisons between products in terms of production costs. We illustrate this extension with a practical example by modeling the creation of valid run-lists for Chef, a widely used configuration management tool. Also, we execute our formal specification in a distributed system using SCOOP and we provide strategies to optimize the effort required to compute a SPLA term.},
author = {Camacho, Carlos and Llana, Luis and N{\'{u}}{\~{n}}ez, Alberto},
doi = {10.1016/j.jlamp.2015.09.009},
issn = {23522216},
month = {jan},
number = {1},
pages = {227--244},
publisher = {Elsevier Inc.},
title = {{Cost-related interface for software product lines}},
volume = {85},
year = {2016}
}
@inproceedings{Chrszon2016,
abstract = {Feature-based formalisms provide an elegant way to specify families of systems that share a base functionality and differ in certain features. They can also facilitate an all-in-one analysis, where all systems of the family are analyzed at once on a single family model instead of one-by-one. This paper presents the basic concepts of the tool ProFeat, which provides a guarded-command language for modeling families of probabilistic systems and an automatic translation of family models to the input language of the probabilistic model checker Prism. This translational approach enables a family-based quantitative analysis with Prism. Besides modeling families of systems that differ in system parameters such as the number of identical processes or channel sizes, ProFeat also provides special support for the modeling and analysis of (probabilistic) product lines with dynamic feature switches, multifeatures and feature attributes. By means of several case studies we show how ProFeat eases family-based modeling and compare the one-by-one and all-in-one analysis approach.},
author = {Chrszon, Philipp and Dubslaff, Clemens and Kl{\"{u}}ppelholz, Sascha and Baier, Christel},
doi = {10.1007/978-3-662-49665-7_17},
isbn = {9783662496640},
issn = {16113349},
pages = {287--304},
publisher = {Springer Verlag},
title = {{Family-based modeling and analysis for probabilistic systems – featuring PROFEAT}},
volume = {9633},
year = {2016}
}
@inproceedings{Diedrich2016,
abstract = {In recent years, the complexity of production plants and therefore of the underlying automation systems has grown significantly. This makes the manual design of automation systems increasingly difficult. As a result, errors are found only during production, plant modifications are hindered by not maintainable automation solutions and criteria such as energy efficiency or cost are often not optimized. This work shows how utilizing Minimum Correction Subsets (MCS) of a Constraint Satisfaction Problem improves the collaboration of automation system designers and prevents inconsistent requirements and thus subsequent errors in the design. This opens up a new field of application for constraint satisfaction techniques. As a use case, an example from the field of automation system design is presented. To meet the automation industry's requirement for standardised solutions that assure reliability, the calculation of MCS is formulated in such a way that most constraint solvers can be used without any extensions. Experimental results with typical problems demonstrate the practicalness concerning runtime and hardware resources.},
author = {Diedrich, Alexander and B{\"{o}}ttcher, Bj{\"{o}}rn and Niggemann, Oliver},
isbn = {9789897581724},
pages = {280--287},
publisher = {SciTePress},
title = {{Exposing design mistakes during requirements engineering by solving constraint satisfaction problems to obtain minimum correction subsets}},
volume = {2},
year = {2016}
}
@article{Duran2016,
abstract = {A fundamental task when reusing software artifacts is to determine the most appropriate artifact for the current reuse context. Goal modeling allows modelers to capture the advantages and disadvantages of reusable candidate artifacts, which in turn helps reason about the most appropriate candidate artifact. However, goal models are rarely used in isolation for the description of an artifact, but are combined with other models that impose additional constraints on the most appropriate candidate. Furthermore, reusable artifacts are assembled into reuse hierarchies to realize an application. This paper presents a novel goal model evaluation mechanism for the selection of the most appropriate candidate, which (i) takes into account additional configuration constraints expressed with feature models and run-time constraints expressed with workflow models that may affect the selection of reusable software artifacts, (ii) considers reuse hierarchies, and (iii) establishes a history of design decisions. Furthermore, a proof-of-concept implementation of the novel evaluation mechanism is discussed.},
author = {Duran, Mustafa Berk and Mussbacher, Gunter},
doi = {10.1007/s10796-016-9657-7},
issn = {15729419},
month = {oct},
number = {5},
pages = {855--875},
publisher = {Springer New York LLC},
title = {{Investigation of feature run-time conflicts on goal model-based reuse}},
volume = {18},
year = {2016}
}
@inproceedings{Eyal-Salman2016,
abstract = {Usually, companies meet different customer needs in a particular domain by developing variants of a software product. This is often performed by ad-hoc copying and modifying of various existing variants to fit purposes of new one. As the number of product variants grows, such an adhoc development causes severe problems to maintain these variants. Software Product Line Engineering (SPLE) can be helpful here by supporting a large-scale reuse systematically. SPL architecture (SPLA) is a key asset as it is used to derive architecture for each product in SPL. Unfortunately, developing SPLA from scratch is a costly task. In this paper, we propose an approach to contribute for recovering SPLA from existing product variants. This contribution is two-fold. Firstly, identifying common features and variation points of features of a given collection of product variants. Secondly, exploiting commonality and variability in terms of features to identify mandatory components and variation points of components as an important step in this recovering process. To evaluate the proposed approach, we applied it to two case studies. The experimental results bring evidence the effectiveness of our approach.},
author = {Eyal-Salman, Hamzeh and Seriai, Abdelhak Djamel},
isbn = {189170639X},
issn = {23259086},
pages = {1--7},
publisher = {Knowledge Systems Institute Graduate School},
title = {{Toward recovering component-based software product line architecture from object-oriented product variants}},
year = {2016}
}
@article{Ferrer2016,
abstract = {In smart cities, the use of intelligent automatic techniques to find efficient cycle programs of traffic lights is becoming an innovative front for traffic flow management. However, this automatic programming of traffic lights requires a validation process of the generated solutions, since they can affect the mobility (and security) of millions of citizens. In this paper, we propose a validation strategy based on genetic algorithms and feature models for the automatic generation of different traffic scenarios checking the robustness of traffic light cycle programs. We have concentrated on an extensive urban area in the city of Malaga (in Spain), in which we validate a set of candidate cycle programs generated by means of four optimization algorithms: Particle Swarm Optimization for Traffic Lights, Differential Evolution for Traffic Lights, random search, and Sumo Cycle Program Generator. We can test the cycles of traffic lights considering the different states of the city, weather, congestion, driver expertise, vehicle's features, and so forth, but prioritizing the most relevant scenarios among a large and varied set of them. The improvement achieved in solution quality is remarkable, especially for C O 2 emissions, in which we have obtained a reduction of 126.99{\%} compared with the experts' solutions.},
author = {Ferrer, Javier and Garc{\'{i}}a-Nieto, Jos{\'{e}} and Alba, Enrique and Chicano, Francisco},
doi = {10.1155/2016/3871046},
issn = {15635147},
publisher = {Hindawi Publishing Corporation},
title = {{Intelligent testing of traffic light programs: Validation in smart mobility scenarios}},
volume = {2016},
year = {2016}
}
@inproceedings{Fischer2016,
abstract = {Extensive work on Search-Based Software Testing for Software Product Lines has been published in the last few years. Salient among them is the use of similarity as a surrogate metric for t-wise coverage whenever higher strengths are needed or whenever the size of the test suites is infeasible because of technological or budget limitations. Though promising, this metric has not been assessed with real fault data. In this paper, we address this limitation by using Drupal, a widely used open source web content management system, as an industry-strength case study for which both variability information and fault data have been recently made available. Our preliminary assessment corroborates some of the previous findings but also raises issues on some assumptions and claims made. We hope our work encourages further empirical evaluations of Combinatorial Interaction Testing approaches for Software Product Lines.},
author = {Fischer, Stefan and Lopez-Herrejon, Roberto E. and Ramler, Rudolf and Egyed, Alexander},
doi = {10.1145/2897010.2897011},
isbn = {9781450341660},
month = {may},
pages = {15--18},
publisher = {Association for Computing Machinery, Inc},
title = {{A preliminary empirical assessment of similarity for combinatorial interaction testing of software product lines}},
year = {2016}
}
@article{Galindo2016,
abstract = {Software product lines are used to develop a set of software products that, while being different, share a common set of features. Feature models are used as a compact representation of all the products (e.g., possible configurations) of the product line. The number of products that a feature model encodes may grow exponentially with the number of features. This increases the cost of testing the products within a product line. Some proposals deal with this problem by reducing the testing space using different techniques. However, a daunting challenge is to explore how the cost and value of test cases can be modeled and optimized in order to have lower-cost testing processes. In this paper, we present TESting vAriAbiLity Intensive Systems (TESALIA), an approach that uses automated analysis of feature models to optimize the testing of variability-intensive systems. We model test value and cost as feature attributes, and then we use a constraint satisfaction solver to prune, prioritize and package product line tests complementing prior work in the software product line testing literature. A prototype implementation of TESALIA is used for validation in an Android example showing the benefits of maximizing the mobile market share (the value function) while meeting a budgetary constraint.},
author = {Galindo, Jos{\'{e}} A. and Turner, Hamilton and Benavides, David and White, Jules},
doi = {10.1007/s11219-014-9258-y},
issn = {15731367},
month = {jun},
number = {2},
pages = {365--405},
publisher = {Springer New York LLC},
title = {{Testing variability-intensive systems using automated analysis: an application to Android}},
volume = {24},
year = {2016}
}
@inproceedings{Garba2016,
abstract = {Variability management is one of the main activities in the Software Product Line Engineering process. Common and varied features of related products are modelled along with the dependencies and relationships among them. With the increase in size and complexity of product lines and the more holistic systems approach to the design process, managing the ever-growing variability models has become a challenge. In this paper, we present MUSA, a tool for managing variability and features in large-scale models. MUSA adopts the Separation of Concerns design principle by providing multiple perspectives to the model, each conveying different set of information. The demonstration is conducted using a real-life model (comprising of 1000+ features) particularly showing the Structural View, which is displayed using a mind-mapping visualisation technique (hyperbolic trees), and the Dependency View, which is displayed graphically using logic gates.},
author = {Garba, Muhammad and Noureddine, Adel and Bashroush, Rabih},
doi = {10.1109/WICSA.2016.45},
isbn = {9781509021314},
month = {jul},
pages = {299--302},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{MUSA: A scalable multi-touch and multi-perspective variability management tool}},
year = {2016}
}
@inproceedings{Garcia-Galan2016,
abstract = {Multi-tenancy is a key pillar of cloud services. It allows different users to share computing and virtual resources transparently, meanwhile guaranteeing substantial cost savings. Due to the tradeoff between scalability and customization, one of the major drawbacks of multi-tenancy is limited configurability. Since users may often have conflicting configuration preferences, offering the best user experience is an open challenge for service providers. In addition, the users, their preferences, and the operational environment may change during the service operation, thus jeopardizing the satisfaction of user preferences. In this article, we present an approach to support user-centric adaptation of multi-tenant services. We describe how to engineer the activities of the Monitoring, Analysis, Planning, Execution (MAPE) loop to support user-centric adaptation, and we focus on adaptation analysis. Our analysis computes a service configuration that optimizes user satisfaction, complies with infrastructural constraints, and minimizes reconfiguration obtrusiveness when user- or service-related changes take place. To support our analysis, we model multitenant services and user preferences by using feature and preference models, respectively. We illustrate our approach by utilizing different cases of virtual desktops. Our results demonstrate the effectiveness of the analysis in improving user preferences satisfaction in negligible time.},
author = {Garc{\'{i}}a-Gal{\'{a}}n, Jes{\'{u}}s and Pasquale, Liliana and Trinidad, Pablo and Ruiz-Cort{\'{e}}s, Antonio},
doi = {10.1145/2790303},
issn = {15564703},
month = {feb},
number = {4},
publisher = {Association for Computing Machinery},
title = {{User-centric adaptation analysis of multi-tenant services}},
volume = {10},
year = {2016}
}
@article{Garcia-Galan2016a,
abstract = {With an increasing number of cloud computing offerings in the market, migrating an existing computational infrastructure to the cloud requires comparison of different offers in order to find the most suitable configuration. Cloud providers offer many configuration options, such as location, purchasing mode, redundancy, and extra storage. Often, the information about such options is not well organised. This leads to large and unstructured configuration spaces, and turns the comparison into a tedious, error-prone search problem for the customers. In this work we focus on supporting customer decision making for selecting the most suitable cloud configuration - in terms of infrastructural requirements and cost. We achieve this by means of variability modelling and analysis techniques. Firstly, we structure the configuration space of an IaaS using feature models, usually employed for the modelling of variability-intensive systems, and present the case study of the Amazon EC2. Secondly, we assist the configuration search process. Feature models enable the use of different analysis operations that, among others, automate the search of optimal configurations. Results of our analysis show how our approach, with a negligible analysis time, outperforms commercial approaches in terms of expressiveness and accuracy.},
author = {Garc{\'{i}}a-Gal{\'{a}}n, Jes{\'{u}}s and Trinidad, Pablo and Rana, Omer F. and Ruiz-Cort{\'{e}}s, Antonio},
doi = {10.1016/j.future.2015.03.006},
issn = {0167739X},
month = {feb},
pages = {200--212},
publisher = {Elsevier},
title = {{Automated configuration support for infrastructure migration to the cloud}},
volume = {55},
year = {2016}
}
@inproceedings{Han2016,
abstract = {In the current mobile software environment, the device fragmentation phenomenon causes a serious problem to the mobile software ecosystem stakeholders. Since mobile manufacturers make various differentiated hardware components for product differentiation around strategically selected open platforms, a huge number of devices are produced each year. Since the application developers have to verify manually whether the developed application is compatible with specific devices, a tremendous burden is put on the application developers. To solve this problem, we propose a feature-oriented mobile software development framework and implement as part of it an automated tool for compatibility verification. To evaluate our framework, we conduct a case study with 10 devices and 21 features from the real world. The result of the case study indicates that a significant effort reduction can be achieved by using our framework.},
author = {Han, Younghun and Go, Gyeongmin and Kang, Sungwon and Lee, Heuijin},
doi = {10.1007/978-3-319-38904-2_20},
isbn = {9783319389035},
issn = {18678211},
pages = {189--199},
publisher = {Springer Verlag},
title = {{A feature-oriented mobile software development framework to resolve the device fragmentation phenomenon for application developers in the mobile software ecosystem}},
volume = {167},
year = {2016}
}
@article{Heradio2016,
abstract = {Mass customization is the new frontier in business competition for both manufacturing and service industries. To improve customer satisfaction, reduce lead-times and shorten costs, families of similar products are built jointly by combining reusable parts that implement the features demanded by the customers. To guarantee the validity of the products derived from mass customization processes, feature dependencies and incompatibilities are usually specified with a variability model. As market demand grows and evolves, variability models become increasingly complex. In such entangled models it is hard to identify which features are essential, dispensable, highly required by other features, or highly incompatible with the remaining features. This paper exposes the limitations of existing approaches to gather such knowledge and provides efficient algorithms to retrieve that information from variability models.},
author = {Heradio, Ruben and Perez-Morago, Hector and Alf{\'{e}}rez, Mauricio and Fernandez-Amoros, David and Alf{\'{e}}rez, Germ{\'{a}}n H.},
doi = {10.1016/j.ejor.2015.08.005},
issn = {03772217},
month = {feb},
number = {3},
pages = {1066--1077},
publisher = {Elsevier},
title = {{Augmenting measure sensitivity to detect essential, dispensable and highly incompatible features in mass customization}},
volume = {248},
year = {2016}
}
@article{Heradio2016a,
abstract = {Context: Software product line engineering has proven to be an efficient paradigm to developing families of similar software systems at lower costs, in shorter time, and with higher quality. Objective: This paper analyzes the literature on product lines from 1995 to 2014, identifying the most influential publications, the most researched topics, and how the interest in those topics has evolved along the way. Method: Bibliographic data have been gathered from ISI Web of Science and Scopus. The data have been examined using two prominent bibliometric approaches: science mapping and performance analysis. Results: According to the study carried out, (i) software architecture was the initial motor of research in SPL; (ii) work on systematic software reuse has been essential for the development of the area; and (iii) feature modeling has been the most important topic for the last fifteen years, having the best evolution behavior in terms of number of published papers and received citations. Conclusion: Science mapping has been used to identify the main researched topics, the evolution of the interest in those topics and the relationships among topics. Performance analysis has been used to recognize the most influential papers, the journals and conferences that have published most papers, how numerous is the literature on product lines and what is its distribution over time.},
author = {Heradio, Ruben and Perez-Morago, Hector and Fernandez-Amoros, David and {Javier Cabrerizo}, Francisco and Herrera-Viedma, Enrique},
doi = {10.1016/j.infsof.2015.11.004},
issn = {09505849},
month = {apr},
pages = {1--15},
publisher = {Elsevier},
title = {{A bibliometric analysis of 20 years of research on software product lines}},
volume = {72},
year = {2016}
}
@article{Hierons2016,
abstract = {A feature model specifies the sets of features that define valid products in a software product line. Recent work has considered the problem of choosing optimal products from a feature model based on a set of user preferences, with this being represented as a many-objective optimization problem. This problem has been found to be difficult for a purely search-based approach, leading to classicalmany-objective optimization algorithms being enhanced either by adding in a valid product as a seed or by introducing additional mutation and replacement operators that use an SAT solver. In this article, we instead enhance the search in two ways: by providing a novel representation and by optimizing first on the number of constraints that hold and only then on the other objectives. In the evaluation, we also used feature models with realistic attributes, in contrast to previous work that used randomly generated attribute values. The results of experiments were promising, with the proposed (SIP) method returning valid products with six published feature models and a randomly generated feature model with 10,000 features. For the model with 10,000 features, the search took only a few minutes.},
author = {Hierons, Robert M. and Li, Miqing and Liu, Xiaohui and Segura, Sergio and Zheng, Wei},
doi = {10.1145/2897760},
issn = {15577392},
month = {apr},
number = {2},
publisher = {Association for Computing Machinery},
title = {{SIP: Optimal product selection from feature models using many-objective evolutionary optimization}},
volume = {25},
year = {2016}
}
@article{Hu2016,
abstract = {Feature model is an essential concept and artifact in feature oriented software development (FOSD). It depicts commonality and variability (C{\&}V) of products in terms of features. With increasingly frequent software evolution, keeping the feature model in consistent with the evolution is very important. Most of the related researches usually analyze the C{\&}V on the requirement level, and modeling the analyzed C{\&}V by the feature model. However, since the feature changes may cause the ripple effect during the modeling process, some new commonalities and variability may be derived. The current researches are still not able to resolve this problem, which leads to some potential overlooking commonalities and inefficiency in reuse. This paper proposes an approach to extend the feature model and analyze the software evolution based on the feature model. The extensions of feature dependency and evolution meta-operators can support the ripple effect analysis of the feature changes, as well as the exploration of the potential commonalities. The new approach also develops some refactoring strategies and a semi-automated tool to support commonality extraction and feature refactoring. In addition, rules and strategies are designed to resolve typical configuration conflicts. Finally, the paper employs a case study to validate the applicability and effectiveness of the presented method.},
author = {Hu, Jie and Wang, Qing},
doi = {10.13328/j.cnki.jos.004829},
issn = {10009825},
month = {may},
number = {5},
pages = {1212--1229},
publisher = {Chinese Academy of Sciences},
title = {{Extensions and evolution analysis method for software feature models}},
volume = {27},
year = {2016}
}
@article{Karatas2016,
abstract = {Extended feature models enable the expression of complex cross-tree constraints involving feature attributes. The inclusion of attributes in cross-tree relations not only enriches the constraints, but also engenders an extended type of variability that involves attributes. In this article, we elaborate on the effects of this new variability type on feature models. We start by analyzing the nature of the variability involving attributes and extend the definitions of the configuration and the product to suit the emerging requirements. Next, we propose classifications for the features, configurations, and products to identify and formalize the ramifications that arise due to the new type of variability. Then, we provide a semantic foundation grounded on constraint satisfaction for our proposal. We introduce an ordering relation between configurations and show that the set of all the configurations represented by a feature model forms a semilattice. This is followed by a demonstration of how the feature model analyses will be affected using illustrative examples selected from existing and novel analysis operations. Finally, we summarize our experiences, gained from a commercial research and development project that employs an extended feature model.},
author = {Karataş, Ahmet Serkan and Oğuzt{\"{u}}z{\"{u}}n, Halit},
doi = {10.1007/s00766-014-0216-9},
issn = {1432010X},
month = {jun},
number = {2},
pages = {185--208},
publisher = {Springer-Verlag London Ltd},
title = {{Attribute-based variability in feature models}},
volume = {21},
year = {2016}
}
@inproceedings{Kim2016,
abstract = {This paper presents a formal analysis framework to analyze a family of platform products w.r.t. real-time properties. First, we propose an extension of the widely-used feature model, called Property Feature Model (PFM), that distinguishes features and properties explicitly Second, we present formal behavioral models of components of a realtime scheduling unit such that all real-time scheduling units implied by a PFM are automatically composed to be analyzed against the properties given by the PFM. We apply our approach to the verification of the schedulability of a family of scheduling units using the symbolic and statistical model checkers of Uppaal.},
author = {Kim, Jin Hyun and Legay, Axel and Traonouez, Louis Marie and Acher, Mathieu and Kaist, Sungwon Kang},
doi = {10.1145/2851613.2851977},
isbn = {9781450337397},
month = {apr},
pages = {1562--1565},
publisher = {Association for Computing Machinery},
title = {{A formal modeling and analysis framework for software product line of preemptive real-time systems}},
year = {2016}
}
@incollection{Lopez-Herrejon2016,
abstract = {Because of economical, technological and marketing reasons today's software systems are more frequently being built as families where each product variant implements a different combination of features. Software families are commonly called Software Product Lines (SPLs) and over the past three decades have been the subject of extensive research and application. Among the benefits of SPLs are: increased software reuse, faster and easier product customization, and reduced time to market. However, testing SPLs is specially challenging as the number of product variants is usually large making it infeasible to test every single variant. In recent years there has been an increasing interest in applying evolutionary computation techniques for SPL testing. In this chapter, we provide a concise overview of the state of the art and practice in SPL testing with evolutionary techniques as well as to highlight open questions and areas for future research.},
author = {Lopez-Herrejon, Roberto E. and Ferrer, Javier and Chicano, Francisco and Egyed, Alexander and Alba, Enrique},
doi = {10.1007/978-3-319-25964-2_4},
issn = {1860949X},
month = {jan},
pages = {59--87},
publisher = {Springer Verlag},
title = {{Evolutionary computation for software product line testing: An overview and open challenges}},
volume = {617},
year = {2016}
}
@inproceedings{Martinez2016,
abstract = {It is common belief that high impact research in software reuse requires assessment in realistic, non-trivial, comparable, and reproducible settings. However, real software artefacts and common representations are usually unavailable. Also, establishing a representative ground truth is a challenging and debatable subject. Feature location in the context of software families is a research field that is becoming more mature with a high proliferation of techniques. We present EFLBench, a benchmark and a framework to provide a common ground for this field. EFLBench leverages the efforts made by the Eclipse Community which provides real feature-based family artefacts and their implementations. Eclipse is an active and non-trivial project and thus, it establishes an unbiased ground truth. EFLBench is publicly available and supports all tasks for feature location techniques integration, benchmark construction and benchmark usage. We demonstrate its usage and its simplicity and reproducibility by comparing four techniques.},
author = {Martinez, Jabier and Ziadi, Tewfik and Papadakis, Mike and Bissyand{\'{e}}, Tegawend{\'{e}} F. and Klein, Jacques and Traon, Yves Le},
doi = {10.1007/978-3-319-35122-3_18},
isbn = {9783319351216},
issn = {16113349},
pages = {267--283},
publisher = {Springer Verlag},
title = {{Feature location benchmark for software families using eclipse community releases}},
volume = {9679},
year = {2016}
}
@inproceedings{Mauro2016,
abstract = {Software Product Lines (SPLs) are a mechanism for largescale reuse where families of related software systems are represented in terms of commonalities and variabilities, e.g., using Feature Models (FMs). While FMs define all possible configurations of the SPL, when considering dynamic SPLs not every possible configuration may be valid in all possible contexts. Unfortunately, common FMs can not capture this context dependence. In this paper, we remedy this problem by extending attributed FMs with Validity Formulas (VFs) that constrain the selection of a particular feature to a speci fic context and that are located directly within the FM. We provide a reconfiguration engine that checks if the active configuration is valid in the current context and, if not, computes how to reconfigure it. Furthermore, we present our implementation and demonstrate its feasibility within a case study derived from scenarios of our industry partner in the automotive domain.},
author = {Mauro, Jacopo and Nieke, Michael and Seidl, Christoph and Yu, Ingrid Chieh},
doi = {10.1145/2866614.2866620},
isbn = {9781450340199},
month = {jan},
pages = {41--48},
publisher = {Association for Computing Machinery},
title = {{Context aware reconfiguration in Software Product Lines}},
year = {2016}
}
@inproceedings{Metzger2016,
abstract = {Distributed systems, such as cloud systems or cyber-physical systems, involve the orchestration of different variability-intensive, adaptive sub-systems. Each of these sub-systems may perform adaptations simultaneously and independently from each other. Yet, if dependencies between the adaptations of the sub-systems are not considered, this may lead to conflicting adaptations or untapped synergies among adaptations. This paper introduces FCORE, a model-based approach, which facilitates coordinating adaptations among variability-intensive systems. The permissible run-time reconfigurations of each system is specified by an FCORE model, which combines feature models used in Dynamic Software Product Lines with goal models. FCORE models are mapped to constraint satisfaction problems to determine conflicts and synergies among the adaptations of the systems during execution. We demonstrate the FCORE approach by using a cloud system as a typical exemplar for a distributed system. The cloud system is part of an industrial use case concerned with offering value-added cloud services.},
author = {Metzger, Andreas and Bayer, Andreas and Doyle, Daniel and Sharifloo, Amir Molzam and Pohl, Klaus and Wessling, Florian},
doi = {10.1145/2897045.2897049},
isbn = {9781450341769},
month = {may},
pages = {5--11},
publisher = {Association for Computing Machinery, Inc},
title = {{Coordinated run-time adaptation of variability-intensive systems: An application in cloud computing}},
year = {2016}
}
@article{Narwane2016,
abstract = {In a Software Product Line (SPL), the central notion of implementability provides the requisite connection between specifications and their implementations, leading to the definition of products. While it appears to be a simple extension of the traceability relation between components and features, it involves several subtle issues that were overlooked in the existing literature. In this paper, we have introduced a precise and formal definition of implementability over a fairly expressive traceability relation. The consequent definition of products in the given SPL naturally entails a set of useful analysis problems that are either refinements of known problems or are completely novel. We also propose a new approach to solve these analysis problems by encoding them as Quantified Boolean Formulae (QBF) and solving them through Quantified Satisfiability (QSAT) solvers. QBF can represent more complex analysis operations, which cannot be represented by using propositional formulae. The methodology scales much better than the SAT-based solutions hinted in the literature and were demonstrated through a tool called SPLAnE (SPL Analysis Engine) on a large set of SPL models.},
author = {Narwane, Ganesh Khandu and Galindo, Jos{\'{e}} A. and Krishna, Shankara Narayanan and Benavides, David and Millo, Jean Vivien and Ramesh, S.},
doi = {10.3390/e18080269},
issn = {10994300},
number = {8},
publisher = {MDPI AG},
title = {{Traceability analyses between features and assets in software product lines}},
volume = {18},
year = {2016}
}
@article{Parejo2016,
abstract = {Test case prioritization schedules test cases for execution in an order that attempts to accelerate the detection of faults. The order of test cases is determined by prioritization objectives such as covering code or critical components as rapidly as possible. The importance of this technique has been recognized in the context of Highly-Configurable Systems (HCSs), where the potentially huge number of configurations makes testing extremely challenging. However, current approaches for test case prioritization in HCSs suffer from two main limitations. First, the prioritization is usually driven by a single objective which neglects the potential benefits of combining multiple criteria to guide the detection of faults. Second, instead of using industry-strength case studies, evaluations are conducted using synthetic data, which provides no information about the effectiveness of different prioritization objectives. In this paper, we address both limitations by studying 63 combinations of up to three prioritization objectives in accelerating the detection of faults in the Drupal framework. Results show that non–functional properties such as the number of changes in the features are more effective than functional metrics extracted from the configuration model. Results also suggest that multi-objective prioritization typically results in faster fault detection than mono-objective prioritization.},
author = {Parejo, Jos{\'{e}} A. and S{\'{a}}nchez, Ana B. and Segura, Sergio and Ruiz-Cort{\'{e}}s, Antonio and Lopez-Herrejon, Roberto E. and Egyed, Alexander},
doi = {10.1016/j.jss.2016.09.045},
issn = {01641212},
month = {dec},
pages = {287--310},
publisher = {Elsevier Inc.},
title = {{Multi-objective test case prioritization in highly configurable systems: A case study}},
volume = {122},
year = {2016}
}
@inproceedings{Peng2016,
abstract = {Due to the increasing complexity of software products as well as the restriction of the development budget and time, requirements prioritization, i.e., selecting more crucial requirements to be designed and developed firstly, has become increasingly important in the software development lifetime. Considering the fact that a feature in a feature model can be viewed as a set of closely related requirements, feature prioritization will contribute to requirements prioritization to a large extent. Therefore, how to measure the priority of features within a feature model becomes an important issue in requirements analysis. In this paper, a software feature prioritization approach is proposed, which utilizes the dependencies between features to build a feature probability network and measures feature prioritization through the nodes centrality in the network. Experiments conducted on real world feature models show that the proposed approach can accurately prioritize features in feature models.},
author = {Peng, Zhenlian and Wang, Jian and He, Keqing and Li, Hongtao},
doi = {10.1007/978-3-319-35122-3_8},
isbn = {9783319351216},
issn = {16113349},
pages = {106--121},
publisher = {Springer Verlag},
title = {{An approach for prioritizing software features based on node centrality in probability network}},
volume = {9679},
year = {2016}
}
@article{Peng2016a,
abstract = {With the rapid development of Internet and Web service related technologies,developing software system on Internet is increasingly popular. Software development is a multi-knowledge-intensive process in which requirements elicitation plays a key role. Software systems deployed on Internet need to meet the needs of various kinds of customers and users who are geographically distributed,which increases the difficulties of software requirements elicitation. Meanwhile,more and more software systems that share similar functions are deployed on Internet,which provides a new way to elicit software requirements. Toward this end,recommender systems have been leveraged in the requirements elicitation to recommend missing features for software products by comparing the requirements descriptions of existing similar software systems. In order to improve the prediction accuracy of the recommended features of the software system,a requirements elicitation approach based on feature model and KNN (K-nearest neighbors) collaborative filtering recommendation system is proposed in this paper. An algorithm named FM{\_}KNN is presented by utilizing constraint relations between features in KNN collaborative filtering recommendation system. Experiments conducted on a real data set and a simulated data set, by comparing the proposed FM{\_}KNN with two existing methods, i.e., KNN and an approach that combines association rule mining with KNN, show that the proposed approach can achieve higher precision.},
author = {Peng, Zhenlian and Wang, Jian and He, Keqing and Tang, Mingdong},
doi = {10.7544/issn1000-1239.2016.20150426},
issn = {10001239},
month = {sep},
number = {9},
pages = {2055--2066},
publisher = {Science Press},
title = {{A requirements elicitation approach based on feature model and collaborative filtering}},
volume = {53},
year = {2016}
}
@inproceedings{Pereira2016,
abstract = {In the last decades, variability management for similar products is one of the main challenges in software systems. In this context, feature models are used to describe the dependencies between reusable common and variable artifacts, called features. However, for large feature models it is a complex task to find a valid feature combination as product configuration. Our Eclipse plug-in FeatureIDE provides several mechanisms, such as information hiding and decision propagation, which support the configuration process to combine the reusable artifacts in various manners. We illustrate the applications of these mechanisms from a user's point of view.},
author = {Pereira, Juliana Alves and Krieter, Sebastian and Meinicke, Jens and Schr{\"{o}}ter, Reimar and Saake, Gunter and Leich, Thomas},
doi = {10.1007/978-3-319-35122-3_27},
isbn = {9783319351216},
issn = {16113349},
pages = {397--401},
publisher = {Springer Verlag},
title = {{FeatureIDE: Scalable product configuration of variable systems}},
volume = {9679},
year = {2016}
}
@inproceedings{Perrouin2016,
abstract = {By analogy with software product reuse, the ability to reuse (meta)models and model transformations is key to achieve better quality and productivity. To this end, various opportunistic reuse techniques have been developed, such as higher-order transformations, metamodel adaptation, and model types. However, in contrast to software product development that has moved to systematic reuse by adopting (model-driven) software product lines, we are not quite there yet for modelling languages, missing economies of scope and automation opportunities. Our vision is to transpose the product line paradigm at the metamodel level, where reusable assets are formed by metamodel and transformation fragments and "products" are reusable language building blocks (model types). We introduce featured model types to concisely model variability amongst metamodelling elements, enabling configuration, automated analysis, and derivation of tailored model types. We provide a wish list of software engineering activities to work with featured model types.},
author = {Perrouin, Gilles and Amrani, Moussa and Acher, Mathieu and Combemale, Benoit and Legay, Axel and Schobbens, Pierre Yves},
doi = {10.1145/2896982.2896987},
isbn = {9781450341646},
month = {may},
pages = {1--7},
publisher = {Association for Computing Machinery, Inc},
title = {{Featured model types: Towards systematic reuse in modelling language engineering}},
year = {2016}
}
@article{Ripon2016,
abstract = {Feature Tree represents all the features along with their relationship of a Software Product Line. Any defect in feature model can diminish the benefits of product line approach. Hence, the analysis of feature model plays a key role towards the success of any Software Product Line. This paper presents various analysis rules for cardinality-based feature model of both dead and false optional features. These rules are then verified by using Bayesian Network Based inference mechanism. Such verification not only confirms the analysis rules of the feature trees but also ensures the applicability of probabilistic information into the feature trees.},
author = {Ripon, Shamim and Rahman, Musfiqur and Ferdous, Javedul and Hossain, Md Delwar},
doi = {10.17485/ijst/2016/v9i31/93731},
issn = {09745645},
number = {31},
publisher = {Indian Society for Education and Environment},
title = {{Verification of SPL feature model by using Bayesian Network}},
volume = {9},
year = {2016}
}
@article{Saeed2016,
abstract = {Context Feature models are commonly used to capture and communicate the commonality and variability of features in a Software Product Line. The core component of Feature models is feature diagrams, which graphically depict features in a hierarchical form. In previous work we have proposed a new notation that aims to improve the cognitive effectiveness of feature diagrams. Objective The objective of this paper is to empirically validate the cognitive effectiveness of the new feature diagrams notation in comparison to its original form. Methods We use two distinct empirical user-studies to validate the new notation. The first empirical study uses the survey approach while the second study is a subject-based experiment. The survey study investigates the semantic transparency of the new notation while the second study investigates the speed and accuracy of reading the notation. Results The results of the studies indicate that the proposed changes have significantly improved its cognitive effectiveness. Conclusions The cognitive effectiveness of feature diagrams has been improved, however there remains further research for full acceptance of the new notation by its potential user community.},
author = {Saeed, Mazin and Saleh, Faisal and Al-Insaif, Sadiq and El-Attar, Mohamed},
doi = {10.1016/j.infsof.2015.10.012},
issn = {09505849},
month = {mar},
pages = {1--26},
publisher = {Elsevier},
title = {{Empirical validating the cognitive effectiveness of a new feature diagrams visual syntax}},
volume = {71},
year = {2016}
}
@inproceedings{Safilian2016,
abstract = {Feature modeling is the most common approach to specify software product lines. The main part of a feature model is a special tree of features called a feature diagram. Cardinality-based feature diagrams provide the most expressive tool among the current feature diagram languages. The most common characterization of the semantics of a cardinality-based diagram is the set of flat multisets over features satisfying the constraints. However, this semantics provides a poor abstract view of the diagram. We address this problem by proposing another multiset theory for the diagram, called the hierarchical theory. We show that the theory captures all information of the diagram so that one can retrieve the diagram from its theory. This provides us with a theoretical framework for addressing some challenging issues in feature modeling, e.g., feature model management and reverse engineering of feature models.},
author = {Safilian, Aliakbar and Maibaum, Tom},
doi = {10.1109/TASE.2016.14},
isbn = {9781509017638},
month = {aug},
pages = {136--143},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Hierarchical Multiset Theories of Cardinality-Based Feature Diagrams}},
year = {2016}
}
@inproceedings{Schnabel2016,
abstract = {Cardinality-based feature models (CFM) constitute a crucial and non-trivial extension to FODA feature models in terms of UML-like feature multiplicities and corresponding cardinality constraints. CFM allow for specifying configuration choices of software systems incorporating multiple instances (copies) of features, e.g., for tailoring customer-specific and even potentially unrestricted application resources. Nevertheless, the improved expressiveness of CFM compared to FODA feature models complicates configuration semantics, including sub-tree cloning and potentially unbounded configuration spaces. As a consequence, entirely novel anomalies might arise such as dead cardinality intervals, false unboundedness, and cardinality gaps, which are not properly treated by recent feature-modeling tools. In this paper, we present comprehensive tool support for assisting specification, validation, and configuration of CFM. Our tool CardyGAn, therefore, incorporates capabilities for CFM editing, automated CFM validation including anomaly detection based on a combination of ILP and SMT solvers, as well as a CFM configuration engine based on Alloy.},
author = {Schnabel, Thomas and Weckesser, Markus and Kluge, Roland and Lochau, Malte and Sch{\"{u}}rr, Andy},
doi = {10.1145/2866614.2866619},
isbn = {9781450340199},
month = {jan},
pages = {33--40},
publisher = {Association for Computing Machinery},
title = {{CardyGAn: Tool support for cardinality-based feature models}},
year = {2016}
}
@inproceedings{Schroter2016,
abstract = {Today's software systems are often customizable by means of load-time or compile-time configuration options. These options are typically not independent and their dependencies can be specified by means of feature models. As many industrial systems contain thousands of options, the maintenance and utilization of feature models is a challenge for all stakeholders. In the last two decades, numerous approaches have been presented to support stakeholders in analyzing feature models. Such analyses are commonly reduced to satis fiability problems, which suffer from the growing number of options. While first attempts have been made to decompose feature models into smaller parts, they still require to compose all parts for analysis. We propose the concept of a feature-model interface that only consists of a subset of features, typically selected by experts, and hides all other features and dependencies. Based on a formalization of feature-model interfaces, we prove compositionality properties. We evaluate feature-model interfaces using a three-month history of an industrial feature model from the automotive domain with 18,616 features. Our results indicate performance benefits especially under evolution as often only parts of the feature model need to be analyzed again.},
author = {Schr{\"{o}}ter, Reimar and Krieter, Sebastian and Th{\"{u}}m, Thomas and Benduhn, Fabian and Saake, Gunter},
doi = {10.1145/2884781.2884823},
isbn = {9781450339001},
issn = {02705257},
month = {may},
pages = {667--678},
publisher = {IEEE Computer Society},
title = {{Feature-model interfaces: The highway to compositional analyses of highly-configurable systems}},
year = {2016}
}
@article{Segura2016,
abstract = {A test oracle determines whether a test execution reveals a fault, often by comparing the observed program output to the expected output. This is not always practical, for example when a program's input-output relation is complex and difficult to capture formally. Metamorphic testing provides an alternative, where correctness is not determined by checking an individual concrete output, but by applying a transformation to a test input and observing how the program output 'morphs' into a different one as a result. Since the introduction of such metamorphic relations in 1998, many contributions on metamorphic testing have been made, and the technique has seen successful applications in a variety of domains, ranging from web services to computer graphics. This article provides a comprehensive survey on metamorphic testing: It summarises the research results and application areas, and analyses common practice in empirical studies of metamorphic testing as well as the main open challenges.},
author = {Segura, Sergio and Fraser, Gordon and Sanchez, Ana B. and Ruiz-Cortes, Antonio},
doi = {10.1109/TSE.2016.2532875},
issn = {00985589},
month = {sep},
number = {9},
pages = {805--824},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{A Survey on Metamorphic Testing}},
volume = {42},
year = {2016}
}
@inproceedings{Sheikhalishahi2016,
abstract = {Despite being one of the most common approach in unsupervised data analysis, a very small literature exists on the formalization of clustering algorithms. This paper proposes a semiring-based methodology, named Feature-Cluster Algebra, which is applied to abstract the representation of a labeled tree structure representing a hierarchical categorical clustering algorithm, named CCTree. The elements of the feature-cluster algebra are called terms. We prove that a specific kind of a term, under some conditions, fully abstracts a labeled tree structure. The abstraction methodology maps the original problem to a new representation by removing unwanted details, which makes it simpler to handle. Moreover, we present a set of relations and functions on the algebraic structure to shape the requirements of a term to represent a CCTree structure. The proposed formal approach can be generalized to other categorical clustering (classification) algorithms in which features play key roles in specifying the clusters (classes).},
author = {Sheikhalishahi, Mina and Mejri, Mohamed and Tawbi, Nadia},
doi = {10.1007/978-3-319-41920-6_51},
isbn = {9783319419190},
issn = {16113349},
pages = {659--675},
publisher = {Springer Verlag},
title = {{On the abstraction of a categorical clustering algorithm}},
volume = {9729},
year = {2016}
}
@inproceedings{Silva2016,
abstract = {Looking for a complete modular software development paradigm, this article presents Join Point Interface JPI Feature Models, in the context of a JPI and Feature-Oriented Programming FOP symbiosis paradigm. Therefore, this article describes pros and cons of JPI and FOP approaches for the modular software and software product line production, respective; and highlights the benefits of this mixing proposal; in particular, the JPI Feature Model benefits for a high-level software product line modeling. As an application example, this article applies JPI Features Models on a classic FOP example already modeled using a previous aspect-oriented feature model proposal. Main goals of this application are to visualize traditional feature models preserved components such alternative and optional feature sets and optional and mandatory features as well as special features associations (cross-tree constraints), and differences and advantages with respect to previous research works about extending feature model to support aspect-oriented modeling principles.},
author = {Silva, Cristian Vidal and Galindo, Jose Angel and Villarroel, Rodolfo and Benavides, David and Leger, Paul and Valenzuela, Sebastian},
doi = {10.1109/SCCC.2015.7416583},
isbn = {9781467398176},
issn = {15224902},
month = {feb},
publisher = {IEEE Computer Society},
title = {{JPI feature models-Exploring a JPI and FOP symbiosis for software modeling}},
year = {2016}
}
@article{Tanhaei2016,
abstract = {Context: Feature model is an appropriate and indispensable tool for modeling similarities and differences among products of the Software Product Line (SPL). It not only exposes the validity of the products' configurations in an SPL but also changes in the course of time to support new requirements of the SPL. Modifications made on the feature model in the course of time raise a number of issues. Useless enlargements of the feature model, the existence of dead features, and violated constraints in the feature model are some of the key problems that make its maintenance difficult. Objective: The initial approach to dealing with the above-mentioned problems and improving maintainability of the feature model is refactoring. Refactoring modifies software artifacts in a way that their externally visible behavior does not change. Method: We introduce a method for defining refactoring rules and executing them on the feature model. We use the ATL model transformation language to define the refactoring rules. Moreover, we provide an Alloy model to check the feature model and the safety of the refactorings that are performed on it. Results: In this research, we propose a safe framework for refactoring a feature model. This framework enables users to perform automatic and semi-automatic refactoring on the feature model. Conclusions: Automated tool support for refactoring is a key issue for adopting approaches such as utilizing feature models and integrating them into the software development process of companies. In this work, we define some of the important refactoring rules on the feature model and provide tools that enable users to add new rules using the ATL M2M language. Our framework assesses the correctness of the refactorings using the Alloy language.},
author = {Tanhaei, Mohammad and Habibi, Jafar and Mirian-Hosseinabadi, Seyed Hassan},
doi = {10.1016/j.infsof.2016.08.011},
issn = {09505849},
month = {dec},
pages = {138--157},
publisher = {Elsevier},
title = {{Automating feature model refactoring: A Model transformation approach}},
volume = {80},
year = {2016}
}
@inproceedings{Thum2016,
abstract = {Software product lines are used to efficiently develop and verify similar software products. While they focus on reuse of artifacts between products, a product line may also be reused itself in other product lines. A challenge with such dependent product lines is evolution; every change in a product line may inuence all dependent product lines. With variability hiding, we aim to hide certain features and their artifacts in dependent product lines. In prior work, we focused on feature models and implementation artifacts. We build on this by discussing how variability hiding can be extended to specifications in terms of method contracts. We illustrate variability hiding in contracts by means of a running example and share our insights with preliminary experiments on the benefits for formal verification. In particular, we find that not every change in a certain product line requires a re-verification of other dependent product lines.},
author = {Th{\"{u}}m, Thomas and Winkelmann, Tim and Schr{\"{o}}ter, Reimar and Hentschel, Martin and Kr{\"{u}}ger, Stefan},
doi = {10.1145/2866614.2866628},
isbn = {9781450340199},
month = {jan},
pages = {97--104},
publisher = {Association for Computing Machinery},
title = {{Variability hiding in contracts for dependent software product lines}},
year = {2016}
}
@inproceedings{Tiihonen2016,
abstract = {Software variability modelling (SVM) has become a central concern in software product lines - especially configurable software product lines (CSPL) require rigorous SVM. Dynamic SPLs, service oriented SPLs, and autonomous or pervasive systems are examples where CSPLs are applied. Knowledge-based configuration (KBC) is an established way to address variability modelling aiming for the automatic product configuration of physical products. Our aim was to study what major ideas from KBC can be applied to SVM, particularly in the context of CSPLs. Our main contribution is the identification of major ideas from KBC that could be applied to SVM. First, we call for the separation of types and instances. Second, conceptual clarity of modelling concepts, e.g., having both taxonomical and compositional relations would be useful. Third, we argue for the importance of a conceptual basis that provides a foundation for multiple representations, e.g., graphical and textual. Applying the insights and experiences embedded in these ideas may help in the development of modelling support for software product lines, particularly in terms of conceptual clarity and as a basis for tool support with a high level of automation.},
author = {Tiihonen, Juha and Raatikainen, Mikko and Myll{\"{a}}rniemi, Varvana and M{\"{a}}nnist{\"{o}}, Tomi},
doi = {10.1007/978-3-319-35122-3_4},
isbn = {9783319351216},
issn = {16113349},
pages = {55--62},
publisher = {Springer Verlag},
title = {{Carrying ideas from knowledge-based configuration to software product lines}},
volume = {9679},
year = {2016}
}
@misc{Wang2016,
abstract = {In the context of product lines, test case selection aims at obtaining a set of relevant test cases for a product from the entire set of test cases available for a product line. While working on a research-based innovation project on automated testing of product lines of Video Conferencing Systems (VCSs) developed by Cisco, we felt the need to devise a cost-effective way of selecting relevant test cases for a product. To fulfill such need, we propose a systematic and automated test selection methodology using: 1) Feature Model for Testing (FM{\_}T) to capture commonalities and variabilities of a product line; 2) Component Family Model for Testing (CFM{\_}T) to model the structure of test case repository; 3) A tool to automatically build restrictions from CFM{\_}T to FM{\_}T and traces from CFM{\_}T to the actual test cases. Using our methodology, a test engineer is only required to select relevant features through FM{\_}T at a higher level of abstraction for a product and the corresponding test cases will be obtained automatically. We evaluate our methodology by applying it to a VCS product line called Saturn with seven commercial products and the results show that our methodology can significantly reduce cost measured as test selection time and at the same time achieves higher effectiveness (feature coverage, feature pairwise coverage and fault detection) as compared with the current manual process. Moreover, we conduct a questionnaire-based study to solicit the views of test engineers who are involved in developing FM{\_}T and CFM{\_}T. The results show that test engineers are positive about adapting our methodology in their current practice. Finally, we present a set of lessons learnt while applying product line engineering at Cisco for test case selection.},
author = {Wang, Shuai and Ali, Shaukat and Gotlieb, Arnaud and Liaaen, Marius},
doi = {10.1007/s10664-014-9345-5},
issn = {15737616},
month = {aug},
number = {4},
pages = {1586--1622},
publisher = {Springer New York LLC},
title = {{A systematic test case selection methodology for product lines: results and insights from an industrial case study}},
volume = {21},
year = {2016}
}
@inproceedings{Weckesser2016,
abstract = {Feature models are frequently used for specifying variability of user-configurable software systems, e.g., software product lines. Numerous approaches have been developed for automating feature model validation concerning constraint consistency and absence of anomalies. As a crucial extension to feature models, cardinality annotations and respective constraints allow for multiple, and even potentially unbounded occurrences of feature instances within configurations. This is of particular relevance for user-adjustable application resources as prevalent, e.g., in cloud computing. However, a precise semantic characterization and tool support for automated and scalable validation of cardinality-based feature models is still an open issue. In this paper, we present a comprehensive formalization of cardinality-based feature models with potentially unbounded feature multiplicities. We apply a combination of ILP and SMT solvers to automate consistency checking and anomaly detection, including novel anomalies, e.g., interval gaps.We present evaluation results gained from our tool implementation showing applicability and scalability to larger-scale models.},
author = {Weckesser, Markus and Lochau, Malte and Schnabel, Thomas and Richerzhagen, Bj{\"{o}}rn and Sch{\"{u}}rr, Andy},
doi = {10.1007/978-3-662-49665-7_10},
isbn = {9783662496640},
issn = {16113349},
pages = {158--175},
publisher = {Springer Verlag},
title = {{Mind the gap! automated anomaly detection for potentially unbounded cardinality-based feature models}},
volume = {9633},
year = {2016}
}
@article{Wittern2016,
abstract = {The design of software-intensive service systems involves and affects numerous stakeholders including software engineers, legal and business experts as well as a potentially large number of consumers. In consequence, the challenge arises to adequately represent the interests of these groups with respect to service design decisions. Specifically, shared service design artifacts and participatory methods for influencing their development in consensus are required, which are not yet state of the art in software service engineering. To this end, we present service feature modeling. Using a modeling notation based on feature-oriented analysis, our approach can represent and interrelate diverse service design concerns and capture their potential combinations as service design alternatives. We further present a method that allows stakeholders to rank service design alternatives based on their preferences. The ranking can support service engineers in selecting viable alternatives for implementation. To exploit this potential, we have implemented a toolkit to enable both modeling and participative ranking of service design alternatives. It has been used to apply service feature modeling in the context of public service design and evaluate the approach in this context.},
author = {Wittern, Erik and Zirpins, Christian},
doi = {10.1007/s10270-014-0414-4},
issn = {16191374},
month = {may},
number = {2},
pages = {553--578},
publisher = {Springer Verlag},
title = {{Service feature modeling: modeling and participatory ranking of service design alternatives}},
volume = {15},
year = {2016}
}
@inproceedings{Zhou2016,
abstract = {A feature model is able to identify commonality and variability within a product line, helping stakeholders configure product variants and seize opportunities for reuse. However, no direct customer preference information is incorporated in the feature model when it comes to the question-how many product variants are needed in order to satisfy individual customer needs. This paper proposes to mine customer preference information for individual product features by sentiment analysis of online product reviews. The features commented by the users of a product are used to augment a simple feature model predefined with customer opinionated preference information. In such a way, the customer preference information is considered as one attribute of the features in the model, helping designers make informed decisions when trading off between commonality and variability of a product line. Finally, we present a Kindle Fire tablet case study to demonstrate the proposed method.},
author = {Zhou, F. and Jiao, R. J.},
doi = {10.1109/IEEM.2015.7385935},
isbn = {9781467380669},
issn = {2157362X},
month = {jan},
pages = {1689--1693},
publisher = {IEEE Computer Society},
title = {{Feature model augmentation with sentiment analysis for product line planning}},
year = {2016}
}
