% Encoding: UTF-8

@Article{Abbasi2014,
  author  = {Abbasi, EK and Acher, M and Heymans, P},
  title   = {Reverse engineering web configurators},
  journal = {WCRE},
  year    = {2014},
  review  = {k-vis k-reverse},
  url     = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6747178},
}

@Article{acher2014extraction,
	author = {Acher, Mathieu and Cleve, Anthony and Collet, Philippe and Merle, Philippe and Duchien, Laurence and Lahire, Philippe},
	title = {Extraction and evolution of architectural variability models in plugin-based systems},
	journal = {SOSYM},
	year = {2014},
	volume = {13},
	number = {4},
	pages = {1367--1394},
	abstract = {Variability management is a key issue when building and evolving software-intensive systems, making it possible to extend, configure, customize and adapt such systems to customers' needs and specific deployment contexts. A wide form of variability can be found in extensible software systems, typically built on top of plugin-based architectures that offer a (large) number of configuration options through plugins. In an ideal world, a software architect should be able to generate a system variant on-demand, corresponding to a particular assembly of plugins. To this end, the variation points and constraints between architectural elements should be properly modeled and maintained over time (i.e., for each version of an architecture). A crucial, yet error-prone and time-consuming, task for a software architect is to build an accurate representation of the variability of an architecture, in order to prevent unsafe architectural variants and reach the highest possible level of flexibility. In this article, we propose a reverse engineering process for producing a variability model (i.e., a feature model) of a plugin-based architecture. We develop automated techniques to extract and combine different variability descriptions, including a hierarchical software architecture model, a plugin dependency model and the software architect knowledge. By computing and reasoning about differences between versions of architectural feature models, software architect can control both the variability extraction and evolution processes. The proposed approach has been applied to a representative, large-scale plugin-based system (FraSCAti), considering different versions of its architecture. We report on our experience in this context.},
	date-modified = {2015-06-12 14:06:16 +0000},
	publisher = {Springer},
	review = {k-reverse k-evaluation k-tool}
}

@Article{Acher2012689,
	Title = {Composing multiple variability artifacts to assemble coherent workflows},
	Author = {Acher, M and Collet, P and Gaignard, A and Lahire, P and Montagnat, J and France, R.B.b},
	Journal = {SQJ},
	Year = {2012},
	Note = {cited By 5},
	Number = {3-4},
	Pages = {689-734},
	Volume = {20},
	Abstract = {The development of scientific workflows is evolving toward the systematic use of service-oriented architectures, enabling the composition of dedicated and highly parameterized software services into processing pipelines. Building consistent workflows then becomes a cumbersome and error-prone activity as users cannot manage such large-scale variability. This paper presents a rigorous and tooled approach in which techniques from Software Product Line (SPL) engineering are reused and extended to manage variability in service and workflow descriptions. Composition can be facilitated while ensuring consistency. Services are organized in a rich catalog which is organized as a SPL and structured according to the common and variable concerns captured for all services. By relying on sound merging techniques on the feature models that make up the catalog, reasoning about the compatibility between connected services is made possible. Moreover, an entire workflow is then seen as a multiple SPL (i. e., a composition of several SPLs). When services are configured within, the propagation of variability choices is then automated with appropriate techniques and the user is assisted in obtaining a consistent workflow. The approach proposed is completely supported by a combination of dedicated tools and languages. Illustrations and experimental validations are provided using medical imaging pipelines, which are representative of current scientific workflows in many domains. {\copyright} 2011 Springer Science+Business Media, LLC.},
	Affiliation = {I3S Laboratory (CNRS-UNSA), Les Algorithmes, B{\^a}t Euclide B, 2000 route des Lucioles, B.P. 121, 06903 Sophia Antipolis Cedex, France; Computer Science Department, Colorado State University, Fort Collins, CO, United States},
	Author_keywords = {Composition; Feature models; Scientific workflows; Software product lines},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84865642073&partnerID=40&md5=0aed260c78ee4b9b75e969cb2b51ecf0},
	Bdsk-url-2 = {http://dx.doi.org/10.1007/s11219-011-9170-7},
	Document_type = {Article},
	Doi = {10.1007/s11219-011-9170-7},
	Review = {k-mmodel k-evaluation k-method},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84865642073&partnerID=40&md5=0aed260c78ee4b9b75e969cb2b51ecf0}
}

@Article{AcherColletLahireEtAl2013,
	author = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert B},
	title = {Familiar: A domain-specific language for large scale management of feature models},
	journal = {SCP},
	year = {2013},
	volume = {78},
	number = {6},
	pages = {657--681},
	note = {cited By 23},
	abstract = {The feature model formalism has become the de facto standard for managing variability in software product lines (SPLs). In practice, developing an SPL can involve modeling a large number of features representing different viewpoints, sub-systems or concerns of the software system. This activity is generally tedious and error-prone. In this article, we present FAMILIAR a Domain-Specific Language (DSL) that is dedicated to the large scale management of feature models and that complements existing tool support. The language provides a powerful support for separating concerns in feature modeling, through the provision of composition and decomposition operators, reasoning facilities and scripting capabilities with modularization mechanisms. We illustrate how an SPL consisting of medical imaging services can be practically managed using reusable FAMILIAR scripts that implement reasoning mechanisms. We also report on various usages and applications of FAMILIAR and its operators, to demonstrate their applicability to different domains and use for different purposes. {\copyright} 2012 Elsevier B.V. All rights reserved.},
	affiliation = {University of Namur, PReCISE Research Centre, Belgium; University of Rennes 1, IRISA, INRIA, France; University of Nice Sophia Antipolis, I3S Laboratory, CNRS UMR 6070, France; Colorado State University, Department of Computer Science, United States},
	author_keywords = {Domain-specific language; Feature model; Model management; Software product lines; Variability},
	bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84875729938&partnerID=40&md5=022b272cc23e29c8097a00646802ead0},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.scico.2012.12.004},
	document_type = {Conference Paper},
	doi = {10.1016/j.scico.2012.12.004},
	publisher = {Elsevier},
	review = {k-tool k-configuration k-solution},
	source = {Scopus},
	url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84875729938&partnerID=40&md5=022b272cc23e29c8097a00646802ead0}
}

@Article{Al-MsieDeen2014,
  author    = {Al-Msie'Deen, R. and Huchard, M. and Seriai, A. D. and Urtado, C. and Vauttier, S.},
  title     = {Automatic documentation of [Mined] feature implementations from source code elements and use-case diagrams with the REVPLINE approach},
  journal   = {IJSEKE},
  year      = {2014},
  volume    = {24},
  number    = {10},
  pages     = {1413--1438},
  month     = {dec},
  abstract  = {Companies often develop a set of software variants that share some features and differ in others to meet specific requirements. To exploit the existing software variants as a Software Product Line (SPL), a Feature Model of this SPL must be built as a first step. To do so, it is necessary to define and document the optional and mandatory features that compose the variants. In our previous work, we mined a set of feature implementations as identified sets of source code elements. In this paper, we propose a complementary approach, which aims to document the mined feature implementations by giving them names and descriptions, based on the source code elements that form feature implementations and the use-case diagrams that specify software variants. The novelty of our approach is its use of commonality and variability across software variants, at feature implementation and use-case levels, to run Information Retrieval methods in an efficient way. Experiments on several real case studies (Mobile media and ArgoUML-SPL) validate our approach and show promising results.},
  doi       = {10.1142/S0218194014400142},
  issn      = {02181940},
  publisher = {World Scientific Publishing Co. Pte Ltd},
  review    = {k-reverse k-evaluation},
}

@Article{AndresCamachoLlana2013,
	Title = {A formal framework for software product lines},
	Author = {Andr{\'e}s, C. and Camacho, C. and Llana, L.},
	Journal = {IST},
	Year = {2013},
	Note = {cited By 2},
	Number = {11},
	Pages = {1925-1947},
	Volume = {55},
	Abstract = {Context A Software Product Line is a set of software systems that are built from a common set of features. These systems are developed in a prescribed way and they can be adapted to fit the needs of customers. Feature models specify the properties of the systems that are meaningful to customers. A semantics that models the feature level has the potential to support the automatic analysis of entire software product lines. Objective The objective of this paper is to define a formal framework for Software Product Lines. This framework needs to be general enough to provide a formal semantics for existing frameworks like FODA (Feature Oriented Domain Analysis), but also to be easily adaptable to new problems. Method We define an algebraic language, called SPLA, to describe Software Product Lines. We provide the semantics for the algebra in three different ways. The approach followed to give the semantics is inspired by the semantics of process algebras. First we define an operational semantics, next a denotational semantics, and finally an axiomatic semantics. We also have defined a representation of the algebra into propositional logic. Results We prove that the three semantics are equivalent. We also show how FODA diagrams can be automatically translated into SPLA. Furthermore, we have developed our tool, called AT, that implements the formal framework presented in this paper. This tool uses a SAT-solver to check the satisfiability of an SPL. Conclusion This paper defines a general formal framework for software product lines. We have defined three different semantics that are equivalent; this means that depending on the context we can choose the most convenient approach: operational, denotational or axiomatic. The framework is flexible enough because it is closely related to process algebras. Process algebras are a well-known paradigm for which many extensions have been defined. {\copyright} 2013 Elsevier B.V. All rights reserved.},
	Affiliation = {Departamento de Sistemas Inform{\'a}ticos y Computaci{\'o}n, Universidad Complutense de Madrid, Madrid, Spain},
	Author_keywords = {Feature models; Formal methods; Software product lines},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84884156122&partnerID=40&md5=9af156eaabde52f3319079116dd147d4},
	Bdsk-url-2 = {http://dx.doi.org/10.1016/j.infsof.2013.05.005},
	Document_type = {Article},
	Doi = {10.1016/j.infsof.2013.05.005},
	Review = {k-solution k-testing k-method k-modeling},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84884156122&partnerID=40&md5=9af156eaabde52f3319079116dd147d4}
}

@InProceedings{Antkiewicz2013,
  author    = {Antkiewicz, M and B{\c{a}}k, K and Murashkin, A and Olaechea, R},
  title     = {Clafer tools for product line engineering},
  booktitle = {SPLC},
  year      = {2013},
  abstract  = {Clafer is a lightweight yet expressive language for structural modeling: feature modeling and configuration, class and object modeling, and metamodeling. Clafer Tools is an integrated set of tools based on Clafer. In this paper, we describe some product-line variability modeling scenarios of Clafer Tools from the viewpoints of product-line owner, product-line engineer, and product engineer.},
  journal   = {SPLC},
  review    = {k-modeling k-evaluation},
  url       = {http://dl.acm.org/citation.cfm?id=2499779},
}

@Article{Araar2016,
  author    = {Araar, Imad Eddine and Seridi, Hassina},
  title     = {Software features extraction from object-oriented source code using an overlapping clustering approach},
  journal   = {Informatica},
  year      = {2016},
  volume    = {40},
  number    = {2},
  pages     = {245--255},
  month     = {jun},
  abstract  = {For many decades, numerous organizations have launched software reuse initiatives to improve their productivity. Software product lines (SPL) addressed this problem by organizing software development around a set of features that are shared by a set of products. In order to exploit existing software products for building a new SPL, features composing each of the used products must be specified in the first place. In this paper we analyze the effectiveness of overlapping clustering based technique to mine functional features from object-oriented (OO) source code of existing systems. The evaluation of the proposed approach using two different Java open-source applications, i.e. "Mobile media" and "Drawing Shapes", has revealed encouraging results.},
  issn      = {03505596},
  publisher = {Slovene Society Informatika},
  review    = {k-evaluation k-configuration},
}

@Article{AsadiSoltaniGasevicEtAl2014,
	author = {Asadi, Mohsen and Soltani, Samaneh and Gasevic, Dragan and Hatala, Marek and Bagheri, Ebrahim},
	title = {Toward automated feature model configuration with optimizing non-functional requirements},
	journal = {IST},
	year = {2014},
	volume = {56},
	number = {9},
	pages = {1144--1165},
	publisher = {Elsevier},
	review = {k-modeling k-configuration k-method k-evaluation}
}

@Article{BecanAcherBaudryEtAl2015,
	Title = {Breathing ontological knowledge into feature model synthesis: an empirical study},
	Author = {B{\'e}can, Guillaume and Acher, Mathieu and Baudry, Benoit and Nasr, Sana Ben},
	Journal = {ESE},
	Year = {2015},
	Pages = {1--48},
	Publisher = {Springer},
	Review = {k-reverse k-modeling k-solution k-evaluation}
}

@Article{Burdek2016,
  author    = {B{\"{u}}rdek, Johannes and Kehrer, Timo and Lochau, Malte and Reuling, Dennis and Kelter, Udo and Sch{\"{u}}rr, Andy},
  title     = {Reasoning about product-line evolution using complex feature model differences},
  journal   = {ASEJ},
  year      = {2016},
  volume    = {23},
  number    = {4},
  pages     = {687--733},
  month     = {dec},
  abstract  = {Features define common and variable parts of the members of a (software) product line. Feature models are used to specify the set of all valid feature combinations. Feature models not only enjoy an intuitive tree-like graphical syntax, but also a precise formal semantics, which can be denoted as propositional formulae over Boolean feature variables. A product line usually constitutes a long-term investment and, therefore, has to undergo continuous evolution to meet ever-changing requirements. First of all, product-line evolution leads to changes of the feature model due to its central role in the product-line paradigm. As a result, product-line engineers are often faced with the problems that (1) feature models are changed in an ad-hoc manner without proper documentation, and (2) the semantic impact of feature diagram changes is unclear. In this article, we propose a comprehensive approach to tackle both challenges. For (1), our approach compares the old and new version of the diagram representation of a feature model and specifies the changes using complex edit operations on feature diagrams. In this way, feature model changes are automatically detected and formally documented. For (2), we propose an approach for reasoning about the semantic impact of diagram changes. We present a set of edit operations on feature diagrams, where complex operations are primarily derived from evolution scenarios observed in a real-world case study, i.e., a product line from the automation engineering domain. We evaluated our approach to demonstrate its applicability with respect to the case study, as well as its scalability concerning experimental data sets.},
  doi       = {10.1007/s10515-015-0185-3},
  issn      = {15737535},
  publisher = {Springer New York LLC},
  review    = {k-testing k-evaluation},
}

@Article{bagheri2012formalizing,
	author = {Bagheri, Ebrahim and Noia, Tommaso Di and Gasevic, Dragan and Ragone, Azzurra},
	title = {Formalizing interactive staged feature model configuration},
	journal = {JSEP},
	year = {2012},
	volume = {24},
	number = {4},
	pages = {375--400},
	abstract = {Feature modeling an attractive technique for capturing commonality as well as variability within an application domain for generative programming and software product line engineering. Feature models symbolize an overarching representation of the possible application configuration space, and can hence be customized based on specific domain requirements and stakeholder goals. Most interactive or semi-automated feature model customization processes neglect the need to have a holistic approach towards the integration and satisfaction of the stakeholder's soft and hard constraints, and the application-domain integrity constraints. In this paper, we will show how the structure and constraints of a feature model can be modeled uniformly through Propositional Logic extended with concrete domains, called Pscr(&#55349;&#56489;). Furthermore, we formalize the representation of soft constraints in fuzzy &#55349;&#56491;(&#55349;&#56489;) and explain how semi-automated feature model customization is performed in this setting. The model configuration derivation process that we propose respects the soundness and completeness properties. Copyright © 2011 John Wiley & Sons, Ltd.},
	publisher = {Wiley Online Library},
	review = {k-philosophical k-rmodel k-modeling}
}

@Article{Bagheri2011579,
	Title = {Assessing the maintainability of software product line feature models using structural metrics},
	Author = {Bagheri, E b and Gasevic, D.a},
	Journal = {SQJ},
	Year = {2011},
	Note = {cited By 35},
	Number = {3},
	Pages = {579-612},
	Volume = {19},
	Abstract = {A software product line is a unified representation of a set of conceptually similar software systems that share many common features and satisfy the requirements of a particular domain. Within the context of software product lines, feature models are tree-like structures that are widely used for modeling and representing the inherent commonality and variability of software product lines. Given the fact that many different software systems can be spawned from a single software product line, it can be anticipated that a low-quality design can ripple through to many spawned software systems. Therefore, the need for early indicators of external quality attributes is recognized in order to avoid the implications of defective and low-quality design during the late stages of production. In this paper, we propose a set of structural metrics for software product line feature models and theoretically validate them using valid measurement-theoretic principles. Further, we investigate through controlled experimentation whether these structural metrics can be good predictors (early indicators) of the three main subcharacteristics of maintainability: analyzability, changeability, and understandability. More specifically, a four-step analysis is conducted: (1) investigating whether feature model structural metrics are correlated with feature model maintainability through the employment of classical statistical correlation techniques; (2) understanding how well each of the structural metrics can serve as discriminatory references for maintainability; (3) identifying the sufficient set of structural metrics for evaluating each of the subcharacteristics of maintainability; and (4) evaluating how well different prediction models based on the proposed structural metrics can perform in indicating the maintainability of a feature model. Results obtained from the controlled experiment support the idea that useful prediction models can be built for the purpose of evaluating feature model maintainability using early structural metrics. Some of the structural metrics show significant correlation with the subjective perception of the subjects about the maintainability of the feature models. {\copyright} 2010 Springer Science+Business Media, LLC.},
	Affiliation = {Athabasca University, Athabasca, Canada; National Research Council, Ottawa, ON, Canada},
	Author_keywords = {Controlled experimentation; Feature model; Maintainability; Quality attributes; Software prediction model; Software product line; Structural complexity},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79958248566&partnerID=40&md5=705c3965ef97dc964ddf3dcc4ab5aa61},
	Bdsk-url-2 = {http://dx.doi.org/10.1007/s11219-010-9127-2},
	Document_type = {Article},
	Doi = {10.1007/s11219-010-9127-2},
	Review = {k-testing k-evaluation k-metric},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79958248566&partnerID=40&md5=705c3965ef97dc964ddf3dcc4ab5aa61}
}

@Article{BakarKasirunSalleh2015,
	author = {Bakar, N.H b and Kasirun, Z.M and Salleh, N.c},
	title = {Feature extraction approaches from natural language requirements for reuse in software product lines: A systematic literature review},
	journal = {JSS},
	year = {2015},
	volume = {106},
	pages = {132-149},
	note = {cited By 1},
	abstract = {Abstract Requirements for implemented system can be extracted and reused for a production of a new similar system. Extraction of common and variable features from requirements leverages the benefits of the software product lines engineering (SPLE). Although various approaches have been proposed in feature extractions from natural language (NL) requirements, no related literature review has been published to date for this topic. This paper provides a systematic literature review (SLR) of the state-of-the-art approaches in feature extractions from NL requirements for reuse in SPLE. We have included 13 studies in our synthesis of evidence and the results showed that hybrid natural language processing approaches were found to be in common for overall feature extraction process. A mixture of automated and semi-automated feature clustering approaches from data mining and information retrieval were also used to group common features, with only some approaches coming with support tools. However, most of the support tools proposed in the selected studies were not made available publicly and thus making it hard for practitioners' adoption. As for the evaluation, this SLR reveals that not all studies employed software metrics as ways to validate experiments and case studies. Finally, the quality assessment conducted confirms that practitioners' guidelines were absent in the selected studies. {\copyright} 2015 Elsevier Inc. All rights reserved.},
	affiliation = {Department of Software Engineering, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia; Department of ICT, Centre for Foundation Studies, International Islamic University Malaysia, Petaling Jaya Selangor, Malaysia; Department of Computer Science, Kulliyyah of Information and Communication Technology, International Islamic University Malaysia, Jalan Gombak, Kuala Lumpur, Malaysia},
	art_number = {9509},
	author_keywords = {Feature extractions; Natural language requirements; Requirements reuse; Software product lines; Systematic literature review},
	bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84930795477&partnerID=40&md5=b516f9ecca7c0ac6927da380751deff3},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.jss.2015.05.006},
	document_type = {Article},
	doi = {10.1016/j.jss.2015.05.006},
	review = {k-reverse k-philosophical k-solution},
	source = {Scopus},
	url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84930795477&partnerID=40&md5=b516f9ecca7c0ac6927da380751deff3}
}

@Article{Baresi201242,
	Title = {Service-oriented dynamic software product lines},
	Author = {Baresi, L and Guinea, S and Pasquale, L.b},
	Journal = {Computer},
	Year = {2012},
	Note = {cited By 19},
	Number = {10},
	Pages = {42-48},
	Volume = {45},
	Abstract = {An operational example of controls in a smart home demonstrates the potential of a solution that combines the Common Variability Language and a dynamic extension of the Business Process Execution Language to address the need to manage software system variability at runtime. {\copyright} 2012 IEEE.},
	Affiliation = {Politecnico di Milano, Italy; Leroand-the Irish Software Engineering Research Centre, Ireland},
	Art_number = {6269872},
	Author_keywords = {BPEL; dynamic software product lines; self-adaptation; service-oriented architectures},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867818351&partnerID=40&md5=f2afadd1026575f27b653c20a57c9f9a},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/MC.2012.289},
	Document_type = {Article},
	Doi = {10.1109/MC.2012.289},
	Review = {k-configuration k-experience k-method},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867818351&partnerID=40&md5=f2afadd1026575f27b653c20a57c9f9a}
}

@Article{Berger20131611,
	Title = {A study of variability models and languages in the systems software domain},
	Author = {Berger, T and She, S and Lotufo, R and Wasowski, A and Czarnecki, K.b},
	Journal = {TSE},
	Year = {2013},
	Note = {cited By 9},
	Number = {12},
	Pages = {1611-1640},
	Volume = {39},
	Abstract = {Variability models represent the common and variable features of products in a product line. Since the introduction of FODA in 1990, several variability modeling languages have been proposed in academia and industry, followed by hundreds of research papers on variability models and modeling. However, little is known about the practical use of such languages. We study the constructs, semantics, usage, and associated tools of two variability modeling languages, Kconfig and CDL, which are independently developed outside academia and used in large and significant software projects. We analyze 128 variability models found in 12 open - source projects using these languages. Our study 1) supports variability modeling research with empirical data on the real-world use of its flagship concepts. However, we 2) also provide requirements for concepts and mechanisms that are not commonly considered in academic techniques, and 3) challenge assumptions about size and complexity of variability models made in academic papers. These results are of interest to researchers working on variability modeling and analysis techniques and to designers of tools, such as feature dependency checkers and interactive product configurators. {\copyright} 1976-2012 IEEE.},
	Affiliation = {IT University of Copenhagen, Rued Langgaards Vej 7, Copenhagen 2300, Denmark; Generative Software Development Lab, Department of Electrical and Computer Engineering, University of Waterloo, 200 University Ave. West, Waterloo, ON N2L3G1, Canada},
	Art_number = {6572787},
	Author_keywords = {configuration; Empirical software engineering; feature modeling; open source; software product lines; variability modeling},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84890065386&partnerID=40&md5=f3b1265408019e72ec8edea173428cb7},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/TSE.2013.34},
	Document_type = {Article},
	Doi = {10.1109/TSE.2013.34},
	Review = {k-validation k-modeling k-metric},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84890065386&partnerID=40&md5=f3b1265408019e72ec8edea173428cb7}
}

@Article{Boskovi2010,
  author   = {Bo{\v{s}}kovi, Marko and Bagheri, Ebrahim and Ga{\v{S}}evi, Dragan and Mohabbati, Bardia and Kaviani, Nima and Hatala, Marek},
  title    = {Automated staged configuration with semantic web technologies},
  journal  = {IJSEKE},
  year     = {2010},
  volume   = {20},
  number   = {4},
  pages    = {459--484},
  month    = {jun},
  abstract = {Since the introduction in the early nineties, feature models receive a great deal of attention in industry and academia. Industrial success stories in applying feature models for modeling software product lines, and using them for configuring software-intensive systems motivate academia to discover ways to integrate different feature dependencies into the feature model, and automate verified feature configuration. In this paper we demonstrate how ontologies and Semantic Web technologies facilitate seamless integration of required external services and deployment platform capabilities into the feature model. Furthermore, we also contribute with an algorithm for automating staged configuration using Semantic Web reasoners to discover unfeasible features of the feature model. {\textcopyright} 2010 World Scientific Publishing Company.},
  doi      = {10.1142/S0218194010004827},
  issn     = {02181940},
  review   = {k-vis k-mmodel k-configuration},
}

@Article{Buchmann2013,
  author   = {Buchmann, Thomas and Dotor, Alexander and Westfechtel, Bernhard},
  title    = {MOD2-SCM: A model-driven product line for software configuration management systems},
  journal  = {IST},
  year     = {2013},
  volume   = {55},
  number   = {3},
  pages    = {630--650},
  month    = {mar},
  abstract = {Context: Software Configuration Management (SCM) is the discipline of controlling the evolution of large and complex software systems. Over the years many different SCM systems sharing similar concepts have been implemented from scratch. Since these concepts usually are hard-wired into the respective program code, reuse is hardly possible. Objective: Our objective is to create a model-driven product line for SCM systems. By explicitly describing the different concepts using models, reuse can be performed on the modeling level. Since models are executable, the need for manual programming is eliminated. Furthermore, by providing a library of loosely coupled modules, we intend to support flexible composition of SCM systems. Method: We developed a method and a tool set for model-driven software product line engineering which we applied to the SCM domain. For domain analysis, we applied the FORM method, resulting in a layered feature model for SCM systems. Furthermore, we developed an executable object-oriented domain model which was annotated with features from the feature model. A specific SCM system is configured by selecting features from the feature model and elements of the domain model realizing these features. Results: Due to the orthogonality of both feature model and domain model, a very large number of SCM systems may be configured. We tested our approach by creating instances of the product line which mimic wide-spread systems such as CVS, GIT, Mercurial, and Subversion. Conclusion: The experiences gained from this project demonstrate the feasibility of our approach to model-driven software product line engineering. Furthermore, our work advances the state of the art in the domain of SCM systems since it support the modular composition of SCM systems at the model rather than the code level. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
  doi      = {10.1016/j.infsof.2012.07.010},
  issn     = {09505849},
  review   = {k-vis k-configuration k-evaluation},
}

@Article{Capilla20143,
	Title = {An overview of Dynamic Software Product Line architectures and techniques: Observations from research and industry},
	Author = {Capilla, R and Bosch, J and Trinidad, P and Ruiz-Cort{\'e}s, A and Hinchey, M.d},
	Journal = {JSS},
	Year = {2014},
	Note = {cited By 3},
	Number = {1},
	Pages = {3-23},
	Volume = {91},
	Abstract = {Over the last two decades, software product lines have been used successfully in industry for building families of systems of related products, maximizing reuse, and exploiting their variable and configurable options. In a changing world, modern software demands more and more adaptive features, many of them performed dynamically, and the requirements on the software architecture to support adaptation capabilities of systems are increasing in importance. Today, many embedded system families and application domains such as ecosystems, service-based applications, and self-adaptive systems demand runtime capabilities for flexible adaptation, reconfiguration, and post-deployment activities. However, as traditional software product line architectures fail to provide mechanisms for runtime adaptation and behavior of products, there is a shift toward designing more dynamic software architectures and building more adaptable software able to handle autonomous decision-making, according to varying conditions. Recent development approaches such as Dynamic Software Product Lines (DSPLs) attempt to face the challenges of the dynamic conditions of such systems but the state of these solution architectures is still immature. In order to provide a more comprehensive treatment of DSPL models and their solution architectures, in this research work we provide an overview of the state of the art and current techniques that, partially, attempt to face the many challenges of runtime variability mechanisms in the context of Dynamic Software Product Lines. We also provide an integrated view of the challenges and solutions that are necessary to support runtime variability mechanisms in DSPL models and software architectures. {\copyright} 2014 Elsevier Inc.},
	Affiliation = {Rey Juan Carlos University, Madrid, Spain; Chalmers University of Technology, Gothenburg, Sweden; University of Seville, Seville, Spain; Lero, Irish Software Engineering Research Centre, Limerick, Ireland},
	Author_keywords = {Dynamic Software Product Lines; Dynamic variability; Feature models; Software architecture},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84900605085&partnerID=40&md5=58c6b5d99af36f622795ce5bd54cf6c4},
	Bdsk-url-2 = {http://dx.doi.org/10.1016/j.jss.2013.12.038},
	Document_type = {Article},
	Doi = {10.1016/j.jss.2013.12.038},
	Review = {k-configuration k-philosophical k-method},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84900605085&partnerID=40&md5=58c6b5d99af36f622795ce5bd54cf6c4}
}

@Article{Chimiak-Opoka2011,
  author   = {Chimiak-Opoka, JD and Demuth, B},
  title    = {OCL tools report based on the ide4OCL feature model},
  journal  = {ECEASST},
  year     = {2011},
  abstract = {Previously we have developed the idea of an Integrated DevelopmentEnvironment for OCL (IDE4OCL). Based on the OCL community’s feedback wehave also designed and published an IDE4OCL feature model.  Here we present areport on selected OCL tools developed by the authors and their teams. Each authorgives an overview of their OCL tool, provides a top level architecture, and gives anevaluation of the tool features in a web framework. The framework can also be usedby other potential OCL users and tool developers.  For users it may serve as an aidto choose a suitable tool for their OCL use scenarios. For tool developers it providesa comparative view for further development of the OCL tools.   Our plans are tomaintain the collected data and extend this web framework by further OCL tools.Additionally, we would like to encourage sharing of OCL development resources},
  review   = {k-solution k-modeling},
  url      = {http://journal.ub.tu-berlin.de/eceasst/article/view/665/0},
}

@Article{Classen20111130,
	Title = {A text-based approach to feature modelling: Syntax and semantics of TVL},
	Author = {Classen, A. and Boucher, Q. and Heymans, P.},
	Journal = {SCP},
	Year = {2011},
	Note = {cited By 43},
	Number = {12},
	Pages = {1130-1143},
	Volume = {76},
	Abstract = {In the scientific community, feature models are the de-facto standard for representing variability in software product line engineering. This is different from industrial settings where they appear to be used much less frequently. We and other authors found that in a number of cases, they lack concision, naturalness and expressiveness. This is confirmed by industrial experience. When modelling variability, an efficient tool for making models intuitive and concise are feature attributes. Yet, the semantics of feature models with attributes is not well understood and most existing notations do not support them at all. Furthermore, the graphical nature of feature models' syntax also appears to be a barrier to industrial adoption, both psychological and rational. Existing tool support for graphical feature models is lacking or inadequate, and inferior in many regards to tool support for text-based formats. To overcome these shortcomings, we designed TVL, a text-based feature modelling language. In terms of expressiveness, TVL subsumes most existing dialects. The main goal of designing TVL was to provide engineers with a human-readable language with a rich syntax to make modelling easy and models natural, but also with a formal semantics to avoid ambiguity and allow powerful automation. {\copyright} 2010 Elsevier B.V. All rights reserved.},
	Affiliation = {PReCISE Research Centre, University of Namur, Rue Grandgagnage 21, B-5000 Namur, Belgium},
	Author_keywords = {Code; Feature models; Language; Modelling; Semantics; Software product lines; Syntax},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79958851357&partnerID=40&md5=b5c4a6d1f534e49d61f730121e71a361},
	Bdsk-url-2 = {http://dx.doi.org/10.1016/j.scico.2010.10.005},
	Document_type = {Article},
	Doi = {10.1016/j.scico.2010.10.005},
	Review = {k-modeling k-solution k-mmodel},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79958851357&partnerID=40&md5=b5c4a6d1f534e49d61f730121e71a361}
}

@Article{Costa2015,
  author    = {Costa, Gabriella Castro B and Braga, Regina and David, Jos{\'{e}} Maria N and Campos, Fernanda},
  title     = {A Scientific Software Product Line for the Bioinformatics domain},
  journal   = {JBI},
  year      = {2015},
  volume    = {56},
  pages     = {239--264},
  month     = {aug},
  abstract  = {Context: Most specialized users (scientists) that use bioinformatics applications do not have suitable training on software development. Software Product Line (SPL) employs the concept of reuse considering that it is defined as a set of systems that are developed from a common set of base artifacts. In some contexts, such as in bioinformatics applications, it is advantageous to develop a collection of related software products, using SPL approach. If software products are similar enough, there is the possibility of predicting their commonalities, differences and then reuse these common features to support the development of new applications in the bioinformatics area. Objectives: This paper presents the PL-Science approach which considers the context of SPL and ontology in order to assist scientists to define a scientific experiment, and to specify a workflow that encompasses bioinformatics applications of a given experiment. This paper also focuses on the use of ontologies to enable the use of Software Product Line in biological domains. Method: In the context of this paper, Scientific Software Product Line (SSPL) differs from the Software Product Line due to the fact that SSPL uses an abstract scientific workflow model. This workflow is defined according to a scientific domain and using this abstract workflow model the products (scientific applications/algorithms) are instantiated. Results: Through the use of ontology as a knowledge representation model, we can provide domain restrictions as well as add semantic aspects in order to facilitate the selection and organization of bioinformatics workflows in a Scientific Software Product Line. The use of ontologies enables not only the expression of formal restrictions but also the inferences on these restrictions, considering that a scientific domain needs a formal specification. Conclusions: This paper presents the development of the PL-Science approach, encompassing a methodology and an infrastructure, and also presents an approach evaluation. This evaluation presents case studies in bioinformatics, which were conducted in two renowned research institutions in Brazil.},
  doi       = {10.1016/j.jbi.2015.05.014},
  issn      = {15320464},
  publisher = {Academic Press Inc.},
  review    = {k-evaluation k-validation k-modeling k-vis},
}

@Article{Del-Rio-Ortega2013470,
	author = {Del-R{\'\i}o-Ortega, A. and Resinas, M. and Cabanillas, C. and Ruiz-Cort{\'e}s, A.},
	title = {On the definition and design-time analysis of process performance indicators},
	journal = {IS},
	year = {2013},
	volume = {38},
	number = {4},
	pages = {470-490},
	note = {cited By 10},
	abstract = {A key aspect in any process-oriented organisation is the evaluation of process performance for the achievement of its strategic and operational goals. Process Performance Indicators (PPIs) are a key asset to carry out this evaluation, and, therefore, having an appropriate definition of these PPIs is crucial. After a careful review of the literature related and a study of the current picture in different real organisations, we conclude that there not exists any proposal that allows to define PPIs in a way that is unambiguous and highly expressive, understandable by technical and non-technical users and traceable with the Business Process (BP). In addition, like other activities carried out during the BP lifecycle, the management of PPIs is considered time-consuming and error-prone. Therefore, providing an automated support for them is very appealing from a practical point of view. In this paper, we propose the PPINOT metamodel, which allows such an advanced definition of PPIs and is independent of the language used to model the business process. Furthermore, we provide an automatic semantic mapping from the metamodel to Description Logics (DL) that allows the implementation of design-time analysis operations in such a way that DL reasoners' facilities can be leveraged. These operations provide information that can assist process analysts in the definition and instrumentation of PPIs. Finally, to validate the usefulness of our proposal, we have used the PPINOT metamodel at the core of a software tool called the PPINOT Tool Suite and we have applied it in several real scenarios. {\copyright} 2012 Elsevier Ltd.},
	affiliation = {Dpto. de Lenguajes y Sistemas Inform{\'a}ticos, University of Seville, Av. Reina Mercedes s/n, 41012 Seville, Spain},
	author_keywords = {Automated analysis; Business process management; PPINOT; Process performance indicators; Process performance measurement},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84872148430&partnerID=40&md5=f9c02dd03f4daec7169ae180713b5029},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.is.2012.11.004},
	document_type = {Article},
	doi = {10.1016/j.is.2012.11.004},
	review = {k-vis k-metric k-evaluation},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84872148430&partnerID=40&md5=f9c02dd03f4daec7169ae180713b5029}
}

@Article{DermevalTenorioBittencourtEtAl2015,
	author = {Dermeval, D b and Ten{\'o}rio, T and Bittencourt, I.I and Silva, A and Isotani, S and Ribeiro, M.c},
	title = {Ontology-based feature modeling: An empirical study in changing scenarios},
	journal = {ESA},
	year = {2015},
	volume = {42},
	number = {11},
	pages = {4950-4964},
	note = {cited By 3},
	abstract = {A software product line (SPL) is a set of software systems that have a particular set of common features and that satisfy the needs of a particular market segment or mission. Feature modeling is one of the key activities involved in the design of SPLs. The feature diagram produced in this activity captures the commonalities and variabilities of SPLs. In some complex domains (e.g.; ubiquitous computing, autonomic systems and context-aware computing), it is difficult to foresee all functionalities and variabilities a specific SPL may require. Thus, Dynamic Software Product Lines (DSPLs) bind variation points at runtime to adapt to fluctuations in user needs as well as to adapt to changes in the environment. In this context, relying on formal representations of feature models is important to allow them to be automatically analyzed during system execution. Among the mechanisms used for representing and analyzing feature models, description logic (DL) based approaches demand to be better investigated in DSPLs since it provides capabilities, such as automated inconsistency detection, reasoning efficiency, scalability and expressivity. Ontology is the most common way to represent feature models knowledge based on DL reasoners. Previous works conceived ontologies for feature modeling either based on OWL classes and properties or based on OWL individuals. However, considering change or evolution scenarios of feature models, we need to compare whether a class-based or an individual-based feature modeling style is recommended to describe feature models to support SPLs, and especially its capabilities to deal with changes in feature models, as required by DSPLs. In this paper, we conduct a controlled experiment to empirically compare two approaches based on each one of these modeling styles in several changing scenarios (e.g.; add/remove mandatory feature, add/remove optional feature and so on). We measure time to perform changes, structural impact of changes (flexibility) and correctness for performing changes in our experiment. Our results indicate that using OWL individuals requires less time to change and is more flexible than using OWL classes and properties. These results provide insightful assumptions towards the definition of an approach relying on reasoning capabilities of ontologies that can effectively support products reconfiguration in the context of DSPL. {\copyright} 2015 Elsevier Ltd. All rights reserved.},
	affiliation = {Computing and Systems Department, Federal University of Campina Grande (UFCG), R. Apr{\'\i}gio Veloso, 882, Bodocong{\'o}, Campina Grande, PB, Brazil; Penedo, Campus Arapiraca, Federal University of Alagoas (UFAL), Av. Beira Rio, s/n, Penedo, AL, Brazil; Computing Institute, Federal University of Alagoas (UFAL), Campus A.C. Sim{\~o}es, Macei{\'o}, AL, Brazil; Institute of Mathematics and Computational Sciences, University of S{\~a}o Paulo (USP), Avenida Trabalhador S{\~a}o-carlense, 400 Centro, S{\~a}o Carlos, SP, Brazil},
	author_keywords = {Empirical software engineering; Feature modeling; Ontology; Software product line},
	bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84924777581&partnerID=40&md5=98f6106532ade1eaca24ddf4792f3555},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.eswa.2015.02.020},
	document_type = {Article},
	doi = {10.1016/j.eswa.2015.02.020},
	review = {k-modeling k-evaluation k-method},
	source = {Scopus},
	url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84924777581&partnerID=40&md5=98f6106532ade1eaca24ddf4792f3555}
}

@Article{dougherty2012model,
	author = {Dougherty, Brian and White, Jules and Schmidt, Douglas C},
	title = {Model-driven auto-scaling of green cloud computing infrastructure},
	journal = {FGCS},
	year = {2012},
	volume = {28},
	number = {2},
	pages = {371--378},
	abstract = {Cloud computing can reduce power consumption by using virtualized computational resources to provision an application’s computational resources on-demand. Autoscaling is an important cloud computing technique that dynamically allocates computational resources to applications to match their current loads precisely, thereby removing resources that would otherwise remain idle and waste power. This paper presents a model-driven engineering approach to optimizing the configuration, energy consumption, and operating cost of cloud auto-scaling infrastructure to create greener computing enviornments that reduce emissions resulting from superfluous idle resources. The paper provides four contributions to the study of model-driven configuration of cloud auto-scaling infrastructure by (1) explaining how virtual machine configurations can be captured in feature models, (2) describing how these models can be transformed into constraint satisfaction problems (CSPs) for configuration and energy consumption optimization, (3) showing how optimal auto-scaling configurations can be derived from these CSPs with a constraint solver, and (4) presenting a case-study showing the energy consumption/cost reduction produced by this model-driven approach},
	publisher = {Elsevier},
	review = {k-method k-vis k-evaluation k-modeling}
}

@Article{Dubslaff2015,
  author    = {Dubslaff, Clemens and Baier, Christel and Kl{\"{u}}ppelholz, Sascha},
  title     = {Probabilistic model checking for feature-oriented systems},
  journal   = {TAOSD},
  year      = {2015},
  volume    = {8989},
  pages     = {180--220},
  abstract  = {Within product lines, collections of several related products are defined through their commonalities in terms of features rather than specifying them individually one-by-one. In this paper we present a compositional framework for modeling dynamic product lines by a statebased formalism with both probabilistic and nondeterministic behaviors. Rules for feature changes in products made during runtime are formalized by a coordination component imposing constraints on possible feature activations and deactivations. Our framework supports large-scaled product lines described through multi-features, i.e., where products may involve multiple instances of a feature. To establish temporal properties for products in a product line, verification techniques have to face a combinatorial blow-up that arises when reasoning about several feature combinations. This blow-up can be avoided by family-based approaches exploiting common feature behaviors. We adapt such approaches to our framework, allowing for a quantitative analysis in terms of probabilistic model checking to reason, e.g., about energy and memory consumption, monetary costs, or the reliability of products. Our framework can also be used to compute strategies how to trigger feature changes for optimizing quantitative objectives using probabilistic model-checking techniques. We present a natural and conceptually simple translation of product lines into the input language of the prominent probabilistic model checker Prism and show feasibility of this translation within a case study on an energy-aware server platform product line comprising thousands of products. To cope with the arising complexity, we follow the family-based analysis scheme and apply symbolic methods for a compact state-space representation.},
  doi       = {10.1007/978-3-662-46734-3_5},
  isbn      = {9783662467336},
  issn      = {16113349},
  publisher = {Springer Verlag},
  review    = {k-testing k-modeling k-configuration k-evaluation},
}

@Article{Dunlap2013,
  author   = {Dunlap, R and Rugaber, S and Mark, L},
  title    = {A feature model of coupling technologies for Earth System Models},
  journal  = {C\&G},
  year     = {2013},
  abstract = {Couplers that link together two or more numerical simulations are well-known abstractions in the Earth System Modeling (ESM) community. In the past decade, reusable software assets have emerged to facilitate scientists in implementing couplers. While there is a large amount of overlap in the features supported by software coupling technologies, their implementations differ significantly in terms of both functional and non-functional properties. Using a domain analysis method called feature analysis, we explore the spectrum of features supported by coupling technologies used to build today's production ESMs.},
  review   = {k-evaluation k-vis},
  url      = {http://www.sciencedirect.com/science/article/pii/S0098300411003335},
}

@Article{Eichelberger2014,
  author    = {Eichelberger, Holger and Schmid, Klaus},
  title     = {Mapping the design-space of textual variability modeling languages: a refined analysis},
  journal   = {STTT},
  year      = {2014},
  volume    = {17},
  number    = {5},
  pages     = {559--584},
  month     = {dec},
  abstract  = {Variability modeling is a major part of modern product line engineering. Graphical or table-based approaches to variability modeling are focused around abstract models and specialized tools to interact with these models. However, more recently textual variability modeling languages, comparable to some extent to programming languages, were introduced. We consider the recent trend in product line engineering towards textual variability modeling languages as a phenomenon, which deserves deeper analysis. In this article, we report on the results and approach of a literature survey combined with an expert study. In the literature survey, we identified 11 languages, which enable the textual specification of product line variability and which are sufficiently described for an in-depth analysis. We provide a classification scheme, useful to describe the range of capabilities of such languages. Initially, we identified the relevant capabilities of these languages from a literature survey. The result of this has been refined, validated and partially improved by the expert survey. A second recent phenomenon in product line variability modeling is the increasing scale of variability models. Some authors of textual variability modeling languages argue that these languages are more appropriate for large-scale models. As a consequence, we would expect specific capabilities addressing scalability in the languages. Thus, we compare the capabilities of textual variability modeling techniques, if compared to graphical variability modeling approaches and in particular to analyze their specialized capabilities for large-scale models.},
  doi       = {10.1007/s10009-014-0362-x},
  issn      = {14332787},
  publisher = {Springer Verlag},
  review    = {k-modeling k-philosophical},
}

@Article{EnsanBagheriGasevic2012,
	author = {Ensan, Faezeh and Bagheri, Ebrahim and Ga{\v{s}}evi{\'c}, Dragan},
	title = {Evolutionary search-based test generation for software product line feature models},
	journal = {AISE},
	year = {2012},
	pages = {613--628},
	organization = {Springer},
	review = {k-testing k-solution k-evaluation}
}

@Article{Fernandes2011,
  author   = {Fernandes, Paula and Werner, Cl{\'{a}}udia and Teixeira, Eld{\^{a}}nae},
  title    = {An approach for feature modeling of context-aware software product line},
  journal  = {JUCS},
  year     = {2011},
  volume   = {17},
  number   = {5},
  pages    = {807--829},
  abstract = {Feature modeling is an approach to represent commonalities and variabilities among products of a product line. Context-aware applications use context information to provide relevant services and information for their users. One of the challenges to build a context-aware product line is to develop mechanisms to incorporate context information and adaptation knowledge in a feature model. This paper presents UbiFEX, an approach to support feature analysis for context-aware software product lines, which incorporates a modeling notation and a mechanism to verify the consistency of product configuration regarding context variations. Moreover, an experimental study was performed as a preliminary evaluation, and a prototype was developed to enable the application of the proposed approach. {\textcopyright} J.UCS.},
  issn     = {0958695X},
  review   = {k-configuration k-modeling k-evaluation},
}

@Article{FernandezAmorosHeradioCerradaEtAl2014,
	Title = {A Scalable Approach to Exact Model and Commonality Counting for Extended Feature Models},
	Author = {Fernandez-Amoros, D and Heradio, R and Cerrada, J.A and Cerrada, C.b},
	Journal = {TSE},
	Year = {2014},
	Note = {cited By 2},
	Number = {9},
	Pages = {895-910},
	Volume = {40},
	Abstract = {A software product line is an engineering approach to efficient development of software product portfolios. Key to the success of the approach is to identify the common and variable features of the products and the interdependencies between them, which are usually modeled using feature models. Implicitly, such models also include valuable information that can be used by economic models to estimate the payoffs of a product line. Unfortunately, as product lines grow, analyzing large feature models manually becomes impracticable. This paper proposes an algorithm to compute the total number of products that a feature model represents and, for each feature, the number of products that implement it. The inference of both parameters is helpful to describe the standardization/parameterization balance of a product line, detect scope flaws, assess the product line incremental development, and improve the accuracy of economic models. The paper reports experimental evidence that our algorithm has better runtime performance than existing alternative approaches. {\copyright} 2014 IEEE.},
	Affiliation = {Department of Languages and Computer Systems, Spanish Open University (UNED), Madrid, Spain; Department of Software Engineering and Computer Systems, Spanish Open University (UNED), Madrid, Spain},
	Art_number = {2331073},
	Author_keywords = {economic models; Feature models; formal methods; software product lines},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84934977910&partnerID=40&md5=9a936bf8a2624e7dfe753c4f31de53a4},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/TSE.2014.2331073},
	Document_type = {Article},
	Doi = {10.1109/TSE.2014.2331073},
	Review = {k-evaluation k-modeling k-method},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84934977910&partnerID=40&md5=9a936bf8a2624e7dfe753c4f31de53a4}
}

@Article{Filho2014,
  author    = {Filho, Jo{\~{a}}o Bosco Ferreira and Barais, Olivier and Acher, Mathieu and {Le Noir}, J{\'{e}}r{\^{o}}me and Legay, Axel and Baudry, Benoit},
  title     = {Generating counterexamples of model-based software product lines},
  journal   = {STTT},
  year      = {2014},
  volume    = {17},
  number    = {5},
  pages     = {585--600},
  month     = {aug},
  abstract  = {In a model-based software product line (MSPL), the variability of the domain is characterized in a variability model and the core artifacts are base models conforming to a modeling language (also called metamodel). A realization model connects the features of the variability model to the base model elements, triggering operations over these elements based on a configuration. The design space of an MSPL is extremely complex to manage for the engineer, since the number of variants may be exponential and the derived product models have to be conforming to numerous well-formedness and business rules. In this paper, the objective is to provide a way to generate MSPLs, called counterexamples (also called antipatterns), that can produce invalid product models despite a valid configuration in the variability model. We describe the foundations and motivate the usefulness of counterexamples (e.g., inference of guidelines or domain-specific rules to avoid earlier the specification of incorrect mappings; testing oracles for increasing the robustness of derivation engines given a modeling language). We provide a generic process, based on the common variability language (CVL) to randomly search the space of MSPLs for a specific modeling language. We develop LineGen a tool on top of CVL and modeling technologies to support the methodology and the process. LineGen targets different scenarios and is flexible to work either with just a domain metamodel as input or also with pre-defined variability models and base models. We validate the effectiveness of this process for three formalisms at different scales (up to 247 metaclasses and 684 rules). We also apply the approach in the context of a real industrial scenario involving a large-scale metamodel.},
  doi       = {10.1007/s10009-014-0341-2},
  issn      = {14332787},
  publisher = {Springer Verlag},
  review    = {k-evaluation k-mmodel k-testing},
}

@Article{Gomez20141101,
	Title = {A framework for variable content document generation with multiple actors},
	Author = {G{\'o}mez, A and Penad{\'e}s, M.C and Can{\'o}s, J.H and Borges, M.R.S and Llavador, M.d},
	Journal = {IST},
	Year = {2014},
	Note = {cited By 2},
	Number = {9},
	Pages = {1101-1121},
	Volume = {56},
	Abstract = {Context Advances in customization have highlighted the need for tools supporting variable content document management and generation in many domains. Current tools allow the generation of highly customized documents that are variable in both content and layout. However, most frameworks are technology-oriented, and their use requires advanced skills in implementation-related tools, which means their use by end users (i.e. document designers) is severely limited. Objective Starting from past and current trends for customized document authoring, our goal is to provide a document generation alternative in which variants are specified at a high level of abstraction and content reuse can be maximized in high variability scenarios. Method Based on our experience in Document Engineering, we identified areas in the variable content document management and generation field open to further improvement. We first classified the primary sources of variability in document composition processes and then developed a methodology, which we called DPL - based on Software Product Lines principles - to support document generation in high variability scenarios. Results In order to validate the applicability of our methodology we implemented a tool - DPLfw - to carry out DPL processes. After using this in different scenarios, we compared our proposal with other state-of-the-art tools for variable content document management and generation. Conclusion The DPLfw showed a good capacity for the automatic generation of variable content documents equal to or in some cases surpassing other currently available approaches. To the best of our knowledge, DPLfw is the only framework that combines variable content and document workflow facilities, easing the generation of variable content documents in which multiple actors play different roles. {\copyright} 2014 Elsevier B.V. All rights reserved.},
	Affiliation = {AtlanMod, {\'E}cole des Mines de Nantes, INRIA - LINA, 4 rue Alfred Kastler, 44307 Nantes, France; ISSI, DSIC, Universitat Polit{\`e}cnica de Val{\`e}ncia, Cno. de Vera, s/n, 46022 Valencia, Spain; Programa de P{\'o}s Gradua{\c c}{\~a}o em Inform{\'a}tica, Departamento de Ci{\^e}ncia da Computa{\c c}{\~a}o, Universidade Federal Do Rio de Janeiro, Brazil; Instituto Tecnol{\'o}gico de Inform{\'a}tica, Universitat Polit{\`e}cnica de Val{\`e}ncia, Cno. de Vera, s/n, 46022 Valencia, Spain},
	Author_keywords = {Document generation; Document product line; Document workflow; Feature modeling; Model driven engineering; Variable data printing},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84901616736&partnerID=40&md5=757437f5086b62f8ff9d4340a59cacdb},
	Bdsk-url-2 = {http://dx.doi.org/10.1016/j.infsof.2013.12.006},
	Document_type = {Article},
	Doi = {10.1016/j.infsof.2013.12.006},
	Review = {k-method k-evaluation k-vis},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84901616736&partnerID=40&md5=757437f5086b62f8ff9d4340a59cacdb}
}

@Article{Gunther2012152,
	author = {G{\"u}nther, S. and Sunkle, S.},
	title = {RbFeatures: Feature-oriented programming with Ruby},
	journal = {SCP},
	year = {2012},
	volume = {77},
	number = {3},
	pages = {152-173},
	note = {cited By 3},
	abstract = {Features are pieces of core functionality of a program that is relevant to particular stakeholders. Features pose dependencies and constraints among each other. These dependencies and constraints describe the possible number of variants of the program: A valid feature configuration generates a specific variant with unique behavior. Feature-Oriented Programming is used to implement features as program units. This paper introduces rbFeatures, a feature-oriented programming language implemented on top of the dynamic programming language Ruby. With rbFeatures, programmers use software product lines, variants, and features as first-class entities. This allows several runtime reflection and modification capabilities, including the extension of the product line with new features and the provision of multiple variants. The paper gives a broad overview to the implementation and application of rbFeatures. We explain how features as first-class entities are designed and implemented, and discuss how the semantics of features are carefully added to Ruby programs. We show two case studies: The expression product line, a common example in feature-oriented programming, and a web application. {\copyright} 2011 Elsevier B.V. All rights reserved.},
	affiliation = {Faculty of Computer Science, University of Magdeburg, Germany},
	author_keywords = {Domain-specific languages; Dynamic programming languages; Feature-oriented programming},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84855187033&partnerID=40&md5=22eeb8697a8abfca24357f3ba9ebff20},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.scico.2010.12.007},
	document_type = {Conference Paper},
	doi = {10.1016/j.scico.2010.12.007},
	review = {k-evaluation k-configuration k-method},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84855187033&partnerID=40&md5=22eeb8697a8abfca24357f3ba9ebff20}
}

@Article{GalindoTurnerBenavidesEtAl2014,
	author = {Galindo, Jos{\'e} A and Turner, Hamilton and Benavides, David and White, Jules},
	title = {Testing variability-intensive systems using automated analysis: an application to android},
	journal = {SQJ},
	year = {2014},
	pages = {1--41},
	publisher = {Springer},
	review = {k-testing k-evaluation k-method k-tool}
}

@Article{GalindoDhunganaRabiserEtAl2015,
	author = {Galindo, J.A e and Dhungana, D and Rabiser, R and Benavides, D and Botterweck, G and Gr{\"u}nbacher, P.d},
	title = {Supporting distributed product configuration by integrating heterogeneous variability modeling approaches},
	journal = {IST},
	year = {2015},
	volume = {62},
	number = {1},
	pages = {78-100},
	note = {cited By 1},
	abstract = {Context: In industrial settings products are developed by more than one organization. Software vendors and suppliers commonly typically maintain their own product lines, which contribute to a larger (multi) product line or software ecosystem. It is unrealistic to assume that the participating organizations will agree on using a specific variability modeling technique - they will rather use different approaches and tools to manage the variability of their systems. Objective: We aim to support product configuration in software ecosystems based on several variability models with different semantics that have been created using different notations. Method: We present an integrative approach that provides a unified perspective to users configuring products in multi product line environments, regardless of the different modeling methods and tools used internally. We also present a technical infrastructure and a prototype implementation based on web services. Results: We show the feasibility of the approach and its implementation by using it with the three most widespread types of variability modeling approaches in the product line community, i.e., feature-based, OVM-style, and decision-oriented modeling. To demonstrate the feasibility and flexibility of our approach, we present an example derived from industrial experience in enterprise resource planning. We further applied the approach to support the configuration of privacy settings in the Android ecosystem based on multiple variability models. We also evaluated the performance of different model enactment strategies used in our approach. Conclusions: Tools and techniques allowing stakeholders to handle variability in a uniform manner can considerably foster the initiation and growth of software ecosystems from the perspective of software reuse and configuration. {\copyright} 2015 Elsevier B.V. All rights reserved.},
	affiliation = {Department of Computer Languages and Systems, University of Seville, Spain; Siemens AG {\"O}sterreich, Corporate TechnologyVienna, Austria; Lero-The Irish Software Engineering Research Center, University of Limerick, Ireland; Christian Doppler Laboratory MEVSS, Johannes Kepler University, Linz, Austria; Diverse Team, INRIA Rennes, France},
	author_keywords = {Automated analysis; Product configuration; Software product lines},
	bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84932618234&partnerID=40&md5=f377c33d119e9532ac1f47f46dc4bcef},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.infsof.2015.02.002},
	document_type = {Article},
	doi = {10.1016/j.infsof.2015.02.002},
	review = {k-configuration k-mmodel k-modeling k-evaluation k-method},
	source = {Scopus},
	url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84932618234&partnerID=40&md5=f377c33d119e9532ac1f47f46dc4bcef}
}

@Article{Garcia-Galan2016,
  author   = {Garc{\'{i}}a-Gal{\'{a}}n, J and Trinidad, P and Rana, OF},
  title    = {Automated configuration support for infrastructure migration to the cloud},
  journal  = {FGCS},
  year     = {2016},
  abstract = {With an increasing number of cloud computing offerings in the market, migrating an existing computational infrastructure to the cloud requires comparison of different offers in order to find the most suitable configuration. Cloud providers offer many configuration options, such as location, purchasing mode, redundancy, and extra storage. Often, the information about such options is not well organised. This leads to large and unstructured configuration spaces, and turns the comparison into a tedious, error-prone search problem for the customers. In this work we focus on supporting customer decision making for selecting the most suitable cloud configuration—in terms of infrastructural requirements and cost. We achieve this by means of variability modelling and analysis techniques. Firstly, we structure the configuration space of an IaaS using feature models, usually employed for the modelling of variability-intensive systems, and present the case study of the Amazon EC2. Secondly, we assist the configuration search process. Feature models enable the use of different analysis operations that, among others, automate the search of optimal configurations. Results of our analysis show how our approach, with a negligible analysis time, outperforms commercial approaches in terms of expressiveness and accuracy.},
  review   = {k-evaluation  k-vis  k-configuration},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167739X15000618},
}

@Article{Guo20124987,
	author = {Guo, J and Wang, Y and Trinidad, P and Benavides, D.b},
	title = {Consistency maintenance for evolving feature models},
	journal = {ESA},
	year = {2012},
	volume = {39},
	number = {5},
	pages = {4987-4998},
	note = {cited By 12},
	abstract = {Software product line (SPL) techniques handle the construction of customized systems. One of the most common representations of the decisions a customer can make in SPLs is feature models (FMs). An FM represents the relationships among common and variable features in an SPL. Features are a representation of the characteristics in a system that are relevant to customers. FMs are subject to change since the set of features and their relationships can change along an SPL lifecycle. Due to this evolution, the consistency of FMs may be compromised. There exist some approaches to detect and explain inconsistencies in FMs, however this process can take a long time for large FMs. In this paper we present a complementary approach to dealing with inconsistencies in FM evolution scenarios that improves the performance for existing approaches reducing the impact of change to the smallest part of an FM that changes. To achieve our goal, we formalize FMs from an ontological perspective and define constraints that must be satisfied in FMs to be consistent. We define a set of primitive operations that modify FMs and which are responsible for the FM evolution, analyzing their impact on the FM consistency. We propose a set of predefined strategies to keep the consistency for error-prone operations. As a proof-of-concept we present the results of our experiments, where we check for the effectiveness and efficiency of our approach in FMs with thousands of features. Although our approach is limited by the kinds of consistency constraints and the primitive operations we define, the experiments present a significant improvement in performance results in those cases where they are applicable. {\copyright} 2011 Elsevier Ltd. All rights reserved.},
	affiliation = {Department of Computer Science and Engineering, Shanghai Jiao Tong University, 800 Dong Chuan Road, Minhang, Shanghai 200240, China; Department of Languages and Computer Systems, University of Seville, Av. Reina Mercedes s/n, 41012 Seville, Spain},
	author_keywords = {Consistency maintenance; Evolution; Feature models; Ontology; Semantics; Software product lines},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84855890521&partnerID=40&md5=9658d28cbf84231ff4759c264a221be2},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.eswa.2011.10.014},
	document_type = {Article},
	doi = {10.1016/j.eswa.2011.10.014},
	review = {k-testing k-tool k-evaluation},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84855890521&partnerID=40&md5=9658d28cbf84231ff4759c264a221be2}
}

@Article{Guo2011,
  author   = {Guo, Jianmei and White, Jules and Wang, Guangxin and Li, Jian and Wang, Yinglin},
  title    = {A genetic algorithm for optimized feature selection with resource constraints in software product lines},
  journal  = {JSS},
  year     = {2011},
  volume   = {84},
  number   = {12},
  pages    = {2208--2221},
  month    = {dec},
  abstract = {Software product line (SPL) engineering is a software engineering approach to building configurable software systems. SPLs commonly use a feature model to capture and document the commonalities and variabilities of the underlying software system. A key challenge when using a feature model to derive a new SPL configuration is determining how to find an optimized feature selection that minimizes or maximizes an objective function, such as total cost, subject to resource constraints. To help address the challenges of optimizing feature selection in the face of resource constraints, this paper presents an approach that uses G enetic A lgorithms for optimized FE ature S election (GAFES) in SPLs. Our empirical results show that GAFES can produce solutions with 86-97{\%} of the optimality of other automated feature selection algorithms and in 45-99{\%} less time than existing exact and heuristic feature selection techniques. {\textcopyright} 2011 Elsevier Inc. All rights reserved.},
  doi      = {10.1016/j.jss.2011.06.026},
  issn     = {01641212},
  review   = {k-configuration k-evaluation},
}

@Article{HeiderRabiserGruenbacher2012,
	author = {Heider, Wolfgang and Rabiser, Rick and Gr{\"u}nbacher, Paul},
	title = {Facilitating the evolution of products in product line engineering by capturing and replaying configuration decisionsSTTT},
	journal = {STTT},
	year = {2012},
	volume = {14},
	number = {5},
	pages = {613--630},
	note = {cited By 6},
	abstract = {Software product lines rely on developing reusable artifacts and defining their variability in models to support and accelerate the derivation of individual products. A major challenge in product lines is the continuous evolution of both the reusable artifacts and derived products. Products that have been derived from a product line have to be updated regularly, e. g., after bugfixes or the development of new features. Changes to reusable artifacts and variability models have to be propagated to derived products. The aim of our research is to provide automated support for the evolution of products derived from product lines by capturing and replaying configuration decisions. Our PUPLE (Product Updates in Product Line Engineering) approach supports updating derived products after changes to the product line they have been derived from. It exploits the structure of variability models and uses change-tracking data to minimize user intervention. The paper first explores how different types of product line changes influence the derived products. It then presents extensions to our decision-oriented product line approach DOPLER to support product line evolution. We evaluate the feasibility of the PUPLE approach with evolution tasks that were performed by engineers of an industry partner on a product line of an Eclipse-based tool suite with six derived products. We conclude with lessons learned and limitations of our approach. {\copyright} 2012 Springer-Verlag.},
	affiliation = {Christian Doppler Laboratory for Automated Software Engineering, Johannes Kepler University, Altenberger Str. 69, 4040 Linz, Austria; Systems Engineering and Automation, Johannes Kepler University, Altenberger Str. 69, 4040 Linz, Austria},
	author_keywords = {Product line engineering; Product update tool; Software evolution},
	bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84866291483&partnerID=40&md5=b96c8f668214955951a4a53d9088c23b},
	bdsk-url-2 = {http://dx.doi.org/10.1007/s10009-012-0229-y},
	document_type = {Article},
	doi = {10.1007/s10009-012-0229-y},
	publisher = {Springer},
	review = {k-testing k-configuration k-method k-evaluation},
	source = {Scopus},
	url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84866291483&partnerID=40&md5=b96c8f668214955951a4a53d9088c23b}
}

@Article{Henard2014650,
	Title = {Bypassing the combinatorial explosion: Using similarity to generate and prioritize t-wise test configurations for software product lines},
	Author = {Henard, C and Papadakis, M and Perrouin, G and Klein, J and Heymans, P and Traon, Y.L.a},
	Journal = {TSE},
	Year = {2014},
	Note = {cited By 4},
	Number = {7},
	Pages = {650-670},
	Volume = {40},
	Abstract = {Large Software Product Lines (SPLs) are common in industry, thus introducing the need of practical solutions to test them. To this end, t-wise can help to drastically reduce the number of product configurations to test. Current t-wise approaches for SPLs are restricted to small values of t. In addition, these techniques fail at providing means to finely control the configuration process. In view of this, means for automatically generating and prioritizing product configurations for large SPLs are required. This paper proposes (a) a search-based approach capable of generating product configurations for large SPLs, forming a scalable and flexible alternative to current techniques and (b) prioritization algorithms for any set of product configurations. Both these techniques employ a similarity heuristic. The ability of the proposed techniques is assessed in an empirical study through a comparison with state of the art tools. The comparison focuses on both the product configuration generation and the prioritization aspects. The results demonstrate that existing t-wise tools and prioritization techniques fail to handle large SPLs. On the contrary, the proposed techniques are both effective and scalable. Additionally, the experiments show that the similarity heuristic can be used as a viable alternative to t-wise. {\copyright} 1976-2012 IEEE.},
	Affiliation = {Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg, Luxembourg; Precise Research Center in Software Engineering, University of Namur, Belgium},
	Art_number = {6823132},
	Author_keywords = {prioritization; search-based approaches; similarity; Software product lines; T-wise Interactions; testing},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84904278397&partnerID=40&md5=ffa8dafc288f386b7de9ebc0a571b60a},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/TSE.2014.2327020},
	Document_type = {Article},
	Doi = {10.1109/TSE.2014.2327020},
	Review = {k-testing k-tool k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84904278397&partnerID=40&md5=ffa8dafc288f386b7de9ebc0a571b60a}
}

@Article{HeradioFernandezAmorosCerradaEtAl2013,
	Title = {A literature review on feature diagram product counting and its usage in software product line economic models},
	Author = {Heradio, R and Fernandez-Amoros, D and Cerrada, J.A and Abad, I.a},
	Journal = {IJSEKE},
	Year = {2013},
	Note = {cited By 3},
	Number = {8},
	Pages = {1177-1204},
	Volume = {23},
	Abstract = {In software product line engineering, feature diagrams are a popular means to represent the similarities and differences within a family of related systems. In addition, feature diagrams implicitly model valuable information that can be used in economic models to estimate the cost savings of a product line. In particular, this paper reviews existing proposals on computing the total number of products modeled with a feature diagram and, given a feature, the number of products that implement it. This paper also reviews the economic information that can be estimated when such numbers are known. Thus, this paper contributes by bringing together previously-disparate streams of work: the automated analysis of feature diagrams and economic models for product lines. {\copyright} 2013 World Scientific Publishing Company.},
	Affiliation = {Department of Software Engineering and Computer Systems, Spanish Open University, Juan del Rosal 16, Madrid 28040, Spain; Department of Languages and Computer Systems, Spanish Open University, Juan del Rosal 16, Madrid 28040, Spain},
	Author_keywords = {economic model; feature diagram; model counting; Software product line},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84894146091&partnerID=40&md5=3ece08b132f3394d4e8e2c74ab186e26},
	Bdsk-url-2 = {http://dx.doi.org/10.1142/S0218194013500368},
	Document_type = {Article},
	Doi = {10.1142/S0218194013500368},
	Review = {k-configuration k-modeling k-philosophical},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84894146091&partnerID=40&md5=3ece08b132f3394d4e8e2c74ab186e26}
}

@Article{Heradio2016,
  author    = {Heradio, Ruben and Perez-Morago, Hector and Alf{\'{e}}rez, Mauricio and Fernandez-Amoros, David and Alf{\'{e}}rez, Germ{\'{a}}n H.},
  title     = {Augmenting measure sensitivity to detect essential, dispensable and highly incompatible features in mass customization},
  journal   = {EJOR},
  year      = {2016},
  volume    = {248},
  number    = {3},
  pages     = {1066--1077},
  month     = {feb},
  abstract  = {Mass customization is the new frontier in business competition for both manufacturing and service industries. To improve customer satisfaction, reduce lead-times and shorten costs, families of similar products are built jointly by combining reusable parts that implement the features demanded by the customers. To guarantee the validity of the products derived from mass customization processes, feature dependencies and incompatibilities are usually specified with a variability model. As market demand grows and evolves, variability models become increasingly complex. In such entangled models it is hard to identify which features are essential, dispensable, highly required by other features, or highly incompatible with the remaining features. This paper exposes the limitations of existing approaches to gather such knowledge and provides efficient algorithms to retrieve that information from variability models.},
  doi       = {10.1016/j.ejor.2015.08.005},
  issn      = {03772217},
  publisher = {Elsevier},
  review    = {k-configuration k-testing k-evaluation},
}

@Article{Heradio2016a,
  author    = {Heradio, Ruben and Perez-Morago, Hector and Fernandez-Amoros, David and {Javier Cabrerizo}, Francisco and Herrera-Viedma, Enrique},
  title     = {A bibliometric analysis of 20 years of research on software product lines},
  journal   = {IST},
  year      = {2016},
  volume    = {72},
  pages     = {1--15},
  month     = {apr},
  abstract  = {Context: Software product line engineering has proven to be an efficient paradigm to developing families of similar software systems at lower costs, in shorter time, and with higher quality. Objective: This paper analyzes the literature on product lines from 1995 to 2014, identifying the most influential publications, the most researched topics, and how the interest in those topics has evolved along the way. Method: Bibliographic data have been gathered from ISI Web of Science and Scopus. The data have been examined using two prominent bibliometric approaches: science mapping and performance analysis. Results: According to the study carried out, (i) software architecture was the initial motor of research in SPL; (ii) work on systematic software reuse has been essential for the development of the area; and (iii) feature modeling has been the most important topic for the last fifteen years, having the best evolution behavior in terms of number of published papers and received citations. Conclusion: Science mapping has been used to identify the main researched topics, the evolution of the interest in those topics and the relationships among topics. Performance analysis has been used to recognize the most influential papers, the journals and conferences that have published most papers, how numerous is the literature on product lines and what is its distribution over time.},
  doi       = {10.1016/j.infsof.2015.11.004},
  issn      = {09505849},
  publisher = {Elsevier},
  review    = {k-philosophical k-opinion
k-vis k-mmodel k-configuration k-testing k-modeling k-reverse},
}

@Article{Heradio20127919,
	author = {Heradio, R d and Fernandez-Amoros, D d d and Torre-Cubillo, L d d and Perez Garcia-Plaza, A d d},
	title = {Improving the accuracy of COPLIMO to estimate the payoff of a software product line},
	journal = {ESA},
	year = {2012},
	volume = {39},
	number = {9},
	pages = {7919-7928},
	note = {cited By 4},
	abstract = {Software product line engineering pursues the efficient development of families of similar products. COPLIMO is an economic model that relies on COCOMO II to estimate the benefits of adopting a product line approach compared to developing the products one by one. Although COPLIMO is an ideal economic model to support decision making on the incremental development of a product line, it makes some simplifying assumptions that may produce high distortions in the estimates (e.g.; COPLIMO takes for granted that all the products have the same size). This paper proposes a COPLIMO reformulation that avoids such assumptions and, consequently, improves the accuracy of the estimates. To support our proposal, we present an algorithm that infers the additional information that our COPLIMO reformulation requires from feature diagrams, which is a widespread notation to model the domain of a product line. {\copyright} 2012 Elsevier Ltd. All rights reserved.},
	affiliation = {Dept. of Software Engineering and Computer Systems, Juan del Rosal 16, E-28040 Madrid, Spain; Dept. of Languages and Computer Systems, Juan del Rosal 16, E-28040 Madrid, Spain; Dept. of Computer Science and Automatic Control, Juan del Rosal 16, E-28040 Madrid, Spain; Universidad Nacional de Educaci{\'o}n A Distancia, Juan del Rosal 16, E-28040 Madrid, Spain},
	author_keywords = {Decision support; Economic model; Feature diagram; Product counting; Software product line},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84858342500&partnerID=40&md5=ece2ba6729a480b6c327c8a3231f3416},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.eswa.2012.01.109},
	document_type = {Article},
	doi = {10.1016/j.eswa.2012.01.109},
	review = {k-metric k-configuration k-solution},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84858342500&partnerID=40&md5=ece2ba6729a480b6c327c8a3231f3416}
}

@Article{Heradio-Gil2011496,
	author = {Heradio-Gil, R. and Fernandez-Amoros, D. and Cerrada, J.A. and Cerrada, C.},
	title = {Supporting commonality-based analysis of software product lines},
	journal = {IET},
	year = {2011},
	volume = {5},
	number = {6},
	pages = {496-509},
	note = {cited By 2},
	abstract = {Software product line (SPL) engineering is a cost-effective approach to developing families of similar products. Key to the success of this approach is to correctly scope the domain of the SPL, identifying the common and variable features of the products and the interdependencies between features. In this study, the authors show how the commonality of a feature (i.e. the reuse ratio of the feature among the products) can be used to detect scope flaws in the early stages of development. SPL domains are usually modelled by means of feature diagrams following the feature-oriented domain analysis (FODA) notation. The authors extend classical FODA trees with unrestricted cardinalities, and present an algorithm to compute the number of products modelled by a feature diagram and the commonality of the features. Finally, the authors compare the performance of their algorithm with two other approaches built on top of boolean logic satisfiability (SAT)-solver technology such as cachet and relsat. {\copyright} 2011 The Institution of Engineering and Technology.},
	affiliation = {ETS de Ingenieria Informatica, Universidad Nacional de Educacion A Distancia, Madrid, Spain},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84864265673&partnerID=40&md5=d35bed2fc7540a45deb655c838b0c7d6},
	bdsk-url-2 = {http://dx.doi.org/10.1049/iet-sen.2010.0022},
	document_type = {Article},
	doi = {10.1049/iet-sen.2010.0022},
	review = {k-evaluation k-tool k-configuration},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84864265673&partnerID=40&md5=d35bed2fc7540a45deb655c838b0c7d6}
}

@Article{Heymans2012,
  author   = {Heymans, Patrick and Boucher, Quentin and Classen, Andreas and Bourdoux, Arnaud and Demonceau, Laurent},
  title    = {A code tagging approach to software product line development: An application to satellite communication libraries},
  journal  = {STTT},
  year     = {2012},
  volume   = {14},
  number   = {5},
  pages    = {553--566},
  abstract = {Software product line engineering seeks to systematise reuse when developing families of similar software systems so as to minimise development time, cost and defects. To realise variability at the code level, product line methods classically advocate usage of inheritance, components, frameworks, aspects or generative techniques. However, these might require unaffordable paradigm shifts for developers if the software was not thought at the outset as a product line. Furthermore, these techniques can be conflicting with a company's coding practices or external regulations. These concerns were the motivation for the industry-university collaboration described in this paper in which we developed a minimally intrusive coding technique based on tags. The approach was complemented with traceability from code to feature diagrams which were exploited for automated configuration. It is supported by a toolchain and is now in use in the partner company for the development of flight-grade satellite communication software libraries. {\textcopyright} 2012 Springer-Verlag.},
  doi      = {10.1007/s10009-012-0242-1},
  issn     = {14332779},
  review   = {k-experience k-configuration},
}

@Article{Hidaka2016,
  author    = {Hidaka, Soichiro and Tisi, Massimo and Cabot, Jordi and Hu, Zhenjiang},
  title     = {Feature-based classification of bidirectional transformation approaches},
  journal   = {SOSYM},
  year      = {2016},
  volume    = {15},
  number    = {3},
  pages     = {907--928},
  month     = {jul},
  abstract  = {Bidirectional model transformation is a key technology in model-driven engineering (MDE), when two models that can change over time have to be kept constantly consistent with each other. While several model transformation tools include at least a partial support to bidirectionality, it is not clear how these bidirectional capabilities relate to each other and to similar classical problems in computer science, from the view update problem in databases to bidirectional graph transformations. This paper tries to clarify and visualize the space of design choices for bidirectional transformations from an MDE point of view, in the form of a feature model. The selected list of existing approaches are characterized by mapping them to the feature model. Then, the feature model is used to highlight some unexplored research lines in bidirectional transformations.},
  doi       = {10.1007/s10270-014-0450-0},
  issn      = {16191374},
  publisher = {Springer Verlag},
  review    = {k-modeling k-philosophical},
}

@Article{Hu2016,
  author    = {Hu, Jie and Wang, Qing},
  title     = {Extensions and evolution analysis method for software feature models},
  journal   = {JS},
  year      = {2016},
  volume    = {27},
  number    = {5},
  pages     = {1212--1229},
  month     = {may},
  abstract  = {Feature model is an essential concept and artifact in feature oriented software development (FOSD). It depicts commonality and variability (C{\&}V) of products in terms of features. With increasingly frequent software evolution, keeping the feature model in consistent with the evolution is very important. Most of the related researches usually analyze the C{\&}V on the requirement level, and modeling the analyzed C{\&}V by the feature model. However, since the feature changes may cause the ripple effect during the modeling process, some new commonalities and variability may be derived. The current researches are still not able to resolve this problem, which leads to some potential overlooking commonalities and inefficiency in reuse. This paper proposes an approach to extend the feature model and analyze the software evolution based on the feature model. The extensions of feature dependency and evolution meta-operators can support the ripple effect analysis of the feature changes, as well as the exploration of the potential commonalities. The new approach also develops some refactoring strategies and a semi-automated tool to support commonality extraction and feature refactoring. In addition, rules and strategies are designed to resolve typical configuration conflicts. Finally, the paper employs a case study to validate the applicability and effectiveness of the presented method.},
  doi       = {10.13328/j.cnki.jos.004829},
  issn      = {10009825},
  publisher = {Chinese Academy of Sciences},
  review    = {k-testing k-modeling k-evaluation},
}

@Article{Hubaux2013641,
	author = {Hubaux, A and Heymans, P b and Schobbens, P.-Y and Deridder, D and Abbasi, E.K.a},
	title = {Supporting multiple perspectives in feature-based configuration},
	journal = {SOSYM},
	year = {2013},
	volume = {12},
	number = {3},
	pages = {641-663},
	note = {cited By 5},
	abstract = {Feature diagrams have become commonplace in software product line engineering as a means to document variability early in the life cycle. Over the years, their application has also been extended to assist stakeholders in the configuration of software products. However, existing feature-based configuration techniques offer little support for tailoring configuration views to the profiles of the various stakeholders. In this paper, we propose a lightweight, yet formal and flexible, mechanism to leverage multidimensional separation of concerns in feature-based configuration. We propose a technique to specify concerns in feature diagrams and to generate automatically concern-specific configuration views. Three alternative visualisations are proposed. Our contributions are motivated and illustrated through excerpts from a real web-based meeting management application which was also used for a preliminary evaluation. We also report on the progress made in the development of a tool supporting multi-view feature-based configuration. {\copyright} 2011 Springer-Verlag.},
	affiliation = {PReCISE Research Centre, Faculty of Computer Science, University of Namur, Namur, Belgium; INRIA Lille-Nord Europe, Universit{\'e} de Lille 1 - LIFL - CNRS, Lille, France; Smals vzw, Software Languages Lab, Vrije Universiteit Brussel, Brussels, Belgium},
	author_keywords = {Feature diagram; Feature-based configuration; Multi-view; Separation of concerns; Software product line engineering},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84879788174&partnerID=40&md5=dee1ff6a27f859c32d424a1528d81ada},
	bdsk-url-2 = {http://dx.doi.org/10.1007/s10270-011-0220-1},
	document_type = {Article},
	doi = {10.1007/s10270-011-0220-1},
	review = {k-configuration k-method k-solution},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84879788174&partnerID=40&md5=dee1ff6a27f859c32d424a1528d81ada}
}

@Article{Hubaux2013,
	author = {Hubaux, A and Tun, T.T b and Heymans, P.a},
	title = {Separation of concerns in feature diagram languages: A systematic survey},
	journal = {ACMS},
	year = {2013},
	volume = {45},
	number = {4},
	note = {cited By 4},
	abstract = {The need for flexible customization of large feature-rich software systems, according to requirements of various stakeholders, has become an important problem in software development. Among the many software engineering approaches dealing with variability management, the notion of Software Product Line (SPL) has emerged as a major unifying concept. Drawing from established disciplines of manufacturing, SPL approaches aim to design repertoires of software artifacts, from which customized software systems for specific stakeholder requirements can be developed. A major difficulty SPL approaches attempt to address is the modularization of software artifacts, which reconciles the user's needs for certain features and the development and technical constraints. Towards this end, many SPL approaches use feature diagrams to describe possible configurations of a feature set. There have been several proposals for feature diagram languages with varying degrees of expressiveness, intuitiveness, and precision. However, these feature diagram languages have limited scalability when applied to realistic software systems. This article provides a systematic survey of various concerns of feature diagrams and ways in which concerns have been separated. The survey shows how the uncertainty in the purpose of feature diagram languages creates both conceptual and practical limitations to scalability of those languages. {\copyright} 2013 ACM.},
	affiliation = {PReCISE Research Centre, Faculty of Computer Science, University of Namur, Belgium; Open University, United Kingdom},
	art_number = {2501665},
	author_keywords = {Feature diagram; Separation of concerns; Software product line; Variability},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84885220291&partnerID=40&md5=954c05149edd6f2b59184be6c4abbbc9},
	bdsk-url-2 = {http://dx.doi.org/10.1145/2501654.2501665},
	document_type = {Article},
	doi = {10.1145/2501654.2501665},
	review = {k-modeling k-tool k-philosophical},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84885220291&partnerID=40&md5=954c05149edd6f2b59184be6c4abbbc9}
}

@Article{Jezequel2012,
	author = {J{\'e}z{\'e}quel, Jean-Marc},
	title = {Model-driven engineering for software product lines},
	journal = {ISRN},
	year = {2012},
	volume = {2012},
	publisher = {Hindawi Publishing Corporation},
	review = {k-modeling k-solution}
}

@Article{Karatas2013,
  author   = {Karataş, AS and Oğuzt{\"{u}}z{\"{u}}n, H and Doğru, A},
  title    = {From extended feature models to constraint logic programming},
  journal  = {SCP},
  year     = {2013},
  abstract = {Since feature models for realistic product families may be quite complicated, the automated analysis of feature models is desirable. Although several approaches reported in the literature address this issue, complex cross-tree relationships involving attributes in extended feature models have not been handled. In this article, we introduce a mapping from extended feature models to constraint logic programming over finite domains. This mapping is used to translate into constraint logic programs; basic, cardinality-based and extended feature models, which can include complex cross-tree relationships involving attributes. This translation enables the use of off-the-shelf constraint solvers for the automated analysis of extended feature models involving such complex relationships. We also present the performance results of some well-known analysis operations on an example translated model.},
  review   = {k-evaluation k-configuration k-modeling},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642312001153},
}

@Article{Karatas2016,
  author    = {Karataş, Ahmet Serkan and Oğuzt{\"{u}}z{\"{u}}n, Halit},
  title     = {Attribute-based variability in feature models},
  journal   = {REJ},
  year      = {2016},
  volume    = {21},
  number    = {2},
  pages     = {185--208},
  month     = {jun},
  abstract  = {Extended feature models enable the expression of complex cross-tree constraints involving feature attributes. The inclusion of attributes in cross-tree relations not only enriches the constraints, but also engenders an extended type of variability that involves attributes. In this article, we elaborate on the effects of this new variability type on feature models. We start by analyzing the nature of the variability involving attributes and extend the definitions of the configuration and the product to suit the emerging requirements. Next, we propose classifications for the features, configurations, and products to identify and formalize the ramifications that arise due to the new type of variability. Then, we provide a semantic foundation grounded on constraint satisfaction for our proposal. We introduce an ordering relation between configurations and show that the set of all the configurations represented by a feature model forms a semilattice. This is followed by a demonstration of how the feature model analyses will be affected using illustrative examples selected from existing and novel analysis operations. Finally, we summarize our experiences, gained from a commercial research and development project that employs an extended feature model.},
  doi       = {10.1007/s00766-014-0216-9},
  issn      = {1432010X},
  publisher = {Springer-Verlag London Ltd},
  review    = {k-modeling 
k-evaluation},
}

@Article{Kastner201467,
	author = {Kastner, C and Dreiling, A and Ostermann, K.c},
	title = {Variability mining: Consistent semi-automatic detection of product-line features},
	journal = {TSE},
	year = {2014},
	volume = {40},
	number = {1},
	pages = {67-82},
	note = {cited By 4},
	abstract = {Software product line engineering is an efficient means to generate a set of tailored software products from a common implementation. However, adopting a product-line approach poses a major challenge and significant risks, since typically legacy code must be migrated toward a product line. Our aim is to lower the adoption barrier by providing semi-automatic tool support-called variability mining-to support developers in locating, documenting, and extracting implementations of product-line features from legacy code. Variability mining combines prior work on concern location, reverse engineering, and variability-aware type systems, but is tailored specifically for the use in product lines. Our work pursues three technical goals: (1) we provide a consistency indicator based on a variability-aware type system, (2) we mine features at a fine level of granularity, and (3) we exploit domain knowledge about the relationship between features when available. With a quantitative study, we demonstrate that variability mining can efficiently support developers in locating features. {\copyright} 2014 IEEE.},
	affiliation = {School of Computer Science, Carnegie Mellon University, United States; University of Magdeburg, Deutsche Bank AG, Germany; Department of Mathematics and Computer Science, Philipps University, Marburg, Germany},
	art_number = {6613490},
	author_keywords = {feature; feature location; LEADT; mining; reverse engineering; software product line; Variability},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84898456736&partnerID=40&md5=00d3be74262281d6cd89242e8cf02a1d},
	bdsk-url-2 = {http://dx.doi.org/10.1109/TSE.2013.45},
	document_type = {Article},
	doi = {10.1109/TSE.2013.45},
	review = {k-reverse k-method k-evaluation},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84898456736&partnerID=40&md5=00d3be74262281d6cd89242e8cf02a1d}
}

@Article{Lee2014,
  author    = {Lee, Hyesun and Yang, Jin Seok and Kang, Kyo Chul and Pyun, Jai Jeong},
  title     = {Domain-oriented variability modeling for reuse of simulation models},
  journal   = {SIMULATION},
  year      = {2014},
  volume    = {90},
  number    = {4},
  pages     = {438--459},
  abstract  = {Reusability is an important quality attribute for defense modeling and simulation (MS) due to the ever-changing combat simulations and new requirements. There has been research conducted worldwide for reusing simulation models. The methods proposed in these studies (including One Semi-Automated Forces (OneSAF)) support reuse of simulation components in the development of new models. As the reuse units in the existing methods are at the simulation component level, when existing components do not satisfy new simulation requirements, new components have to be developed and maintained separately from the existing ones. However, simulation components in the same domain tend to have common parts; behavior models for tactical missions and battlefield functions in the same domain are derived from the same tactical doctrine/manual, and thus they tend to have a common structure. There is a need for a new method to maximize reusability by providing "fine-grained" reuse, i.e. composing simulation components from reusable fine-grained modules (i.e. behaviors/functions). We address the problem by applying the product line engineering concept to the development of simulation components. Commonalities and variabilities (CVs) of domain-specific simulation requirements and CVs of tactical behaviors and battlefield functions are identified in domain-oriented variability modeling. Then, the CVs are used to design and implement domain-specific simulation component assets with domain-specific tactical behaviors and battlefield functions while embedding the identified variabilities. These domain-specific component assets are instantiated based on selections of variabilities and then integrated to develop a simulation model. Feasibility of the method was demonstrated in an infantry squad combat domain of the Republic of Korea armed forces. {\textcopyright} 2014 The Society for Modeling and Simulation International.},
  doi       = {10.1177/0037549714525679},
  issn      = {17413133},
  publisher = {SAGE Publications Ltd},
  review    = {k-vis k-modeling k-mmodel k-configuration k-evaluation k-validation},
}

@Article{LeeKotonya2010,
	Title = {Combining service-orientation with product line engineering},
	Author = {Lee, Jaejoon and Kotonya, Gerald},
	Journal = {Software, IEEE},
	Year = {2010},
	Number = {3},
	Pages = {35--41},
	Volume = {27},
	Abstract = {Software product line engineering (SPLE) is a paradigm of software reuse for developing a family of products with reduced time to market and improved quality. Most SPLE approaches, however, have focused on developing statically configured products using core assets. That is, all variations are instantiated before a product is delivered to the customers, making it difficult for them to make any changes to the product. However, various application areas are increasing the demand for dynamic product reconfiguration. A service-oriented product line (SOPL) is a DSPL application domain that's built on services and a service-oriented architecture. An example of an application area for an SOPL approach is a virtual office (VO). A VO includes many business peripherals with various services that interact with one another and that respond to their various environments to assist office workers.},
	Publisher = {IEEE},
	Review = {k-vis k-philosophical k-method}
}

@Article{lisboa2010systematic,
	Title = {A systematic review of domain analysis tools},
	Author = {Lisboa, Liana Barachisio and Garcia, Vinicius Cardoso and Lucr{\'e}dio, Daniel and de Almeida, Eduardo Santana and de Lemos Meira, Silvio Romero and de Mattos Fortes, Renata Pontin},
	Journal = {IST},
	Year = {2010},
	Number = {1},
	Pages = {1--13},
	Volume = {52},
	Abstract = {The domain analysis process is used to identify and document common and variable characteristics of systems in a specific domain. In order to achieve an effective result, it is necessary to collect, organize and analyze several sources of information about different applications in this domain. Consequently, this process involves distinct phases and activities and also needs to identify which artifacts, arising from these activities, have to be traceable and consistent. In this context, performing a domain analysis process without tool support increases the risks of failure, but the used tool should support the complete process and not just a part of it. This article presents a systematic review of domain analysis tools that aims at finding out how the available tools offer support to the process. As a result, the review identified that these tools are usually focused on supporting only one process and there are still gaps in the complete process support. Furthermore, the results can provide insights for new research in the domain engineering area for investigating and defining new tools, and the study also aids in the identification of companies’ needs for a domain analysis tool.},
	Publisher = {Elsevier},
	Review = {k-modeling k-method k-solution}
}

@Article{Liu2010a,
  author   = {Liu, YJ and Lai, KL and Dai, G and Yuen, MMF},
  title    = {A semantic feature model in concurrent engineering},
  journal  = {TASE},
  year     = {2010},
  abstract = {Concurrent engineering (CE) is a methodology applied to
 product lifecycle development so that high quality, well designed products
 can be provided at lower prices and in less time. Many research works
 have been proposed for efficiently modeling of different domains in CE.
 However, an integration of these works with consistent data flow is absent
 and still in great demand in industry. In this paper, we present a generic
 integration framework with a semantic feature model for knowledge
 representation and reasoning across domains in CE. An implementation
 of the proposed semantic feature model is presented to demonstrate its
 advantage in knowledge representation by feature transformation across
 domains in CE.
 Note to Practitioners—In this paper, an important problem in manufacturing
 industry is addressed: how semantic features can be used across
 different domains in CE. The proposed hierarchical feature model in this
 paper offers a solution to two aspects in this problem: (a) how to capture the
 specific knowledge consistently in different domains and (b) how to reuse
 the existing data. The presented modeling approach is an attempt that uses
 a semantic feature language representation in CE and sheds some light on
 a practical solution to this difficult problem in industry.},
  review   = {k-modeling k-mmodel k-solution},
  url      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5439907},
}

@Article{LochauOsterGoltzEtAl2012,
	author = {Lochau, Malte and Oster, Sebastian and Goltz, Ursula and Sch{\"u}rr, Andy},
	title = {Model-based pairwise testing for feature interaction coverage in software product line engineering},
	journal = {SQJ},
	year = {2012},
	volume = {20},
	number = {3-4},
	pages = {567--604},
	publisher = {Springer},
	review = {k-testing k-evaluation k-method}
}

@Article{LopezHerrejonLinsbauerEgyed2015,
	Title = {A systematic mapping study of search-based software engineering for software product lines},
	Author = {Lopez-Herrejon, R.E. and Linsbauer, L. and Egyed, A.},
	Journal = {IST},
	Year = {2015},
	Note = {cited By 2},
	Pages = {33-51},
	Volume = {61},
	Abstract = {Context Search-Based Software Engineering (SBSE) is an emerging discipline that focuses on the application of search-based optimization techniques to software engineering problems. Software Product Lines (SPLs) are families of related software systems whose members are distinguished by the set of features each one provides. SPL development practices have proven benefits such as improved software reuse, better customization, and faster time to market. A typical SPL usually involves a large number of systems and features, a fact that makes them attractive for the application of SBSE techniques which are able to tackle problems that involve large search spaces. Objective The main objective of our work is to identify the quantity and the type of research on the application of SBSE techniques to SPL problems. More concretely, the SBSE techniques that have been used and at what stage of the SPL life cycle, the type of case studies employed and their empirical analysis, and the fora where the research has been published. Method A systematic mapping study was conducted with five research questions and assessed 77 publications from 2001, when the term SBSE was coined, until 2014. Results The most common application of SBSE techniques found was testing followed by product configuration, with genetic algorithms and multi-objective evolutionary algorithms being the two most commonly used techniques. Our study identified the need to improve the robustness of the empirical evaluation of existing research, a lack of extensive and robust tool support, and multiple avenues worthy of further investigation. Conclusions Our study attested the great synergy existing between both fields, corroborated the increasing and ongoing interest in research on the subject, and revealed challenging open research questions. {\copyright} 2015 Elsevier B.V. All rights reserved.},
	Affiliation = {Institute for Software Systems Engineering, Johannes Kepler University Linz, Altenbergerstr. 69, Linz, Austria},
	Author_keywords = {Evolutionary algorithm; Metaheuristics; Search based software engineering; Software product line; Systematic mapping study},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84924704473&partnerID=40&md5=4da0e47fdd29cd2f9f70f1c1be8ff2cf},
	Bdsk-url-2 = {http://dx.doi.org/10.1016/j.infsof.2015.01.008},
	Document_type = {Review},
	Doi = {10.1016/j.infsof.2015.01.008},
	Review = {k-configuration k-reverse k-philosophical k-method},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84924704473&partnerID=40&md5=4da0e47fdd29cd2f9f70f1c1be8ff2cf}
}

@Article{LopezHerrejonLinsbauerGalindoEtAl2015b,
	Title = {An assessment of search-based techniques for reverse engineering feature models},
	Author = {Lopez-Herrejon, R.E and Linsbauer, L and Galindo, J.A and Parejo, J.A and Benavides, D and Segura, S and Egyed, A.a},
	Journal = {JSS},
	Year = {2015},
	Note = {cited By 3},
	Pages = {353-369},
	Volume = {103},
	Abstract = {Successful software evolves from a single system by adding and changing functionality to keep up with users' demands and to cater to their similar and different requirements. Nowadays it is a common practice to offer a system in many variants such as community, professional, or academic editions. Each variant provides different functionality described in terms of features. Software Product Line Engineering (SPLE) is an effective software development paradigm for this scenario. At the core of SPLE is variability modelling whose goal is to represent the combinations of features that distinguish the system variants using feature models, the de facto standard for such task. As SPLE practices are becoming more pervasive, reverse engineering feature models from the feature descriptions of each individual variant has become an active research subject. In this paper we evaluated, for this reverse engineering task, three standard search based techniques (evolutionary algorithms, hill climbing, and random search) with two objective functions on 74 SPLs. We compared their performance using precision and recall, and found a clear trade-off between these two metrics which we further reified into a third objective function based on Fβ, an information retrieval measure, that showed a clear performance improvement. We believe that this work sheds light on the great potential of search-based techniques for SPLE tasks. {\copyright} 2014 Elsevier Inc. All rights reserved.},
	Affiliation = {Institute for Software Systems Engineering, Johannes Kepler University Linz, Altenbergerstr. 69, Linz, Austria; Department of Computer Languages and Systems, University of Seville, Av Reina Mercedes S/N, Seville, Spain},
	Author_keywords = {Feature model; Reverse engineering; Search Based Software Engineering},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84924858053&partnerID=40&md5=6887e2270ea620201f397e6912b392ea},
	Bdsk-url-2 = {http://dx.doi.org/10.1016/j.jss.2014.10.037},
	Document_type = {Conference Paper},
	Doi = {10.1016/j.jss.2014.10.037},
	Publisher = {Elsevier},
	Review = {k-reverse k-method k-evaluation},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84924858053&partnerID=40&md5=6887e2270ea620201f397e6912b392ea}
}

@Article{Luo2011,
  author   = {Luo, Shutong and Pei, Zhili and Zhang, Changhai and Jin, Ying},
  title    = {A of feature reuse method at requirement level based on aspect encapsulation},
  journal  = {JCRD},
  year     = {2011},
  volume   = {48},
  number   = {9},
  pages    = {1714--1721},
  month    = {sep},
  abstract = {Identification of reusable software assets is the basis of software reusable exercise. Feature model can organize software requirements effectively in a certain domain by defining features and their relationship, which provides strong support for domain requirements reuse. Aspect-oriented system design emphasizes reducing entangles among requirements or codes produced during software development and achieving high modularity by encapsulating crosscutting concerns into aspects, which benefits maintenance and reuse. A method of aspect encapsulation of features from feature model at requirement level is proposed for the purpose of feature reuse, and it can identify the module reused from legacy systems in one domain. At first, through analyzing requirements documents of multi-legacy systems, system concerns are elicited and domain concern hierarchical structure is established. Next, a set of domain features are identified, and aspect encapsulation is done on similar features, and the feature layer model is set up. Finally a new system is developed with the assistance and reuse of feature layer model and encapsulated aspects. A case study is done by applying our method to design a new Web system from two legacy Web systems. It has been indicated that our approach is helpful for reusing multi-legacy systems in one domain.},
  issn     = {10001239},
  review   = {k-evaluation k-configuration},
}

@Article{Ma2014,
  author    = {Ma, Zhiyi and He, Xiao},
  title     = {Building modeling tools based on metamodeling and product line technologies},
  journal   = {CJE},
  year      = {2014},
  volume    = {23},
  number    = {2},
  pages     = {219--226},
  abstract  = {With the evolution of existing modeling languages and the emergence of more and more new modcling languages, it is necessary to rapidly build the corresponding software modeling tools with good quality. However, modeling tools for larger modeling languages are usually diversity in function and complexity in implementation technology. Taking building modeling tools as a domain, this paper presents an approach to building software modcling tools based on metamodeling and product line technologies. The paper provides the concept system of the approach and a feature model from diverse functions of modcling tools in order to specify the commonality and variability of the tools by deeply making the domain analysis, discusses the design and implementation of a general tool framework that provides the conveniences for reusing components and generating code for components, and specifies the mapping between the feature model and the components for modeling tools.},
  issn      = {10224653},
  publisher = {Chinese Institute of Electronics},
  review    = {k-evaluation k-reverse k-modeling k-configuration},
}

@Article{Maazoun2016,
  author    = {Ma{\^{a}}zoun, Jihen and Bouassida, Nadia and Ben-Abdallah, Han{\^{e}}ne},
  title     = {Change impact analysis for software product lines},
  journal   = {JKSU},
  year      = {2016},
  volume    = {28},
  number    = {4},
  pages     = {364--380},
  month     = {oct},
  abstract  = {A software product line (SPL) represents a family of products in a given application domain. Each SPL is constructed to provide for the derivation of new products by covering a wide range of features in its domain. Nevertheless, over time, some domain features may become obsolete with the apparition of new features while others may become refined. Accordingly, the SPL must be maintained to account for the domain evolution. Such evolution requires a means for managing the impact of changes on the SPL models, including the feature model and design. This paper presents an automated method that analyzes feature model evolution, traces their impact on the SPL design, and offers a set of recommendations to ensure the consistency of both models. The proposed method defines a set of new metrics adapted to SPL evolution to identify the effort needed to maintain the SPL models consistently and with a quality as good as the original models. The method and its tool are illustrated through an example of an SPL in the Text Editing domain. In addition, they are experimentally evaluated in terms of both the quality of the maintained SPL models and the precision of the impact change management.},
  doi       = {10.1016/j.jksuci.2016.01.005},
  issn      = {22131248},
  publisher = {King Saud bin Abdulaziz University},
  review    = {k-testing k-evaluation},
}

@Article{Machado20141183,
	author = {Machado, I.D.C and McGregor, J.D and Cavalcanti, Y.C and De Almeida, E.S.a},
	title = {On strategies for testing software product lines: A systematic literature review},
	journal = {IST},
	year = {2014},
	volume = {56},
	number = {10},
	pages = {1183-1199},
	note = {cited By 2},
	abstract = {Context Testing plays an important role in the quality assurance process for software product line engineering. There are many opportunities for economies of scope and scale in the testing activities, but techniques that can take advantage of these opportunities are still needed. Objective The objective of this study is to identify testing strategies that have the potential to achieve these economies, and to provide a synthesis of available research on SPL testing strategies, to be applied towards reaching higher defect detection rates and reduced quality assurance effort. Method We performed a literature review of two hundred seventy-six studies published from the year 1998 up to the 1st semester of 2013. We used several filters to focus the review on the most relevant studies and we give detailed analyses of the core set of studies. Results The analysis of the reported strategies comprised two fundamental aspects for software product line testing: the selection of products for testing, and the actual test of products. Our findings indicate that the literature offers a large number of techniques to cope with such aspects. However, there is a lack of reports on realistic industrial experiences, which limits the inferences that can be drawn. Conclusion This study showed a number of leveraged strategies that can support both the selection of products, and the actual testing of products. Future research should also benefit from the problems and advantages identified in this study. {\copyright} 2014 Elsevier B.V. All rights reserved.},
	affiliation = {Computer Science Department, Federal University of Bahia, UFBA, Salvador, Brazil; School of Computing, Clemson University, Clemson, SC, United States; Federal Data Processing Service, SERPRO, Florian{\'o}polis, Brazil},
	author_keywords = {Software product lines; Software quality; Software testing; Systematic literature review},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905124696&partnerID=40&md5=d721f4c875b495092524907c14f11b31},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.infsof.2014.04.002},
	document_type = {Review},
	doi = {10.1016/j.infsof.2014.04.002},
	review = {k-testing k-philosophical k-method},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905124696&partnerID=40&md5=d721f4c875b495092524907c14f11b31}
}

@Article{MaianideMelloNogueiraTeixeiraSchotsEtAl2014,
	author = {Maiani de Mello, R. and Nogueira Teixeira, E. and Schots, M. and Lima Werner, C.M. and Travassos, G.H.},
	title = {Verification of Software Product Line artefacts: A checklist to support feature model inspections},
	journal = {JUCS},
	year = {2014},
	volume = {20},
	number = {5},
	pages = {720-745},
	note = {cited By 2},
	abstract = {Software Product Line Engineering (SPL) should ensure the correctness, completeness and consistency of its artefacts and related domain to prevent the propagation of defects in derived products. Software inspection techniques are effective in detecting defects in software artefacts and avoiding their propagation throughout the software development process. However, the results of a quasi-systematic review of the technical literature reported in this paper pointed to a lack of such techniques to support the inspection of SPL artefacts, including techniques to support the inspection of feature models (FMs) that are largely used in domain modelling. Therefore, a checklist-based inspection technique (FMCheck) has been developed to support the detection of defects on FMs. FMCheck is configurable and can be applied to the original feature model notation (the FODA approach) and its extensions, including the Odyssey-FEX notation. The inspection technique was empirically evaluated, having indicated its feasibility and effectiveness. It is possible to see that inspectors applying FMCheck to inspect FMs can be more effective than those applying ad-hoc techniques, regarding four distinct domains. {\copyright} J.UCS.},
	affiliation = {COPPE, Federal University of Rio de Janeiro, Rio de Janeiro, Brazil},
	author_keywords = {Domain engineering; Experimental software engineering; Feature model; Software inspection; Software product line; Software reuse},
	bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84904721463&partnerID=40&md5=3b1d70235978d949dcf4dbe267f1d29c},
	document_type = {Article},
	review = {k-testing k-configuration k-evaluation k-method},
	source = {Scopus},
	url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84904721463&partnerID=40&md5=3b1d70235978d949dcf4dbe267f1d29c}
}

@Article{MazoSalinesiDiazEtAl2012,
	author = {Mazo, R and Salinesi, C and Diaz, D and Djebbi, O and Lora-Michiels, A.b},
	title = {Constraints: The heart of domain and application engineering in the product lines engineering strategy},
	journal = {IJISMD},
	year = {2012},
	volume = {3},
	number = {2},
	pages = {33-68},
	note = {cited By 17},
	abstract = {Drawing from an analogy between features based Product Line (PL) models and Constraint Programming (CP), this paper explores the use of CP in the Domain Engineering and Application Engineering activities that are put in motion in a Product Line Engineering strategy. Specifying a PL as a constraint program instead of a feature model carries out two important qualities of CP: expressiveness and direct automation. On the one hand, variables in CP can take values over boolean, integer, real or even complex domains and not only boolean values as in most PL languages such as the Feature-Oriented Domain Analysis (FODA). Specifying boolean, arithmetic, symbolic and reified constraint, provides a power of expression that spans beyond that provided by the boolean dependencies in FODA models. On the other hand, PL models expressed as constraint programs can directly be executed and analyzed by off-the-shelf solvers. This paper explores the issues of (a) how to specify a PL model using CP, including in the presence of multi-model representation, (b) how to verify PL specifications, (c) how to specify configuration requirements, and (d) how to support the product configuration activity. Tests performed on a benchmark of 50 PL models show that the approach is efficient and scales up easily to very large and complex PL specifications. Copyright {\copyright} 2012, IGI Global.},
	affiliation = {University of Antioquia, CRI Panth{\'e}on Sorbonne University, France; Baxter International Inc, Belgium},
	author_keywords = {Computer science; Constraint-based product lines; Information systems; Product line analysis; Product line configuration; Product line integration; Product line reasoning; Product line specification; Product line verification},
	bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84866296760&partnerID=40&md5=b6df92893765e28f868a5701f3c4a370},
	bdsk-url-2 = {http://dx.doi.org/10.4018/jismd.2012040102},
	document_type = {Article},
	doi = {10.4018/jismd.2012040102},
	review = {k-philosophical k-configuration},
	source = {Scopus},
	url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84866296760&partnerID=40&md5=b6df92893765e28f868a5701f3c4a370}
}

@Article{Mendonca2010311,
	author = {Mendonca, M. and Cowan, D.},
	title = {Decision-making coordination and efficient reasoning techniques for feature-based configuration},
	journal = {SCP},
	year = {2010},
	volume = {75},
	number = {5},
	pages = {311-332},
	note = {cited By 21},
	abstract = {Software Product Lines is a contemporary approach to software development that exploits the similarities and differences within a family of systems in a particular domain of interest in order to provide a common infrastructure for deriving members of this family in a timely fashion, with high-quality standards, and at lower costs. In Software Product Lines, feature-based product configuration is the process of selecting the desired features for a given software product from a repository of features called a feature model. This process is usually carried out collaboratively by people with distinct skills and interests called stakeholders. Collaboration benefits stakeholders by allowing them to directly intervene in the configuration process. However, collaboration also raises an important side effect, i.e., the need of stakeholders to cope with decision conflicts. Conflicts arise when decisions that are locally consistent cannot be applied globally because they violate one or more constraints in the feature model. Unfortunately, current product configuration systems are typically single-user-based in the sense that they do not provide means to coordinate concurrent decision-making on the feature model. As a consequence, configuration is carried out by a single person that is in charge of representing the interests of all stakeholders and managing decision conflicts on their own. This results in an error-prone and time-consuming process that requires past decisions to be revisited continuously either to correct misinterpreted stakeholder requirements or to handle decision conflicts. Yet another challenging issue related to configuration problems is the typically high computational cost of configuration algorithms. In fact, these algorithms frequently fall into the category of NP-hard and thus can become intractable in practice. In this paper, our goal is two-fold. First, we revisit our work on Collaborative Product Configuration (CPC) in which we proposed an approach to describe and validate collaborative configuration scenarios. We discuss how collaborative configuration can be described in terms of a workflow-like plan that safely guides stakeholders during the configuration process. Second, we propose a preliminary set of reasoning algorithms tailored to the feature modelling domain that can be used to provide automated support for product configuration. In addition, we compare empirically the performance of the proposed algorithms to that of a general-purpose solution. We hope that the insights provided in this paper will encourage other researchers to develop new algorithms in the near future. {\copyright} 2009 Elsevier B.V. All rights reserved.},
	affiliation = {David R. Cheriton School of Computer Science, University of Waterloo, Canada},
	author_keywords = {Automated reasoning; Constraint-based reasoning; Decision-making coordination; Feature modelling; Feature models; Product configuration; Software Product Lines},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77649337969&partnerID=40&md5=644773597d2207f1e7714c6da1a674d0},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.scico.2009.12.004},
	document_type = {Article},
	doi = {10.1016/j.scico.2009.12.004},
	review = {k-configuration k-method k-evaluation},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77649337969&partnerID=40&md5=644773597d2207f1e7714c6da1a674d0}
}

@Article{Mussbacher2012,
  author   = {Mussbacher, Gunter and Ara{\'{u}}jo, Jo{\~{a}}o and Moreira, Ana and Amyot, Daniel},
  title    = {AoURN-based modeling and analysis of software product lines},
  journal  = {SQJ},
  year     = {2012},
  volume   = {20},
  number   = {3-4},
  pages    = {645--687},
  month    = {sep},
  abstract = {Software Product Line Engineering concerns itself with domain engineering and application engineering. During domain engineering, the whole product family is modeled with a preferred flavor of feature models and additional models as required (e. g., domain models or scenario-based models). During application engineering, the focus shifts toward a single family member and the configuration of the member's features. Recently, aspectual concepts have been employed to better encapsulate individual features of a Software Product Line (SPL), but the existing body of SPL work does not include a unified reasoning framework that integrates aspect-oriented feature description artifacts with the capability to reason about stakeholders' goals while taking feature interactions into consideration. Goal-oriented SPL approaches have been proposed, but do not provide analysis capabilities that help modelers meet the needs of the numerous stakeholders involved in an SPL while at the same time considering feature interactions. We present an aspect-oriented SPL approach for the requirements phase that allows modelers (a) to capture features, goals, and scenarios in a unified framework and (b) to reason about stakeholders' needs and perform trade-off analyses while considering undesirable interactions that are not obvious from the feature model. The approach is based on the Aspect-oriented User Requirements Notation (AoURN) and helps identify, prioritize, and choose products based on analysis results provided by AoURN editor and analysis tools. We apply the AoURN-based SPL framework to the Via Verde SPL to demonstrate the feasibility of this approach through the selection of a Via Verde product configuration that satisfies stakeholders' needs and results in a high-level, scenario-based specification that is free from undesirable feature interactions. {\textcopyright} 2011 Springer Science+Business Media, LLC.},
  doi      = {10.1007/s11219-011-9153-8},
  issn     = {09639314},
  review   = {k-evaluation k-mmodel k-modeling},
}

@Article{NoehrerEgyed2013,
	Title = {C2o configurator: a tool for guided decision-making},
	Author = {N{\"o}hrer, Alexander and Egyed, Alexander},
	Journal = {ASEJ},
	Year = {2013},
	Note = {cited By 6},
	Number = {2},
	Pages = {265--296},
	Volume = {20},
	Abstract = {Decision models are widely used in software engineering to describe and restrict decision-making (e.g., deriving a product from a product-line). Since decisions are typically interdependent, it is often neither obvious which decisions have the most significant impact nor which decisions might ultimately conflict. Unfortunately, the current state-of-the-art provides little support for dealing with such situations. On the one hand, some conflicts can be avoided by providing more freedom in which order decisions are made (i.e., most important decisions first). On the other hand, conflicts are unavoidable at times, and living with conflicts may be preferable over forcing the user to fix them right away - particularly because fixing conflicts becomes easier as more is known about a user's intentions. This paper introduces the C2O (Configurator 2.0) tool for guided decision-making. The tool allows the user to answer questions in an arbitrary order - with and without the presence of inconsistencies. While giving users those freedoms, it still supports and guides them by (i) rearranging the order of questions according to their potential to minimize user input, (ii) providing guidance to avoid follow-on conflicts, and (iii) supporting users in fixing conflicts at a later time. {\copyright} 2013 Springer Science+Business Media New York.},
	Affiliation = {Institute for Systems Engineering and Automation, Johannes Kepler University, Linz, Austria},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84879502708&partnerID=40&md5=3bebca6fc76f2134ddb5e1c54a63f520},
	Bdsk-url-2 = {http://dx.doi.org/10.1007/s10515-012-0117-4},
	Document_type = {Article},
	Doi = {10.1007/s10515-012-0117-4},
	Publisher = {Springer},
	Review = {k-configuration k-tool k-solution},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84879502708&partnerID=40&md5=3bebca6fc76f2134ddb5e1c54a63f520}
}

@Article{Nadi2015,
  author    = {Nadi, Sarah and Berger, Thorsten and K{\"{a}}stner, Christian and Czarnecki, Krzysztof},
  title     = {Where do configuration constraints stem from? An extraction approach and an empirical study},
  journal   = {TSE},
  year      = {2015},
  volume    = {41},
  number    = {8},
  pages     = {820--841},
  month     = {aug},
  abstract  = {Highly configurable systems allow users to tailor software to specific needs. Valid combinations of configuration options are often restricted by intricate constraints. Describing options and constraints in a variability model allows reasoning about the supported configurations. To automate creating and verifying such models, we need to identify the origin of such constraints. We propose a static analysis approach, based on two rules, to extract configuration constraints from code. We apply it on four highly configurable systems to evaluate the accuracy of our approach and to determine which constraints are recoverable from the code. We find that our approach is highly accurate (93{\%} and 77{\%} respectively) and that we can recover 28{\%} of existing constraints. We complement our approach with a qualitative study to identify constraint sources, triangulating results from our automatic extraction, manual inspections, and interviews with 27 developers. We find that, apart from low-level implementation dependencies, configuration constraints enforce correct runtime behavior, improve users' configuration experience, and prevent corner cases. While the majority of constraints is extractable from code, our results indicate that creating a complete model requires further substantial domain knowledge and testing. Our results aim at supporting researchers and practitioners working on variability model engineering, evolution, and verification techniques.},
  doi       = {10.1109/TSE.2015.2415793},
  issn      = {00985589},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  review    = {k-reverse k-evaluation},
}

@Article{Noorian2014,
  author    = {Noorian, Mehdi and Asadi, Mohsen and Bagheri, Ebrahim and Du, Weichang},
  title     = {Addressing non-functional properties in feature models: A goal-oriented approach},
  journal   = {IJSEKE},
  year      = {2014},
  volume    = {24},
  number    = {10},
  pages     = {1439--1487},
  month     = {dec},
  abstract  = {Software Product Line (SPL) engineering is a systematic reuse-based software development approach which is founded on the idea of building software products using a set of core assets rather than developing individual software systems from scratch. Feature models are among the widely used artefacts for SPL development that mostly capture functional and operational variability of a system. Researchers have argued that connecting intentional variability models such as goal models with feature variability models in a target domain can enrich feature models with valuable quality and non-functional information. Interrelating goal models and feature models has already been proposed in the literature for capturing non-functional properties in software product lines; however, this manual integration process is cumbersome and tedious. In this paper, we propose a (semi) automated approach that systematically integrates feature models and goal models through standard ontologies. Our proposed approach connects feature model and goal model elements through measuring the semantic similarity of their annotated ontological concepts. Our work not only provides the means to systematically interrelate feature models and goal models but also allows domain engineers to identify and model the role and significance of non-functional properties in the domain represented by the feature model.},
  doi       = {10.1142/S0218194014400154},
  issn      = {02181940},
  publisher = {World Scientific Publishing Co. Pte Ltd},
  review    = {k-mmodel k-evaluation k-configuration},
}

@Article{NummenmaaNummenmaaZhang2014,
	author = {Nummenmaa, J. and Nummenmaa, T. and Zhang, Z.},
	title = {On the Use of LTSs to Analyze Software Product Line Products Composed of Features},
	journal = {AISC},
	year = {2014},
	volume = {214},
	pages = {531-541},
	note = {cited By 1},
	abstract = {In product line engineering, it is common to define the products as sets of features, where each feature has a related set of requirements. Typically, there is a common set of features/requirements, and some variable features/requirements for building different products. In an earlier proposal to use labeled transition systems (LTSs) to model and check the products, the products were composed using the feature-oriented approach and LTS models were analyzed using a related LTS analyzer tool. However, no further details or analysis about the models and possible conflicts were given. We investigate in more detail the types of conflicts that may arise and discuss the integration strategies for building an integrated LTS for the product composed of features. {\copyright} Springer-Verlag Berlin Heidelberg 2014.},
	affiliation = {School of Information Sciences, University of Tampere, Tampere, Finland},
	author_keywords = {Feature model; Functional requirement; Labeled transition system; Software product line},
	bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84888402271&partnerID=40&md5=f3a59e8161fb9611c43fdddc5140daed},
	bdsk-url-2 = {http://dx.doi.org/10.1007/978-3-642-37832-4_48},
	document_type = {Conference Paper},
	doi = {10.1007/978-3-642-37832-4_48},
	review = {k-modeling k-solution k-configuration k-method},
	source = {Scopus},
	url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84888402271&partnerID=40&md5=f3a59e8161fb9611c43fdddc5140daed}
}

@Article{Paskevicius2012,
  author   = {Pa{\v{s}}kevi{\v{c}}ius, Paulius and Dama{\v{s}}evi{\v{c}}ius, Robertas and Kar{\v{c}}iauskas, Eimutis and Marcinkevi{\v{c}}ius, Romas},
  title    = {Automatic extraction of features and generation of feature models from java programs},
  journal  = {ITC},
  year     = {2012},
  volume   = {41},
  number   = {4},
  pages    = {376--384},
  abstract = {Feature modelling is a key technique for identifying common and variable features in software (software component families). The result of feature modelling is a feature model: a concise specification of product features and their relationships. Feature models have been proven to be useful for software variability modelling and management. However, there is a wide gap between feature models and program source code. Here we focus on reverse engineering of source code to feature models. We present a framework for the automated derivation of feature models from the existing software artefacts (components, libraries, etc.), which includes a formal description of a feature model, a program-feature relation meta-model, and a method for feature model generation based on feature dependency extraction and clustering. Feature models are generated in Feature Description Language (FDL) and as Prolog rules.},
  issn     = {1392124X},
  review   = {k-configuration k-reverse k-solution},
}

@Article{PascualLopezHerrejonPintoEtAl2015,
	Title = {Applying multiobjective evolutionary algorithms to dynamic software product lines for reconfiguring mobile applications},
	Author = {Pascual, G.G and Lopez-Herrejon, R.E and Pinto, M and Fuentes, L and Egyed, A.b},
	Journal = {JSS},
	Year = {2015},
	Note = {cited By 4},
	Pages = {392-411},
	Volume = {103},
	Abstract = {Mobile applications require dynamic reconfiguration services (DRS) to self-adapt their behavior to the context changes (e.g., scarcity of resources). Dynamic Software Product Lines (DSPL) are a well-accepted approach to manage runtime variability, by means of late binding the variation points at runtime. During the system's execution, the DRS deploys different configurations to satisfy the changing requirements according to a multiobjective criterion (e.g., insufficient battery level, requested quality of service). Search-based software engineering and, in particular, multiobjective evolutionary algorithms (MOEAs), can generate valid configurations of a DSPL at runtime. Several approaches use MOEAs to generate optimum configurations of a Software Product Line, but none of them consider DSPLs for mobile devices. In this paper, we explore the use of MOEAs to generate at runtime optimum configurations of the DSPL according to different criteria. The optimization problem is formalized in terms of a Feature Model (FM), a variability model. We evaluate six existing MOEAs by applying them to 12 different FMs, optimizing three different objectives (usability, battery consumption and memory footprint). The results are discussed according to the particular requirements of a DRS for mobile applications, showing that PAES and NSGA-II are the most suitable algorithms for mobile environments. {\copyright} 2015 Elsevier Inc. All rights reserved.},
	Affiliation = {Department of Languages and Computer Science, University of M{\'a}laga, M{\'a}laga, Spain; Institute for Systems Engineering and Automation, Johannes Kepler University Linz, Austria},
	Author_keywords = {DSPL; Dynamic reconfiguration; Evolutionary algorithms},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84924992041&partnerID=40&md5=9bb337d5cc967e3a4be5f44f79fcb946},
	Bdsk-url-2 = {http://dx.doi.org/10.1016/j.jss.2014.12.041},
	Document_type = {Conference Paper},
	Doi = {10.1016/j.jss.2014.12.041},
	Review = {k-configuration k-method k-evaluation},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84924992041&partnerID=40&md5=9bb337d5cc967e3a4be5f44f79fcb946}
}

@Article{Paskevicius2012a,
  author   = {Paskevicius, Paulius and Damasevicius, Robertas and {\v{S}}tuikys, Vytautas},
  title    = {Change impact analysis of feature models},
  journal  = {JKSU},
  year     = {2012},
  volume   = {319 CCIS},
  pages    = {108--122},
  abstract = {Changeability is a fundamental property of software systems. Every software system must evolve at all levels of abstraction (models, architecture, source code, documentation, etc.) to meet changing user and context requirements. To assess the extent of a change, change impact analysis must be performed. In this paper, we propose a taxonomy of change aspects in feature modelling domain, and analyse changeability of feature models, a high level representation of system's external user-visible characteristics. We propose the change impact model based on a feature dependency matrix to assess validity of feature change, to follow feature change propagation and to estimate changeability of a feature model using a Jaccard distance measure. The model is implemented using Prolog logic rules. A case study is presented. {\textcopyright} 2012 Springer-Verlag.},
  doi      = {10.1007/978-3-642-33308-8_10},
  isbn     = {9783642333071},
  issn     = {18650929},
  review   = {k-testing k-evaluation},
}

@Article{Peng2016,
  author    = {Peng, Junjie and Chen, Jinbao and Zhi, Xiaofei and Qiu, Meikang and Xie, Xiaolan},
  title     = {Research on application classification method in cloud computing environment},
  journal   = {JSC},
  year      = {2016},
  pages     = {1--20},
  month     = {feb},
  abstract  = {Energy consumption is a very important issue that has attracted the attention of many cloud providers as it takes a large quotient of the operation cost for cloud data center. To decrease the energy consumption in cloud data center, one possible solution is to process different types of applications with different strategies. To reach this goal, it is important to know the type of application before it be dealt with. In this paper, we present an application type classification method by monitoring the usage of the resources of application. Through analysis, we find that only part of the parameters are much related to different types of applications. Using these parameters we put forward a feature model that can effectively classify the types of different applications. Extensive experiments show that the model put forward can effectively and accurately classify CPU intensive application, I/O intensive application and network intensive application. It can be used as the basis of efficient utilization of the cloud resources.},
  doi       = {10.1007/s11227-016-1663-5},
  issn      = {15730484},
  publisher = {Springer New York LLC},
  review    = {k-configuration k-evaluation},
}

@Article{Perrouin2012605,
	author = {Perrouin, G and Oster, S and Sen, S and Klein, J and Baudry, B and le Traon, Y.d},
	title = {Pairwise testing for software product lines: Comparison of two approaches},
	journal = {SQJ},
	year = {2012},
	volume = {20},
	number = {3-4},
	pages = {605-643},
	note = {cited By 23},
	abstract = {Software Product Lines (SPL) are difficult to validate due to combinatorics induced by variability, which in turn leads to combinatorial explosion of the number of derivable products. Exhaustive testing in such a large products space is hardly feasible. Hence, one possible option is to test SPLs by generating test configurations that cover all possible t feature interactions (t-wise). It dramatically reduces the number of test products while ensuring reasonable SPL coverage. In this paper, we report our experience on applying t-wise techniques for SPL with two independent toolsets developed by the authors. One focuses on generality and splits the generation problem according to strategies. The other emphasizes providing efficient generation. To evaluate the respective merits of the approaches, measures such as the number of generated test configurations and the similarity between them are provided. By applying these measures, we were able to derive useful insights for pairwise and t-wise testing of product lines. {\copyright} 2011 Springer Science+Business Media, LLC.},
	affiliation = {University of Namur, PReCISE, B-5000 Namur, Belgium; Real-Time Systems Group, Technische Universit{\"a}t, Darmstadt, Germany; INRIA Sophia Antipolis, 2004, route des Lucioles, BP 93, 06902 Sophia Antipolis Cedex, France; University of Luxembourg, SnT and LASSY, Campus Kirchberg, Luxembourg-Kirchberg, Luxembourg; Triskell Team, IRISA/INRIA Rennes Bretagne Atlantique, Rennes, France},
	author_keywords = {Alloy; Model-based engineering and testing; Software product lines; t-wise and pairwise; Test generation},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84865618500&partnerID=40&md5=34390679678d0763cb70abc86c0e32b7},
	bdsk-url-2 = {http://dx.doi.org/10.1007/s11219-011-9160-9},
	document_type = {Article},
	doi = {10.1007/s11219-011-9160-9},
	review = {k-testing k-philosophical k-method},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84865618500&partnerID=40&md5=34390679678d0763cb70abc86c0e32b7}
}

@Article{Pleuss20122261,
	author = {Pleuss, A and Botterweck, G and Dhungana, D and Polzer, A and Kowalewski, S.c},
	title = {Model-driven support for product line evolution on feature level},
	journal = {JSS},
	year = {2012},
	volume = {85},
	number = {10},
	pages = {2261-2274},
	note = {cited By 10},
	abstract = {Software Product Lines (SPL) are an engineering technique to efficiently derive a set of similar products from a set of shared assets. In particular in conjunction with model-driven engineering, SPL engineering promises high productivity benefits. There is however, a lack of support for systematic management of SPL evolution, which is an important success factor as a product line often represents a long term investment. In this article, we present a model-driven approach for managing SPL evolution on feature level. To reduce complexity we use model fragments to cluster related elements. The relationships between these fragments are specified using feature model concepts itself leading to a specific kind of feature model called EvoFM. A configuration of EvoFM represents an evolution step and can be transformed to a concrete instance of the product line (i.e., a feature model for the corresponding point in time). Similarly, automatic transformations allow the derivation of an EvoFM from a given set of feature models. This enables retrospective analysis of historic evolution and serves as a starting point for introduction of EvoFM, e.g., to plan future evolution steps. {\copyright} 2011 Elsevier Inc. All rights reserved.},
	affiliation = {Lero, University of Limerick, Ireland; Siemens AG {\"O}sterreich, Vienna, Austria; RWTH Aachen, Ahornstr. 55, 52074 Aachen, Germany},
	author_keywords = {Evolving systems; Feature modeling; Model-driven engineering; Software Product Lines},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84863621956&partnerID=40&md5=b7e08c4e5223a3978bd7cb40891b184c},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.jss.2011.08.008},
	document_type = {Article},
	doi = {10.1016/j.jss.2011.08.008},
	review = {k-testing k-method k-solution},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84863621956&partnerID=40&md5=b7e08c4e5223a3978bd7cb40891b184c}
}

@InProceedings{Quinton2014,
  author    = {Quinton, C and Pleuss, A and Berre, DL and Duchien, L},
  title     = {Consistency checking for the evolution of cardinality-based feature models},
  booktitle = {SPLC},
  year      = {2014},
  journal   = {SPLC},
  review    = {k-testing  k-evaluation},
  url       = {http://dl.acm.org/citation.cfm?id=2648524},
}

@Article{Rauber2015,
  author   = {Rauber, TW and Boldt, F de Assis},
  title    = {Heterogeneous feature models and feature selection applied to bearing fault diagnosis},
  journal  = {TIE},
  year     = {2015},
  abstract = {Distinct feature extraction methods are simultaneously
used to describe bearing faults. This approach
produces a large number of heterogeneous features that
augment discriminative information but, at the same time,
create irrelevant and redundant information. A subsequent
feature selection phase filters out the most discriminative
features. The feature models are based on the complex
envelope spectrum, statistical time- and frequency-domain
parameters, and wavelet packet analysis. Feature selection
is achieved by conventional search of the feature space by
greedy methods. For the final fault diagnosis, the k-nearest
neighbor classifier, feedforward net, and support vector
machine are used. Performance criteria are the estimated
error rate and the area under the receiver operating characteristic
curve (AUC-ROC). Experimental results are shown
for the Case Western Reserve University Bearing Data.
The main contribution of this paper is the strategy to use
several different feature models in a single pool, together
with feature selection to optimize the fault diagnosis system.
Moreover, robust performance estimation techniques
usually not encountered in the context of engineering are
employed},
  review   = {k-mmodel k-configuration},
  url      = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6823731},
}

@Article{RinconGiraldoMazoEtAl2014,
	Title = {An ontological rule-based approach for analyzing dead and false optional features in feature models},
	Author = {Rinc{\'o}n, LF and Giraldo, Gloria Lucia and Mazo, Ra{\'u}l and Salinesi, Camille},
	Journal = {ENTCS},
	Year = {2014},
	Note = {cited By 6},
	Pages = {111--132},
	Volume = {302},
	Abstract = {Feature models are a common way to represent variability requirements of software product lines by expressing the set of feature combinations that software products can have. Assuring quality of feature models is thus of paramount importance for assuring quality in software product line engineering. However, feature models can have several types of defects that disminish benefits of software product line engineering.Two of such defects are dead features and false optional features. Several state-of-the-art techniques identify these defects, but only few of them tackle the problem of identifying their causes. Besides, the explanations they provide are cumbersome and hard to understand by humans. In this paper, we propose an ontological rule-based approach to: (a) identify dead and false optional features; (b)identify certain causes of these defects; and (c) explain these causes in natural language helping modelers to correct found defects. We represent our approach with a feature model taken from literature. A preliminary empirical evaluation of our approach over 31 FMs shows that our proposal is effective, accurate and scalable to 150 features. {\copyright} 2014 Elsevier B.V.},
	Affiliation = {Departamento de Ciencias de la Computaci{\'o}n y de la Decisi{\'o}n, National University of Colombia, Medell{\'\i}n, Colombia; CRI, Panth{\'e}on Sorbonne University, Paris, France},
	Author_keywords = {Defects; Feature Models; Ontologies; Software Engineering},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84894169420&partnerID=40&md5=5f5b06c8d8fbd689236613af40646a7d},
	Bdsk-url-2 = {http://dx.doi.org/10.1016/j.entcs.2014.01.023},
	Document_type = {Article},
	Doi = {10.1016/j.entcs.2014.01.023},
	Publisher = {Elsevier},
	Review = {k-testing k-method k-solution},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84894169420&partnerID=40&md5=5f5b06c8d8fbd689236613af40646a7d}
}

@Article{Roos-Frantz2012519,
	author = {Roos-Frantz, F and Benavides, D and Ruiz-Cort{\'e}s, A and Heuer, A and Lauenroth, K.b},
	title = {Quality-aware analysis in product line engineering with the orthogonal variability model},
	journal = {SQJ},
	year = {2012},
	volume = {20},
	number = {3-4},
	pages = {519-565},
	note = {cited By 9},
	abstract = {Software product line engineering is about producing a set of similar products in a certain domain. A variability model documents the variability amongst products in a product line. The specification of variability can be extended with quality information, such as measurable quality attributes (e. g., CPU and memory consumption) and constraints on these attributes (e. g., memory consumption should be in a range of values). However, the wrong use of constraints may cause anomalies in the specification which must be detected (e. g., the model could represent no products). Furthermore, based on such quality information, it is possible to carry out quality-aware analyses, i. e., the product line engineer may want to verify whether it is possible to build a product that satisfies a desired quality. The challenge for quality-aware specification and analysis is threefold. First, there should be a way to specify quality information in variability models. Second, it should be possible to detect anomalies in the variability specification associated with quality information. Third, there should be mechanisms to verify the variability model to extract useful information, such as the possibility to build a product that fulfils certain quality conditions (e. g., is there any product that requires less than 512 MB of memory?). In this article, we present an approach for quality-aware analysis in software product lines using the orthogonal variability model (OVM) to represent variability. We propose to map variability represented in the OVM associated with quality information to a constraint satisfaction problem and to use an off-the-shelf constraint programming solver to automatically perform the verification task. To illustrate our approach, we use a product line in the automotive domain which is an example that was created in a national project by a leading car company. We have developed a prototype tool named FaMa-OVM, which works as a proof of concepts. We were able to identify void models, dead and false optional elements, and check whether the product line example satisfies quality conditions. {\copyright} 2011 Springer Science+Business Media, LLC.},
	affiliation = {Department Computer Languages and Systems, University of Seville, Avda. Reina Mercedes s/n, 41012 Seville, Spain; Paluno-The Ruhr Institute for Software Technology, University of Duisburg-Essen, Gerlingstr. 16, 45127 Essen, Germany},
	author_keywords = {Automated analysis; Orthogonal variability model; Quality modelling; Quality-aware analysis; Software product lines},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84865635115&partnerID=40&md5=0b0c54699f136f7bfb2b6378fe072f03},
	bdsk-url-2 = {http://dx.doi.org/10.1007/s11219-011-9156-5},
	document_type = {Article},
	doi = {10.1007/s11219-011-9156-5},
	review = {k-configuration k-rmodel k-evaluation},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84865635115&partnerID=40&md5=0b0c54699f136f7bfb2b6378fe072f03}
}

@Article{Sanchez2015,
  author    = {S{\'{a}}nchez, Ana B. and Segura, Sergio and Parejo, Jos{\'{e}} A. and Ruiz-Cort{\'{e}}s, Antonio},
  title     = {Variability testing in the wild: the Drupal case study},
  journal   = {SOSYM},
  year      = {2015},
  month     = {apr},
  abstract  = {Variability testing techniques search for effective and manageable test suites that lead to the rapid detection of faults in systems with high variability. Evaluating the effectiveness of these techniques in realistic settings is a must, but challenging due to the lack of variability-intensive systems with available code, automated tests and fault reports. In this article, we propose using the Drupal framework as a case study to evaluate variability testing techniques. First, we represent the framework variability using a feature model. Then, we report on extensive non-functional data extracted from the Drupal Git repository and the Drupal issue tracking system. Among other results, we identified 3392 faults in single features and 160 faults triggered by the interaction of up to four features in Drupal v7.23. We also found positive correlations relating the number of bugs in Drupal features to their size, cyclomatic complexity, number of changes and fault history. To show the feasibility of our work, we evaluated the effectiveness of non-functional data for test case prioritization in Drupal. Results show that non-functional attributes are effective at accelerating the detection of faults, outperforming related prioritization criteria as test case similarity.},
  doi       = {10.1007/s10270-015-0459-z},
  issn      = {16191374},
  publisher = {Springer Verlag},
  review    = {k-vis k-evaluation k-testing},
}

@Article{SabouriKhosravi2014,
	author = {Sabouri, H and Khosravi, R b},
	title = {Reducing the verification cost of evolving product families using static analysis techniques},
	journal = {SCP},
	year = {2014},
	volume = {83},
	pages = {35-55},
	note = {cited By 1},
	abstract = {Software product line engineering enables proactive reuse among a set of related products through explicit modeling of commonalities and differences among them. Software product lines are intended to be used in a long period of time. As a result, they evolve over time, due to the changes in the requirements. Having several individual products in a software family, verification of the entire family may take a considerable effort. In this paper we aim to decrease this cost by reducing the number of verified products using static analysis techniques. Furthermore, to reduce model checking costs after product line evolution, we restrict the number of products that should be re-verified by reusing the previous verification result. All proposed techniques are based on static analysis of the product family model with respect to the property and can be automated. To show the effectiveness of these techniques we apply them on a set of case studies and present the results. {\copyright} 2013 Elsevier B.V.},
	affiliation = {School of Electrical and Computer Engineering, University of Tehran, Karegar Ave., Tehran, Iran; School of Computer Science, Institute for Research in Fundamental Sciences (IPM), Tehran, Iran},
	author_keywords = {Model checking; Program slicing; Reduction techniques; Software product lines; Static analysis},
	bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84894570545&partnerID=40&md5=678754f017d4e61ed50311e5a7deaee4},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.scico.2013.06.009},
	document_type = {Article},
	doi = {10.1016/j.scico.2013.06.009},
	review = {k-testing k-method k-evaluation},
	source = {Scopus},
	url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84894570545&partnerID=40&md5=678754f017d4e61ed50311e5a7deaee4}
}

@Article{Sabouri2013207,
	author = {Sabouri, H and Khosravi, R b},
	title = {Modeling and verification of reconfigurable actor families},
	journal = {JUCS},
	year = {2013},
	volume = {19},
	number = {2},
	pages = {207-232},
	note = {cited By 2},
	abstract = {Software product line engineering enables proactive reuse among a set of related products through explicit modeling of commonalities and differences among them. Features are usually used to distinguish different products as a product is identified by its supported feature set that is represented by a configuration. Dynamic product lines enhance flexibility of a product by allowing run-time reconfiguration. In this paper, we focus on modeling and verification of families of concurrent and distributed systems that are reconfigurable. To this end, we introduce the notion of variability in actor models to achieve family of reconfigurable actors. Then, we present our methodology to model this concept using the actor-based modeling language Rebeca. The model checking backbone of Rebeca enables us to ensure establishment of certain constraints on reconfigurations. We show the applicability and effectiveness of our approach by applying it on a set of case studies. {\copyright} J.UCS.},
	affiliation = {School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran; School of Computer Science, Institute for Research in Fundamental Sciences (IPM), Tehran, Iran},
	author_keywords = {Actor models; Dynamic software product lines; Model checking; Reconfiguration},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84876494130&partnerID=40&md5=5f83f63dfcfe00a4d2492e1329a31e94},
	document_type = {Article},
	review = {k-modeling k-rmodel k-evaluation},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84876494130&partnerID=40&md5=5f83f63dfcfe00a4d2492e1329a31e94}
}

@Article{Saeed2016,
  author    = {Saeed, Mazin and Saleh, Faisal and Al-Insaif, Sadiq and El-Attar, Mohamed},
  title     = {Empirical validating the cognitive effectiveness of a new feature diagrams visual syntax},
  journal   = {IST},
  year      = {2016},
  volume    = {71},
  pages     = {1--26},
  month     = {mar},
  abstract  = {Context Feature models are commonly used to capture and communicate the commonality and variability of features in a Software Product Line. The core component of Feature models is feature diagrams, which graphically depict features in a hierarchical form. In previous work we have proposed a new notation that aims to improve the cognitive effectiveness of feature diagrams. Objective The objective of this paper is to empirically validate the cognitive effectiveness of the new feature diagrams notation in comparison to its original form. Methods We use two distinct empirical user-studies to validate the new notation. The first empirical study uses the survey approach while the second study is a subject-based experiment. The survey study investigates the semantic transparency of the new notation while the second study investigates the speed and accuracy of reading the notation. Results The results of the studies indicate that the proposed changes have significantly improved its cognitive effectiveness. Conclusions The cognitive effectiveness of feature diagrams has been improved, however there remains further research for full acceptance of the new notation by its potential user community.},
  doi       = {10.1016/j.infsof.2015.10.012},
  issn      = {09505849},
  publisher = {Elsevier},
  review    = {k-modeling k-validation},
}

@Article{SchaeferRabiserClarkeEtAl2012b,
	author = {Schaefer, I and Rabiser, R and Clarke, D and Bettini, L and Benavides, D and Botterweck, G.f and Pathak, A.g and Trujillo, S and Villela, K},
	title = {Software diversity: State of the art and perspectives},
	journal = {STTT},
	year = {2012},
	volume = {14},
	number = {5},
	pages = {477-495},
	note = {cited By 30},
	abstract = {Diversity is prevalent in modern software systems to facilitate adapting the software to customer requirements or the execution environment. Diversity has an impact on all phases of the software development process. Appropriate means and organizational structures are required to deal with the additional complexity introduced by software variability. This introductory article to the special section "Software Diversity-Modeling, Analysis and Evolution" provides an overview of the current state of the art in diverse systems development and discusses challenges and potential solutions. The article covers requirements analysis, design, implementation, verification and validation, maintenance and evolution as well as organizational aspects. It also provides an overview of the articles which are part of this special section and addresses particular issues of diverse systems development. {\copyright} 2012 Springer-Verlag.},
	affiliation = {TU Braunschweig, Braunschweig, Germany; Christian Doppler Laboratory for Automated Software Engineering, JKU Linz, Linz, Austria; Katholieke Universiteit Leuven, Leuven, Belgium; Dipartimento di Informatica, Universit{\`a} di Torino, Turin, Italy; Dpto. de Lenguajes y Sistemas Informaticos, University of Seville, Seville, Spain; Lero, The Irish Software Engineering Research Centre, University of Limerick, Limerick, Ireland; INRIA Paris-Rocquencourt, Paris, France; IKERLAN, Mondrag{\'o}n, Spain; Fraunhofer Institute for Experimental Software Engineering, Kaiserslautern, Germany},
	author_keywords = {Software diversity; Software product lines; Variability},
	bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84866293757&partnerID=40&md5=d57e1fb55ac152cf99f124e6b490a529},
	bdsk-url-2 = {http://dx.doi.org/10.1007/s10009-012-0253-y},
	document_type = {Article},
	doi = {10.1007/s10009-012-0253-y},
	publisher = {Springer},
	review = {k-opinion k-modeling},
	source = {Scopus},
	url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84866293757&partnerID=40&md5=d57e1fb55ac152cf99f124e6b490a529}
}

@Article{Schneeweiss2013,
  author   = {Schneeweiss, D and Hofstedt, P},
  title    = {FdConfig: a constraint-based interactive product configurator},
  journal  = {ADPKM},
  year     = {2013},
  abstract = {We present a constraint-based approach to interactive product configuration. Our configurator tool FdConfig is based on feature models for the representation of the product domain. Such models can be directly mapped into constraint satisfaction problems and dealt with by appropriate constraint solvers. During the interactive configuration process the user generates new constraints as a result of his configuration decisions and even may retract constraints posted earlier. We discuss the configuration process, explain the underlying techniques and show optimizations.},
  review   = {k-evaluation k-configuration k-opinion},
  url      = {http://link.springer.com/chapter/10.1007/978-3-642-41524-1{\_}13},
}

@Article{segura2011functional,
	author = {Segura, Sergio and Benavides, Daniel and Ruiz-Cort{\'e}s, Antonio},
	title = {Functional testing of feature model analysis tools: a test suite},
	journal = {IET},
	year = {2011},
	volume = {5},
	number = {1},
	pages = {70--82},
	publisher = {IET},
	review = {k-testing k-evaluation k-tool}
}

@Article{Segura2015,
  author   = {Segura, S and Dur{\'{a}}n, A and S{\'{a}}nchez, AB},
  title    = {Automated metamorphic testing of variability analysis tools},
  journal  = {STVR},
  year     = {2015},
  abstract = {Variability determines the capability of software applications to be configured and customized. A common
need during the development of variability–intensive systems is the automated analysis of their underlying
variability models, e.g. detecting contradictory configuration options. The analysis operations that are
performed on variability models are often very complex, which hinders the testing of the corresponding
analysis tools and makes difficult, often infeasible, to determine the correctness of their outputs, i.e.
the well–known oracle problem in software testing. In this article, we present a generic approach for
the automated detection of faults in variability analysis tools overcoming the oracle problem. Our work
enables the generation of random variability models together with the exact set of valid configurations
represented by these models. These test data are generated from scratch using step–wise transformations
and assuring that certain constraints (a.k.a. metamorphic relations) hold at each step. To show the feasibility
and generalizability of our approach, it has been used to automatically test several analysis tools in three
variability domains: feature models, CUDF documents and Boolean formulas. Among other results, we
detected 19 real bugs in 7 out of the 15 tools under test.},
  review   = {k-testing k-evaluation},
  url      = {http://onlinelibrary.wiley.com/doi/10.1002/stvr.1566/full},
}

@Article{Segura2016,
  author    = {Segura, Sergio and Fraser, Gordon and Sanchez, Ana B. and Ruiz-Cortes, Antonio},
  title     = {A Survey on Metamorphic Testing},
  journal   = {TSE},
  year      = {2016},
  volume    = {42},
  number    = {9},
  pages     = {805--824},
  month     = {sep},
  abstract  = {A test oracle determines whether a test execution reveals a fault, often by comparing the observed program output to the expected output. This is not always practical, for example when a program's input-output relation is complex and difficult to capture formally. Metamorphic testing provides an alternative, where correctness is not determined by checking an individual concrete output, but by applying a transformation to a test input and observing how the program output 'morphs' into a different one as a result. Since the introduction of such metamorphic relations in 1998, many contributions on metamorphic testing have been made, and the technique has seen successful applications in a variety of domains, ranging from web services to computer graphics. This article provides a comprehensive survey on metamorphic testing: It summarises the research results and application areas, and analyses common practice in empirical studies of metamorphic testing as well as the main open challenges.},
  doi       = {10.1109/TSE.2016.2532875},
  issn      = {00985589},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  review    = {k-testing 
k-philosophical k-opinion},
}

@Article{Segura20111124,
  author          = {Segura, S and Hierons, R.M. and Benavides, D and Ruiz-Cort{\'e}s , A},
  title           = {Mutation testing on an object-oriented framework: An experience report},
  journal         = {IST},
  year            = {2011},
  volume          = {53},
  number          = {10},
  pages           = {1124-1136},
  note            = {cited By 4},
  abstract        = {Context: The increasing presence of Object-Oriented (OO) programs in industrial systems is progressively drawing the attention of mutation researchers toward this paradigm. However, while the number of research contributions in this topic is plentiful, the number of empirical results is still marginal and mostly provided by researchers rather than practitioners. Objective: This article reports our experience using mutation testing to measure the effectiveness of an automated test data generator from a user perspective. Method: In our study, we applied both traditional and class-level mutation operators to FaMa, an open source Java framework currently being used for research and commercial purposes. We also compared and contrasted our results with the data obtained from some motivating faults found in the literature and two real tools for the analysis of feature models, FaMa and SPLOT. Results: Our results are summarized in a number of lessons learned supporting previous isolated results as well as new findings that hopefully will motivate further research in the field. Conclusion: We conclude that mutation testing is an effective and affordable technique to measure the effectiveness of test mechanisms in OO systems. We found, however, several practical limitations in current tool support that should be addressed to facilitate the work of testers. We also missed specific techniques and tools to apply mutation testing at the system level. {\copyright} 2011 Elsevier B.V. All rights reserved.},
  affiliation     = {Department of Computer Languages and Systems, University of Seville, Av. Reina Mercedes S/N, 41012 Seville, Spain; School of Information Systems, Computing and Mathematics, Brunel University, Uxbridge, Middlesex UB7 7NU, United Kingdom},
  author_keywords = {Automated analysis; Feature models; Mutation testing; Test adequacy; Test data generation},
  bdsk-url-1      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79959923541&partnerID=40&md5=f5abf9dcee32a0c18a7565bfdeca0598},
  bdsk-url-2      = {http://dx.doi.org/10.1016/j.infsof.2011.03.006},
  document_type   = {Article},
  doi             = {10.1016/j.infsof.2011.03.006},
  review          = {k-testing k-evaluation k-method},
  source          = {Scopus},
  url             = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79959923541&partnerID=40&md5=f5abf9dcee32a0c18a7565bfdeca0598},
}

@Article{Segura2011245,
  author          = {Segura, S and Hierons, R.M and Benavides, D and Ruiz-Cort{\'e}s, A},
  title           = {Automated metamorphic testing on the analyses of feature models},
  journal         = {IST},
  year            = {2011},
  volume          = {53},
  number          = {3},
  pages           = {245-258},
  note            = {cited By 22},
  abstract        = {Context: A feature model (FM) represents the valid combinations of features in a domain. The automated extraction of information from FMs is a complex task that involves numerous analysis operations, techniques and tools. Current testing methods in this context are manual and rely on the ability of the tester to decide whether the output of an analysis is correct. However, this is acknowledged to be time-consuming, error-prone and in most cases infeasible due to the combinatorial complexity of the analyses, this is known as the oracle problem. Objective: In this paper, we propose using metamorphic testing to automate the generation of test data for feature model analysis tools overcoming the oracle problem. An automated test data generator is presented and evaluated to show the feasibility of our approach. Method: We present a set of relations (so-called metamorphic relations) between input FMs and the set of products they represent. Based on these relations and given a FM and its known set of products, a set of neighbouring FMs together with their corresponding set of products are automatically generated and used for testing multiple analyses. Complex FMs representing millions of products can be efficiently created by applying this process iteratively. Results: Our evaluation results using mutation testing and real faults reveal that most faults can be automatically detected within a few seconds. Two defects were found in FaMa and another two in SPLOT, two real tools for the automated analysis of feature models. Also, we show how our generator outperforms a related manual suite for the automated analysis of feature models and how this suite can be used to guide the automated generation of test cases obtaining important gains in efficiency. Conclusion: Our results show that the application of metamorphic testing in the domain of automated analysis of feature models is efficient and effective in detecting most faults in a few seconds without the need for a human oracle. {\copyright} 2010 Elsevier B.V. All rights reserved.},
  affiliation     = {Department of Computer Languages and Systems, University of Seville, Av Reina Mercedes S/N, 41012 Seville, Spain; School of Information Systems, Computing and Mathematics, Brunel University, Uxbridge, Middlesex UB7 7NU, United Kingdom},
  author_keywords = {Automated analysis; Feature models; Metamorphic testing; Mutation testing; Product lines; Test data generation},
  bdsk-url-1      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79251616991&partnerID=40&md5=5db3b344d535c982d7e0c0ddb0fbe12b},
  bdsk-url-2      = {http://dx.doi.org/10.1016/j.infsof.2010.11.002},
  document_type   = {Article},
  doi             = {10.1016/j.infsof.2010.11.002},
  review          = {k-testing k-evaluation k-method},
  source          = {Scopus},
  url             = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79251616991&partnerID=40&md5=5db3b344d535c982d7e0c0ddb0fbe12b},
}

@Article{Segura20143975,
  author          = {Segura, S and Parejo, J.A and Hierons, R.M and Benavides, D and Ruiz-Cort{\'e}s, A},
  title           = {Automated generation of computationally hard feature models using evolutionary algorithms},
  journal         = {ESA},
  year            = {2014},
  volume          = {41},
  number          = {8},
  pages           = {3975-3992},
  note            = {cited By 4},
  abstract        = {A feature model is a compact representation of the products of a software product line. The automated extraction of information from feature models is a thriving topic involving numerous analysis operations, techniques and tools. Performance evaluations in this domain mainly rely on the use of random feature models. However, these only provide a rough idea of the behaviour of the tools with average problems and are not sufficient to reveal their real strengths and weaknesses. In this article, we propose to model the problem of finding computationally hard feature models as an optimization problem and we solve it using a novel evolutionary algorithm for optimized feature models (ETHOM). Given a tool and an analysis operation, ETHOM generates input models of a predefined size maximizing aspects such as the execution time or the memory consumption of the tool when performing the operation over the model. This allows users and developers to know the performance of tools in pessimistic cases providing a better idea of their real power and revealing performance bugs. Experiments using ETHOM on a number of analyses and tools have successfully identified models producing much longer executions times and higher memory consumption than those obtained with random models of identical or even larger size. {\copyright} 2013 Elsevier Ltd. All rights reserved.},
  affiliation     = {Department of Computer Languages and Systems, University of Seville, Av Reina Mercedes S/N, 41012 Seville, Spain; School of Information Systems, Computing and Mathematics, Brunel University, Uxbridge, Middlesex UB7 7NU, United Kingdom},
  author_keywords = {Automated analysis; Evolutionary algorithms; Feature models; Performance testing; Search-based testing; Software product lines},
  bdsk-url-1      = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84892757033&partnerID=40&md5=b5c5fd23707e60ab0e56458607d83d03},
  bdsk-url-2      = {http://dx.doi.org/10.1016/j.eswa.2013.12.028},
  document_type   = {Article},
  doi             = {10.1016/j.eswa.2013.12.028},
  review          = {k-testing k-evaluation k-method},
  source          = {Scopus},
  url             = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84892757033&partnerID=40&md5=b5c5fd23707e60ab0e56458607d83d03},
}

@Article{Tanhaei2016,
  author    = {Tanhaei, Mohammad and Habibi, Jafar and Mirian-Hosseinabadi, Seyed Hassan},
  title     = {Automating feature model refactoring: A Model transformation approach},
  journal   = {IST},
  year      = {2016},
  volume    = {80},
  pages     = {138--157},
  month     = {dec},
  abstract  = {Context: Feature model is an appropriate and indispensable tool for modeling similarities and differences among products of the Software Product Line (SPL). It not only exposes the validity of the products' configurations in an SPL but also changes in the course of time to support new requirements of the SPL. Modifications made on the feature model in the course of time raise a number of issues. Useless enlargements of the feature model, the existence of dead features, and violated constraints in the feature model are some of the key problems that make its maintenance difficult. Objective: The initial approach to dealing with the above-mentioned problems and improving maintainability of the feature model is refactoring. Refactoring modifies software artifacts in a way that their externally visible behavior does not change. Method: We introduce a method for defining refactoring rules and executing them on the feature model. We use the ATL model transformation language to define the refactoring rules. Moreover, we provide an Alloy model to check the feature model and the safety of the refactorings that are performed on it. Results: In this research, we propose a safe framework for refactoring a feature model. This framework enables users to perform automatic and semi-automatic refactoring on the feature model. Conclusions: Automated tool support for refactoring is a key issue for adopting approaches such as utilizing feature models and integrating them into the software development process of companies. In this work, we define some of the important refactoring rules on the feature model and provide tools that enable users to add new rules using the ATL M2M language. Our framework assesses the correctness of the refactorings using the Alloy language.},
  doi       = {10.1016/j.infsof.2016.08.011},
  issn      = {09505849},
  publisher = {Elsevier},
  review    = {k-testing k-solution},
}

@Article{Teixeira2013,
  author   = {Teixeira, Leopoldo and Borba, Paulo and Gheyi, Rohit},
  title    = {Safe composition of configuration knowledge-based software product lines},
  journal  = {JSS},
  year     = {2013},
  volume   = {86},
  number   = {4},
  pages    = {1038--1053},
  month    = {apr},
  abstract = {Mistakes made when implementing or specifying the models of a Software Product Line (SPL) can result in ill-formed products - the safe composition problem. Such problem can hinder productivity and it might be hard to detect, since SPLs can have thousands of products. In this article, we propose a language independent approach for verifying safe composition of SPLs with dedicated Configuration Knowledge models. We translate feature model and Configuration Knowledge into propositional logic and use the Alloy Analyzer to perform the verification. To provide evidence for the generality of our approach, we instantiate this approach in different compositional settings. We deal with different kinds of assets such as use case scenarios and Eclipse RCP components. We analyze both the code and the requirements for a larger scale SPL, finding problems that affect thousands of products in minutes. Moreover, our evaluation suggests that the analysis time grows linearly with respect to the number of products in the analyzed SPLs. {\textcopyright} 2012 Elsevier Inc.},
  doi      = {10.1016/j.jss.2012.11.006},
  issn     = {01641212},
  review   = {k-testing k-evaluation k-mmodel},
}

@Article{Thum2014,
	Title = {A classification and survey of analysis strategies for software product lines},
	Author = {Th{\"u}m, T and Apel, S and K{\"a}stner, C and Schaefer, I and Saake, G.a},
	Journal = {ACMCS},
	Year = {2014},
	Note = {cited By 11},
	Number = {1},
	Volume = {47},
	Abstract = {Software-product-line engineering has gained considerable momentum in recent years, both in industry and in academia. A software product line is a family of software products that share a common set of features. Software product lines challenge traditional analysis techniques, such as type checking, model checking, and theorem proving, in their quest of ensuring correctness and reliability of software. Simply creating and analyzing all products of a product line is usually not feasible, due to the potentially exponential number of valid feature combinations. Recently, researchers began to develop analysis techniques that take the distinguishing properties of software product lines into account, for example, by checking feature-related code in isolation or by exploiting variability information during analysis. The emerging field of productline analyses is both broad and diverse, so it is difficult for researchers and practitioners to understand their similarities and differences. We propose a classification of product-line analyses to enable systematic research and application. Based on our insights with classifying and comparing a corpus of 123 research articles, we develop a research agenda to guide future research on product-line analyses. {\copyright} 2014 ACM.},
	Affiliation = {University of Magdeburg, Germany; University of Passau, Germany; Carnegie Mellon University, Pittsburgh, PA, United States; University of Braunschweig, Germany},
	Art_number = {a6},
	Author_keywords = {Model checking; Product-line analysis; Program family; Software analysis; Software product line; Static analysis; Theorem proving; Type checking},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905827308&partnerID=40&md5=0bc11d140fadb6e734f0acf89a65ccf0},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/2580950},
	Document_type = {Review},
	Doi = {10.1145/2580950},
	Review = {k-philosophical k-metric k-vis k-testing k-reverse k-modeling k-configuration},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84905827308&partnerID=40&md5=0bc11d140fadb6e734f0acf89a65ccf0}
}

@Article{ThuemKaestnerBenduhnEtAl2014,
	author = {Th{\"u}m, Thomas and K{\"a}stner, Christian and Benduhn, Fabian and Meinicke, Jens and Saake, Gunter and Leich, Thomas},
	title = {FeatureIDE: An extensible framework for feature-oriented software development},
	journal = {SCP},
	year = {2014},
	volume = {79},
	pages = {70--85},
	publisher = {Elsevier},
	review = {k-tool k-configuration k-evaluation}
}

@Article{Varela-Vaca20131948,
	author = {Varela-Vaca, A.J. and Gasca, R.M.},
	title = {Towards the automatic and optimal selection of risk treatments for business processes using a constraint programming approach},
	journal = {IST},
	year = {2013},
	volume = {55},
	number = {11},
	pages = {1948-1973},
	note = {cited By 2},
	abstract = {Context The use of Business Process Management Systems (BPMS) has emerged in the IT arena for the automation of business processes. In the majority of cases, the issue of security is overlooked by default in these systems, and hence the potential cost and consequences of the materialization of threats could produce catastrophic loss for organizations. Therefore, the early selection of security controls that mitigate risks is a real and important necessity. Nevertheless, there exists an enormous range of IT security controls and their configuration is a human, manual, time-consuming and error-prone task. Furthermore, configurations are carried out separately from the organization perspective and involve many security stakeholders. This separation makes difficult to ensure the effectiveness of the configuration with regard to organizational requirements. Objective In this paper, we strive to provide security stakeholders with automated tools for the optimal selection of IT security configurations in accordance with a range of business process scenarios and organizational multi-criteria. Method An approach based on feature model analysis and constraint programming techniques is presented, which enable the automated analysis and selection of optimal security configurations. Results A catalogue of feature models is determined by analyzing typical IT security controls for BPMSs for the enforcement of the standard goals of security: integrity, confidentiality, availability, authorization, and authentication. These feature models have been implemented through constraint programs, and Constraint Programming techniques based on optimized and non-optimized searches are used to automate the selection and generation of configurations. In order to compare the results of the determination of configuration a comparative analysis is given. Conclusion In this paper, we present innovative tools based on feature models, Constraint Programming and multi-objective techniques that enable the agile, adaptable and automatic selection and generation of security configurations in accordance with the needs of the organization. {\copyright} 2013 Elsevier B.V. All rights reserved.},
	affiliation = {Department of Computer Languages and Systems, ETS Ingenier{\'\i}a Inform{\'a}tica, University of Seville, Avda. Reina Mercedes S/N, 41012 Sevilla, Spain},
	author_keywords = {Business process; Business process management systems; Constraint programming; Feature model; Risk treatments; Security},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84884155582&partnerID=40&md5=245e12280bdbeecb5e3c0ca5ce8b14a7},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.infsof.2013.05.007},
	document_type = {Article},
	doi = {10.1016/j.infsof.2013.05.007},
	review = {k-vis k-method k-evaluation},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84884155582&partnerID=40&md5=245e12280bdbeecb5e3c0ca5ce8b14a7}
}

@Article{Vijaya2016,
  author    = {Vijaya, Aparna and Neelanarayanan, V.},
  title     = {A model driven framework for portable cloud services},
  journal   = {IJECE},
  year      = {2016},
  volume    = {6},
  number    = {2},
  pages     = {708--716},
  month     = {apr},
  abstract  = {Cloud Computing is an evolving technology as it offers significant benefits like pay only for what you use, scale the resources according to the needs and less in-house staff and resources. These benefits have resulted in tremendous increase in the number of applications and services hosted in the cloud which inturn has resulted in increase in the number of cloud providers in the market. Cloud service providers have a lot of heterogeneity in the resources they use. They have their own servers, different cloud infrastructures, API's and methods to access the cloud resources. Despite its benefits; lack of standards among service providers has caused a high level of vendor lock-in when a software developer tries to change its cloud provider. In this paper we give an overview on the ongoing and current trends in the area of cloud service portability and we also propose a new cloud portability platform. Our new platform is based on establishing feature models which offers the desired cloud portability. Our solution DSkyL uses feature models and domain model analysis to support development, customization and deployment of application components across multiple clouds. The main goal of our approach is to reduce the effort and time needed for porting applications across different clouds. This paper aims to give an overview on DSkyL.},
  doi       = {10.11591/ijece.v6i1.8270},
  issn      = {20888708},
  publisher = {Institute of Advanced Engineering and Science},
  review    = {k-vis k-configuration
k-solution k-evaluation},
}

@Article{Wang2016,
  author    = {Wang, Shuai and Ali, Shaukat and Gotlieb, Arnaud and Liaaen, Marius},
  title     = {A systematic test case selection methodology for product lines: results and insights from an industrial case study},
  journal   = {ESE},
  year      = {2016},
  volume    = {21},
  number    = {4},
  pages     = {1586--1622},
  month     = {aug},
  abstract  = {In the context of product lines, test case selection aims at obtaining a set of relevant test cases for a product from the entire set of test cases available for a product line. While working on a research-based innovation project on automated testing of product lines of Video Conferencing Systems (VCSs) developed by Cisco, we felt the need to devise a cost-effective way of selecting relevant test cases for a product. To fulfill such need, we propose a systematic and automated test selection methodology using: 1) Feature Model for Testing (FM{\_}T) to capture commonalities and variabilities of a product line; 2) Component Family Model for Testing (CFM{\_}T) to model the structure of test case repository; 3) A tool to automatically build restrictions from CFM{\_}T to FM{\_}T and traces from CFM{\_}T to the actual test cases. Using our methodology, a test engineer is only required to select relevant features through FM{\_}T at a higher level of abstraction for a product and the corresponding test cases will be obtained automatically. We evaluate our methodology by applying it to a VCS product line called Saturn with seven commercial products and the results show that our methodology can significantly reduce cost measured as test selection time and at the same time achieves higher effectiveness (feature coverage, feature pairwise coverage and fault detection) as compared with the current manual process. Moreover, we conduct a questionnaire-based study to solicit the views of test engineers who are involved in developing FM{\_}T and CFM{\_}T. The results show that test engineers are positive about adapting our methodology in their current practice. Finally, we present a set of lessons learnt while applying product line engineering at Cisco for test case selection.},
  doi       = {10.1007/s10664-014-9345-5},
  issn      = {15737616},
  publisher = {Springer New York LLC},
  review    = {k-testing
k-evaluation k-validation},
}

@Article{WangAliGotlieb2015,
	author = {Wang, S b and Ali, S and Gotlieb, A.a},
	title = {Cost-effective test suite minimization in product lines using search techniques},
	journal = {JSS},
	year = {2015},
	volume = {103},
	pages = {370-391},
	note = {cited By 1},
	abstract = {Cost-effective testing of a product in a product line requires obtaining a set of relevant test cases from the entire test suite via test selection and minimization techniques. In this paper, we particularly focus on test minimization for product lines, which identifies and eliminates redundant test cases from test suites in order to reduce the total number of test cases to execute, thereby improving the efficiency of testing. However, such minimization may result in the minimized test suite with low test coverage, low fault revealing capability, low priority test cases, and require more time than the allowed testing budget (e.g., time) as compared to the original test suite. To deal with the above issues, we formulated the minimization problem as a search problem and defined a fitness function considering various optimization objectives based on the above issues. To assess the performance of our fitness function, we conducted an extensive empirical evaluation by investigating the fitness function with three weight-based Genetic Algorithms (GAs) and seven multi-objective search algorithms using an industrial case study and 500 artificial problems inspired from the industrial case study. The results show that Random-Weighted Genetic Algorithm (RWGA) significantly outperforms the other algorithms since RWGA can balance all the objectives together by dynamically updating weights during each generation. Based on the results of our empirical evaluation, we also implemented a tool called TEst Minimization using Search Algorithms (TEMSA) to support test minimization using various search algorithms in the context of product lines. {\copyright} 2014 Elsevier Inc. All rights reserved.},
	affiliation = {Certus Software VandV Center, Simula Research Laboratory, P.O. 134, Lysaker, Oslo, Norway; Department of Informatics, University of Oslo, P.O. 1080, Blindern, Oslo, Norway},
	author_keywords = {Product line; Search algorithm; Test suite minimization},
	bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84924958712&partnerID=40&md5=fefb76c6dbd14d17f9b74fb65f46d477},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.jss.2014.08.024},
	document_type = {Conference Paper},
	doi = {10.1016/j.jss.2014.08.024},
	review = {k-testing k-method k-evaluation},
	source = {Scopus},
	url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84924958712&partnerID=40&md5=fefb76c6dbd14d17f9b74fb65f46d477}
}

@Article{White20101094,
	Title = {Automated diagnosis of feature model configurations},
	Author = {White, J and Benavides, D and Schmidt, D.C and Trinidad, P and Dougherty, B and Ruiz-Cortes, A.c},
	Journal = {JSS},
	Year = {2010},
	Note = {cited By 24},
	Number = {7},
	Pages = {1094-1107},
	Volume = {83},
	Abstract = {Software product-lines (SPLs) are software platforms that can be readily reconfigured for different project requirements. A key part of an SPL is a model that captures the rules for reconfiguring the software. SPLs commonly use feature models to capture SPL configuration rules. Each SPL configuration is represented as a selection of features from the feature model. Invalid SPL configurations can be created due to feature conflicts introduced via staged or parallel configuration or changes to the constraints in a feature model. When invalid configurations are created, a method is needed to automate the diagnosis of the errors and repair the feature selections. This paper provides two contributions to research on automated configuration of SPLs. First, it shows how configurations and feature models can be transformed into constraint satisfaction problems to automatically diagnose errors and repair invalid feature selections. Second, it presents empirical results from diagnosing configuration errors in feature models ranging in size from 100 to 5,000 features. The results of our experiments show that our CSP-based diagnostic technique can scale up to models with thousands of features. {\copyright} 2010 Elsevier Inc. All rights reserved.},
	Affiliation = {Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA 24061, United States; Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN 37204, United States; Department of Computer Languages, Systems University of Seville, Avda. de la Reina Mercedes, s/n B, 41012 Seville, Spain},
	Author_keywords = {Configuration; Constraint satisfaction; Diagnosis; Optimization; Software product-lines},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77953132059&partnerID=40&md5=2f87ba959d35ef385ba7e9a2f3c75379},
	Bdsk-url-2 = {http://dx.doi.org/10.1016/j.jss.2010.02.017},
	Document_type = {Article},
	Doi = {10.1016/j.jss.2010.02.017},
	Review = {k-testing k-method k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77953132059&partnerID=40&md5=2f87ba959d35ef385ba7e9a2f3c75379}
}

@Article{White2014119,
	author = {White, J and Galindo, J.A and Saxena, T and Dougherty, B and Benavides, D and Schmidt, D.C.a},
	title = {Evolving feature model configurations in software product lines},
	journal = {JSS},
	year = {2014},
	volume = {87},
	number = {1},
	pages = {119-136},
	note = {cited By 2},
	abstract = {The increasing complexity and cost of software-intensive systems has led developers to seek ways of reusing software components across development projects. One approach to increasing software reusability is to develop a software product-line (SPL), which is a software architecture that can be reconfigured and reused across projects. Rather than developing software from scratch for a new project, a new configuration of the SPL is produced. It is hard, however, to find a configuration of an SPL that meets an arbitrary requirement set and does not violate any configuration constraints in the SPL. Existing research has focused on techniques that produce a configuration of an SPL in a single step. Budgetary constraints or other restrictions, however, may require multi-step configuration processes. For example, an aircraft manufacturer may want to produce a series of configurations of a plane over a span of years without exceeding a yearly budget to add features. This paper provides three contributions to the study of multi-step configuration for SPLs. First, we present a formal model of multi-step SPL configuration and map this model to constraint satisfaction problems (CSPs). Second, we show how solutions to these SPL configuration problems can be automatically derived with a constraint solver by mapping them to CSPs. Moreover, we show how feature model changes can be mapped to our approach in a multi-step scenario by using feature model drift. Third, we present empirical results demonstrating that our CSP-based reasoning technique can scale to SPL models with hundreds of features and multiple configuration steps. {\copyright} 2013 Elsevier Inc.},
	affiliation = {Vanderbilt University, Nashville, TN, United States; University of Seville, Seville, Spain},
	author_keywords = {Feature model; Multi-step configuration; Software product line},
	bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84888645293&partnerID=40&md5=2aae066262ae2dc929dd7ba74b62a35a},
	bdsk-url-2 = {http://dx.doi.org/10.1016/j.jss.2013.10.010},
	document_type = {Article},
	doi = {10.1016/j.jss.2013.10.010},
	review = {k-testing k-method k-evaluation},
	source = {Scopus},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84888645293&partnerID=40&md5=2aae066262ae2dc929dd7ba74b62a35a}
}

@Article{Yan2010,
  author   = {Yan, Hua and Zhang, Wei and Zhao, Hai Yan and Mei, Hong},
  title    = {BDD-based approach to the verification of feature models},
  journal  = {JS},
  year     = {2010},
  volume   = {21},
  number   = {1},
  pages    = {84--97},
  month    = {jan},
  abstract = {The feature model is a reusable requirements model generated from the domain analysis. The reuse of feature models is usually achieved by a customizing-based approach. One important issue in feature models' customization is the verification problem, caused by the fact that there are usually constraints among features, and that a valid customizing result must satisfy all these constraints. Because of the NP-hard nature of this problem, it is usually difficult to verify feature models in an efficient way. This paper presents a BDD (binary decision diagram)-based approach to verifying feature models by only traversing once to the nodes in BDDs, an approach that makes an efficient use of the BDD data structures based on the unique characteristics of feature models' verification. It should be pointed out that this approach does not attempt to resolve the NP-hard difficulty of the verification problem in a general sense, but just tries to improve the scalability and efficiency of methods for feature models' verification based on the utilization of this problem's uniqueness. Experimental results show that this BDD-based approach is more efficient and can verify more complex feature models than the previous method. {\textcopyright} by Institute of Software, the Chinese Academy of Sciences. All rights reserved.},
  doi      = {10.3724/SP.J.1001.2010.03525},
  issn     = {10009825},
  review   = {k-testing k-evaluation},
}

@Article{Yi2013,
  author   = {Yi, Li and Zhao, Hai Yan and Zhang, Wei and Jin, Zhi and Mei, Hong},
  title    = {Research on the merging of feature models},
  journal  = {CJC},
  year     = {2013},
  volume   = {36},
  number   = {1},
  pages    = {1--9},
  month    = {jan},
  abstract = {Feature models provide an effective way to organize and reuse software requirements in a specific domain. Constructing a feature model needs a systematic analysis of as many applications as possible in a domain, to identify commonality, variability, and dependencies among requirements. With the increasing complexity of domains, the scale of feature models can be extremely large, and the construction of large feature models is an overwhelming task for human that computer-aided automation is needed. A feasible way is to merge existing feature models into a large one, and human developers only need to do some refactoring work. In this paper, we survey six methods of merging feature models. We propose a conceptual framework first, and then analyze and compare the six methods. Finally, we identify three problems in existing research, and propose possible ideas to handle these problems.},
  doi      = {10.3724/SP.J.1016.2013.00001},
  issn     = {02544164},
  review   = {k-mmodel k-philosophical},
}

@Article{ZhangYeLin2014,
	author = {Zhang, Guoheng and Ye, Huilin and Lin, Yuqing},
	title = {Quality attribute modeling and quality aware product configuration in software product lines},
	journal = {SQJ},
	year = {2014},
	volume = {22},
	number = {3},
	pages = {365--401},
	publisher = {Springer},
	review = {k-configuration k-modeling k-model k-method k-solution}
}

@InProceedings{AlHajjajiThuemMeinickeEtAl2014,
	Title = {Similarity-based prioritization in software product-line testing},
	Author = {Al-Hajjaji, Mustafa and Th{\"u}m, Thomas and Meinicke, Jens and Lochau, Malte and Saake, Gunter},
	Booktitle = {SPLC},
	Year = {2014},
	Organization = {ACM},
	Pages = {197--206},
	Review = {k-testing k-evaluation k-method}
}

@InProceedings{Andersen2012106,
	Title = {Efficient synthesis of feature models},
	Author = {Andersen, N and Czarnecki, K and She, S and Wa̧sowski, A.a},
	Booktitle = {SPLC},
	Year = {2012},
	Note = {cited By 4},
	Pages = {106-115},
	Volume = {1},
	Abstract = {Variability modeling, and in particular feature modeling, is a central element of model-driven software product line architectures. Such architectures often emerge from legacy code, but, unfortunately creating feature models from large, legacy systems is a long and arduous task. We address the problem of automatic synthesis of feature models from propositional constraints. We show that this problem is NP-hard. We design efficient techniques for synthesis of models from respectively CNF and DNF formulas, showing a 10- to 1000-fold performance improvement over known techniques for realistic benchmarks. Our algorithms are the first known techniques that are efficient enough to be applied to dependencies extracted from real systems, opening new possibilities of creating reverse engineering and model management tools for variability models. We discuss several such scenarios in the paper. Copyright {\copyright} 2012 ACM.},
	Affiliation = {IT University of Copenhagen, Denmark; Generative Software Development Lab, University of Waterloo, Canada},
	Author_keywords = {Feature models; Software product lines; Variability models},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867481198&partnerID=40&md5=bcc25eb2b0e7cbec936563ab51273db0},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/2362536.2362553},
	Date-modified = {2015-06-12 14:49:15 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1145/2362536.2362553},
	Journal = {SPLC},
	Review = {k-reverse k-evaluation k-tool},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867481198&partnerID=40&md5=bcc25eb2b0e7cbec936563ab51273db0}
}

@InProceedings{AsadiBagheriMohabbatiEtAl2012b,
	Title = {Requirements engineering in feature oriented software product lines: An initial analytical study},
	Author = {Asadi, M and Bagheri, E and Mohabbati, B and Ga{\v s}evi, D.b},
	Booktitle = {SPLC},
	Year = {2012},
	Note = {cited By 1},
	Pages = {36-43},
	Volume = {2},
	Abstract = {Requirements engineering is recognized as a critical stage in software development lifecycle. Given the nature of Software Product Lines (SPL), the importance of requirements engineering is more pronounced as SPLs pose more complex challenges than development of a 'single' product. Several methods have been proposed in the literature, which encompass activities for capturing requirements, their variability and commonality. To investigate the maturity and effectiveness of the current requirements engineering approaches in software product lines, we develop an evaluation framework containing a set of evaluation criteria and assess feature oriented requirements engineering methods based on the proposed criteria. As a result of this initial study, we find out the majority of approaches lacks proper techniques for supporting the validation of family requirements models as well as dealing with delta requirements. Additionally, capturing stakeholders' preferences and applying them during the course of software feature configuration have not been taken into account and addressed in the proposed approaches. Copyright 2012 ACM.},
	Affiliation = {Simon Fraser University, Canada; Athabasca University, Canada},
	Author_keywords = {Evaluation criteria; Requirements engineering; Software product line engineering},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84867465599&partnerID=40&md5=7f654cd589eabed400eddf2cac082e0e},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/2364412.2364419},
	Document_type = {Conference Paper},
	Doi = {10.1145/2364412.2364419},
	Review = {k-modeling k-validation},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84867465599&partnerID=40&md5=7f654cd589eabed400eddf2cac082e0e}
}

@InProceedings{Bagheri201016,
	Title = {Configuring software product line feature models based on stakeholders' soft and hard requirements},
	Author = {Bagheri, E. and Di Noia, T. and Ragone, A. and Gasevic, D.},
	Booktitle = {SPLC},
	Year = {2010},
	Note = {cited By 5},
	Pages = {16-31},
	Volume = {6287 LNCS},
	Abstract = {Feature modeling is a technique for capturing commonality and variability. Feature models symbolize a representation of the possible application configuration space, and can be customized based on specific domain requirements and stakeholder goals. Most feature model configuration processes neglect the need to have a holistic approach towards the integration and satisfaction of the stakeholder's soft and hard constraints, and the application-domain integrity constraints. In this paper, we will show how the structure and constraints of a feature model can be modeled uniformly through Propositional Logic extended with concrete domains, called . Furthermore, we formalize the representation of soft constraints in fuzzy and explain how semi-automated feature model configuration is performed. The model configuration derivation process that we propose respects the soundness and completeness properties. {\copyright} 2010 Springer-Verlag Berlin Heidelberg.},
	Affiliation = {NRC-IIT, Politecnico di Bari, University of Trento, Athabasca University, Italy},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78049389967&partnerID=40&md5=14bbeca1d47ba07a4e865041ade01cbd},
	Bdsk-url-2 = {http://dx.doi.org/10.1007/978-3-642-15579-6_2},
	Date-modified = {2015-06-12 14:48:50 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1007/978-3-642-15579-6_2},
	Journal = {SPLC},
	Review = {k-configuration k-evaluation k-method},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78049389967&partnerID=40&md5=14bbeca1d47ba07a4e865041ade01cbd}
}

@InProceedings{BroekGalvaoLourencodaSilvaNoppen2010,
	Title = {Merging feature models},
	Author = {van den Broek, PM and Galvao Lourenco da Silva, I and Noppen, JAR},
	Booktitle = {SPLC},
	Year = {2010},
	Publisher = {Lancaster University, Lancaster, UK},
	Abstract = {In this paper, we consider the problem of merging feature models which consist of trees with "requires" and "excludes" constraints. For any two such feature models which are parent-compatible, their merge is defined to be the smallest parent-compatible feature model which has all products of the constituents. We show how the specification can be implemented, present a number of properties of the merged feature models and give some examples.},
	Review = {k-mmodel k-solution k-method}
}

@InProceedings{Chen201135,
	Title = {Optimizing the product derivation process},
	Author = {Chen, S. and Erwig, M.},
	Booktitle = {SPLC},
	Year = {2011},
	Note = {cited By 2},
	Pages = {35-44},
	Abstract = {Feature modeling is widely used in software product-line engineering to capture the commonalities and variabilities within an application domain. As feature models evolve, they can become very complex with respect to the number of features and the dependencies among them, which can cause the product derivation based on feature selection to become quite time consuming and error prone. We address this problem by presenting techniques to find good feature selection sequences that are based on the number of products that contain a particular feature and the impact of a selected feature on the selection of other features. Specifically, we identify a feature selection strategy, which brings up highly selective features early for selection. By prioritizing feature selection based on the selectivity of features our technique makes the feature selection process more efficient. Moreover, our approach helps with the problem of unexpected side effects of feature selection in later stages of the selection process, which is commonly considered a difficult problem. We have run our algorithm on the e-Shop and Berkeley DB feature models and also on some automatically generated feature models. The evaluation results demonstrate that our techniques can shorten the product derivation processes significantly. {\copyright} 2011 IEEE.},
	Affiliation = {School of EECS, Oregon State University, United States},
	Art_number = {6030044},
	Author_keywords = {Decision Sequence; Feature Model; Feature Selection},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054056715&partnerID=40&md5=ea7e3638afe02fbefa59ae5827265538},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/SPLC.2011.47},
	Date-modified = {2015-06-12 14:49:03 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/SPLC.2011.47},
	Journal = {SPLC},
	Review = {k-configuration k-tool k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054056715&partnerID=40&md5=ea7e3638afe02fbefa59ae5827265538}
}


@InProceedings{DumitrescuMazoSalinesiEtAl2013,
	Title = {Bridging the gap between product lines and systems engineering: an experience in variability management for automotive model based systems engineering},
	Author = {Dumitrescu, Cosmin and Mazo, Raul and Salinesi, Camille and Dauron, Alain},
	Booktitle = {SPLC},
	Year = {2013},
	Organization = {ACM},
	Pages = {254--263},
	Abstract = {We present in this paper an experience in modeling a family of parking brake systems, with shared assets and alternative solutions, and relate them to the needs of Renault in terms of variability management. The models are realized using a set of customized tools for model based systems engineering and variability management, based on SysML models. The purpose is to present an industrial context that requires the adoption of a product line approach and of variability modeling techniques, outside of a pure-software domain. At Renault, the interest is in identifying variations and reuse opportunities early in the product development cycle, as well as in preparing vehicle configuration specifications during the systems engineering process. This would lead to lowering the engineering effort and to higher quality and confidence in carry-over and carry across based solutions. We advocate for a tight integration of variability management with the model based systems engineering approach, which needs to address methodological support, modeling techniques and efficient tools for interactive configuration, adapted for engineering activities.},
	Review = {k-experience k-configuration}
}

@InProceedings{eichelberger2013systematic,
	Title = {A systematic analysis of textual variability modeling languages},
	Author = {Eichelberger, Holger and Schmid, Klaus},
	Booktitle = {SPLC},
	Year = {2013},
	Organization = {ACM},
	Pages = {12--21},
	Abstract = {Industrial variability models tend to grow in size and complexity due to ever-increasing functionality and complexity of software systems. Some authors report on variability models specifying several thousands of variabilities. However, traditional variability modeling approaches do not seem to scale adequately to cope with size and complexity of such models. Recently, textual variability modeling languages have been advocated as one scalable solution. In this paper, we provide a systematic analysis of the capabilities of current textual variability modeling languages, in particular regarding variability management in the large. Towards this aim, we define a classification schema consisting of five dimensions, classify ten different textual variability modeling languages using the classification schema and provide an analysis. In summary, some textual variability modeling languages go beyond textual representations of traditional variability modeling approaches and provide sophisticated modeling concepts and constraint languages. Three textual variability modeling approaches already support mechanisms for large-scale variability modeling such as model composition, modularization, or evolution support.},
	Date-modified = {2015-06-12 14:34:10 +0000},
	Review = {k-philosophical k-rmodel k-modeling}
}

@InProceedings{ElSharkawyDederichsSchmid2012,
	Title = {From feature models to decision models and back again an analysis based on formal transformations},
	Author = {El-Sharkawy, Sascha and Dederichs, Stephan and Schmid, Klaus},
	Booktitle = {SPLC},
	Year = {2012},
	Organization = {ACM},
	Pages = {126--135},
	Review = {k-modeling k-solution}
}

@InProceedings{GhezziSharifloo2011,
	Title = {Verifying non-functional properties of software product lines: Towards an efficient approach using parametric model checking},
	Author = {Ghezzi, Carlo and Sharifloo, Amir Molzam},
	Booktitle = {SPLC},
	Year = {2011},
	Organization = {IEEE},
	Pages = {170--174},
	Abstract = {In this paper, we describe how probabilistic model checking techniques and tools can be used to verify non-functional properties of different configurations of a software product line. We propose a model-based approach that enables software engineers to assess their design solutions in the early stages of development. Furthermore, we discuss how verification time can surprisingly be reduced by applying parametric model checking instead of classic model checking, and show that the approach can be effective in practice.},
	Review = {k-solution k-opinion}
}

@InProceedings{Henard201362,
	Title = {Multi-objective test generation for software product lines},
	Author = {Henard, C and Papadakis, M and Perrouin, G and Klein, J and Le Traon, Y.a},
	Booktitle = {SPLC},
	Year = {2013},
	Note = {cited By 2},
	Pages = {62-71},
	Abstract = {Software Products Lines (SPLs) are families of products sharing common assets representing code or functionalities of a software product. These assets are represented as features, usually organized into Feature Models (FMs) from which the user can configure software products. Generally, few features are sufficient to allow configuring millions of software products. As a result, selecting the products matching given testing objectives is a difficult problem. The testing process usually involves multiple and potentially conflicting testing objectives to fulfill, e.g. maximizing the number of optional features to test while at the same time both minimizing the number of products and minimizing the cost of testing them. However, most approaches for generating products usually target a single objective, like testing the maximum amount of feature interactions. While focusing on one objective may be sufficient in certain cases, this practice does not reflect real-life testing situations. The present paper proposes a genetic algorithm to handle multiple conflicting objectives in test generation for SPLs. Experiments conducted on FMs of different sizes demonstrate the effectiveness, feasibility and practicality of the introduced approach. {\copyright} 2013 ACM.},
	Affiliation = {SnT, University of Luxembourg, Luxembourg, Luxembourg; PReCISE, University of Namur, Namur, Belgium},
	Author_keywords = {feature models; genetic algorithms; multi-objective optimization; software product lines; test generation},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84883893596&partnerID=40&md5=a0e24b953e4c82521fabaa276a307fdd},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/2491627.2491635},
	Date-modified = {2015-06-12 14:47:45 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1145/2491627.2491635},
	Journal = {SPLC},
	Review = {k-testing k-method k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84883893596&partnerID=40&md5=a0e24b953e4c82521fabaa276a307fdd}
}

@InProceedings{JohansenHaugenFleurey2012,
	Title = {An algorithm for generating t-wise covering arrays from large feature models},
	Author = {Johansen, Martin Fagereng and Haugen, {\O}ystein and Fleurey, Franck},
	Booktitle = {SPLC},
	Year = {2012},
	Organization = {ACM},
	Pages = {46--55},
	Review = {k-testing k-evaluation k-solution k-method}
}

@InProceedings{KaratasOuztuezuenDoru2010a,
	Title = {Mapping extended feature models to constraint logic programming over finite domains},
	Author = {Karata{\c s}, A.S. and O{\v g}uzt{\"u}z{\"u}n, H. and Do{\v g}ru, A.},
	Booktitle = {SPLC},
	Year = {2010},
	Note = {cited By 9},
	Pages = {286-299},
	Volume = {6287 LNCS},
	Abstract = {As feature models for realistic product families may be quite complicated, automated analysis of feature models is desirable. Although several approaches reported in the literature addressed this issue, complex feature-attribute and attribute-attribute relationships in extended feature models were not handled effectively. In this article, we introduce a mapping from extended feature models to constraint logic programming over finite domains. This mapping is used to translate basic, cardinality-based, and extended feature models, which may include complex feature-feature, feature-attribute and attribute-attribute cross-tree relationships, into constraint logic programs. It thus enables use of off-the-shelf constraint solvers for the automated analysis of extended feature models involving such complex relationships. We also briefly discuss the ramifications of including feature-attribute relationships in operations of analysis. We believe that this proposal will be effective for further leveraging of constraint logic programming for automated analysis of feature models. {\copyright} 2010 Springer-Verlag Berlin Heidelberg.},
	Affiliation = {Department of Computer Engineering, Middle East Technical University, Ankara 06531, Turkey},
	Author_keywords = {Constraint logic programming; Extended feature model; Feature attribute; Variability modeling},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-78049398041&partnerID=40&md5=48f430c3fda165cb3d1241c227a64afc},
	Bdsk-url-2 = {http://dx.doi.org/10.1007/978-3-642-15579-6_20},
	Document_type = {Conference Paper},
	Doi = {10.1007/978-3-642-15579-6_20},
	Review = {k-modeling k-configuration k-tool k-metric},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-78049398041&partnerID=40&md5=48f430c3fda165cb3d1241c227a64afc}
}

@InProceedings{LeeKang2010,
	Title = {Usage context as key driver for feature selection},
	Author = {Lee, Kwanwoo and Kang, Kyo C},
	Booktitle = {SPLC},
	Year = {2010},
	Pages = {32--46},
	Publisher = {Springer},
	Abstract = {Product derivation in software product line engineering starts with selection of variable features manifested in a feature model. Selection of variable features for a particular product, however, is not made arbitrarily. There are various factors affecting feature selection. We experienced that the usage context of a product is often the primary driver for feature selection. In this paper, we propose a model showing how product usage contexts are related to product features, and present a method for developing such a model during the domain engineering process and utilizing it to derive an optimal product configuration during the application engineering process. An elevator control software example is used to illustrate and validate the concept and the method.},
	Review = {k-configuration k-solution k-method k-evaluation}
}

@InProceedings{Lopez-Herrejon2011181,
	Title = {From requirements to features: An exploratory study of feature-oriented refactoring},
	Author = {Lopez-Herrejon, R.E and Montalvillo-Mendizabal, L and Egyed, A.a},
	Booktitle = {SPLC},
	Year = {2011},
	Note = {cited By 8},
	Pages = {181-190},
	Abstract = {More and more frequently successful software systems need to evolve into families of systems, known as Software Product Lines (SPLs), to be able to cater to the different functionality requirements demanded by different customers while at the same time aiming to exploit as much common functionality as possible. As a first step, this evolution demands a clear understanding of how the functional requirements map into the features of the original system. Using this knowledge, features can be refactored so that they are reused for building the new systems of the evolved SPL. In this paper we present our experience in refactoring features based on the requirements specifications of a small and a medium size systems. Our work identified eight refactoring patterns that describe how to extract the elements of features which were subsequently implemented using Feature Oriented Software Development (FOSD) a novel modularization paradigm whose driving goal is to effectively modularize features for the development of variable systems. We argue that the identification of refactoring patterns are a stepping stone towards automating Feature-Oriented Refactoring, and present some open issues that should be addressed to that avail. {\copyright} 2011 IEEE.},
	Affiliation = {Systems Engineering and Automation, Johannes Kepler University Linz, Austria; Universitat Politecnica de Catalunya, Barcelona, Spain},
	Art_number = {6030060},
	Author_keywords = {Feature Orientation; Feature Oriented Refactoring; Product Line Evolution; Software Product Lines},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054070982&partnerID=40&md5=a8c67214830aa4b713539dd291a4f14d},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/SPLC.2011.52},
	Date-modified = {2015-06-12 14:46:22 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/SPLC.2011.52},
	Journal = {SPLC},
	Review = {k-rmodel k-solution k-testing k-evolution},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054070982&partnerID=40&md5=a8c67214830aa4b713539dd291a4f14d}
}

@InProceedings{LotufoSheBergerEtAl2010,
	author = {Lotufo, Rafael and She, Steven and Berger, Thorsten and Czarnecki, Krzysztof and W{\k{a}}sowski, Andrzej},
	title = {Evolution of the linux kernel variability model},
	booktitle = {SPLC},
	year = {2010},
	pages = {136--150},
	publisher = {Springer},
	review = {k-vis k-modeling k-evaluation}
}

@InProceedings{MohalikRameshMilloEtAl2012,
	Title = {Tracing spls precisely and efficiently},
	Author = {Mohalik, Swarup and Ramesh, S and Millo, Jean-Vivien and Krishna, Shankara Narayanan and Narwane, Ganesh Khandu},
	Booktitle = {SPLC},
	Year = {2012},
	Organization = {ACM},
	Pages = {186--195},
	Abstract = {In a Software Product Line (SPL) comprising specifications
		(feature sets), implementations (component sets) and traceability
		between them, the definition of product is quite subtle.
		Intuitively, a strong relation of implementability should
		be established between implementations and specifications
		due to traceability. Various notions of traceability has been
		proposed in the literature : [13], [17], [8], [9]; but we found in
		our experience that they do not capture all situations that
		arise in practice. One example is the case where, an implementation,
		due to packaging reasons, contains additional
		components not required for a particular product specification.
		We have defined a general notion of traceability in
		order to cover such situations. Moreover, state-of-the-art
		satisfiability based notions lead to products where the implementability
		relation does not exist. Therefore, in this paper,
		we propose a simple, set-theoretic formalism to express
		the notions of traceability and implementability in a formal
		manner. The subsequent definition of SPL products is used
		to introduce a set of analysis problems that are either re-
		finements of known problems, or are completely novel. Last
		but not the least, we propose encoding the analysis problems
		as Quantified Boolean Formula (QBF) constraints and
		use Quantified SAT (QSAT) solvers to solve these problems
		efficiently. To the best of our knowledge, the QBF encoding
		is novel; we prove the correctness of our encoding and
		demonstrate its practical feasibility through our prototype
		implementation Software Product Line Engine (SPLE)},
	Review = {k-evaluation k-configuration}
}

@InProceedings{Oster2010196,
	Title = {Automated incremental pairwise testing of software product lines},
	Author = {Oster, S and Markert, F and Ritter, P.a},
	Booktitle = {SPLC},
	Year = {2010},
	Note = {cited By 20},
	Pages = {196-210},
	Volume = {6287 LNCS},
	Abstract = {Testing Software Product Lines is very challenging due to a high degree of variability leading to an enormous number of possible products. The vast majority of today's testing approaches for Software Product Lines validate products individually using different kinds of reuse techniques for testing. Due to the enormous number of possible products, individual product testing becomes more and more unfeasible. Combinatorial testing offers one possibility to test a subset of all possible products. In this contribution we provide a detailed description of a methodology to apply combinatorial testing to a feature model of a Software Product Line. We combine graph transformation, combinatorial testing, and forward checking for that purpose. Additionally, our approach considers predefined sets of products. {\copyright} 2010 Springer-Verlag Berlin Heidelberg.},
	Affiliation = {Real-Time Systems Group, Australia; Computer Systems Group, Technische Universit{\"a}t Darmstadt, Germany},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78049410016&partnerID=40&md5=7a66495ae74b419a9b649991aeaa361e},
	Bdsk-url-2 = {http://dx.doi.org/10.1007/978-3-642-15579-6_14},
	Date-modified = {2015-06-12 14:47:31 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1007/978-3-642-15579-6_14},
	Journal = {SPLC},
	Review = {k-testing k-method k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78049410016&partnerID=40&md5=7a66495ae74b419a9b649991aeaa361e}
}

@InProceedings{passos2011study,
	Title = {A study of non-boolean constraints in variability models of an embedded operating system},
	Author = {Passos, Leonardo and Novakovic, Marko and Xiong, Yingfei and Berger, Thorsten and Czarnecki, Krzysztof and W{\k{a}}sowski, Andrzej},
	Booktitle = {SPLC},
	Year = {2011},
	Organization = {ACM},
	Pages = {2},
	Abstract = {Many variability modeling tasks can be supported by automated analyses of models. Unfortunately, most analyses for Boolean variability models are NP-hard, while analyses for non-Boolean models easily become undecidable. It is thus crucial to exploit the properties of realistic models to construct viable analysis algorithms. Unfortunately, little work exists about non-Boolean models, and no benchmarks are available for such. We present the non-Boolean aspects of 116 variability models available in the codebase of eCos-a real time embedded operating system. We characterize the types of non- Boolean features in the models, kinds and quantities of non- Boolean constraints in use, and the impact of these characteristics on the hardness of this model from analysis perspective. This way we provide researchers and practitioners with a basis for discussion of relevance of non-Boolean models and their analyses, along with the first ever benchmark for effectiveness of such analyses. Copyright © 2011 ACM.},
	Date-modified = {2015-06-12 14:35:38 +0000},
	Review = {k-vis k-evaluation k-rmodel}
}

@InProceedings{QuintonRomeroDuchien2013b,
	Title = {Cardinality-based feature models with constraints: A pragmatic approach},
	Author = {Quinton, C. and Romero, D. and Duchien, L.},
	Booktitle = {SPLC},
	Year = {2013},
	Note = {cited By 1},
	Organization = {ACM},
	Pages = {162-166},
	Abstract = {Feature models originating from Software Product Line Engineering are a well-known approach to variability modeling. In many situations, the variability does not apply only on features but also on the number of times these features can be cloned. In such a case, cardinality-based feature models are used to specify the number of clones for a given feature. Although previous works already investigated approaches for feature modeling with cardinality, there is still a lack of support for constraints in the presence of clones. To overcome this limitation, we present an abstract model to define constraints in cardinality-based feature models and propose a formal semantics for this kind of constraints. We illustrate the practical usage of our approach with examples from our recent experiences on cloud computing platform configuration. {\copyright} 2013 ACM.},
	Affiliation = {INRIA Lille - Nord Europe, LIFL UMR CNRS 8022, University Lille 1, France},
	Author_keywords = {cardinality; constraint; feature model; modeling; Variability},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84883865735&partnerID=40&md5=26f60053ac6893cabc0c49f39e08ab38},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/2491627.2491638},
	Document_type = {Conference Paper},
	Doi = {10.1145/2491627.2491638},
	Journal = {SPLC},
	Review = {k-modeling k-solution},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84883865735&partnerID=40&md5=26f60053ac6893cabc0c49f39e08ab38}
}

@InProceedings{SchaeferBettiniBonoEtAl2010,
	author = {Schaefer, Ina and Bettini, Lorenzo and Bono, Viviana and Damiani, Ferruccio and Tanzarella, Nico},
	title = {Delta-oriented programming of software product lines},
	booktitle = {SPLC},
	year = {2010},
	pages = {77--91},
	publisher = {Springer},
	abstract = {Feature-oriented programming (FOP) implements software product lines by composition of feature modules. It relies on the principles of stepwise development. Feature modules are intended to refer to exactly one product feature and can only extend existing implementations. To provide more flexibility for implementing software product lines, we propose delta-oriented programming (DOP) as a novel programming language approach. A product line is represented by a core module and a set of delta modules. The core module provides an implementation of a valid product that can be developed with well-established single application engineering techniques. Delta modules specify changes to be applied to the core module to implement further products by adding, modifying and removing code. Application conditions attached to delta modules allow handling combinations of features explicitly. A product implementation for a particular feature configuration is generated by applying incrementally all delta modules with valid application condition to the core module. In order to evaluate the potential of DOP, we compare it to FOP, both conceptually and empirically.},
	review = {k-configuration k-solution k-philosophical}
}

@InProceedings{SchroeterSiegmundThuemEtAl2014,
  author       = {Schr{\"o}ter, Reimar and Siegmund, Norbert and Th{\"u}m, Thomas and Saake, Gunter},
  title        = {Feature-context interfaces: tailored programming interfaces for software product lines},
  booktitle    = {SPLC},
  year         = {2014},
  pages        = {102--111},
  organization = {ACM},
  review       = {k-modeling k-method k-evaluation},
}

@InProceedings{soltani2012automated,
	Title = {Automated planning for feature model configuration based on functional and non-functional requirements},
	Author = {Soltani, Samaneh and Asadi, Mohsen and Ga{\v{s}}evi{\'c}, Dragan and Hatala, Marek and Bagheri, Ebrahim},
	Booktitle = {SPLC},
	Year = {2012},
	Organization = {ACM},
	Pages = {56--65},
	Abstract = {Feature modeling is one of the main techniques used in Software Product Line Engineering to manage the variability within the products of a family. Concrete products of the family can be generated through a configuration process. The configuration process selects and/or removes features from the feature model according to the stakeholders' requirements. Selecting the right set of features for one product from amongst all of the available features in the feature model is a complex task because: 1) the multiplicity of stakeholders' functional requirements; 2) the positive or negative impact of features on non-functional properties; and 3) the stakeholders' preferences w.r.t. the desirable non-functional properties of the final product. Many configurations techniques have already been proposed to facilitate automated product derivation. However, most of the current proposals are not designed to consider stakeholders' preferences and constraints especially with regard to non-functional properties. We address the software product line configuration problem and propose a framework, which employs an artificial intelligence planning technique to automatically select suitable features that satisfy both the stakeholders' functional and non-functional preferences and constraints. We also provide tooling support to facilitate the use of our framework. Our experiments show that despite the complexity involved with the simultaneous consideration of both functional and non-functional properties our configuration technique is scalable.},
	Date-modified = {2015-06-12 14:36:25 +0000},
	Review = {k-configuration k-method k-solution}
}

@InProceedings{SteinNunesCirilo2014b,
	Title = {Preference-based feature model configuration with multiple stakeholders},
	Author = {Stein, Jacob and Nunes, Ingrid and Cirilo, Elder},
	Booktitle = {SPLC},
	Year = {2014},
	Organization = {ACM},
	Pages = {132--141},
	Review = {k-mmodel k-configuration k-evaluation}
}

@InProceedings{Tawhid201180,
	Title = {Automatic derivation of a product performance model from a software product line model},
	Author = {Tawhid, R and Petriu, D.C.b},
	Booktitle = {SPLC},
	Year = {2011},
	Note = {cited By 5},
	Pages = {80-89},
	Abstract = {We propose to integrate performance analysis in the early phases of the model-driven development process for Software Product Lines (SPL). We start with a multi-view UML model of the core family assets representing the commonality and variability between different products, which we call the SPL model. We add another perspective to the SPL model, annotating it with generic performance specifications expressed in the standard UML profile MARTE, recently adopted by OMG. The runtime performance of a product is affected by factors contained in the UML model of the product (derived from the SPL model), but also by external factors depending on the implementation and execution environments. The external factors not contained in the SPL model need to be eventually represented in the performance model. In order to do so, we propose to represent the variability space of different possible implementation and execution environments through a so called "performance completion (PC) feature model". These PC features are mapped to MARTE performance-related stereotypes and attributes attached to the SPL model elements. A first model transformation realized in the Atlas Transformation Language (ATL) derives the UML model of a specific product with concrete MARTE annotations from the SPL model. A second transformation generates a Layered Queueing Network (LQN) performance model for the given product by applying an existing transformation named PUMA, developed in previous work. The proposed technique is illustrated with an e-commerce case study. A LQN model is derived for a product and the impact of different levels of secure communication channels on its performance is analyzed by using the LQN model. {\copyright} 2011 IEEE.},
	Affiliation = {School of Computer Science, Carleton University, Ottawa, ON, Canada; Dept. of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada},
	Art_number = {6030049},
	Author_keywords = {ATL; MARTE; Model-driven development; Performance analysis; Performance Completion; SPL; UML},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054088286&partnerID=40&md5=c3e25beb5024ec1ec793b98de9b9c747},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/SPLC.2011.27},
	Date-modified = {2015-06-12 14:41:43 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/SPLC.2011.27},
	Journal = {SPLC},
	Review = {k-modeling k-process k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054088286&partnerID=40&md5=c3e25beb5024ec1ec793b98de9b9c747}
}

@InProceedings{Thum2011191,
	Title = {Abstract features in feature modeling},
	Author = {Th{\"u}m, T and K{\"a}stner, C and Erdweg, S and Siegmund, N.a},
	Booktitle = {SPLC},
	Year = {2011},
	Note = {cited By 15},
	Pages = {191-200},
	Abstract = {A software product line is a set of program variants, typically generated from a common code base. Feature models describe variability in product lines by documenting features and their valid combinations. In product-line engineering, we need to reason about variability and program variants for many different tasks. For example, given a feature model, we might want to determine the number of all valid feature combinations or compute specific feature combinations for testing. However, we found that contemporary reasoning approaches can only reason about feature combinations, not about program variants, because they do not take abstract features into account. Abstract features are features used to structure a feature model that, however, do not have any impact at implementation level. Using existing feature-model reasoning mechanisms for program variants leads to incorrect results. Hence, although abstract features represent domain decisions that do not affect the generation of a program variant. We raise awareness of the problem of abstract features for different kinds of analyses on feature models. We argue that, in order to reason about program variants, abstract features should be made explicit in feature models. We present a technique based on propositional formulas that enables to reason about program variants rather than feature combinations. In practice, our technique can save effort that is caused by considering the same program variant multiple times, for example, in product-line testing. {\copyright} 2011 IEEE.},
	Affiliation = {University of Magdeburg, Germany; Philipps University Marburg, Germany},
	Art_number = {6030061},
	Author_keywords = {automated analyses; feature model; feature modeling; program families; software product lines},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054080510&partnerID=40&md5=2f2302508697637403dcc659657db16f},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/SPLC.2011.53},
	Date-modified = {2015-06-12 14:37:27 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/SPLC.2011.53},
	Journal = {SPLC},
	Review = {k-modeling k-rmodel k-solution},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054080510&partnerID=40&md5=2f2302508697637403dcc659657db16f}
}

@InProceedings{YuZhangZhaoEtAl2014,
	Title = {TDL: a transformation description language from feature model to use case for automated use case derivation},
	Author = {Yu, Wenjing and Zhang, Wei and Zhao, Haiyan and Jin, Zhi},
	Booktitle = {SPLC},
	Year = {2014},
	Organization = {ACM},
	Pages = {187--196},
	Review = {k-testing k-model k-modeling k-method k-evaluation}
}

@InProceedings{Zhang2011,
  author    = {Zhang, G and Ye, H and Lin, Y},
  title     = {Using knowledge-based systems to manage quality attributes in software product lines},
  booktitle = {SPLC},
  year      = {2011},
  abstract  = {Product configuration in a feature model in software product line engineering is a process, in which the desired features are selected based on the customers' functional requirements and non-functional requirements. The functional requirements of the target product can be satisfied by including the proper functional features. However, there is no such a straightforward way to realize the non-functional requirements and quality attributes of the target product. In our early work, we have developed a quantitative based method to assess the quality attributes for a configured product. However, this approach cannot adequately represent the inter-relationships among quality attributes which play an important role in product configuration process. We supplement our previous work by introducing a quality attribute knowledge base (QA_KB) to represent the inter-relationships among different quality attributes in a SPL. Furthermore, we develop algorithms for configuring a product based on customers' quality requirements. We also use a case study to illustrate our approach.},
  journal   = {Proc. 15th Int. Softw.},
  review    = {k-mmodel k-modeling k-evaluation},
  url       = {http://dl.acm.org/citation.cfm?id=2019172},
}

@InProceedings{cordy2013beyond,
	Title = {Beyond boolean product-line model checking: dealing with feature attributes and multi-features},
	Author = {Cordy, Maxime and Schobbens, Pierre-Yves and Heymans, Patrick and Legay, Axel},
	Booktitle = {ICSE},
	Year = {2013},
	Organization = {IEEE Press},
	Pages = {472--481},
	Date-modified = {2015-06-12 14:33:54 +0000},
	Review = {k-testing k-configuration k-method k-evaluation}
}

@InProceedings{Dumitru2011181,
	Title = {On-demand feature recommendations derived from mining public product descriptions},
	Author = {Dumitru, H. and Gibiec, M. and Hariri, N. and Cleland-Huang, J. and Mobasher, B. and Castro-Herrera, C. and Mirakhorli, M.},
	Booktitle = {ICSE},
	Year = {2011},
	Note = {cited By 30},
	Pages = {181-190},
	Abstract = {We present a recommender system that models and recommends product features for a given domain. Our approach mines product descriptions from publicly available online specifications, utilizes text mining and a novel incremental diffusive clustering algorithm to discover domain-specific features, generates a probabilistic feature model that represents commonalities, variants, and cross-category features, and then uses association rule mining and the k-Nearest-Neighbor machine learning strategy to generate product specific feature recommendations. Our recommender system supports the relatively labor-intensive task of domain analysis, potentially increasing opportunities for re-use, reducing time-to-market, and delivering more competitive software products. The approach is empirically validated against 20 different product categories using thousands of product descriptions mined from a repository of free software applications. {\copyright} 2011 ACM.},
	Affiliation = {DePaul University, 243 S. Wabash Ave, Chicago, IL 60604, United States},
	Author_keywords = {clustering; domain analysis; recommender systems},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79959861140&partnerID=40&md5=286054a044b0eb6577b575017e96304e},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/1985793.1985819},
	Date-modified = {2015-06-12 14:47:21 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1145/1985793.1985819},
	Journal = {ICSE},
	Review = {k-rmodel k-evolution k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79959861140&partnerID=40&md5=286054a044b0eb6577b575017e96304e}
}

@InProceedings{FamelisSalayChechik2012,
	Title = {Partial models: Towards modeling and reasoning with uncertainty},
	Author = {Famelis, Michalis and Salay, Rick and Chechik, Marsha},
	Booktitle = {ICSE},
	Year = {2012},
	Organization = {IEEE},
	Pages = {573--583},
	Review = {k-solution k-configuration}
}

@InProceedings{HenardPapadakisHarmanEtAl2015,
	Title = {Combining multi-objective search and constraint solving for configuring large software product lines},
	Author = {Henard, Christopher and Papadakis, Mike and Harman, Mark and Le Traon, Yves},
	Booktitle = {ICSE},
	Year = {2015},
	Organization = {IEEE},
	Pages = {517--528},
	Volume = {1},
	Review = {k-configuration k-method k-evaluation}
}

@InProceedings{Henard20131245,
	Title = {Towards automated testing and fixing of re-engineered Feature Models},
	Author = {Henard, C and Papadakis, M and Perrouin, G and Klein, J and Le Traon, Y.a},
	Booktitle = {ICSE},
	Year = {2013},
	Note = {cited By 7},
	Pages = {1245-1248},
	Abstract = {Mass customization of software products requires their efficient tailoring performed through combination of features. Such features and the constraints linking them can be represented by Feature Models (FMs), allowing formal analysis, derivation of specific variants and interactive configuration. Since they are seldom present in existing systems, techniques to re-engineer FMs have been proposed. There are nevertheless error-prone and require human intervention. This paper introduces an automated search-based process to test and fix FMs so that they adequately represent actual products. Preliminary evaluation on the Linux kernel FM exhibit erroneous FM constraints and significant reduction of the inconsistencies. {\copyright} 2013 IEEE.},
	Affiliation = {Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Precise Research Center in Software Engineering (PReCISE), University of Namur, Namur, Belgium},
	Art_number = {6606689},
	Author_keywords = {Feature Model; Fixing; Search-based; Testing},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84883876633&partnerID=40&md5=ca2deec8377515002d5e908795ebf51c},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/ICSE.2013.6606689},
	Date-modified = {2015-06-12 14:46:02 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/ICSE.2013.6606689},
	Journal = {ICSE},
	Review = {k-reverse k-tool k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84883876633&partnerID=40&md5=ca2deec8377515002d5e908795ebf51c}
}

@InProceedings{nadi2014mining,
	Title = {Mining configuration constraints: Static analyses and empirical results},
	Author = {Nadi, Sarah and Berger, Thorsten and K{\"a}stner, Christian and Czarnecki, Krzysztof},
	Booktitle = {ICSE},
	Year = {2014},
	Organization = {ACM},
	Pages = {140--151},
	Abstract = {Highly-configurable systems allow users to tailor the software to their specific needs. Not all combinations of configuration options are valid though, and constraints arise for technical or non-technical reasons. Explicitly describing these constraints in a variability model allows reasoning about the supported configurations. To automate creating variability models, we need to identify the origin of such configuration constraints. We propose an approach which uses build-time errors and a novel feature-effect heuristic to automatically extract configuration constraints from C code. We conduct an empirical study on four highly-configurable open-source systems with existing variability models having three objectives in mind: evaluate the accuracy of our approach, determine the recoverability of existing variability-model constraints using our analysis, and classify the sources of variability-model constraints. We find that both our extraction heuristics are highly accurate (93% and 77% respectively), and that we can recover 19% of the existing variability-models using our approach. However, we find that many of the remaining constraints require expert knowledge or more expensive analyses. We argue that our approach, tooling, and experimental results support researchers and practitioners working on variability model re-engineering, evolution, and consistency-checking techniques.},
	Date-modified = {2015-06-12 14:35:11 +0000},
	Review = {k-evaluation k-reverse k-rmodel}
}

@InProceedings{Sayyad2013492,
	Title = {On the value of user preferences in search-based software engineering: A case study in software product lines},
	Author = {Sayyad, A.S. and Menzies, T. and Ammar, H.},
	Booktitle = {ICSE},
	Year = {2013},
	Note = {cited By 16},
	Pages = {492-501},
	Abstract = {Software design is a process of trading off competing objectives. If the user objective space is rich, then we should use optimizers that can fully exploit that richness. For example, this study configures software product lines (expressed as feature maps) using various search-based software engineering methods. As we increase the number of optimization objectives, we find that methods in widespread use (e.g. NSGA-II, SPEA2) perform much worse than IBEA (Indicator-Based Evolutionary Algorithm). IBEA works best since it makes most use of user preference knowledge. Hence it does better on the standard measures (hypervolume and spread) but it also generates far more products with 0% violations of domain constraints. Our conclusion is that we need to change our methods for search-based software engineering, particularly when studying complex decision spaces. {\copyright} 2013 IEEE.},
	Affiliation = {Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, United States},
	Art_number = {6606595},
	Author_keywords = {Feature Models; Indicator-Based Evolutionary Algorithm; Multiobjective Optimization; Optimal Feature Selection; Search-Based Software Engineering; Software Product Lines},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84886494195&partnerID=40&md5=b0c8ff32e95ccba5bf1a4128ff1d0627},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/ICSE.2013.6606595},
	Date-modified = {2015-06-12 14:44:50 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/ICSE.2013.6606595},
	Journal = {ICSE},
	Review = {k-configuration k-philosophical k-metric},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84886494195&partnerID=40&md5=b0c8ff32e95ccba5bf1a4128ff1d0627}
}

@InProceedings{Schroter2016,
  author    = {Schr{\"{o}}ter, Reimar and Krieter, Sebastian and Th{\"{u}}m, Thomas and Benduhn, Fabian and Saake, Gunter},
  title     = {Feature-model interfaces: The highway to compositional analyses of highly-configurable systems},
  booktitle = {ICSE},
  year      = {2016},
  pages     = {667--678},
  month     = {may},
  publisher = {IEEE Computer Society},
  abstract  = {Today's software systems are often customizable by means of load-time or compile-time configuration options. These options are typically not independent and their dependencies can be specified by means of feature models. As many industrial systems contain thousands of options, the maintenance and utilization of feature models is a challenge for all stakeholders. In the last two decades, numerous approaches have been presented to support stakeholders in analyzing feature models. Such analyses are commonly reduced to satis fiability problems, which suffer from the growing number of options. While first attempts have been made to decompose feature models into smaller parts, they still require to compose all parts for analysis. We propose the concept of a feature-model interface that only consists of a subset of features, typically selected by experts, and hides all other features and dependencies. Based on a formalization of feature-model interfaces, we prove compositionality properties. We evaluate feature-model interfaces using a three-month history of an industrial feature model from the automotive domain with 18,616 features. Our results indicate performance benefits especially under evolution as often only parts of the feature model need to be analyzed again.},
  doi       = {10.1145/2884781.2884823},
  isbn      = {9781450339001},
  issn      = {02705257},
  review    = {k-configuration k-modeling k-evaluation},
}

@InProceedings{She2011461,
	Title = {Reverse engineering feature models},
	Author = {She, S and Lotufo, R and Berger, T and Wa̧sowski, A and Czarnecki, K.a},
	Booktitle = {ICSE},
	Year = {2011},
	Note = {cited By 67},
	Pages = {461-470},
	Abstract = {Feature models describe the common and variable characteristics of a product line. Their advantages are well recognized in product line methods. Unfortunately, creating a feature model for an existing project is time-consuming and requires substantial effort from a modeler. We present procedures for reverse engineering feature models based on a crucial heuristic for identifying parents - the major challenge of this task. We also automatically recover constructs such as feature groups, mandatory features, and implies/excludes edges. We evaluate the technique on two large-scale software product lines with existing reference feature models - the Linux and eCos kernels - and FreeBSD, a project without a feature model. Our heuristic is effective across all three projects by ranking the correct parent among the top results for a vast majority of features. The procedures effectively reduce the information a modeler has to consider from thousands of choices to typically five or less. {\copyright} 2011 ACM.},
	Affiliation = {University of Waterloo, Waterloo, ON, Canada; University of Leipzig, Leipzig, Germany; IT University of Copenhagen, Copenhagen, Denmark},
	Author_keywords = {feature models; feature similarity; variability modeling},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79959904833&partnerID=40&md5=df5e8df2f3e897681ef99a78546b1159},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/1985793.1985856},
	Date-modified = {2015-06-12 14:43:46 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1145/1985793.1985856},
	Journal = {ICSE},
	Review = {k-reverse k-method k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79959904833&partnerID=40&md5=df5e8df2f3e897681ef99a78546b1159}
}

@InProceedings{siegmund2012predicting,
	Title = {Predicting performance via automated feature-interaction detection},
	Author = {Siegmund, Norbert and Kolesnikov, Sergiy S and K{\"a}stner, Christian and Apel, Sven and Batory, Don and Rosenm{\"u}ller, Marko and Saake, Gunter},
	Booktitle = {ICSE},
	Year = {2012},
	Organization = {IEEE Press},
	Pages = {167--177},
	Date-modified = {2015-06-12 14:36:16 +0000},
	Review = {k-metric k-configuration k-evaluation}
}

@InProceedings{VonRheinGrebhahnApelEtAl2015,
	Title = {Presence-condition simplification in highly configurable systems},
	Author = {Von Rhein, A and Grebhahn, A and Apel, S and Siegmund, N and Beyer, D and Berger, T.b},
	Booktitle = {ICSE},
	Year = {2015},
	Note = {cited By 1},
	Pages = {178-188},
	Volume = {1},
	Abstract = {For the analysis of highly configurable systems, analysis approaches need to take the inherent variability of these systems into account. The notion of presence conditions is central to such approaches. A presence condition specifies a subset of system configurations in which a certain artifact or a concern of interest is present (e.g., a defect associated with this subset). In this paper, we introduce and analyze the problem of presence-condition simplification. A key observation is that presence conditions often contain redundant information, which can be safely removed in the interest of simplicity and efficiency. We present a formalization of the problem, discuss application scenarios, compare different algorithms for solving the problem, and empirically evaluate the algorithms by means of a set of substantial case studies. {\copyright} 2015 IEEE.},
	Affiliation = {University of Passau, Passau, Germany; University of Waterloo, Canada},
	Art_number = {7194572},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84939514440&partnerID=40&md5=f2974707281c750efe123aec366f79e1},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/ICSE.2015.39},
	Document_type = {Conference Paper},
	Doi = {10.1109/ICSE.2015.39},
	Review = {k-evaluation k-testing k-configuration k-method},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84939514440&partnerID=40&md5=f2974707281c750efe123aec366f79e1}
}

@InProceedings{abele2010cvm,
	Title = {The CVM Framework-A Prototype Tool for Compositional Variability Management.},
	Author = {Abele, Andreas and Papadopoulos, Yiannis and Servat, David and T{\"o}rngren, Martin and Weber, Matthias},
	Booktitle = {VAMOS},
	Year = {2010},
	Pages = {101--105},
	Volume = {10},
	Date-modified = {2015-06-12 14:48:06 +0000},
	Journal = {VaMoS},
	Review = {k-tool k-mmodel k-evaluation}
}

@InProceedings{acher2013support,
	Title = {Support for reverse engineering and maintaining feature models},
	Author = {Acher, Mathieu and Baudry, Benoit and Heymans, Patrick and Cleve, Anthony and Hainaut, Jean-Luc},
	Booktitle = {VAMOS},
	Year = {2013},
	Organization = {ACM},
	Pages = {20},
	Abstract = {Feature Models (FMs) are a popular formalism for modelling and reasoning about commonality and variability of a system. In essence, FMs aim to define a set of valid combinations of features, also called configurations. In this paper, we tackle the problem of synthesising an FM from a set of configurations. The main challenge is that numerous candidate FMs can be extracted from the same input configurations, yet only a few of them are meaningful and maintainable. We first characterise the different meanings of FMs and identify the key properties allowing to discriminate between them. We then develop a generic synthesis procedure capable of restituting the intended meanings of FMs based on inferred or user-specified knowledge. Using k-tool support, we show how the integration of knowledge into FM synthesis can be realized in different practical application scenarios that involve reverse engineering and maintaining FMs.},
	Date-modified = {2015-06-12 14:58:37 +0000},
	Review = {k-mmodel k-validation k-tool k-reverse}
}

@InProceedings{Acher201245,
	Title = {On extracting feature models from product descriptions},
	Author = {Acher, M and Cleve, A and Perrouin, G and Heymans, P and Vanbeneden, C and Collet, P and Lahire, P.c},
	Booktitle = {VAMOS},
	Year = {2012},
	Note = {cited By 3},
	Pages = {45-54},
	Abstract = {In product line engineering, domain analysis is the process of analyzing related products to identify their common and variable features. This process is generally carried out by experts on the basis of existing product descriptions, which are expressed in a more or less structured way. Modeling and reasoning about product descriptions are error-prone and time consuming tasks. Feature models (FMs) constitute popular means to specify product commonalities and variabilities in a compact way, and to provide automated support to the domain analysis process. This paper aims at easing the transition from product descriptions expressed in a tabular format to FMs accurately representing them. This process is parameterized through a dedicated language and high-level directives (e.g., products/features scoping). We guarantee that the resulting FM represents the set of legal feature combinations supported by the considered products and has a readable tree hierarchy together with variability information. We report on our experiments based on public data and characterize the properties of the derived FMs. Copyright 2012 ACM.},
	Affiliation = {PReCISE Research Centre, Faculty of Computer Science, University of Namur, Belgium; INRIA Lille-Nord Europe, Universit{\'e} Lille 1, CNRS, France; University of Nice Sophia Antipolis, I3S Laboratory (CNRS UMR 6070), France},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84857592542&partnerID=40&md5=92f597c86a4b8d299de188d7205ef837},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/2110147.2110153},
	Date-modified = {2015-06-12 14:49:54 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1145/2110147.2110153},
	Journal = {vamos},
	Review = {k-reverse k-validation k-method},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84857592542&partnerID=40&md5=92f597c86a4b8d299de188d7205ef837}
}

@InProceedings{AcherColletLahireEtAl2011g,
	Title = {Managing feature models with familiar: A demonstration of the language and its tool support},
	Author = {Acher, M and Collet, P and Lahire, P and France, R.B.b},
	Booktitle = {VAMOS},
	Year = {2011},
	Note = {cited By 1},
	Pages = {91-96},
	Abstract = {Developing software product lines involves modeling a large number of features, usually using feature models, that represent different viewpoints, sub-systems or concerns of the software system. To manage complexity on a large scale, there is a need to separate, relate and compose several feature models while automating the reasoning on their compositions. This demonstration gives an overview of a Domain-Specific Language, familiar, that is dedicated to the management of feature models. Its comprehensive programming environment, based on Eclipse, is also described. It complements existing tool support (i.e., FeatureIDE). Copyright 2011 ACM.},
	Affiliation = {University of Nice Sophia Antipolis, I3S Laboratory, CNRS UMR 6070, France; Computer Science Department, Colorado State University, United States},
	Author_keywords = {Domain-specific language; Feature models; Product lines},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-79952823634&partnerID=40&md5=233c9740c702a3d9d72277a5f2927365},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/1944892.1944903},
	Document_type = {Conference Paper},
	Doi = {10.1145/1944892.1944903},
	Review = {k-tool k-solution k-evaluation},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-79952823634&partnerID=40&md5=233c9740c702a3d9d72277a5f2927365}
}

@InProceedings{Bezerra2016,
  author    = {Bezerra, Carla I M and Monteiro, Jos{\'{e}} Maria and Andrade, Rossana M C and Rocha, Lincoln S.},
  title     = {Analyzing the feature models maintainability over their evolution process: An exploratory study},
  booktitle = {VAMOS},
  year      = {2016},
  pages     = {17--24},
  month     = {jan},
  publisher = {Association for Computing Machinery},
  abstract  = {The feature model is one of the most important artifact of a Software Product Line (SPL). It is built in the early stages of SPL development and describes the main features and relationships. The feature model evolves according to the evolution of the SPL. Thus, it is important to build maintainable feature models. In this scenario, measures have been proven useful in the maintainability evaluation of the feature models. This paper presents an exploratory study on the impact of feature models maintainability over the SPL evolution process. In order to support this analysis, we built a dataset containing a compiled set of 21 maintainability structural measures extracted from 16 feature models and respective versions. Although not conclusive, our findings indicate that the feature models maintainability tends to decrease as it evolves. We also identified the most common changes performed in a feature model during its evolution process.},
  doi       = {10.1145/2866614.2866617},
  isbn      = {9781450340199},
  review    = {k-testing k-evaluation},
}

@InProceedings{BoucherPerrouinHeymans2012b,
	Title = {Deriving configuration interfaces from feature models: A vision paper},
	Author = {Boucher, Q and Perrouin, G and Heymans, P b},
	Booktitle = {VAMOS},
	Year = {2012},
	Note = {cited By 1},
	Pages = {37-44},
	Abstract = {In software product lines, feature models are the de-facto standard for representing variability as well as for configuring products. Yet, configuration relying on feature models faces two issues: i) it assumes knowledge of the underlying formalism, which may not be true for end users and ii) it does not take advantage of advanced user-interface controls, leading to usability and integration problems with other parts of the user interface. To address these issues, our research focuses on the generation of configuration interfaces based on variability models, both from the visual and behavioral perspectives. We tackle visual issues by generating abstract user-interfaces from feature models. Regarding configuration behavior, in particular the configuration sequence, we plan to use feature configuration workows, variability-aware models that exhibit similar characteristics as of task, user, discourse and business models found in the in the human-computer interaction community. This paper discusses the main challenges and possible solutions to realize our vision. Copyright 2012 ACM.},
	Affiliation = {PReCISE Research Centre, Faculty of Computer Science, University of Namur, Belgium; INRIA Lille-Nord Europe, Universit{\'e} Lille 1, CNRS, France},
	Author_keywords = {Configuration interfaces; Feature configuration workows; Software product lines},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84857587812&partnerID=40&md5=fbaffe38f1b7fa02cf67f7511cc87cd9},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/2110147.2110152},
	Document_type = {Conference Paper},
	Doi = {10.1145/2110147.2110152},
	Review = {k-opinion k-configuration},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84857587812&partnerID=40&md5=fbaffe38f1b7fa02cf67f7511cc87cd9}
}

@InProceedings{CordyClassenSchobbensEtAl2012,
	author = {Cordy, Maxime and Classen, Andreas and Schobbens, Pierre-Yves and Heymans, Patrick and Legay, Axel},
	title = {Managing evolution in software product lines: A model-checking perspective},
	booktitle = {VAMOS},
	year = {2012},
	pages = {183--191},
	organization = {ACM},
	review = {k-testing k-modeling k-method}
}

@InProceedings{CzarneckiGruenbacherRabiserEtAl2012b,
	Title = {Cool features and tough decisions: a comparison of variability modeling approaches},
	Author = {Czarnecki, Krzysztof and Gr{\"u}nbacher, Paul and Rabiser, Rick and Schmid, Klaus and W{\k{a}}sowski, Andrzej},
	Booktitle = {VAMOS},
	Year = {2012},
	Note = {cited By 14},
	Organization = {ACM},
	Pages = {173--182},
	Abstract = {Variability modeling is essential for defining and managing the commonalities and variabilities in software product lines. Numerous variability modeling approaches exist today to support domain and application engineering activities. Most are based on feature modeling (FM) or decision modeling (DM), but so far no systematic comparison exists between these two classes of approaches. Over the last two decades many new features have been added to both FM and DM and it is tough to decide which approach to use for what purpose. This paper clarifies the relation between FM and DM. We aim to systematize the research field of variability modeling and to explore potential synergies. We compare multiple aspects of FM and DM ranging from historical origins and rationale, through syntactic and semantic richness, to tool support, identifying commonalities and differences. We hope that this effort will improve the understanding of the range of approaches to variability modeling by discussing the possible variations. This will provide insights to users considering adopting variability modeling in practice and to designers of new languages, such as the new OMG Common Variability Language. Copyright 2012 ACM.},
	Affiliation = {University of Waterloo, Canada; Johannes Kepler University, Linz, Austria; CD Lab for Autom. Softw. Eng., JKU Linz, Austria; University of Hildesheim, Germany; IT University of Copenhagen, Denmark},
	Author_keywords = {Decision modeling; Feature modeling; Product lines; Variability modeling},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84857574303&partnerID=40&md5=f7df9b2475a1e8a72e48aec116bedc11},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/2110147.2110167},
	Document_type = {Conference Paper},
	Doi = {10.1145/2110147.2110167},
	Journal = {VAMOS},
	Review = {k-modeling k-evaluation},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84857574303&partnerID=40&md5=f7df9b2475a1e8a72e48aec116bedc11}
}

@InProceedings{DhunganaSeichterBotterweckEtAl2013,
	author = {Dhungana, Deepak and Seichter, Dominik and Botterweck, Goetz and Rabiser, Rick and Gr{\"u}nbacher, Paul and Benavides, David and Galindo, Jos{\'e} A},
	title = {Integrating heterogeneous variability modeling approaches with invar},
	booktitle = {VAMOS},
	year = {2013},
	pages = {8},
	organization = {ACM},
	review = {k-mmodel k-configuraiton k-evaluation k-method}
}

@InProceedings{DintznerVanDeursenPinzger2014,
	author = {Dintzner, Nicolas and Van Deursen, Arie and Pinzger, Martin},
	title = {Extracting feature model changes from the Linux kernel using FMDiff},
	booktitle = {VAMOS},
	year = {2014},
	pages = {22},
	organization = {ACM},
	review = {k-testing k-modeling k-validation k-vis}
}

@InProceedings{GomezRamos2010,
	Title = {Cardinality-Based Feature Modeling and Model-Driven Engineering: Fitting them Together.},
	Author = {G{\'o}mez, Abel and Ramos, Isidro},
	Booktitle = {VAMOS},
	Year = {2010},
	Pages = {61--68},
	Volume = {37},
	Abstract = {Feature models originating from Software Product Line Engineering are a well-known approach to variability modeling. In many situations, the variability does not apply only on features but also on the number of times these features can be cloned. In such a case, cardinality-based feature models are used to specify the number of clones for a given feature. Although previous works already investigated approaches for feature modeling with cardinality, there is still a lack of support for constraints in the presence of clones. To overcome this limitation, we present an abstract model to define constraints in cardinality-based feature models and propose a formal semantics for this kind of constraints. We illustrate the practical usage of our approach with examples from our recent experiences on cloud computing platform configuration.},
	Review = {k-model k-evaluation k-solution k-modeling}
}

@InProceedings{HaslingerLopezHerrejonEgyed2013c,
	author = {Haslinger, Evelyn Nicole and Lopez-Herrejon, Roberto E and Egyed, Alexander},
	title = {Using feature model knowledge to speed up the generation of covering arrays},
	booktitle = {VAMOS},
	year = {2013},
	pages = {16},
	organization = {ACM},
	abstract = {Combinatorial Interaction Testing has shown great potential for effectively testing Software Product Lines (SPLs). An important part of this type of testing is determining a subset of SPL products in which interaction errors are more likely to occur. Such sets of products are obtained by computing a so called t-wise Covering Array (tCA), whose computation is known to be NP-complete. Recently, the ICPL algorithm has been proposed to compute these covering arrays. In this research-in-progress paper, we propose a set of rules that exploit basic feature model knowledge to reduce the number of elements (i.e. t-sets) required by ICPL without weakening the strength of the generated arrays. We carried out a comparison of runtime performance that shows a significant reduction of the needed execution time for the majority of our SPL case studies.},
	review = {k-testing k-evaluation}
}

@InProceedings{Kang2010,
  author    = {Kang},
  title     = {FODA: Twenty Years of Perspective on Feature Modeling.},
  booktitle = {VAMOS},
  year      = {2010},
  review    = {k-opinion k-mmodel k-configuration k-testing k-modeling k-reverse},
}

@InProceedings{KolesnikovApelSiegmundEtAl2013,
	author = {Kolesnikov, Sergiy S and Apel, Sven and Siegmund, Norbert and Sobernig, Stefan and K{\"a}stner, Christian and Senkaya, Semah},
	title = {Predicting quality attributes of software product lines using software and network measures and sampling},
	booktitle = {VAMOS},
	year = {2013},
	pages = {6},
	organization = {ACM},
	abstract = {Software product-line engineering aims at developing families
		of related products that share common assets to provide
		customers with tailor-made products. Customers are
		often interested not only in particular functionalities (i.e.,
		features), but also in non-functional quality attributes, such
		as performance, reliability, and footprint. Measuring quality
		attributes of all products of a product line usually does not
		scale. In this research-in-progress report, we propose a systematic
		approach aiming at efficient and scalable prediction
		of quality attributes of products. To this end, we establish
		predictors for certain categories of quality attributes (e.g., a
		predictor for high memory consumption) based on software
		and network measures, and receiver operating characteristic
		analysis. We use these predictors to guide a sampling
		process that takes the assets of a product line as input and
		determines the products that fall into the category denoted
		by the given predictor (e.g., products with high memory
		consumption). We propose to use predictors to make the
		process of finding “acceptable�? products more efficient. We
		discuss and compare several strategies to incorporate predictors
		in the sampling process.},
	review = {k-solution k-reverse k-method}
}

@InProceedings{LopezHerrejonEgyed2012,
	author = {Lopez-Herrejon, Roberto E and Egyed, Alexander},
	title = {Towards fixing inconsistencies in models with variability},
	booktitle = {VAMOS},
	year = {2012},
	pages = {93--100},
	organization = {ACM},
	review = {k-testing k-method k-solution}
}

@InProceedings{mazo2011using,
	Title = {Using constraint programming to verify DOPLER variability models},
	Author = {Mazo, Raul and Gr{\"u}nbacher, Paul and Heider, Wolfgang and Rabiser, Rick and Salinesi, Camille and Diaz, Daniel},
	Booktitle = {VAMOS},
	Year = {2011},
	Organization = {ACM},
	Pages = {97--103},
	Abstract = {Software product lines are typically developed using model-based approaches. Models are used to guide and automate key activities such as the derivation of products. The verification of product line models is thus essential to ensure the consistency of the derived products. While many authors have proposed approaches for verifying feature models there is so far no such approach for decision models. We discuss challenges of analyzing and verifying decision-oriented DOPLER variability models. The manual verification of these models is an error-prone, tedious, and sometimes infeasible task. We present a preliminary approach that converts DOPLER variability models into constraint programs to support their verification. We assess the feasibility of our approach by identifying defects in two existing variability models.},
	Date-modified = {2015-06-12 14:34:24 +0000},
	Review = {k-testing k-rmodel k-evaluation}
}

@InProceedings{merschen2011experiences,
	Title = {Experiences of applying model-based analysis to support the development of automotive software product lines},
	Author = {Merschen, Daniel and Polzer, Andreas and Botterweck, Goetz and Kowalewski, Stefan},
	Booktitle = {VAMOS},
	Year = {2011},
	Organization = {ACM},
	Pages = {141--150},
	Abstract = {In embedded systems in general and in automotive systems in particular the systematic reuse of existing assets is crucial. Moreover, companies in these domains often offer whole families of similar products. Hence, the application of product line engineering seems to be an obvious option.
		However, current products have reached a complexity level where management of products within a product line cannot be handled with current techniques and tools (e.g. Matlab/Simulink) alone. To sustain an efficient engineering process and to reach the required quality levels of the products, additional techniques are required.
		In this paper we report on a prototypical framework for the analysis of embedded systems product lines. The techniques and tools offered by the framework were developed to support engineers in typical tasks, which occur during design, implementation, and maintenance of embedded software product lines. The techniques allow to analyse product line artefacts by transforming them into models, which are then used in an analysis process based on model transformation languages.},
	Date-modified = {2015-06-12 14:34:47 +0000},
	Review = {k-evaluation k-tool k-configuration}
}

@InProceedings{michel2011formal,
	Title = {A formal semantics for feature cardinalities in feature diagrams},
	Author = {Michel, Raphael and Classen, Andreas and Hubaux, Arnaud and Boucher, Quentin},
	Booktitle = {VAMOS},
	Year = {2011},
	Organization = {ACM},
	Pages = {82--89},
	Abstract = {Feature cardinalities in feature diagrams determine the number of times a feature and its subtree can be duplicated during configuration by an operation named "cloning". Other authors already investigated the problem and published different proposals of semantics for this construct. However, this previous work is not easily amenable to the formal study of the various properties of feature diagrams and their derived configurations. Also, cross-tree constraint languages still need to be properly extended to account for feature cardinalities. This paper presents an extension of an earlier formal semantics of feature diagrams by adding support for feature cardinalities.},
	Date-modified = {2015-06-12 14:34:56 +0000},
	Review = {k-modeling k-rmodel k-philosophical}
}

@InProceedings{oster2011moso,
	Title = {MoSo-PoLiTe: tool support for pairwise and model-based software product line testing},
	Author = {Oster, Sebastian and Zorcic, Ivan and Markert, Florian and Lochau, Malte},
	Booktitle = {VAMOS},
	Year = {2011},
	Organization = {ACM},
	Pages = {79--82},
	Abstract = {Testing Software Product Lines is a very challenging task and approaches like combinatorial testing and model-based testing are frequently used to reduce the effort of testing Software Product Lines and to reuse test artifacts. In this contribution we present a tool chain realizing our MoSo-PoLiTe concept combining combinatorial and model-based testing. Our tool chain contains a pairwise configuration selection component on the basis of a feature model. This component implements an heuristic finding a minimal subset of configurations covering 100% pairwise interaction. Additionally, our tool chain allows the model-based test case generation for each configuration within this generated subset. This tool chain is based on commercial tools since it was developed within industrial cooperations. A non-commercial implementation of pairwise configuration selection is available and an integration with an Open Source model-based testing tool is under development.},
	Date-modified = {2015-06-12 14:35:31 +0000},
	Review = {k-tool k-testing k-validation}
}

@InProceedings{passos2013feature,
	Title = {Feature-oriented software evolution},
	Author = {Passos, Leonardo and Czarnecki, Krzysztof and Apel, Sven and W{\k{a}}sowski, Andrzej and K{\"a}stner, Christian and Guo, Jianmei},
	Booktitle = {VAMOS},
	Year = {2013},
	Organization = {ACM},
	Pages = {17},
	Abstract = {In this paper, we develop a vision of software evolution based on a feature-oriented perspective. From the fact that features provide a common ground to all stakeholders, we derive a hypothesis that changes can be effectively managed in a feature-oriented manner. Assuming that the hypothesis holds, we argue that feature-oriented software evolution relying on automatic traceability, analyses, and recommendations reduces existing challenges in understanding and managing evolution. We illustrate these ideas using an automotive example and raise research questions for the community. © 2013 ACM.},
	Date-modified = {2015-06-12 14:35:43 +0000},
	Review = {k-testing k-opinion k-method}
}

@InProceedings{pleuss2010integrating,
	Title = {Integrating automated product derivation and individual user interface design},
	Author = {Pleuss, Andreas and Botterweck, Goetz and Dhungana, Deepak},
	Booktitle = {VAMOS},
	Year = {2010},
	Abstract = {Software Product Lines, in conjunction with modeldriven product derivation, are successful examples for extensive automation and reuse in software development. However, often each single product requires an individual, tailored user interface of its own to achieve the desired usability. Moreover, in some cases (e.g., online shops, games) it is even mandatory that each product has an individual, unique user interface of its own. Usually, this results in manual user interface design independent from the model-driven product derivation. Consequently, each product configuration has to be mapped manually to a corresponding user interface which can become a tedious and error-prone task for large and complex product lines. This paper addresses this problem by integrating concepts from SPL product derivation and Model-based User Interface Development. This facilitates both (1) a systematic and semi-automated creation of user interfaces during product derivation while (2) still supporting for individual, creative design.},
	Date-modified = {2015-06-12 14:45:45 +0000},
	Journal = {Vamos},
	Review = {k-configuration k-solution k-method}
}

@InProceedings{Rosenmuller2011,
  author    = {Rosenm{\"{u}}ller, Marko and Siegmund, Norbert and Th{\"{u}}m, Thomas and Saake, Gunter},
  title     = {Multi-dimensional variability modeling},
  booktitle = {VAMOS},
  year      = {2011},
  pages     = {11--20},
  abstract  = {The variability of a software product line (SPL) is often described with a feature model. To avoid highly complex models, stakeholders usually try to separate different variability dimensions, such as domain variability and implementation variability. This results in distinct variability models, which are easier to handle than one large model. On the other hand, it is sometimes required to analyze the variability dimensions of an SPL in combination using a single model only. To combine separate modeling and integrated analysis of variability, we present Velvet, a language for multi-dimensional variability modeling. Velvet allows stakeholders to model each variability dimension of an SPL separately and to compose the separated dimensions on demand. This improves reuse of feature models and supports independent modeling variability dimensions. Furthermore, Velvet integrates feature modeling and configuration in a single language. The combination of both concepts creates further reuse opportunities and allows stakeholders to independently configure variability dimensions. Copyright 2011 ACM.},
  doi       = {10.1145/1944892.1944894},
  isbn      = {9781450305709},
  review    = {k-mmodel k-configuration k-modeling k-solution},
}

@InProceedings{SanchezSeguraRuizCortes2014c,
	author = {S{\'a}nchez, Ana B and Segura, Sergio and Ruiz-Cort{\'e}s, Antonio},
	title = {The drupal framework: A case study to evaluate variability testing techniques},
	booktitle = {VAMOS},
	year = {2014},
	pages = {11},
	organization = {ACM},
	review = {k-vis k-testing k-validation k-method}
}

@InProceedings{schaefer2010variability,
	Title = {Variability Modelling for Model-Driven Development of Software Product Lines.},
	Author = {Schaefer, Ina},
	Booktitle = {VAMOS},
	Year = {2010},
	Pages = {85--92},
	Volume = {10},
	Abstract = {Model-driven development of software-intensive systems aims at designing systems by stepwise model re- finement. In order to create software product lines by model-driven development, product variability has to be represented on every modelling level and preserved under model refinement. In this paper, we propose ∆-modelling as an generally applicable variability modelling concept that is orthogonal to model refinement. Products on each modelling level are represented by a core model and a set of ∆- models specifying changes to the core to incorporate product features. Core and ∆-models can be refined independently to obtain a more detailed model of the product line. Based on a formalization of ∆-modelling, we establish conditions that model refinement and model configuration commute resulting in an incremental model-driven development process},
	Date-modified = {2015-06-12 14:44:39 +0000},
	Journal = {VaMoS},
	Review = {k-process k-modeling k-solution}
}

@InProceedings{Schmid2011119,
	Title = {A comparison of decision modeling approaches in product lines},
	Author = {Schmid, K and Rabiser, R and Gr{\"u}nbacher, P.c},
	Booktitle = {VAMOS},
	Year = {2011},
	Note = {cited By 7},
	Pages = {119-126},
	Abstract = {It has been shown that product line engineering can significantly improve the productivity, quality and time-to-market of software development by leveraging extensive reuse. Variability models are currently the most advanced approach to define, document and manage the commonalities and variabilities of reusable artifacts such as software components, requirements, test cases, etc. These models provide the basis for automating the derivation of new products and are thus the key artifact to leverage the flexibility and adaptability of systems in a product line. Among the existing approaches to variability modeling feature modeling and decision modeling have gained most importance. A significant amount of research exists on comparing and analyzing different feature modeling approaches. However, despite their significant role in product line research and practical applications, only little effort has been devoted to compare and analyze decision modeling approaches. In order to address this shortcoming and to provide a basis for more structured research on decision modeling in the future, we present a comparative analysis of representative approaches. We identify their major modeling concepts and present an analysis of their commonalities and variabilities. Copyright 2011 ACM.},
	Affiliation = {Software Systems Engineering, University of Hildesheim, Marienburger Platz 22, 31141 Hildesheim, Germany; Christian Doppler Laboratory for Automated Software Engineering, Johannes Kepler University, Altenberger Str. 69, 4040 Linz, Austria; Systems Engineering and Automation, Johannes Kepler University, Altenberger Str. 69, 4040 Linz, Austria},
	Author_keywords = {Comparison; Decision models; Product lines; Survey; Variability modeling},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79952826790&partnerID=40&md5=a68bbb5dea519d7b1002ddf9c20b43bd},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/1944892.1944907},
	Date-modified = {2015-06-12 14:44:29 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1145/1944892.1944907},
	Journal = {Vamos},
	Review = {k-modeling k-method k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79952826790&partnerID=40&md5=a68bbb5dea519d7b1002ddf9c20b43bd}
}

@InProceedings{SchroeterThuemSiegmundEtAl2013b,
	Title = {Automated analysis of dependent feature models},
	Author = {Schr{\"o}ter, Reimar and Th{\"u}m, Thomas and Siegmund, Norbert and Saake, Gunter},
	Booktitle = {VAMOS},
	Year = {2013},
	Organization = {ACM},
	Pages = {9},
	Abstract = {Feature models specify valid combinations of features in software
		product lines. With dependent feature models (DFMs),
		we apply separation of concerns to feature models for two
		main benefits. First, we can modularize feature models into
		parts relevant to groups of stakeholders. Second, we are able
		to model dependencies between different software product
		lines in a multi-product-line scenario. To ensure consistency
		and correctness of DFMs, we have to apply analyses, such
		as dead-feature detection. We discuss why DFMs challenge
		the detection of inconsistencies, present how to reuse existing
		analyses for DFMs, and propose new analyses to supplement
		existing ones. We apply automated analyses in five
		steps and evaluate the approach using DFMs specified in
		VELVET by our prototype VeAnalyzer},
	Review = {k-mmodel k-configuration k-testing k-evaluation}
}

@InProceedings{segura2012betty,
	Title = {BeTTy: benchmarking and testing on the automated analysis of feature models},
	Author = {Segura, Sergio and Galindo, Jos{\'e} A and Benavides, David and Parejo, Jos{\'e} A and Ruiz-Cort{\'e}s, Antonio},
	Booktitle = {VAMOS},
	Year = {2012},
	Organization = {ACM},
	Pages = {63--71},
	Date-modified = {2015-06-12 14:35:59 +0000},
	Review = {k-testing k-tool k-evaluation}
}

@InProceedings{SeidlSchaeferAssmann2014,
	Title = {Capturing variability in space and time with hyper feature models},
	Author = {Seidl, Christoph and Schaefer, Ina and Assmann, Uwe},
	Booktitle = {VAMOS},
	Year = {2014},
	Organization = {ACM},
	Pages = {6},
	Review = {k-modeling k-model k-evaluation}
}

@InProceedings{she2010variability,
	Title = {The Variability Model of The Linux Kernel.},
	Author = {She, Steven and Lotufo, Rafael and Berger, Thorsten and Wasowski, Andrzej and Czarnecki, Krzysztof},
	Booktitle = {VAMOS},
	Year = {2010},
	Pages = {45--51},
	Volume = {10},
	Date-modified = {2015-06-12 14:44:03 +0000},
	Journal = {VaMoS},
	Review = {k-vis k-modeling k-metric k-validation}
}

@InProceedings{von2013pla,
	Title = {The PLA model: on the combination of product-line analyses},
	Author = {Von Rhein, Alexander and Apel, Sven and K{\"a}stner, Christian and Th{\"u}m, Thomas and Schaefer, Ina},
	Booktitle = {VAMOS},
	Year = {2013},
	Organization = {ACM},
	Pages = {14},
	Abstract = {Product-line analysis has received considerable attention in the last decade. As it is often infeasible to analyze each product of a product line individually, researchers have developed analyses, called variability-aware analyses, that consider and exploit variability manifested in a code base. Variabilityaware analyses are often significantly more efficient than traditional analyses, but each of them has certain weaknesses regarding applicability or scalability. We present the Product-Line-Analysis model, a formal model for the classi- fication and comparison of existing analyses, including traditional and variability-aware analyses, and lay a foundation for formulating and exploring further, combined analyses. As a proof of concept, we discuss different examples of analyses in the light of our model, and demonstrate its benefits for systematic comparison and exploration of product-line analyses.},
	Date-modified = {2015-06-12 14:36:38 +0000},
	Review = {k-rmodel k-evaluation k-configuration}
}

@InProceedings{Wulf-Hadash2013,
  author    = {Wulf-Hadash, Ora and Reinhartz-Berger, Iris},
  title     = {Cross product line analysis},
  booktitle = {VAMOS},
  year      = {2013},
  abstract  = {Due to increase in market competition and merger and acquisition of companies, different software product lines (SPLs) may exist under the same roof. These SPLs may be developed applying different domain analysis processes, but are likely not disjoint. Cross product line analysis aims to examine the common and variable aspects of different SPLs for improving maintenance and future development of related SPLs. Currently different SPL artifacts, or more accurately feature models, are compared, matched, and merged for supporting scalability, increasing modularity and reuse, synchronizing feature model versions, and modeling multiple SPLs for software supply chains. However, in all these cases the focus is on creating valid merged models from the input feature models. Furthermore, the terminology used in all the input feature models is assumed to be the same, namely similar features are named the same. As a result these methods cannot be simply applied to feature models that represent different SPLs. In this work we offer adapting similarity metrics and text clustering techniques in order to enable cross product line analysis. This way analysis of feature models that use different terminologies in the same domain can be done in order to improve the management of the involved SPLs. Preliminary results reveal that the suggested method helps systematically analyze the commonality and variability between related SPLs, potentially suggesting improvements to existing SPLs and to the maintenance of sets of SPLs. {\textcopyright} 2013 ACM.},
  doi       = {10.1145/2430502.2430531},
  isbn      = {9781450315418},
  review    = {k-mmodel k-evaluation},
}

@InProceedings{Abal2014,
  author    = {Abal, I and Brabrand, C and Wasowski, A},
  title     = {42 variability bugs in the linux kernel: a qualitative analysis},
  booktitle = {ASE},
  year      = {2014},
  journal   = {ASE '14 Proceedings of the 29th ACM/IEEE international conference on Automated software engineering},
  review    = {k-vis k-testing},
  url       = {http://dl.acm.org/citation.cfm?id=2642990},
}

@InProceedings{Acher2011424,
	Title = {Slicing feature models},
	Author = {Acher, M and Collet, P and Lahire, P and France, R.B.b},
	Booktitle = {ASE},
	Year = {2011},
	Note = {cited By 7},
	Pages = {424-427},
	Abstract = {Feature models (FMs) are a popular formalism for describing the commonality and variability of software product lines (SPLs) in terms of features. As SPL development increasingly involves numerous large FMs, scalable modular techniques are required to manage their complexity. In this paper, we present a novel slicing technique that produces a projection of an FM, including constraints. The slicing allows SPL practitioners to find semantically meaningful decompositions of FMs and has been integrated into the FAMILIAR language. {\copyright} 2011 IEEE.},
	Affiliation = {I3S - CNRS UMR 6070, Universit{\"a} Nice Sophia Antipolis, France; Computer Science Department, Colorado State University, United States},
	Art_number = {6100089},
	Author_keywords = {Feature Models; Slicing; Software Product Lines},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84855429099&partnerID=40&md5=9b9b506bee41ecca4148064cba38af5a},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/ASE.2011.6100089},
	Date-modified = {2015-06-12 14:49:33 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/ASE.2011.6100089},
	Journal = {ASE},
	Review = {k-mmodel k-solution k-tool},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84855429099&partnerID=40&md5=9b9b506bee41ecca4148064cba38af5a}
}

@InProceedings{Acher2011600,
	Title = {Decomposing feature models: Language, environment, and applications},
	Author = {Acher, M and Collet, P and Lahire, P and France, R.B.b},
	Booktitle = {ASE},
	Year = {2011},
	Note = {cited By 2},
	Pages = {600-603},
	Abstract = {Variability in software product lines is often expressed through feature models (FMs). To handle the complexity of increasingly larger FMs, we propose semantically meaningful decomposition support through a slicing operator. We describe how the slicing operator is integrated into the FAMILIAR environment and how it can be combined with other operators to support complex tasks over FMs in different case studies. {\copyright} 2011 IEEE.},
	Affiliation = {I3S - CNRS UMR 6070, Universit{\'e} Nice Sophia Antipolis, France; Computer Science Department, Colorado State University, United States},
	Art_number = {6100135},
	Author_keywords = {Feature Models; Model Composition; Separation of Concerns; Slicing; Software Product Lines},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84855454415&partnerID=40&md5=b405a52af313d75929dd05333c0f926e},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/ASE.2011.6100135},
	Date-modified = {2015-06-12 14:49:24 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/ASE.2011.6100135},
	Journal = {ASE},
	Review = {k-mmodel k-validation k-tool},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84855454415&partnerID=40&md5=b405a52af313d75929dd05333c0f926e}
}

@InProceedings{apel2011detection,
	Title = {Detection of feature interactions using feature-aware verification},
	Author = {Apel, Sven and Speidel, Hendrik and Wendler, Philipp and Von Rhein, Alexander and Beyer, Dirk},
	Booktitle = {ASE},
	Year = {2011},
	Organization = {IEEE Computer Society},
	Pages = {372--375},
	Abstract = {A software product line is a set of software products that are distinguished in terms of features (i.e., end-user-visible units of behavior). Feature interactions-- situations in which the combination of features leads to emergent and possibly critical behavior --are a major source of failures in software product lines. We explore how feature-aware verification can improve the automatic detection of feature interactions in software product lines. Feature-aware verification uses product-line-verification techniques and supports the specification of feature properties along with the features in separate and composable units. It integrates the technique of variability encoding to verify a product line without generating and checking a possibly exponential number of feature combinations. We developed the tool suite SPLVERIFIER for feature-aware verification, which is based on standard model-checking technology. We applied it to an e-mail system that incorporates domain knowledge of AT&T. We found that feature interactions can be detected automatically based on specifications that have only local knowledge.},
	Date-modified = {2015-06-12 14:58:57 +0000},
	Review = {k-evaluation k-testing k-tool}
}

@InProceedings{Berger201073,
	Title = {Variability modeling in the real: A perspective from the operating systems domain},
	Author = {Berger, T and She, S and Lotufo, R and Wa̧sowski, A and Czarnecki, K.b},
	Booktitle = {ASE},
	Year = {2010},
	Note = {cited By 49},
	Pages = {73-82},
	Abstract = {Variability models represent the common and variable features of products in a product line. Several variability modeling languages have been proposed in academia and industry; however, little is known about the practical use of such languages. We study and compare the constructs, semantics, usage and tools of two variability modeling languages, Kconfig and CDL. We provide empirical evidence for the real-world use of the concepts known from variability modeling research. Since variability models provide basis for automated tools (feature dependency checkers and product configurators), we believe that our findings will be of interest to variability modeling language and tool designers. {\copyright} 2010 ACM.},
	Affiliation = {University of Leipzig, Germany; University of Waterloo, Canada; IT University of Copenhagen, Denmark},
	Author_keywords = {Configuration; Empirical software engineering; Feature models; Product line architectures; Variability modeling},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78649773984&partnerID=40&md5=97685bd9356b508a04834177497c92d5},
	Bdsk-url-2 = {http://dx.doi.org/10.1145/1858996.1859010},
	Date-modified = {2015-06-12 14:48:33 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1145/1858996.1859010},
	Journal = {ASE},
	Review = {k-validation k-modeling k-metric},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78649773984&partnerID=40&md5=97685bd9356b508a04834177497c92d5}
}

@InProceedings{Guo2014,
  author    = {Guo, J and Zulkoski, E and Olaechea, R and Rayside, D},
  title     = {Scaling exact multi-objective combinatorial optimization by parallelization},
  booktitle = {ASE},
  year      = {2014},
  journal   = {Proc. 29th},
  review    = {k-configuration k-evaluation},
  url       = {http://dl.acm.org/citation.cfm?id=2642971},
}

@InProceedings{Pohl2011313,
	Title = {A performance comparison of contemporary algorithmic approaches for automated analysis operations on feature models},
	Author = {Pohl, R. and Lauenroth, K. and Pohl, K.},
	Booktitle = {ASE},
	Year = {2011},
	Note = {cited By 10},
	Pages = {313-322},
	Abstract = {The formalization of variability models (e.g. feature models) is a prerequisite for the automated analysis of these models. The efficient execution of the analysis operations depends on the selection of well-suited solver implementations. Regarding feature models, on the one hand, the formalization with Boolean expressions enables the use of SAT or BDD solvers. On the other hand, feature models can be transformed into a Constraint-Satisfaction Problem (CSP) in order to use CSP solvers for validation. This paper presents a performance comparison regarding nine contemporary high-performance solvers, three for each base problem structure (BDD, CSP, and SAT). Four operations on 90 feature models are run on each solver. The results will in turn clear the way for new improvements regarding the automatic verification of software product lines, since the efficient execution of analysis operations is essential to such automatic verification approaches. {\copyright} 2011 IEEE.},
	Affiliation = {Paluno - the Ruhr Institute for Software Technology, University of Duisburg-Essen, 45127 Essen, Germany},
	Art_number = {6100068},
	Author_keywords = {automated reasoning techniques; feature model; performance measurement; software product line},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84855445523&partnerID=40&md5=535e27ef00f2d7fe868f4ee683045f1e},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/ASE.2011.6100068},
	Date-modified = {2015-06-12 14:45:36 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/ASE.2011.6100068},
	Journal = {ASE},
	Review = {k-configuration k-philosophical k-method},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84855445523&partnerID=40&md5=535e27ef00f2d7fe868f4ee683045f1e}
}

@InProceedings{PohlStrickerPohl2013c,
	Title = {Measuring the structural complexity of feature models},
	Author = {Pohl, R. and Stricker, V. and Pohl, K.},
	Booktitle = {ASE},
	Year = {2013},
	Note = {cited By 4},
	Organization = {IEEE},
	Pages = {454-464},
	Abstract = {The automated analysis of feature models (FM) is based on SAT, BDD, and CSP - known NP-complete problems. Therefore, the analysis could have an exponential worst-case execution time. However, for many practical relevant analysis cases, state-of-the-art (SOTA) analysis tools quite successfully master the problem of exponential worst-case execution time based on heuristics. So far, however, very little is known about the structure of FMs that cause the cases in which the execution time (hardness) for analyzing a given FM increases unpredictably for SOTA analysis tools. In this paper, we propose to use width measures from graph theory to characterize the structural complexity of FMs as a basis for an estimation of the hardness of analysis operations on FMs with SOTA analysis tools. We present an experiment that we use to analyze the reasonability of graph width measures as metric for the structural complexity of FMs and the hardness of FM analysis. Such a complexity metric can be used as a basis for a unified method to systematically improve SOTA analysis tools. {\copyright} 2013 IEEE.},
	Affiliation = {Paluno - Ruhr Institute for Software Technology, University of Duisburg-Essen, Gerlingstr. 16, 45127 Essen, Germany},
	Art_number = {6693103},
	Author_keywords = {automated analysis; feature model; performance measurement; software product line},
	Bdsk-url-1 = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84892693494&partnerID=40&md5=ac3e8e9c251b4e227b6d7fa758c57f33},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/ASE.2013.6693103},
	Document_type = {Conference Paper},
	Doi = {10.1109/ASE.2013.6693103},
	Journal = {ASE},
	Review = {k-metric k-modeling k-evaluation},
	Source = {Scopus},
	Url = {https://www.scopus.com/inward/record.url?eid=2-s2.0-84892693494&partnerID=40&md5=ac3e8e9c251b4e227b6d7fa758c57f33}
}

@InProceedings{Sannier2013580,
	Title = {From comparison matrix to Variability Model: The Wikipedia case study},
	Author = {Sannier, N. and Acher, M. and Baudry, B.},
	Booktitle = {ASE},
	Year = {2013},
	Note = {cited By 5},
	Pages = {580-585},
	Abstract = {Product comparison matrices (PCMs) provide a convenient way to document the discriminant features of a family of related products and now abound on the internet. Despite their apparent simplicity, the information present in existing PCMs can be very heterogeneous, partial, ambiguous, hard to exploit by users who desire to choose an appropriate product. Variability Models (VMs) can be employed to formulate in a more precise way the semantics of PCMs and enable automated reasoning such as assisted configuration. Yet, the gap between PCMs and VMs should be precisely understood and automated techniques should support the transition between the two. In this paper, we propose variability patterns that describe PCMs content and conduct an empirical analysis of 300+ PCMs mined from Wikipedia. Our findings are a first step toward better engineering techniques for maintaining and configuring PCMs. {\copyright} 2013 IEEE.},
	Affiliation = {University of Rennes 1, Irisa/Inria, Campus Universitaire de Beaulieu, 35042 Rennes Cedex, France},
	Art_number = {6693116},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893556728&partnerID=40&md5=a51c53b37c394abf3b3362977ef54d9f},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/ASE.2013.6693116},
	Date-modified = {2015-06-12 14:45:25 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/ASE.2013.6693116},
	Journal = {ASE},
	Review = {k-reverse k-method k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893556728&partnerID=40&md5=a51c53b37c394abf3b3362977ef54d9f}
}

@InProceedings{Sayyad2013465,
	Title = {Scalable product line configuration: A straw to break the camel's back},
	Author = {Sayyad, A.S. and Ingram, J. and Menzies, T. and Ammar, H.},
	Booktitle = {ASE},
	Year = {2013},
	Note = {cited By 9},
	Pages = {465-474},
	Abstract = {Software product lines are hard to configure. Techniques that work for medium sized product lines fail for much larger product lines such as the Linux kernel with 6000+ features. This paper presents simple heuristics that help the Indicator-Based Evolutionary Algorithm (IBEA) in finding sound and optimum configurations of very large variability models in the presence of competing objectives. We employ a combination of static and evolutionary learning of model structure, in addition to utilizing a pre-computed solution used as a 'seed' in the midst of a randomly-generated initial population. The seed solution works like a single straw that is enough to break the camel's back -given that it is a feature-rich seed. We show promising results where we can find 30 sound solutions for configuring upward of 6000 features within 30 minutes. {\copyright} 2013 IEEE.},
	Affiliation = {Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, United States},
	Art_number = {6693104},
	Author_keywords = {automated configuration; evolutionary algorithms; multiobjective optimization; SMT solvers; Variability models},
	Bdsk-url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893626659&partnerID=40&md5=e9b2bd52b54b13d433f13407d8f0694a},
	Bdsk-url-2 = {http://dx.doi.org/10.1109/ASE.2013.6693104},
	Date-modified = {2015-06-12 14:45:08 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/ASE.2013.6693104},
	Journal = {ASE},
	Review = {k-configuration k-method k-evaluation},
	Source = {Scopus},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893626659&partnerID=40&md5=e9b2bd52b54b13d433f13407d8f0694a}
}

@InProceedings{Segura2014a,
  author    = {Segura, Sergio and S{\'{a}}nchez, Ana B. and Ruiz-Cort{\'{e}}s, Antonio},
  title     = {Automated variability analysis and testing of an e-commerce site. An experience report},
  booktitle = {ASE},
  year      = {2014},
  pages     = {139--149},
  publisher = {Association for Computing Machinery, Inc},
  abstract  = {In this paper, we report on our experience on the development of La Hilandera, an e-commerce site selling haberdashery products and craft supplies in Europe. The store has a huge input space where customers can place almost three millions of different orders which made testing an extremely difficult task. To address the challenge, we explored the applicability of some of the practices for variability management in software product lines. First, we used a feature model to represent the store input space which provided us with a variability view easy to understand, share and discuss with all the stakeholders. Second, we used techniques for the automated analysis of feature models for the detection and repair of inconsistent and missing configuration settings. Finally, we used test selection and prioritization techniques for the generation of a manageable and effective set of test cases. Our findings, summarized in a set of lessons learnt, suggest that variability techniques could successfully address many of the challenges found when developing e-commerce sites.},
  doi       = {10.1145/2642937.2642939},
  isbn      = {9781450330138},
  review    = {k-testing k-vis k-evaluation},
}

@InProceedings{Soltani2011536,
	Title = {Automated planning for feature model configuration based on stakeholders' business concerns},
	Author = {Soltani, S and Asadi, M and Hatala, M and Ga{\v s}evi{\'c}, D and Bagheri, E.b},
	Booktitle = {ASE},
	Year = {2011},
	Note = {cited By 4},
	Pages = {536-539},
	Abstract = {In Software Product Line Engineering, concrete products of a family can be generated through a configuration process over a feature model. The configuration process selects features from the feature model according to the stakeholders' requirements. Selecting the right set of features for one product from all the available features in the feature model is a cumbersome task because 1) the stakeholders may have diverse business concerns and limited resources that they can spend on a product and 2) features may have negative and positive contributions on different business concern. Many configurations techniques have been proposed to facilitate software developers' tasks through automated product derivation. However, most of the current proposals for automatic configuration are not devised to cope with business oriented requirements and stakeholders' resource limitations. We propose a framework, which employs an artificial intelligence planning technique to automatically select suitable features that satisfy the stakeholders' business concerns and resource limitations. We also provide tooling support to facilitate the use of our framework. {\copyright} 2011 IEEE.},
	Affiliation = {School of Interactive Art and Technology, Simon Fraser University, Surrey, BC, Canada; School of Computing and Information Systems, Athabasca University, Athabasca, AB, Canada},
	Art_number = {6100118},
	Author_keywords = {Artificial Intelligence; Configuration; Feature Model},
	Date-modified = {2015-06-12 14:43:12 +0000},
	Document_type = {Conference Paper},
	Doi = {10.1109/ASE.2011.6100118},
	Journal = {ASE},
	Review = {k-testing k-tool k-evaluation},
	Source = {Scopus}
}

@InProceedings{vierhauser2010flexible,
	Title = {Flexible and scalable consistency checking on product line variability models},
	Author = {Vierhauser, Michael and Gr{\"u}nbacher, Paul and Egyed, Alexander and Rabiser, Rick and Heider, Wolfgang},
	Booktitle = {ASE},
	Year = {2010},
	Organization = {ACM},
	Pages = {63--72},
	Abstract = {The complexity of product line variability models makes it hard to maintain their consistency over time regardless of the modeling approach used. Engineers thus need support for detecting and resolving inconsistencies. We describe experiences of applying a tool-supported approach for incremental consistency checking on variability models. Our approach significantly improves the overall performance and scalability compared to batch-oriented techniques and allows providing immediate feedback to modelers. It is extensible as new consistency constraints can easily be added. Furthermore, the approach is flexible as it is not limited to variability models and it also checks the consistency of the models with the underlying code base of the product line. We report the results of a thorough evaluation based on real-world product line models and discuss lessons learned.},
	Date-modified = {2015-06-12 14:36:32 +0000},
	Review = {k-configuration k-method k-solution}
}

@Comment{jabref-meta: databaseType:bibtex;}
